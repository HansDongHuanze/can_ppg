{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9eebafaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入库\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "import torchvision #加载图片\n",
    "from torchvision import transforms #图片变换\n",
    "\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    " \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt #绘图\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "from preprocess import Process\n",
    "from transformer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f369c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 26\n",
    "def get_random_seed(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "get_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a98ad843",
   "metadata": {},
   "outputs": [],
   "source": [
    "#独热编码\n",
    "def one_hot(x,class_count=10):\n",
    "    return torch.eye(class_count)[x,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64c2d341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject 13 abandoned\n",
      "subject 16 abandoned\n",
      "subject 17 abandoned\n",
      "subject 18 abandoned\n",
      "subject 20 abandoned\n",
      "subject 26 abandoned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhz/anaconda3/lib/python3.9/site-packages/scipy/interpolate/fitpack2.py:280: UserWarning: \n",
      "The maximal number of iterations maxit (set to 20 by the program)\n",
      "allowed for finding a smoothing spline with fp=s has been reached: s\n",
      "too small.\n",
      "There is an approximation returned but the corresponding weighted sum\n",
      "of squared residuals does not satisfy the condition abs(fp-s)/s < tol.\n",
      "  warnings.warn(message)\n",
      "/home/dhz/anaconda3/lib/python3.9/site-packages/numpy/ma/core.py:5244: RuntimeWarning: Mean of empty slice.\n",
      "  result = super().mean(axis=axis, dtype=dtype, **kwargs)[()]\n",
      "/home/dhz/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3723: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject 42 abandoned\n",
      "subject 47 abandoned\n",
      "subject 48 abandoned\n",
      "subject 50 abandoned\n"
     ]
    }
   ],
   "source": [
    "series = []\n",
    "items = 3\n",
    "step = 3\n",
    "subject_num = 0\n",
    "\n",
    "for num in range(2, 66):\n",
    "    try:\n",
    "        series += Process(num).prepro(1024, step, items)\n",
    "        subject_num += 1\n",
    "    except:\n",
    "        print(f'subject {num} abandoned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c6e9e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, series, items, subject_num):\n",
    "        self.series = series\n",
    "        self.codes = []\n",
    "        self.subject_num = subject_num\n",
    "        self.labels = np.zeros((len(self.series), self.subject_num), dtype='double')\n",
    "        for i in range(self.subject_num):\n",
    "            for j in range(items):\n",
    "                self.labels[i * 3 + j][i] = 1.0            \n",
    "\n",
    "    # need to overload\n",
    "    def __len__(self):\n",
    "        return len(self.series)\n",
    "\n",
    "    # need to overload\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.series[idx]), torch.tensor(self.labels[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "463a2d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset(series, items=items, subject_num=subject_num)\n",
    "dataloader = torch.utils.data.DataLoader(dataset,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0415007e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义生成器\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, subject_num):\n",
    "        super(Generator,self).__init__()\n",
    "        self.linear1 = nn.Linear(100,512)\n",
    "        self.bn1=nn.BatchNorm1d(512)\n",
    "        self.subject_num = subject_num\n",
    "        self.linear2 = nn.Linear(subject_num,512)\n",
    "        self.bn2=nn.BatchNorm1d(512)\n",
    "        \n",
    "        self.deconv1 = nn.Conv1d(1, 3, kernel_size=2, padding='same')\n",
    "        self.bn3=nn.BatchNorm1d(3)\n",
    "        self.deconv2 = nn.Conv1d(3, 6, kernel_size=2, padding='same')\n",
    "        self.bn4=nn.BatchNorm1d(6)\n",
    "        self.deconv3 = nn.Conv1d(6, 1, kernel_size=2, padding='same')\n",
    "        \n",
    "    def forward(self,x1,x2):\n",
    "        x1=F.relu(self.linear1(x1.to(torch.float64)))\n",
    "        x1=self.bn1(x1)\n",
    "        x2=F.relu(self.linear2(x2))\n",
    "        x2=self.bn2(x2)\n",
    "        x=torch.cat([x1,x2],axis=1)\n",
    "        x=F.relu(self.deconv1(torch.reshape(x, (x.size(0), 1, x.size(1)))))\n",
    "        x=self.bn3(x)\n",
    "        x=F.relu(self.deconv2(x))\n",
    "        x=self.bn4(x)\n",
    "        x=torch.tanh(self.deconv3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c55045ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义判别器\n",
    "#输入：1，28，28图片和长度为10的condition\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, subject_num):\n",
    "        super(Discriminator,self).__init__()\n",
    "        self.subject_num = subject_num\n",
    "        self.linear = nn.Linear(self.subject_num,1024)\n",
    "        self.conv1 = nn.Conv1d(1,32,kernel_size=2,padding='same')\n",
    "        self.conv2 = nn.Conv1d(32,128,kernel_size=2,padding='same')\n",
    "        self.bn = nn.BatchNorm1d(128)\n",
    "        self.fc = nn.Linear(2048,1)\n",
    "    def forward(self,x1,x2): #x1代表label,x2代表image\n",
    "        x1=F.leaky_relu(self.linear(x1))\n",
    "        x=torch.cat([x1,x2],axis=1)            \n",
    "        x= F.dropout1d(F.leaky_relu(self.conv1(torch.reshape(x, (x.size(0), 1, x.size(1))))))\n",
    "        x= F.dropout1d(F.leaky_relu(self.conv2(x)))\n",
    "        x = self.bn(x)\n",
    "        x = torch.sigmoid(self.fc(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b06c0a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContinuityLoss(nn.Module):\n",
    "    def __init__(self, weight=1.0):\n",
    "        super(ContinuityLoss, self).__init__()\n",
    "        self.weight = weight\n",
    "        \n",
    "    def forward(self, predictions):\n",
    "        diff = predictions[:][1:] - predictions[:][:-1]\n",
    "        loss = torch.mean(torch.abs(diff))\n",
    "        return loss * self.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e672af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapeLoss(nn.Module):\n",
    "    def __init__(self, weight=1.0):\n",
    "        super(ShapeLoss, self).__init__()\n",
    "        self.weight = weight\n",
    "        \n",
    "    def forward(self, predictions, labels):\n",
    "        loss = torch.mean(torch.abs(predictions - labels))\n",
    "        return loss * self.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55bc25ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxValueLoss(nn.Module):\n",
    "    def __init__(self, weight=1.0):\n",
    "        super(MaxValueLoss, self).__init__()\n",
    "        self.weight = weight\n",
    "        self.MCE = nn.CrossEntropyLoss()\n",
    "    def forward(self, input1):\n",
    "        input2 = torch.zeros_like(input1)\n",
    "        types = torch.argmax(input1, dim = 0, keepdim=False)\n",
    "        for i in range(input1.size(0)):\n",
    "            input2[i][types[i]] = 1\n",
    "        loss = self.MCE(input1, input2)\n",
    "        return loss * self.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86bdfd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassLoss(nn.Module):\n",
    "    def __init__(self, weight=1.0):\n",
    "        super(ClassLoss, self).__init__()\n",
    "        self.weight = weight\n",
    "    def forward(self, input1, input2):\n",
    "        diff = input1 - input2\n",
    "        loss = torch.mean(torch.abs(diff))\n",
    "        return loss * self.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64a75c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassLoss(nn.Module):\n",
    "    def __init__(self, weight=1.0):\n",
    "        super(ClassLoss, self).__init__()\n",
    "        self.weight = weight\n",
    "        self.MCE = nn.CrossEntropyLoss()\n",
    "    def forward(self, input1, input2):\n",
    "        loss = self.MCE(input1, input2)\n",
    "        return loss * self.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be96d7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#设备的配置\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#初化生成器和判别器把他们放到相应的设备上\n",
    "gen = Generator(subject_num).to(device)\n",
    "gen = gen.double()\n",
    "dis = Discriminator(subject_num).to(device)\n",
    "dis = dis.double()\n",
    "cls = torch.load(\"classification\").to(device)\n",
    "cls = cls.double()\n",
    "#交叉熵损失函数\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "continue_loss_weight = 0.8\n",
    "continue_loss = ShapeLoss(weight=continue_loss_weight)\n",
    "class_loss_weight = 0.2\n",
    "class_loss = ClassLoss(weight=class_loss_weight)\n",
    "#训练器的优化器\n",
    "discriminator_rate = 1e-5\n",
    "generator_rate = 1e-4\n",
    "d_optimizer = torch.optim.Adam(dis.parameters(),lr=discriminator_rate)\n",
    "#训练生成器的优化器\n",
    "g_optimizer = torch.optim.Adam(gen.parameters(),lr=generator_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3004abc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#设置生成绘图图片的随机张量，这里可视化16张图片\n",
    "#生成16个长度为100的随机正态分布张量\n",
    "noise_seed = torch.randn(16,100,device=device)\n",
    "label_seed = torch.randint(0,subject_num,size=(16,))\n",
    "label_seed_onehot = one_hot(label_seed, class_count=subject_num).to(device)\n",
    " \n",
    "D_loss = [] #记录训练过程中判别器的损失\n",
    "G_loss = [] #记录训练过程中生成器的损失\n",
    "S_loss = []\n",
    "C_loss = []\n",
    "accs = []\n",
    "epoch_num = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dc5c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhz/anaconda3/lib/python3.9/site-packages/torch/nn/modules/conv.py:309: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:895.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/4000], Discriminator Loss: 0.0963, Generator Loss: 0.1354, Series Loss: 0.0404, Class Loss: 0.2715, Accuracy: 0.1358\n",
      "Epoch [2/4000], Discriminator Loss: 0.0960, Generator Loss: 0.1346, Series Loss: 0.0399, Class Loss: 0.2713, Accuracy: 0.1481\n",
      "Epoch [3/4000], Discriminator Loss: 0.0957, Generator Loss: 0.1339, Series Loss: 0.0394, Class Loss: 0.2709, Accuracy: 0.1420\n",
      "Epoch [4/4000], Discriminator Loss: 0.0957, Generator Loss: 0.1335, Series Loss: 0.0390, Class Loss: 0.2708, Accuracy: 0.1481\n",
      "Epoch [5/4000], Discriminator Loss: 0.0953, Generator Loss: 0.1329, Series Loss: 0.0386, Class Loss: 0.2706, Accuracy: 0.2037\n",
      "Epoch [6/4000], Discriminator Loss: 0.0953, Generator Loss: 0.1324, Series Loss: 0.0382, Class Loss: 0.2706, Accuracy: 0.2284\n",
      "Epoch [7/4000], Discriminator Loss: 0.0952, Generator Loss: 0.1320, Series Loss: 0.0378, Class Loss: 0.2702, Accuracy: 0.2037\n",
      "Epoch [8/4000], Discriminator Loss: 0.0946, Generator Loss: 0.1316, Series Loss: 0.0375, Class Loss: 0.2701, Accuracy: 0.2531\n",
      "Epoch [9/4000], Discriminator Loss: 0.0946, Generator Loss: 0.1315, Series Loss: 0.0371, Class Loss: 0.2703, Accuracy: 0.2407\n",
      "Epoch [10/4000], Discriminator Loss: 0.0946, Generator Loss: 0.1311, Series Loss: 0.0368, Class Loss: 0.2698, Accuracy: 0.2778\n",
      "Epoch [11/4000], Discriminator Loss: 0.0944, Generator Loss: 0.1309, Series Loss: 0.0366, Class Loss: 0.2698, Accuracy: 0.3025\n",
      "Epoch [12/4000], Discriminator Loss: 0.0946, Generator Loss: 0.1306, Series Loss: 0.0363, Class Loss: 0.2699, Accuracy: 0.2654\n",
      "Epoch [13/4000], Discriminator Loss: 0.0945, Generator Loss: 0.1302, Series Loss: 0.0359, Class Loss: 0.2697, Accuracy: 0.2840\n",
      "Epoch [14/4000], Discriminator Loss: 0.0944, Generator Loss: 0.1300, Series Loss: 0.0357, Class Loss: 0.2696, Accuracy: 0.3333\n",
      "Epoch [15/4000], Discriminator Loss: 0.0942, Generator Loss: 0.1300, Series Loss: 0.0355, Class Loss: 0.2694, Accuracy: 0.2963\n",
      "Epoch [16/4000], Discriminator Loss: 0.0942, Generator Loss: 0.1296, Series Loss: 0.0352, Class Loss: 0.2696, Accuracy: 0.3333\n",
      "Epoch [17/4000], Discriminator Loss: 0.0943, Generator Loss: 0.1295, Series Loss: 0.0349, Class Loss: 0.2693, Accuracy: 0.3210\n",
      "Epoch [18/4000], Discriminator Loss: 0.0939, Generator Loss: 0.1295, Series Loss: 0.0348, Class Loss: 0.2693, Accuracy: 0.3457\n",
      "Epoch [19/4000], Discriminator Loss: 0.0941, Generator Loss: 0.1293, Series Loss: 0.0345, Class Loss: 0.2692, Accuracy: 0.3272\n",
      "Epoch [20/4000], Discriminator Loss: 0.0936, Generator Loss: 0.1290, Series Loss: 0.0344, Class Loss: 0.2689, Accuracy: 0.3457\n",
      "Epoch [21/4000], Discriminator Loss: 0.0938, Generator Loss: 0.1287, Series Loss: 0.0342, Class Loss: 0.2689, Accuracy: 0.3333\n",
      "Epoch [22/4000], Discriminator Loss: 0.0935, Generator Loss: 0.1289, Series Loss: 0.0340, Class Loss: 0.2687, Accuracy: 0.3827\n",
      "Epoch [23/4000], Discriminator Loss: 0.0939, Generator Loss: 0.1285, Series Loss: 0.0338, Class Loss: 0.2686, Accuracy: 0.3889\n",
      "Epoch [24/4000], Discriminator Loss: 0.0938, Generator Loss: 0.1284, Series Loss: 0.0336, Class Loss: 0.2687, Accuracy: 0.3827\n",
      "Epoch [25/4000], Discriminator Loss: 0.0936, Generator Loss: 0.1282, Series Loss: 0.0335, Class Loss: 0.2686, Accuracy: 0.3889\n",
      "Epoch [26/4000], Discriminator Loss: 0.0934, Generator Loss: 0.1280, Series Loss: 0.0333, Class Loss: 0.2685, Accuracy: 0.3765\n",
      "Epoch [27/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1279, Series Loss: 0.0331, Class Loss: 0.2686, Accuracy: 0.3765\n",
      "Epoch [28/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1276, Series Loss: 0.0328, Class Loss: 0.2682, Accuracy: 0.4506\n",
      "Epoch [29/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1275, Series Loss: 0.0326, Class Loss: 0.2685, Accuracy: 0.4198\n",
      "Epoch [30/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1277, Series Loss: 0.0326, Class Loss: 0.2682, Accuracy: 0.4012\n",
      "Epoch [31/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1275, Series Loss: 0.0323, Class Loss: 0.2682, Accuracy: 0.4506\n",
      "Epoch [32/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1273, Series Loss: 0.0322, Class Loss: 0.2681, Accuracy: 0.4691\n",
      "Epoch [33/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1272, Series Loss: 0.0321, Class Loss: 0.2678, Accuracy: 0.4321\n",
      "Epoch [34/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1270, Series Loss: 0.0319, Class Loss: 0.2681, Accuracy: 0.4506\n",
      "Epoch [35/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1272, Series Loss: 0.0317, Class Loss: 0.2679, Accuracy: 0.4444\n",
      "Epoch [36/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1269, Series Loss: 0.0316, Class Loss: 0.2678, Accuracy: 0.4444\n",
      "Epoch [37/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1269, Series Loss: 0.0315, Class Loss: 0.2679, Accuracy: 0.4506\n",
      "Epoch [38/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1268, Series Loss: 0.0313, Class Loss: 0.2675, Accuracy: 0.4815\n",
      "Epoch [39/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1269, Series Loss: 0.0312, Class Loss: 0.2679, Accuracy: 0.4259\n",
      "Epoch [40/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1267, Series Loss: 0.0310, Class Loss: 0.2678, Accuracy: 0.4877\n",
      "Epoch [41/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1267, Series Loss: 0.0309, Class Loss: 0.2678, Accuracy: 0.4938\n",
      "Epoch [42/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1264, Series Loss: 0.0308, Class Loss: 0.2676, Accuracy: 0.4444\n",
      "Epoch [43/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1264, Series Loss: 0.0306, Class Loss: 0.2676, Accuracy: 0.4383\n",
      "Epoch [44/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1262, Series Loss: 0.0305, Class Loss: 0.2674, Accuracy: 0.4938\n",
      "Epoch [45/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1264, Series Loss: 0.0304, Class Loss: 0.2677, Accuracy: 0.4444\n",
      "Epoch [46/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1261, Series Loss: 0.0302, Class Loss: 0.2674, Accuracy: 0.4815\n",
      "Epoch [47/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1261, Series Loss: 0.0301, Class Loss: 0.2676, Accuracy: 0.4753\n",
      "Epoch [48/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1260, Series Loss: 0.0299, Class Loss: 0.2673, Accuracy: 0.4568\n",
      "Epoch [49/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1258, Series Loss: 0.0298, Class Loss: 0.2674, Accuracy: 0.4568\n",
      "Epoch [50/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1258, Series Loss: 0.0297, Class Loss: 0.2673, Accuracy: 0.4938\n",
      "Epoch [51/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1259, Series Loss: 0.0296, Class Loss: 0.2674, Accuracy: 0.4691\n",
      "Epoch [52/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1256, Series Loss: 0.0295, Class Loss: 0.2673, Accuracy: 0.4938\n",
      "Epoch [53/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1259, Series Loss: 0.0294, Class Loss: 0.2672, Accuracy: 0.4815\n",
      "Epoch [54/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1258, Series Loss: 0.0293, Class Loss: 0.2672, Accuracy: 0.4691\n",
      "Epoch [55/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1258, Series Loss: 0.0292, Class Loss: 0.2674, Accuracy: 0.4938\n",
      "Epoch [56/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1256, Series Loss: 0.0291, Class Loss: 0.2673, Accuracy: 0.4444\n",
      "Epoch [57/4000], Discriminator Loss: 0.0911, Generator Loss: 0.1253, Series Loss: 0.0290, Class Loss: 0.2671, Accuracy: 0.5123\n",
      "Epoch [58/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1254, Series Loss: 0.0289, Class Loss: 0.2671, Accuracy: 0.5062\n",
      "Epoch [59/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1256, Series Loss: 0.0288, Class Loss: 0.2672, Accuracy: 0.5062\n",
      "Epoch [60/4000], Discriminator Loss: 0.0909, Generator Loss: 0.1252, Series Loss: 0.0287, Class Loss: 0.2671, Accuracy: 0.4815\n",
      "Epoch [61/4000], Discriminator Loss: 0.0908, Generator Loss: 0.1256, Series Loss: 0.0286, Class Loss: 0.2671, Accuracy: 0.5000\n",
      "Epoch [62/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1250, Series Loss: 0.0284, Class Loss: 0.2672, Accuracy: 0.4691\n",
      "Epoch [63/4000], Discriminator Loss: 0.0909, Generator Loss: 0.1249, Series Loss: 0.0284, Class Loss: 0.2673, Accuracy: 0.4691\n",
      "Epoch [64/4000], Discriminator Loss: 0.0905, Generator Loss: 0.1252, Series Loss: 0.0283, Class Loss: 0.2671, Accuracy: 0.4753\n",
      "Epoch [65/4000], Discriminator Loss: 0.0910, Generator Loss: 0.1249, Series Loss: 0.0282, Class Loss: 0.2671, Accuracy: 0.4691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [66/4000], Discriminator Loss: 0.0904, Generator Loss: 0.1252, Series Loss: 0.0281, Class Loss: 0.2671, Accuracy: 0.5062\n",
      "Epoch [67/4000], Discriminator Loss: 0.0908, Generator Loss: 0.1249, Series Loss: 0.0280, Class Loss: 0.2670, Accuracy: 0.5000\n",
      "Epoch [68/4000], Discriminator Loss: 0.0903, Generator Loss: 0.1252, Series Loss: 0.0279, Class Loss: 0.2670, Accuracy: 0.5123\n",
      "Epoch [69/4000], Discriminator Loss: 0.0907, Generator Loss: 0.1250, Series Loss: 0.0279, Class Loss: 0.2670, Accuracy: 0.4815\n",
      "Epoch [70/4000], Discriminator Loss: 0.0905, Generator Loss: 0.1250, Series Loss: 0.0277, Class Loss: 0.2668, Accuracy: 0.5000\n",
      "Epoch [71/4000], Discriminator Loss: 0.0903, Generator Loss: 0.1250, Series Loss: 0.0277, Class Loss: 0.2668, Accuracy: 0.5309\n",
      "Epoch [72/4000], Discriminator Loss: 0.0902, Generator Loss: 0.1249, Series Loss: 0.0276, Class Loss: 0.2668, Accuracy: 0.5123\n",
      "Epoch [73/4000], Discriminator Loss: 0.0904, Generator Loss: 0.1247, Series Loss: 0.0275, Class Loss: 0.2667, Accuracy: 0.4877\n",
      "Epoch [74/4000], Discriminator Loss: 0.0899, Generator Loss: 0.1248, Series Loss: 0.0275, Class Loss: 0.2669, Accuracy: 0.4877\n",
      "Epoch [75/4000], Discriminator Loss: 0.0900, Generator Loss: 0.1250, Series Loss: 0.0273, Class Loss: 0.2671, Accuracy: 0.4815\n",
      "Epoch [76/4000], Discriminator Loss: 0.0904, Generator Loss: 0.1252, Series Loss: 0.0273, Class Loss: 0.2668, Accuracy: 0.5123\n",
      "Epoch [77/4000], Discriminator Loss: 0.0901, Generator Loss: 0.1246, Series Loss: 0.0273, Class Loss: 0.2668, Accuracy: 0.5185\n",
      "Epoch [78/4000], Discriminator Loss: 0.0900, Generator Loss: 0.1248, Series Loss: 0.0272, Class Loss: 0.2668, Accuracy: 0.5062\n",
      "Epoch [79/4000], Discriminator Loss: 0.0900, Generator Loss: 0.1246, Series Loss: 0.0271, Class Loss: 0.2667, Accuracy: 0.5123\n",
      "Epoch [80/4000], Discriminator Loss: 0.0900, Generator Loss: 0.1249, Series Loss: 0.0271, Class Loss: 0.2668, Accuracy: 0.5309\n",
      "Epoch [81/4000], Discriminator Loss: 0.0895, Generator Loss: 0.1248, Series Loss: 0.0269, Class Loss: 0.2669, Accuracy: 0.5185\n",
      "Epoch [82/4000], Discriminator Loss: 0.0899, Generator Loss: 0.1246, Series Loss: 0.0269, Class Loss: 0.2667, Accuracy: 0.4877\n",
      "Epoch [83/4000], Discriminator Loss: 0.0897, Generator Loss: 0.1245, Series Loss: 0.0268, Class Loss: 0.2667, Accuracy: 0.5432\n",
      "Epoch [84/4000], Discriminator Loss: 0.0895, Generator Loss: 0.1248, Series Loss: 0.0268, Class Loss: 0.2668, Accuracy: 0.5309\n",
      "Epoch [85/4000], Discriminator Loss: 0.0892, Generator Loss: 0.1245, Series Loss: 0.0267, Class Loss: 0.2668, Accuracy: 0.5062\n",
      "Epoch [86/4000], Discriminator Loss: 0.0891, Generator Loss: 0.1248, Series Loss: 0.0268, Class Loss: 0.2668, Accuracy: 0.5062\n",
      "Epoch [87/4000], Discriminator Loss: 0.0892, Generator Loss: 0.1247, Series Loss: 0.0266, Class Loss: 0.2668, Accuracy: 0.5617\n",
      "Epoch [88/4000], Discriminator Loss: 0.0892, Generator Loss: 0.1244, Series Loss: 0.0266, Class Loss: 0.2666, Accuracy: 0.5000\n",
      "Epoch [89/4000], Discriminator Loss: 0.0893, Generator Loss: 0.1244, Series Loss: 0.0266, Class Loss: 0.2668, Accuracy: 0.5556\n",
      "Epoch [90/4000], Discriminator Loss: 0.0894, Generator Loss: 0.1246, Series Loss: 0.0265, Class Loss: 0.2667, Accuracy: 0.5185\n",
      "Epoch [91/4000], Discriminator Loss: 0.0889, Generator Loss: 0.1249, Series Loss: 0.0264, Class Loss: 0.2668, Accuracy: 0.4938\n",
      "Epoch [92/4000], Discriminator Loss: 0.0894, Generator Loss: 0.1244, Series Loss: 0.0264, Class Loss: 0.2668, Accuracy: 0.5247\n",
      "Epoch [93/4000], Discriminator Loss: 0.0893, Generator Loss: 0.1245, Series Loss: 0.0263, Class Loss: 0.2667, Accuracy: 0.5432\n",
      "Epoch [94/4000], Discriminator Loss: 0.0891, Generator Loss: 0.1247, Series Loss: 0.0264, Class Loss: 0.2668, Accuracy: 0.5185\n",
      "Epoch [95/4000], Discriminator Loss: 0.0889, Generator Loss: 0.1250, Series Loss: 0.0263, Class Loss: 0.2666, Accuracy: 0.5185\n",
      "Epoch [96/4000], Discriminator Loss: 0.0889, Generator Loss: 0.1242, Series Loss: 0.0263, Class Loss: 0.2668, Accuracy: 0.4815\n",
      "Epoch [97/4000], Discriminator Loss: 0.0885, Generator Loss: 0.1246, Series Loss: 0.0261, Class Loss: 0.2669, Accuracy: 0.5062\n",
      "Epoch [98/4000], Discriminator Loss: 0.0890, Generator Loss: 0.1242, Series Loss: 0.0261, Class Loss: 0.2667, Accuracy: 0.5494\n",
      "Epoch [99/4000], Discriminator Loss: 0.0887, Generator Loss: 0.1246, Series Loss: 0.0261, Class Loss: 0.2670, Accuracy: 0.4877\n",
      "Epoch [100/4000], Discriminator Loss: 0.0888, Generator Loss: 0.1241, Series Loss: 0.0261, Class Loss: 0.2668, Accuracy: 0.5432\n",
      "Epoch [101/4000], Discriminator Loss: 0.0890, Generator Loss: 0.1243, Series Loss: 0.0261, Class Loss: 0.2666, Accuracy: 0.5062\n",
      "Epoch [102/4000], Discriminator Loss: 0.0886, Generator Loss: 0.1244, Series Loss: 0.0260, Class Loss: 0.2666, Accuracy: 0.5679\n",
      "Epoch [103/4000], Discriminator Loss: 0.0889, Generator Loss: 0.1245, Series Loss: 0.0260, Class Loss: 0.2667, Accuracy: 0.5123\n",
      "Epoch [104/4000], Discriminator Loss: 0.0885, Generator Loss: 0.1243, Series Loss: 0.0260, Class Loss: 0.2670, Accuracy: 0.5062\n",
      "Epoch [105/4000], Discriminator Loss: 0.0889, Generator Loss: 0.1243, Series Loss: 0.0260, Class Loss: 0.2669, Accuracy: 0.5309\n",
      "Epoch [106/4000], Discriminator Loss: 0.0889, Generator Loss: 0.1243, Series Loss: 0.0260, Class Loss: 0.2668, Accuracy: 0.4938\n",
      "Epoch [107/4000], Discriminator Loss: 0.0883, Generator Loss: 0.1246, Series Loss: 0.0259, Class Loss: 0.2666, Accuracy: 0.5185\n",
      "Epoch [108/4000], Discriminator Loss: 0.0884, Generator Loss: 0.1246, Series Loss: 0.0259, Class Loss: 0.2669, Accuracy: 0.5123\n",
      "Epoch [109/4000], Discriminator Loss: 0.0889, Generator Loss: 0.1240, Series Loss: 0.0259, Class Loss: 0.2667, Accuracy: 0.5432\n",
      "Epoch [110/4000], Discriminator Loss: 0.0884, Generator Loss: 0.1245, Series Loss: 0.0258, Class Loss: 0.2668, Accuracy: 0.5062\n",
      "Epoch [111/4000], Discriminator Loss: 0.0882, Generator Loss: 0.1241, Series Loss: 0.0258, Class Loss: 0.2667, Accuracy: 0.4753\n",
      "Epoch [112/4000], Discriminator Loss: 0.0882, Generator Loss: 0.1243, Series Loss: 0.0258, Class Loss: 0.2666, Accuracy: 0.5247\n",
      "Epoch [113/4000], Discriminator Loss: 0.0883, Generator Loss: 0.1241, Series Loss: 0.0258, Class Loss: 0.2669, Accuracy: 0.5000\n",
      "Epoch [114/4000], Discriminator Loss: 0.0881, Generator Loss: 0.1242, Series Loss: 0.0258, Class Loss: 0.2667, Accuracy: 0.5247\n",
      "Epoch [115/4000], Discriminator Loss: 0.0881, Generator Loss: 0.1247, Series Loss: 0.0258, Class Loss: 0.2669, Accuracy: 0.5000\n",
      "Epoch [116/4000], Discriminator Loss: 0.0880, Generator Loss: 0.1244, Series Loss: 0.0257, Class Loss: 0.2667, Accuracy: 0.5185\n",
      "Epoch [117/4000], Discriminator Loss: 0.0881, Generator Loss: 0.1249, Series Loss: 0.0258, Class Loss: 0.2667, Accuracy: 0.5432\n",
      "Epoch [118/4000], Discriminator Loss: 0.0884, Generator Loss: 0.1238, Series Loss: 0.0257, Class Loss: 0.2668, Accuracy: 0.4877\n",
      "Epoch [119/4000], Discriminator Loss: 0.0882, Generator Loss: 0.1243, Series Loss: 0.0257, Class Loss: 0.2669, Accuracy: 0.5185\n",
      "Epoch [120/4000], Discriminator Loss: 0.0880, Generator Loss: 0.1246, Series Loss: 0.0257, Class Loss: 0.2665, Accuracy: 0.5062\n",
      "Epoch [121/4000], Discriminator Loss: 0.0883, Generator Loss: 0.1239, Series Loss: 0.0257, Class Loss: 0.2666, Accuracy: 0.5185\n",
      "Epoch [122/4000], Discriminator Loss: 0.0880, Generator Loss: 0.1243, Series Loss: 0.0257, Class Loss: 0.2667, Accuracy: 0.5185\n",
      "Epoch [123/4000], Discriminator Loss: 0.0880, Generator Loss: 0.1247, Series Loss: 0.0257, Class Loss: 0.2668, Accuracy: 0.5123\n",
      "Epoch [124/4000], Discriminator Loss: 0.0882, Generator Loss: 0.1240, Series Loss: 0.0256, Class Loss: 0.2667, Accuracy: 0.5062\n",
      "Epoch [125/4000], Discriminator Loss: 0.0878, Generator Loss: 0.1244, Series Loss: 0.0257, Class Loss: 0.2666, Accuracy: 0.5000\n",
      "Epoch [126/4000], Discriminator Loss: 0.0878, Generator Loss: 0.1245, Series Loss: 0.0256, Class Loss: 0.2668, Accuracy: 0.5062\n",
      "Epoch [127/4000], Discriminator Loss: 0.0876, Generator Loss: 0.1243, Series Loss: 0.0256, Class Loss: 0.2668, Accuracy: 0.5370\n",
      "Epoch [128/4000], Discriminator Loss: 0.0876, Generator Loss: 0.1248, Series Loss: 0.0257, Class Loss: 0.2668, Accuracy: 0.4877\n",
      "Epoch [129/4000], Discriminator Loss: 0.0884, Generator Loss: 0.1247, Series Loss: 0.0257, Class Loss: 0.2665, Accuracy: 0.5494\n",
      "Epoch [130/4000], Discriminator Loss: 0.0880, Generator Loss: 0.1246, Series Loss: 0.0257, Class Loss: 0.2668, Accuracy: 0.5309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [131/4000], Discriminator Loss: 0.0876, Generator Loss: 0.1237, Series Loss: 0.0257, Class Loss: 0.2665, Accuracy: 0.5370\n",
      "Epoch [132/4000], Discriminator Loss: 0.0876, Generator Loss: 0.1246, Series Loss: 0.0257, Class Loss: 0.2666, Accuracy: 0.5679\n",
      "Epoch [133/4000], Discriminator Loss: 0.0881, Generator Loss: 0.1245, Series Loss: 0.0257, Class Loss: 0.2669, Accuracy: 0.4691\n",
      "Epoch [134/4000], Discriminator Loss: 0.0878, Generator Loss: 0.1246, Series Loss: 0.0257, Class Loss: 0.2665, Accuracy: 0.5494\n",
      "Epoch [135/4000], Discriminator Loss: 0.0876, Generator Loss: 0.1240, Series Loss: 0.0257, Class Loss: 0.2667, Accuracy: 0.5432\n",
      "Epoch [136/4000], Discriminator Loss: 0.0877, Generator Loss: 0.1241, Series Loss: 0.0258, Class Loss: 0.2664, Accuracy: 0.5494\n",
      "Epoch [137/4000], Discriminator Loss: 0.0877, Generator Loss: 0.1240, Series Loss: 0.0257, Class Loss: 0.2665, Accuracy: 0.5741\n",
      "Epoch [138/4000], Discriminator Loss: 0.0877, Generator Loss: 0.1236, Series Loss: 0.0257, Class Loss: 0.2664, Accuracy: 0.5741\n",
      "Epoch [139/4000], Discriminator Loss: 0.0873, Generator Loss: 0.1246, Series Loss: 0.0258, Class Loss: 0.2665, Accuracy: 0.5494\n",
      "Epoch [140/4000], Discriminator Loss: 0.0874, Generator Loss: 0.1247, Series Loss: 0.0257, Class Loss: 0.2666, Accuracy: 0.5802\n",
      "Epoch [141/4000], Discriminator Loss: 0.0877, Generator Loss: 0.1243, Series Loss: 0.0259, Class Loss: 0.2667, Accuracy: 0.5432\n",
      "Epoch [142/4000], Discriminator Loss: 0.0873, Generator Loss: 0.1239, Series Loss: 0.0258, Class Loss: 0.2665, Accuracy: 0.5309\n",
      "Epoch [143/4000], Discriminator Loss: 0.0875, Generator Loss: 0.1243, Series Loss: 0.0258, Class Loss: 0.2668, Accuracy: 0.5370\n",
      "Epoch [144/4000], Discriminator Loss: 0.0876, Generator Loss: 0.1245, Series Loss: 0.0257, Class Loss: 0.2665, Accuracy: 0.5556\n",
      "Epoch [145/4000], Discriminator Loss: 0.0876, Generator Loss: 0.1245, Series Loss: 0.0257, Class Loss: 0.2664, Accuracy: 0.5679\n",
      "Epoch [146/4000], Discriminator Loss: 0.0879, Generator Loss: 0.1240, Series Loss: 0.0258, Class Loss: 0.2666, Accuracy: 0.5556\n",
      "Epoch [147/4000], Discriminator Loss: 0.0875, Generator Loss: 0.1248, Series Loss: 0.0258, Class Loss: 0.2665, Accuracy: 0.5556\n",
      "Epoch [148/4000], Discriminator Loss: 0.0871, Generator Loss: 0.1243, Series Loss: 0.0258, Class Loss: 0.2665, Accuracy: 0.5309\n",
      "Epoch [149/4000], Discriminator Loss: 0.0869, Generator Loss: 0.1241, Series Loss: 0.0257, Class Loss: 0.2665, Accuracy: 0.5741\n",
      "Epoch [150/4000], Discriminator Loss: 0.0870, Generator Loss: 0.1241, Series Loss: 0.0258, Class Loss: 0.2665, Accuracy: 0.5617\n",
      "Epoch [151/4000], Discriminator Loss: 0.0880, Generator Loss: 0.1237, Series Loss: 0.0258, Class Loss: 0.2666, Accuracy: 0.5556\n",
      "Epoch [152/4000], Discriminator Loss: 0.0873, Generator Loss: 0.1249, Series Loss: 0.0259, Class Loss: 0.2665, Accuracy: 0.5494\n",
      "Epoch [153/4000], Discriminator Loss: 0.0878, Generator Loss: 0.1248, Series Loss: 0.0258, Class Loss: 0.2663, Accuracy: 0.5741\n",
      "Epoch [154/4000], Discriminator Loss: 0.0874, Generator Loss: 0.1242, Series Loss: 0.0258, Class Loss: 0.2664, Accuracy: 0.5679\n",
      "Epoch [155/4000], Discriminator Loss: 0.0872, Generator Loss: 0.1240, Series Loss: 0.0258, Class Loss: 0.2663, Accuracy: 0.6049\n",
      "Epoch [156/4000], Discriminator Loss: 0.0872, Generator Loss: 0.1247, Series Loss: 0.0258, Class Loss: 0.2665, Accuracy: 0.5864\n",
      "Epoch [157/4000], Discriminator Loss: 0.0868, Generator Loss: 0.1244, Series Loss: 0.0258, Class Loss: 0.2665, Accuracy: 0.5802\n",
      "Epoch [158/4000], Discriminator Loss: 0.0873, Generator Loss: 0.1246, Series Loss: 0.0259, Class Loss: 0.2663, Accuracy: 0.5741\n",
      "Epoch [159/4000], Discriminator Loss: 0.0867, Generator Loss: 0.1240, Series Loss: 0.0259, Class Loss: 0.2665, Accuracy: 0.5741\n",
      "Epoch [160/4000], Discriminator Loss: 0.0870, Generator Loss: 0.1248, Series Loss: 0.0259, Class Loss: 0.2662, Accuracy: 0.5494\n",
      "Epoch [161/4000], Discriminator Loss: 0.0873, Generator Loss: 0.1249, Series Loss: 0.0258, Class Loss: 0.2665, Accuracy: 0.5617\n",
      "Epoch [162/4000], Discriminator Loss: 0.0870, Generator Loss: 0.1250, Series Loss: 0.0259, Class Loss: 0.2665, Accuracy: 0.6049\n",
      "Epoch [163/4000], Discriminator Loss: 0.0871, Generator Loss: 0.1238, Series Loss: 0.0259, Class Loss: 0.2665, Accuracy: 0.5988\n",
      "Epoch [164/4000], Discriminator Loss: 0.0870, Generator Loss: 0.1242, Series Loss: 0.0259, Class Loss: 0.2663, Accuracy: 0.5988\n",
      "Epoch [165/4000], Discriminator Loss: 0.0867, Generator Loss: 0.1248, Series Loss: 0.0259, Class Loss: 0.2664, Accuracy: 0.5926\n",
      "Epoch [166/4000], Discriminator Loss: 0.0868, Generator Loss: 0.1245, Series Loss: 0.0259, Class Loss: 0.2663, Accuracy: 0.5741\n",
      "Epoch [167/4000], Discriminator Loss: 0.0870, Generator Loss: 0.1237, Series Loss: 0.0259, Class Loss: 0.2663, Accuracy: 0.6049\n",
      "Epoch [168/4000], Discriminator Loss: 0.0867, Generator Loss: 0.1241, Series Loss: 0.0259, Class Loss: 0.2662, Accuracy: 0.6235\n",
      "Epoch [169/4000], Discriminator Loss: 0.0865, Generator Loss: 0.1243, Series Loss: 0.0259, Class Loss: 0.2664, Accuracy: 0.6235\n",
      "Epoch [170/4000], Discriminator Loss: 0.0870, Generator Loss: 0.1243, Series Loss: 0.0258, Class Loss: 0.2662, Accuracy: 0.6049\n",
      "Epoch [171/4000], Discriminator Loss: 0.0867, Generator Loss: 0.1243, Series Loss: 0.0259, Class Loss: 0.2664, Accuracy: 0.6358\n",
      "Epoch [172/4000], Discriminator Loss: 0.0863, Generator Loss: 0.1257, Series Loss: 0.0259, Class Loss: 0.2663, Accuracy: 0.6296\n",
      "Epoch [173/4000], Discriminator Loss: 0.0869, Generator Loss: 0.1243, Series Loss: 0.0259, Class Loss: 0.2663, Accuracy: 0.6173\n",
      "Epoch [174/4000], Discriminator Loss: 0.0871, Generator Loss: 0.1254, Series Loss: 0.0258, Class Loss: 0.2662, Accuracy: 0.5988\n",
      "Epoch [175/4000], Discriminator Loss: 0.0866, Generator Loss: 0.1244, Series Loss: 0.0259, Class Loss: 0.2663, Accuracy: 0.5864\n",
      "Epoch [176/4000], Discriminator Loss: 0.0865, Generator Loss: 0.1250, Series Loss: 0.0259, Class Loss: 0.2663, Accuracy: 0.6173\n",
      "Epoch [177/4000], Discriminator Loss: 0.0871, Generator Loss: 0.1234, Series Loss: 0.0258, Class Loss: 0.2664, Accuracy: 0.6481\n",
      "Epoch [178/4000], Discriminator Loss: 0.0869, Generator Loss: 0.1237, Series Loss: 0.0260, Class Loss: 0.2662, Accuracy: 0.6543\n",
      "Epoch [179/4000], Discriminator Loss: 0.0859, Generator Loss: 0.1254, Series Loss: 0.0260, Class Loss: 0.2663, Accuracy: 0.6420\n",
      "Epoch [180/4000], Discriminator Loss: 0.0868, Generator Loss: 0.1242, Series Loss: 0.0259, Class Loss: 0.2662, Accuracy: 0.6543\n",
      "Epoch [181/4000], Discriminator Loss: 0.0865, Generator Loss: 0.1248, Series Loss: 0.0259, Class Loss: 0.2660, Accuracy: 0.6481\n",
      "Epoch [182/4000], Discriminator Loss: 0.0866, Generator Loss: 0.1241, Series Loss: 0.0259, Class Loss: 0.2662, Accuracy: 0.6543\n",
      "Epoch [183/4000], Discriminator Loss: 0.0866, Generator Loss: 0.1241, Series Loss: 0.0259, Class Loss: 0.2662, Accuracy: 0.6667\n"
     ]
    }
   ],
   "source": [
    "#训练循环\n",
    "for epoch in range(epoch_num):\n",
    "    #初始化损失值\n",
    "    D_epoch_loss = 0\n",
    "    G_epoch_loss = 0\n",
    "    C_epoch_loss = 0\n",
    "    S_epoch_loss = 0\n",
    "    acc_num = 0\n",
    "    item_num = 0\n",
    "    count = len(dataloader.dataset) #返回批次数\n",
    "    #对数据集进行迭代\n",
    "    for step,(img,label) in enumerate(dataloader):\n",
    "        img =img.to(device) #把数据放到设备上\n",
    "        label = label.to(device)\n",
    "        size = img.shape[0] #img的第一位是size,获取批次的大小\n",
    "        random_seed = torch.randn(size,100,device=device)\n",
    "        item_num += size\n",
    "        \n",
    "        #判别器训练(真实图片的损失和生成图片的损失),损失的构建和优化\n",
    "        d_optimizer.zero_grad()#梯度归零\n",
    "        #判别器对于真实图片产生的损失\n",
    "        real_output = dis(label,img) #判别器输入真实的图片，real_output对真实图片的预测结果\n",
    "        d_real_loss = loss_fn(real_output,\n",
    "                              torch.ones_like(real_output,device=device)\n",
    "                              )\n",
    "        d_real_loss.backward()#计算梯度\n",
    "        \n",
    "        #在生成器上去计算生成器的损失，优化目标是判别器上的参数\n",
    "        generated_img = gen(random_seed,label) #得到生成的图片\n",
    "        \n",
    "        #因为优化目标是判别器，所以对生成器上的优化目标进行截断\n",
    "        generated_img = torch.reshape(generated_img, (generated_img.size(0), generated_img.size(2)))\n",
    "        fake_output = dis(label,generated_img.detach()) #判别器输入生成的图片，fake_output对生成图片的预测;detach会截断梯度，梯度就不会再传递到gen模型中了\n",
    "        #判别器在生成图像上产生的损失\n",
    "        d_fake_loss = loss_fn(fake_output,\n",
    "                              torch.zeros_like(fake_output,device=device)\n",
    "                              )\n",
    "        d_fake_loss.backward()\n",
    "        #判别器损失\n",
    "        disc_loss = d_real_loss + d_fake_loss\n",
    "        #判别器优化\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        \n",
    "        #生成器上损失的构建和优化\n",
    "        g_optimizer.zero_grad() #先将生成器上的梯度置零\n",
    "        fake_output = dis(label,generated_img)\n",
    "        class_output = cls(torch.reshape(generated_img, (generated_img.size(0), 1, generated_img.size(1))))\n",
    "        cls_loss = class_loss(class_output, label)\n",
    "        series_loss = continue_loss(generated_img, img)\n",
    "        for i in range(size):\n",
    "            if class_output[i][torch.argmax(label[i])] >= 0.5:\n",
    "                acc_num += 1\n",
    "        gen_loss = loss_fn(fake_output,\n",
    "                              torch.ones_like(fake_output,device=device)\n",
    "                          ) + series_loss + cls_loss\n",
    "        gen_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        #累计每一个批次的loss\n",
    "        with torch.no_grad():\n",
    "            D_epoch_loss +=disc_loss\n",
    "            G_epoch_loss +=gen_loss\n",
    "            S_epoch_loss +=series_loss\n",
    "            C_epoch_loss +=cls_loss\n",
    "    #求平均损失\n",
    "    with torch.no_grad():\n",
    "        D_epoch_loss /=count\n",
    "        G_epoch_loss /=count\n",
    "        S_epoch_loss /=(count * continue_loss_weight)\n",
    "        C_epoch_loss /=(count * class_loss_weight)\n",
    "        acc = acc_num / item_num\n",
    "        D_loss.append(D_epoch_loss)\n",
    "        G_loss.append(G_epoch_loss)\n",
    "        S_loss.append(S_epoch_loss)\n",
    "        C_loss.append(C_epoch_loss)\n",
    "        accs.append(acc)\n",
    "        print(f\"Epoch [{epoch + 1}/{epoch_num}], \"\n",
    "              f\"Discriminator Loss: {D_epoch_loss:.4f}, \"\n",
    "              f\"Generator Loss: {G_epoch_loss:.4f}, \"\n",
    "              f\"Series Loss: {S_epoch_loss:.4f}, \"\n",
    "              f\"Class Loss: {C_epoch_loss:.4f}, \"\n",
    "              f\"Accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ffa546",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_curve = [i.cpu() for i in G_loss]\n",
    "plt.plot(g_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38eb3bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_curve = [i.cpu() for i in D_loss]\n",
    "plt.plot(d_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463f9c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_curve = [i.cpu() for i in S_loss]\n",
    "plt.plot(s_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efa5b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_curve = [i.cpu() for i in C_loss]\n",
    "plt.plot(c_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cada92de",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_curve = [i for i in accs]\n",
    "plt.plot(a_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddb84a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = generated_img.cpu().detach()\n",
    "# output = torch.reshape(output, (output.size(1), output.size(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3dac15",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(output.numpy()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d22f52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose_list(my_list):\n",
    "    transposed_list = list(zip(*my_list))\n",
    "    for i in range(len(transposed_list)):\n",
    "        transposed_list[i] = list(transposed_list[i])\n",
    "    return transposed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d119ae78",
   "metadata": {},
   "outputs": [],
   "source": [
    "transposed_list = transpose_list(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53827e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(series[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee133abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = []\n",
    "for step,(img,label) in enumerate(dataloader):\n",
    "        img =img.to(device) #把数据放到设备上\n",
    "        label = label.to(device)\n",
    "        size = img.shape[0] #img的第一位是size,获取批次的大小\n",
    "        random_seed = torch.randn(size,100,device=device)\n",
    "        \n",
    "        #在生成器上去计算生成器的损失，优化目标是判别器上的参数\n",
    "        generated_img = gen(random_seed,label) #得到生成的图片\n",
    "        generated_img = torch.reshape(generated_img, (generated_img.size(0), generated_img.size(2)))\n",
    "        class_output = cls(torch.reshape(generated_img, (generated_img.size(0), 1, generated_img.size(1))))\n",
    "        true_output = cls(torch.reshape(img, (img.size(0), 1, img.size(1))))\n",
    "        print('fake output:')\n",
    "        for item in class_output:\n",
    "            print(torch.max(item))\n",
    "        print('true output:')\n",
    "        for item in true_output:\n",
    "            print(torch.max(item))\n",
    "        auth.append(class_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b8f055",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f212dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'shapeloss/seed{}'.format(seed) + 'G{}'.format(generator_rate) + 'D{}'.format(discriminator_rate) + 'epoch{}'.format(epoch_num)\n",
    "isExists=os.path.exists(path)\n",
    "if not isExists:\n",
    "    os.mkdir(path)\n",
    "path = path + '/S{}'.format(continue_loss_weight) + 'C{}'.format(class_loss_weight)\n",
    "os.mkdir(path)\n",
    "torch.save(gen, path + '/generator.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e103dde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(dis, path + \"/discriminator.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc12f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "code = []\n",
    "for _, (_, _) in enumerate(dataloader):\n",
    "    random_seed = torch.randn(size,100,device=device)\n",
    "    code.append(random_seed.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f0388c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf42e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(path + '/code.npy', code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d2c6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(accs, path + '/accs.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d70990",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
