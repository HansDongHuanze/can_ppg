{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9eebafaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入库\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "import torchvision #加载图片\n",
    "from torchvision import transforms #图片变换\n",
    "\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    " \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt #绘图\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "from preprocess import Process\n",
    "from transformer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f369c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_seed(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "get_random_seed(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a98ad843",
   "metadata": {},
   "outputs": [],
   "source": [
    "#独热编码\n",
    "def one_hot(x,class_count=10):\n",
    "    return torch.eye(class_count)[x,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64c2d341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject 13 abandoned\n",
      "subject 16 abandoned\n",
      "subject 17 abandoned\n",
      "subject 18 abandoned\n",
      "subject 20 abandoned\n",
      "subject 26 abandoned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhz/anaconda3/lib/python3.9/site-packages/scipy/interpolate/fitpack2.py:280: UserWarning: \n",
      "The maximal number of iterations maxit (set to 20 by the program)\n",
      "allowed for finding a smoothing spline with fp=s has been reached: s\n",
      "too small.\n",
      "There is an approximation returned but the corresponding weighted sum\n",
      "of squared residuals does not satisfy the condition abs(fp-s)/s < tol.\n",
      "  warnings.warn(message)\n",
      "/home/dhz/anaconda3/lib/python3.9/site-packages/numpy/ma/core.py:5244: RuntimeWarning: Mean of empty slice.\n",
      "  result = super().mean(axis=axis, dtype=dtype, **kwargs)[()]\n",
      "/home/dhz/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3723: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject 42 abandoned\n",
      "subject 47 abandoned\n",
      "subject 48 abandoned\n",
      "subject 50 abandoned\n"
     ]
    }
   ],
   "source": [
    "series = []\n",
    "items = 3\n",
    "step = 3\n",
    "subject_num = 0\n",
    "\n",
    "for num in range(2, 66):\n",
    "    try:\n",
    "        series += Process(num).prepro(1024, step, items)\n",
    "        subject_num += 1\n",
    "    except:\n",
    "        print(f'subject {num} abandoned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c6e9e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, series, items, subject_num):\n",
    "        self.series = series\n",
    "        self.codes = []\n",
    "        self.subject_num = subject_num\n",
    "        self.labels = np.zeros((len(self.series), self.subject_num), dtype='double')\n",
    "        for i in range(self.subject_num):\n",
    "            for j in range(items):\n",
    "                self.labels[i + j][i] = 1.0            \n",
    "\n",
    "    # need to overload\n",
    "    def __len__(self):\n",
    "        return len(self.series)\n",
    "\n",
    "    # need to overload\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.series[idx]), torch.tensor(self.labels[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "463a2d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset(series, items=items, subject_num=subject_num)\n",
    "dataloader = torch.utils.data.DataLoader(dataset,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0415007e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义生成器\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, subject_num):\n",
    "        super(Generator,self).__init__()\n",
    "        self.linear1 = nn.Linear(100,512)\n",
    "        self.bn1=nn.BatchNorm1d(512)\n",
    "        self.subject_num = subject_num\n",
    "        self.linear2 = nn.Linear(subject_num,512)\n",
    "        self.bn2=nn.BatchNorm1d(512)\n",
    "        \n",
    "        self.deconv1 = nn.Conv1d(1, 3, kernel_size=2, padding='same')\n",
    "        self.bn3=nn.BatchNorm1d(3)\n",
    "        self.deconv2 = nn.Conv1d(3, 6, kernel_size=2, padding='same')\n",
    "        self.bn4=nn.BatchNorm1d(6)\n",
    "        self.deconv3 = nn.Conv1d(6, 1, kernel_size=2, padding='same')\n",
    "        \n",
    "    def forward(self,x1,x2):\n",
    "        x1=F.relu(self.linear1(x1.to(torch.float64)))\n",
    "        x1=self.bn1(x1)\n",
    "        x2=F.relu(self.linear2(x2))\n",
    "        x2=self.bn2(x2)\n",
    "        x=torch.cat([x1,x2],axis=1)\n",
    "        x=F.relu(self.deconv1(torch.reshape(x, (x.size(0), 1, x.size(1)))))\n",
    "        x=self.bn3(x)\n",
    "        x=F.relu(self.deconv2(x))\n",
    "        x=self.bn4(x)\n",
    "        x=torch.tanh(self.deconv3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c55045ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义判别器\n",
    "#输入：1，28，28图片和长度为10的condition\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, subject_num):\n",
    "        super(Discriminator,self).__init__()\n",
    "        self.subject_num = subject_num\n",
    "        self.linear = nn.Linear(self.subject_num,1024)\n",
    "        self.conv1 = nn.Conv1d(1,32,kernel_size=2,padding='same')\n",
    "        self.conv2 = nn.Conv1d(32,128,kernel_size=2,padding='same')\n",
    "        self.bn = nn.BatchNorm1d(128)\n",
    "        self.fc = nn.Linear(2048,1)\n",
    "    def forward(self,x1,x2): #x1代表label,x2代表image\n",
    "        x1=F.leaky_relu(self.linear(x1))\n",
    "        x=torch.cat([x1,x2],axis=1)            \n",
    "        x= F.dropout1d(F.leaky_relu(self.conv1(torch.reshape(x, (x.size(0), 1, x.size(1))))))\n",
    "        x= F.dropout1d(F.leaky_relu(self.conv2(x)))\n",
    "        x = self.bn(x)\n",
    "        x = torch.sigmoid(self.fc(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b06c0a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContinuityLoss(nn.Module):\n",
    "    def __init__(self, weight=1.0):\n",
    "        super(ContinuityLoss, self).__init__()\n",
    "        self.weight = weight\n",
    "        \n",
    "    def forward(self, predictions):\n",
    "        diff = predictions[:][1:] - predictions[:][:-1]\n",
    "        loss = torch.mean(torch.abs(diff))\n",
    "        return loss * self.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55bc25ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxValueLoss(nn.Module):\n",
    "    def __init__(self, weight=1.0):\n",
    "        super(MaxValueLoss, self).__init__()\n",
    "        self.weight = weight\n",
    "        self.MCE = nn.CrossEntropyLoss()\n",
    "    def forward(self, input1):\n",
    "        input2 = torch.zeros_like(input1)\n",
    "        types = torch.argmax(input1, dim = 0, keepdim=False)\n",
    "        for i in range(input1.size(0)):\n",
    "            input2[i][types[i]] = 1\n",
    "        loss = self.MCE(input1, input2)\n",
    "        return loss * self.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86bdfd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassLoss(nn.Module):\n",
    "    def __init__(self, weight=1.0):\n",
    "        super(ClassLoss, self).__init__()\n",
    "        self.weight = weight\n",
    "    def forward(self, input1, input2):\n",
    "        diff = input1 - input2\n",
    "        loss = torch.mean(torch.abs(diff))\n",
    "        return loss * self.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64a75c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassLoss(nn.Module):\n",
    "    def __init__(self, weight=1.0):\n",
    "        super(ClassLoss, self).__init__()\n",
    "        self.weight = weight\n",
    "        self.MCE = nn.CrossEntropyLoss()\n",
    "    def forward(self, input1, input2):\n",
    "        loss = self.MCE(input1, input2)\n",
    "        return loss * self.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be96d7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#设备的配置\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#初化生成器和判别器把他们放到相应的设备上\n",
    "gen = Generator(subject_num).to(device)\n",
    "gen = gen.double()\n",
    "dis = Discriminator(subject_num).to(device)\n",
    "dis = dis.double()\n",
    "cls = torch.load(\"classification\").to(device)\n",
    "cls = cls.double()\n",
    "#交叉熵损失函数\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "continue_loss_weight = 1\n",
    "continue_loss = ContinuityLoss(weight=continue_loss_weight)\n",
    "class_loss_weight = 1e-2\n",
    "class_loss = ClassLoss(weight=class_loss_weight)\n",
    "#训练器的优化器\n",
    "d_optimizer = torch.optim.Adam(dis.parameters(),lr=1e-5)\n",
    "#训练生成器的优化器\n",
    "g_optimizer = torch.optim.Adam(gen.parameters(),lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3004abc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#设置生成绘图图片的随机张量，这里可视化16张图片\n",
    "#生成16个长度为100的随机正态分布张量\n",
    "noise_seed = torch.randn(16,100,device=device)\n",
    "label_seed = torch.randint(0,subject_num,size=(16,))\n",
    "label_seed_onehot = one_hot(label_seed, class_count=subject_num).to(device)\n",
    " \n",
    "D_loss = [] #记录训练过程中判别器的损失\n",
    "G_loss = [] #记录训练过程中生成器的损失\n",
    "S_loss = []\n",
    "C_loss = []\n",
    "accs = []\n",
    "epoch_num = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77dc5c1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhz/anaconda3/lib/python3.9/site-packages/torch/nn/modules/conv.py:309: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:895.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/4000], Discriminator Loss: 0.0966, Generator Loss: 0.0758, Series Loss: 0.0261, Class Loss: 0.2492, Accuracy: 0.2284\n",
      "Epoch [2/4000], Discriminator Loss: 0.0962, Generator Loss: 0.0756, Series Loss: 0.0257, Class Loss: 0.2491, Accuracy: 0.1852\n",
      "Epoch [3/4000], Discriminator Loss: 0.0955, Generator Loss: 0.0752, Series Loss: 0.0252, Class Loss: 0.2492, Accuracy: 0.1975\n",
      "Epoch [4/4000], Discriminator Loss: 0.0956, Generator Loss: 0.0747, Series Loss: 0.0248, Class Loss: 0.2492, Accuracy: 0.1975\n",
      "Epoch [5/4000], Discriminator Loss: 0.0950, Generator Loss: 0.0746, Series Loss: 0.0242, Class Loss: 0.2492, Accuracy: 0.2222\n",
      "Epoch [6/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0740, Series Loss: 0.0236, Class Loss: 0.2493, Accuracy: 0.2160\n",
      "Epoch [7/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0741, Series Loss: 0.0233, Class Loss: 0.2492, Accuracy: 0.2531\n",
      "Epoch [8/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0731, Series Loss: 0.0225, Class Loss: 0.2491, Accuracy: 0.2037\n",
      "Epoch [9/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0728, Series Loss: 0.0220, Class Loss: 0.2493, Accuracy: 0.1605\n",
      "Epoch [10/4000], Discriminator Loss: 0.0939, Generator Loss: 0.0720, Series Loss: 0.0212, Class Loss: 0.2493, Accuracy: 0.1667\n",
      "Epoch [11/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0712, Series Loss: 0.0206, Class Loss: 0.2491, Accuracy: 0.1605\n",
      "Epoch [12/4000], Discriminator Loss: 0.0939, Generator Loss: 0.0708, Series Loss: 0.0199, Class Loss: 0.2492, Accuracy: 0.1728\n",
      "Epoch [13/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0699, Series Loss: 0.0193, Class Loss: 0.2492, Accuracy: 0.1605\n",
      "Epoch [14/4000], Discriminator Loss: 0.0939, Generator Loss: 0.0691, Series Loss: 0.0185, Class Loss: 0.2492, Accuracy: 0.1667\n",
      "Epoch [15/4000], Discriminator Loss: 0.0937, Generator Loss: 0.0685, Series Loss: 0.0179, Class Loss: 0.2493, Accuracy: 0.1667\n",
      "Epoch [16/4000], Discriminator Loss: 0.0937, Generator Loss: 0.0674, Series Loss: 0.0170, Class Loss: 0.2493, Accuracy: 0.1296\n",
      "Epoch [17/4000], Discriminator Loss: 0.0937, Generator Loss: 0.0665, Series Loss: 0.0162, Class Loss: 0.2494, Accuracy: 0.1667\n",
      "Epoch [18/4000], Discriminator Loss: 0.0934, Generator Loss: 0.0657, Series Loss: 0.0154, Class Loss: 0.2495, Accuracy: 0.1481\n",
      "Epoch [19/4000], Discriminator Loss: 0.0935, Generator Loss: 0.0650, Series Loss: 0.0146, Class Loss: 0.2493, Accuracy: 0.1605\n",
      "Epoch [20/4000], Discriminator Loss: 0.0935, Generator Loss: 0.0636, Series Loss: 0.0137, Class Loss: 0.2494, Accuracy: 0.1543\n",
      "Epoch [21/4000], Discriminator Loss: 0.0932, Generator Loss: 0.0633, Series Loss: 0.0132, Class Loss: 0.2494, Accuracy: 0.1605\n",
      "Epoch [22/4000], Discriminator Loss: 0.0933, Generator Loss: 0.0624, Series Loss: 0.0126, Class Loss: 0.2490, Accuracy: 0.1728\n",
      "Epoch [23/4000], Discriminator Loss: 0.0933, Generator Loss: 0.0616, Series Loss: 0.0118, Class Loss: 0.2493, Accuracy: 0.1667\n",
      "Epoch [24/4000], Discriminator Loss: 0.0930, Generator Loss: 0.0615, Series Loss: 0.0115, Class Loss: 0.2493, Accuracy: 0.1605\n",
      "Epoch [25/4000], Discriminator Loss: 0.0930, Generator Loss: 0.0610, Series Loss: 0.0111, Class Loss: 0.2496, Accuracy: 0.1605\n",
      "Epoch [26/4000], Discriminator Loss: 0.0929, Generator Loss: 0.0609, Series Loss: 0.0107, Class Loss: 0.2493, Accuracy: 0.1667\n",
      "Epoch [27/4000], Discriminator Loss: 0.0932, Generator Loss: 0.0606, Series Loss: 0.0107, Class Loss: 0.2494, Accuracy: 0.1420\n",
      "Epoch [28/4000], Discriminator Loss: 0.0931, Generator Loss: 0.0598, Series Loss: 0.0102, Class Loss: 0.2495, Accuracy: 0.1173\n",
      "Epoch [29/4000], Discriminator Loss: 0.0931, Generator Loss: 0.0598, Series Loss: 0.0101, Class Loss: 0.2497, Accuracy: 0.1358\n",
      "Epoch [30/4000], Discriminator Loss: 0.0928, Generator Loss: 0.0595, Series Loss: 0.0097, Class Loss: 0.2495, Accuracy: 0.1420\n",
      "Epoch [31/4000], Discriminator Loss: 0.0925, Generator Loss: 0.0598, Series Loss: 0.0097, Class Loss: 0.2496, Accuracy: 0.1358\n",
      "Epoch [32/4000], Discriminator Loss: 0.0928, Generator Loss: 0.0594, Series Loss: 0.0096, Class Loss: 0.2497, Accuracy: 0.1296\n",
      "Epoch [33/4000], Discriminator Loss: 0.0929, Generator Loss: 0.0587, Series Loss: 0.0093, Class Loss: 0.2495, Accuracy: 0.1420\n",
      "Epoch [34/4000], Discriminator Loss: 0.0930, Generator Loss: 0.0592, Series Loss: 0.0094, Class Loss: 0.2495, Accuracy: 0.1420\n",
      "Epoch [35/4000], Discriminator Loss: 0.0925, Generator Loss: 0.0586, Series Loss: 0.0091, Class Loss: 0.2493, Accuracy: 0.1358\n",
      "Epoch [36/4000], Discriminator Loss: 0.0926, Generator Loss: 0.0587, Series Loss: 0.0088, Class Loss: 0.2497, Accuracy: 0.1235\n",
      "Epoch [37/4000], Discriminator Loss: 0.0925, Generator Loss: 0.0585, Series Loss: 0.0087, Class Loss: 0.2498, Accuracy: 0.1358\n",
      "Epoch [38/4000], Discriminator Loss: 0.0923, Generator Loss: 0.0588, Series Loss: 0.0087, Class Loss: 0.2496, Accuracy: 0.1111\n",
      "Epoch [39/4000], Discriminator Loss: 0.0929, Generator Loss: 0.0579, Series Loss: 0.0085, Class Loss: 0.2494, Accuracy: 0.1543\n",
      "Epoch [40/4000], Discriminator Loss: 0.0929, Generator Loss: 0.0582, Series Loss: 0.0085, Class Loss: 0.2497, Accuracy: 0.1235\n",
      "Epoch [41/4000], Discriminator Loss: 0.0923, Generator Loss: 0.0583, Series Loss: 0.0084, Class Loss: 0.2495, Accuracy: 0.1111\n",
      "Epoch [42/4000], Discriminator Loss: 0.0921, Generator Loss: 0.0580, Series Loss: 0.0083, Class Loss: 0.2499, Accuracy: 0.1358\n",
      "Epoch [43/4000], Discriminator Loss: 0.0920, Generator Loss: 0.0580, Series Loss: 0.0082, Class Loss: 0.2496, Accuracy: 0.1481\n",
      "Epoch [44/4000], Discriminator Loss: 0.0919, Generator Loss: 0.0579, Series Loss: 0.0081, Class Loss: 0.2497, Accuracy: 0.1049\n",
      "Epoch [45/4000], Discriminator Loss: 0.0922, Generator Loss: 0.0578, Series Loss: 0.0081, Class Loss: 0.2498, Accuracy: 0.1049\n",
      "Epoch [46/4000], Discriminator Loss: 0.0920, Generator Loss: 0.0581, Series Loss: 0.0079, Class Loss: 0.2498, Accuracy: 0.1296\n",
      "Epoch [47/4000], Discriminator Loss: 0.0923, Generator Loss: 0.0575, Series Loss: 0.0079, Class Loss: 0.2497, Accuracy: 0.1420\n",
      "Epoch [48/4000], Discriminator Loss: 0.0926, Generator Loss: 0.0572, Series Loss: 0.0077, Class Loss: 0.2499, Accuracy: 0.1111\n",
      "Epoch [49/4000], Discriminator Loss: 0.0921, Generator Loss: 0.0574, Series Loss: 0.0076, Class Loss: 0.2496, Accuracy: 0.1420\n",
      "Epoch [50/4000], Discriminator Loss: 0.0918, Generator Loss: 0.0578, Series Loss: 0.0074, Class Loss: 0.2497, Accuracy: 0.1481\n",
      "Epoch [51/4000], Discriminator Loss: 0.0918, Generator Loss: 0.0575, Series Loss: 0.0075, Class Loss: 0.2497, Accuracy: 0.1605\n",
      "Epoch [52/4000], Discriminator Loss: 0.0920, Generator Loss: 0.0571, Series Loss: 0.0074, Class Loss: 0.2495, Accuracy: 0.1543\n",
      "Epoch [53/4000], Discriminator Loss: 0.0918, Generator Loss: 0.0572, Series Loss: 0.0074, Class Loss: 0.2496, Accuracy: 0.1543\n",
      "Epoch [54/4000], Discriminator Loss: 0.0921, Generator Loss: 0.0572, Series Loss: 0.0073, Class Loss: 0.2497, Accuracy: 0.1543\n",
      "Epoch [55/4000], Discriminator Loss: 0.0921, Generator Loss: 0.0566, Series Loss: 0.0072, Class Loss: 0.2495, Accuracy: 0.1543\n",
      "Epoch [56/4000], Discriminator Loss: 0.0918, Generator Loss: 0.0574, Series Loss: 0.0073, Class Loss: 0.2496, Accuracy: 0.1728\n",
      "Epoch [57/4000], Discriminator Loss: 0.0920, Generator Loss: 0.0571, Series Loss: 0.0070, Class Loss: 0.2496, Accuracy: 0.1481\n",
      "Epoch [58/4000], Discriminator Loss: 0.0922, Generator Loss: 0.0566, Series Loss: 0.0070, Class Loss: 0.2496, Accuracy: 0.1605\n",
      "Epoch [59/4000], Discriminator Loss: 0.0918, Generator Loss: 0.0571, Series Loss: 0.0069, Class Loss: 0.2495, Accuracy: 0.1605\n",
      "Epoch [60/4000], Discriminator Loss: 0.0917, Generator Loss: 0.0571, Series Loss: 0.0070, Class Loss: 0.2498, Accuracy: 0.1481\n",
      "Epoch [61/4000], Discriminator Loss: 0.0920, Generator Loss: 0.0569, Series Loss: 0.0068, Class Loss: 0.2494, Accuracy: 0.1667\n",
      "Epoch [62/4000], Discriminator Loss: 0.0919, Generator Loss: 0.0564, Series Loss: 0.0067, Class Loss: 0.2498, Accuracy: 0.1358\n",
      "Epoch [63/4000], Discriminator Loss: 0.0920, Generator Loss: 0.0562, Series Loss: 0.0065, Class Loss: 0.2496, Accuracy: 0.1481\n",
      "Epoch [64/4000], Discriminator Loss: 0.0916, Generator Loss: 0.0560, Series Loss: 0.0065, Class Loss: 0.2497, Accuracy: 0.1605\n",
      "Epoch [65/4000], Discriminator Loss: 0.0923, Generator Loss: 0.0557, Series Loss: 0.0065, Class Loss: 0.2495, Accuracy: 0.1481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [66/4000], Discriminator Loss: 0.0920, Generator Loss: 0.0560, Series Loss: 0.0062, Class Loss: 0.2497, Accuracy: 0.1481\n",
      "Epoch [67/4000], Discriminator Loss: 0.0919, Generator Loss: 0.0556, Series Loss: 0.0060, Class Loss: 0.2497, Accuracy: 0.1667\n",
      "Epoch [68/4000], Discriminator Loss: 0.0923, Generator Loss: 0.0552, Series Loss: 0.0060, Class Loss: 0.2496, Accuracy: 0.1605\n",
      "Epoch [69/4000], Discriminator Loss: 0.0923, Generator Loss: 0.0548, Series Loss: 0.0057, Class Loss: 0.2496, Accuracy: 0.1728\n",
      "Epoch [70/4000], Discriminator Loss: 0.0921, Generator Loss: 0.0549, Series Loss: 0.0058, Class Loss: 0.2496, Accuracy: 0.1543\n",
      "Epoch [71/4000], Discriminator Loss: 0.0915, Generator Loss: 0.0554, Series Loss: 0.0056, Class Loss: 0.2498, Accuracy: 0.1605\n",
      "Epoch [72/4000], Discriminator Loss: 0.0919, Generator Loss: 0.0552, Series Loss: 0.0057, Class Loss: 0.2497, Accuracy: 0.1728\n",
      "Epoch [73/4000], Discriminator Loss: 0.0920, Generator Loss: 0.0550, Series Loss: 0.0055, Class Loss: 0.2498, Accuracy: 0.1728\n",
      "Epoch [74/4000], Discriminator Loss: 0.0921, Generator Loss: 0.0550, Series Loss: 0.0055, Class Loss: 0.2498, Accuracy: 0.1605\n",
      "Epoch [75/4000], Discriminator Loss: 0.0923, Generator Loss: 0.0547, Series Loss: 0.0055, Class Loss: 0.2497, Accuracy: 0.1728\n",
      "Epoch [76/4000], Discriminator Loss: 0.0921, Generator Loss: 0.0548, Series Loss: 0.0055, Class Loss: 0.2498, Accuracy: 0.1667\n",
      "Epoch [77/4000], Discriminator Loss: 0.0920, Generator Loss: 0.0546, Series Loss: 0.0054, Class Loss: 0.2496, Accuracy: 0.1852\n",
      "Epoch [78/4000], Discriminator Loss: 0.0916, Generator Loss: 0.0551, Series Loss: 0.0055, Class Loss: 0.2497, Accuracy: 0.1790\n",
      "Epoch [79/4000], Discriminator Loss: 0.0918, Generator Loss: 0.0547, Series Loss: 0.0052, Class Loss: 0.2495, Accuracy: 0.1728\n",
      "Epoch [80/4000], Discriminator Loss: 0.0917, Generator Loss: 0.0549, Series Loss: 0.0053, Class Loss: 0.2498, Accuracy: 0.1667\n",
      "Epoch [81/4000], Discriminator Loss: 0.0915, Generator Loss: 0.0547, Series Loss: 0.0052, Class Loss: 0.2495, Accuracy: 0.1667\n",
      "Epoch [82/4000], Discriminator Loss: 0.0919, Generator Loss: 0.0552, Series Loss: 0.0054, Class Loss: 0.2496, Accuracy: 0.1790\n",
      "Epoch [83/4000], Discriminator Loss: 0.0921, Generator Loss: 0.0546, Series Loss: 0.0053, Class Loss: 0.2495, Accuracy: 0.1728\n",
      "Epoch [84/4000], Discriminator Loss: 0.0920, Generator Loss: 0.0546, Series Loss: 0.0052, Class Loss: 0.2497, Accuracy: 0.1914\n",
      "Epoch [85/4000], Discriminator Loss: 0.0915, Generator Loss: 0.0549, Series Loss: 0.0050, Class Loss: 0.2496, Accuracy: 0.1667\n",
      "Epoch [86/4000], Discriminator Loss: 0.0914, Generator Loss: 0.0545, Series Loss: 0.0051, Class Loss: 0.2495, Accuracy: 0.1790\n",
      "Epoch [87/4000], Discriminator Loss: 0.0914, Generator Loss: 0.0548, Series Loss: 0.0050, Class Loss: 0.2497, Accuracy: 0.1852\n",
      "Epoch [88/4000], Discriminator Loss: 0.0914, Generator Loss: 0.0546, Series Loss: 0.0050, Class Loss: 0.2496, Accuracy: 0.1975\n",
      "Epoch [89/4000], Discriminator Loss: 0.0915, Generator Loss: 0.0545, Series Loss: 0.0050, Class Loss: 0.2496, Accuracy: 0.1914\n",
      "Epoch [90/4000], Discriminator Loss: 0.0918, Generator Loss: 0.0543, Series Loss: 0.0050, Class Loss: 0.2494, Accuracy: 0.1790\n",
      "Epoch [91/4000], Discriminator Loss: 0.0918, Generator Loss: 0.0542, Series Loss: 0.0051, Class Loss: 0.2495, Accuracy: 0.1790\n",
      "Epoch [92/4000], Discriminator Loss: 0.0921, Generator Loss: 0.0543, Series Loss: 0.0051, Class Loss: 0.2497, Accuracy: 0.1790\n",
      "Epoch [93/4000], Discriminator Loss: 0.0915, Generator Loss: 0.0543, Series Loss: 0.0048, Class Loss: 0.2498, Accuracy: 0.1852\n",
      "Epoch [94/4000], Discriminator Loss: 0.0911, Generator Loss: 0.0541, Series Loss: 0.0049, Class Loss: 0.2496, Accuracy: 0.1790\n",
      "Epoch [95/4000], Discriminator Loss: 0.0912, Generator Loss: 0.0544, Series Loss: 0.0047, Class Loss: 0.2496, Accuracy: 0.1728\n",
      "Epoch [96/4000], Discriminator Loss: 0.0916, Generator Loss: 0.0544, Series Loss: 0.0048, Class Loss: 0.2496, Accuracy: 0.1790\n",
      "Epoch [97/4000], Discriminator Loss: 0.0912, Generator Loss: 0.0544, Series Loss: 0.0048, Class Loss: 0.2495, Accuracy: 0.1728\n",
      "Epoch [98/4000], Discriminator Loss: 0.0916, Generator Loss: 0.0541, Series Loss: 0.0046, Class Loss: 0.2497, Accuracy: 0.1790\n",
      "Epoch [99/4000], Discriminator Loss: 0.0913, Generator Loss: 0.0541, Series Loss: 0.0048, Class Loss: 0.2496, Accuracy: 0.1728\n",
      "Epoch [100/4000], Discriminator Loss: 0.0919, Generator Loss: 0.0540, Series Loss: 0.0047, Class Loss: 0.2496, Accuracy: 0.1790\n",
      "Epoch [101/4000], Discriminator Loss: 0.0915, Generator Loss: 0.0542, Series Loss: 0.0047, Class Loss: 0.2498, Accuracy: 0.1852\n",
      "Epoch [102/4000], Discriminator Loss: 0.0909, Generator Loss: 0.0542, Series Loss: 0.0044, Class Loss: 0.2496, Accuracy: 0.1975\n",
      "Epoch [103/4000], Discriminator Loss: 0.0912, Generator Loss: 0.0540, Series Loss: 0.0045, Class Loss: 0.2496, Accuracy: 0.1975\n",
      "Epoch [104/4000], Discriminator Loss: 0.0916, Generator Loss: 0.0542, Series Loss: 0.0045, Class Loss: 0.2497, Accuracy: 0.1790\n",
      "Epoch [105/4000], Discriminator Loss: 0.0912, Generator Loss: 0.0545, Series Loss: 0.0045, Class Loss: 0.2496, Accuracy: 0.2037\n",
      "Epoch [106/4000], Discriminator Loss: 0.0916, Generator Loss: 0.0541, Series Loss: 0.0047, Class Loss: 0.2496, Accuracy: 0.1790\n",
      "Epoch [107/4000], Discriminator Loss: 0.0914, Generator Loss: 0.0540, Series Loss: 0.0045, Class Loss: 0.2497, Accuracy: 0.1790\n",
      "Epoch [108/4000], Discriminator Loss: 0.0909, Generator Loss: 0.0538, Series Loss: 0.0044, Class Loss: 0.2496, Accuracy: 0.1852\n",
      "Epoch [109/4000], Discriminator Loss: 0.0915, Generator Loss: 0.0537, Series Loss: 0.0044, Class Loss: 0.2495, Accuracy: 0.1790\n",
      "Epoch [110/4000], Discriminator Loss: 0.0910, Generator Loss: 0.0539, Series Loss: 0.0044, Class Loss: 0.2498, Accuracy: 0.1852\n",
      "Epoch [111/4000], Discriminator Loss: 0.0905, Generator Loss: 0.0540, Series Loss: 0.0043, Class Loss: 0.2496, Accuracy: 0.1790\n",
      "Epoch [112/4000], Discriminator Loss: 0.0912, Generator Loss: 0.0537, Series Loss: 0.0044, Class Loss: 0.2496, Accuracy: 0.1975\n",
      "Epoch [113/4000], Discriminator Loss: 0.0911, Generator Loss: 0.0539, Series Loss: 0.0042, Class Loss: 0.2497, Accuracy: 0.1852\n",
      "Epoch [114/4000], Discriminator Loss: 0.0912, Generator Loss: 0.0538, Series Loss: 0.0044, Class Loss: 0.2498, Accuracy: 0.1790\n",
      "Epoch [115/4000], Discriminator Loss: 0.0914, Generator Loss: 0.0539, Series Loss: 0.0042, Class Loss: 0.2497, Accuracy: 0.1790\n",
      "Epoch [116/4000], Discriminator Loss: 0.0908, Generator Loss: 0.0542, Series Loss: 0.0045, Class Loss: 0.2496, Accuracy: 0.1728\n",
      "Epoch [117/4000], Discriminator Loss: 0.0919, Generator Loss: 0.0539, Series Loss: 0.0043, Class Loss: 0.2498, Accuracy: 0.1790\n",
      "Epoch [118/4000], Discriminator Loss: 0.0901, Generator Loss: 0.0542, Series Loss: 0.0042, Class Loss: 0.2497, Accuracy: 0.1852\n",
      "Epoch [119/4000], Discriminator Loss: 0.0910, Generator Loss: 0.0539, Series Loss: 0.0043, Class Loss: 0.2494, Accuracy: 0.1914\n",
      "Epoch [120/4000], Discriminator Loss: 0.0907, Generator Loss: 0.0542, Series Loss: 0.0042, Class Loss: 0.2497, Accuracy: 0.1728\n",
      "Epoch [121/4000], Discriminator Loss: 0.0910, Generator Loss: 0.0535, Series Loss: 0.0042, Class Loss: 0.2497, Accuracy: 0.1790\n",
      "Epoch [122/4000], Discriminator Loss: 0.0906, Generator Loss: 0.0541, Series Loss: 0.0041, Class Loss: 0.2499, Accuracy: 0.1852\n",
      "Epoch [123/4000], Discriminator Loss: 0.0910, Generator Loss: 0.0538, Series Loss: 0.0042, Class Loss: 0.2498, Accuracy: 0.1728\n",
      "Epoch [124/4000], Discriminator Loss: 0.0913, Generator Loss: 0.0536, Series Loss: 0.0041, Class Loss: 0.2497, Accuracy: 0.1852\n",
      "Epoch [125/4000], Discriminator Loss: 0.0901, Generator Loss: 0.0540, Series Loss: 0.0040, Class Loss: 0.2497, Accuracy: 0.1790\n",
      "Epoch [126/4000], Discriminator Loss: 0.0905, Generator Loss: 0.0543, Series Loss: 0.0041, Class Loss: 0.2497, Accuracy: 0.1852\n",
      "Epoch [127/4000], Discriminator Loss: 0.0908, Generator Loss: 0.0540, Series Loss: 0.0041, Class Loss: 0.2496, Accuracy: 0.1728\n",
      "Epoch [128/4000], Discriminator Loss: 0.0904, Generator Loss: 0.0537, Series Loss: 0.0040, Class Loss: 0.2497, Accuracy: 0.1852\n",
      "Epoch [129/4000], Discriminator Loss: 0.0902, Generator Loss: 0.0539, Series Loss: 0.0040, Class Loss: 0.2495, Accuracy: 0.1852\n",
      "Epoch [130/4000], Discriminator Loss: 0.0910, Generator Loss: 0.0535, Series Loss: 0.0040, Class Loss: 0.2496, Accuracy: 0.1852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [131/4000], Discriminator Loss: 0.0899, Generator Loss: 0.0542, Series Loss: 0.0040, Class Loss: 0.2497, Accuracy: 0.1852\n",
      "Epoch [132/4000], Discriminator Loss: 0.0904, Generator Loss: 0.0538, Series Loss: 0.0039, Class Loss: 0.2496, Accuracy: 0.1852\n",
      "Epoch [133/4000], Discriminator Loss: 0.0908, Generator Loss: 0.0534, Series Loss: 0.0039, Class Loss: 0.2496, Accuracy: 0.1790\n",
      "Epoch [134/4000], Discriminator Loss: 0.0902, Generator Loss: 0.0543, Series Loss: 0.0039, Class Loss: 0.2496, Accuracy: 0.1914\n",
      "Epoch [135/4000], Discriminator Loss: 0.0905, Generator Loss: 0.0536, Series Loss: 0.0039, Class Loss: 0.2496, Accuracy: 0.1914\n",
      "Epoch [136/4000], Discriminator Loss: 0.0901, Generator Loss: 0.0540, Series Loss: 0.0039, Class Loss: 0.2497, Accuracy: 0.1790\n",
      "Epoch [137/4000], Discriminator Loss: 0.0899, Generator Loss: 0.0537, Series Loss: 0.0039, Class Loss: 0.2497, Accuracy: 0.1914\n",
      "Epoch [138/4000], Discriminator Loss: 0.0894, Generator Loss: 0.0541, Series Loss: 0.0038, Class Loss: 0.2496, Accuracy: 0.1975\n",
      "Epoch [139/4000], Discriminator Loss: 0.0898, Generator Loss: 0.0537, Series Loss: 0.0038, Class Loss: 0.2496, Accuracy: 0.1914\n",
      "Epoch [140/4000], Discriminator Loss: 0.0897, Generator Loss: 0.0540, Series Loss: 0.0038, Class Loss: 0.2499, Accuracy: 0.1790\n",
      "Epoch [141/4000], Discriminator Loss: 0.0902, Generator Loss: 0.0542, Series Loss: 0.0038, Class Loss: 0.2497, Accuracy: 0.1790\n",
      "Epoch [142/4000], Discriminator Loss: 0.0903, Generator Loss: 0.0538, Series Loss: 0.0038, Class Loss: 0.2497, Accuracy: 0.1852\n",
      "Epoch [143/4000], Discriminator Loss: 0.0902, Generator Loss: 0.0542, Series Loss: 0.0037, Class Loss: 0.2498, Accuracy: 0.1852\n",
      "Epoch [144/4000], Discriminator Loss: 0.0901, Generator Loss: 0.0538, Series Loss: 0.0039, Class Loss: 0.2495, Accuracy: 0.1852\n",
      "Epoch [145/4000], Discriminator Loss: 0.0892, Generator Loss: 0.0542, Series Loss: 0.0036, Class Loss: 0.2499, Accuracy: 0.1975\n",
      "Epoch [146/4000], Discriminator Loss: 0.0898, Generator Loss: 0.0539, Series Loss: 0.0038, Class Loss: 0.2498, Accuracy: 0.1852\n",
      "Epoch [147/4000], Discriminator Loss: 0.0899, Generator Loss: 0.0538, Series Loss: 0.0037, Class Loss: 0.2498, Accuracy: 0.1852\n",
      "Epoch [148/4000], Discriminator Loss: 0.0894, Generator Loss: 0.0539, Series Loss: 0.0037, Class Loss: 0.2497, Accuracy: 0.1790\n",
      "Epoch [149/4000], Discriminator Loss: 0.0895, Generator Loss: 0.0538, Series Loss: 0.0036, Class Loss: 0.2497, Accuracy: 0.1914\n",
      "Epoch [150/4000], Discriminator Loss: 0.0902, Generator Loss: 0.0539, Series Loss: 0.0036, Class Loss: 0.2497, Accuracy: 0.1914\n",
      "Epoch [151/4000], Discriminator Loss: 0.0890, Generator Loss: 0.0543, Series Loss: 0.0037, Class Loss: 0.2497, Accuracy: 0.1852\n",
      "Epoch [152/4000], Discriminator Loss: 0.0892, Generator Loss: 0.0541, Series Loss: 0.0036, Class Loss: 0.2497, Accuracy: 0.1790\n",
      "Epoch [153/4000], Discriminator Loss: 0.0894, Generator Loss: 0.0538, Series Loss: 0.0036, Class Loss: 0.2496, Accuracy: 0.1852\n",
      "Epoch [154/4000], Discriminator Loss: 0.0894, Generator Loss: 0.0538, Series Loss: 0.0037, Class Loss: 0.2497, Accuracy: 0.1852\n",
      "Epoch [155/4000], Discriminator Loss: 0.0895, Generator Loss: 0.0540, Series Loss: 0.0037, Class Loss: 0.2498, Accuracy: 0.1852\n",
      "Epoch [156/4000], Discriminator Loss: 0.0897, Generator Loss: 0.0540, Series Loss: 0.0037, Class Loss: 0.2498, Accuracy: 0.1852\n",
      "Epoch [157/4000], Discriminator Loss: 0.0891, Generator Loss: 0.0540, Series Loss: 0.0035, Class Loss: 0.2498, Accuracy: 0.1728\n",
      "Epoch [158/4000], Discriminator Loss: 0.0897, Generator Loss: 0.0541, Series Loss: 0.0036, Class Loss: 0.2496, Accuracy: 0.1914\n",
      "Epoch [159/4000], Discriminator Loss: 0.0891, Generator Loss: 0.0539, Series Loss: 0.0036, Class Loss: 0.2496, Accuracy: 0.1852\n",
      "Epoch [160/4000], Discriminator Loss: 0.0890, Generator Loss: 0.0539, Series Loss: 0.0035, Class Loss: 0.2499, Accuracy: 0.1914\n",
      "Epoch [161/4000], Discriminator Loss: 0.0891, Generator Loss: 0.0538, Series Loss: 0.0036, Class Loss: 0.2497, Accuracy: 0.1728\n",
      "Epoch [162/4000], Discriminator Loss: 0.0896, Generator Loss: 0.0540, Series Loss: 0.0036, Class Loss: 0.2498, Accuracy: 0.1852\n",
      "Epoch [163/4000], Discriminator Loss: 0.0894, Generator Loss: 0.0542, Series Loss: 0.0036, Class Loss: 0.2498, Accuracy: 0.1790\n",
      "Epoch [164/4000], Discriminator Loss: 0.0897, Generator Loss: 0.0538, Series Loss: 0.0035, Class Loss: 0.2498, Accuracy: 0.1852\n",
      "Epoch [165/4000], Discriminator Loss: 0.0887, Generator Loss: 0.0538, Series Loss: 0.0035, Class Loss: 0.2499, Accuracy: 0.1852\n",
      "Epoch [166/4000], Discriminator Loss: 0.0889, Generator Loss: 0.0543, Series Loss: 0.0035, Class Loss: 0.2497, Accuracy: 0.1790\n",
      "Epoch [167/4000], Discriminator Loss: 0.0884, Generator Loss: 0.0539, Series Loss: 0.0035, Class Loss: 0.2497, Accuracy: 0.1790\n",
      "Epoch [168/4000], Discriminator Loss: 0.0890, Generator Loss: 0.0544, Series Loss: 0.0035, Class Loss: 0.2497, Accuracy: 0.1852\n",
      "Epoch [169/4000], Discriminator Loss: 0.0883, Generator Loss: 0.0543, Series Loss: 0.0035, Class Loss: 0.2497, Accuracy: 0.1852\n",
      "Epoch [170/4000], Discriminator Loss: 0.0893, Generator Loss: 0.0537, Series Loss: 0.0035, Class Loss: 0.2497, Accuracy: 0.1790\n",
      "Epoch [171/4000], Discriminator Loss: 0.0891, Generator Loss: 0.0540, Series Loss: 0.0035, Class Loss: 0.2497, Accuracy: 0.1790\n",
      "Epoch [172/4000], Discriminator Loss: 0.0887, Generator Loss: 0.0541, Series Loss: 0.0035, Class Loss: 0.2497, Accuracy: 0.1790\n",
      "Epoch [173/4000], Discriminator Loss: 0.0892, Generator Loss: 0.0540, Series Loss: 0.0034, Class Loss: 0.2495, Accuracy: 0.1852\n",
      "Epoch [174/4000], Discriminator Loss: 0.0882, Generator Loss: 0.0538, Series Loss: 0.0034, Class Loss: 0.2497, Accuracy: 0.1728\n",
      "Epoch [175/4000], Discriminator Loss: 0.0886, Generator Loss: 0.0540, Series Loss: 0.0033, Class Loss: 0.2495, Accuracy: 0.1914\n",
      "Epoch [176/4000], Discriminator Loss: 0.0889, Generator Loss: 0.0541, Series Loss: 0.0034, Class Loss: 0.2498, Accuracy: 0.1728\n",
      "Epoch [177/4000], Discriminator Loss: 0.0890, Generator Loss: 0.0540, Series Loss: 0.0034, Class Loss: 0.2496, Accuracy: 0.1914\n",
      "Epoch [178/4000], Discriminator Loss: 0.0888, Generator Loss: 0.0541, Series Loss: 0.0033, Class Loss: 0.2497, Accuracy: 0.1728\n",
      "Epoch [179/4000], Discriminator Loss: 0.0884, Generator Loss: 0.0537, Series Loss: 0.0034, Class Loss: 0.2497, Accuracy: 0.1728\n",
      "Epoch [180/4000], Discriminator Loss: 0.0884, Generator Loss: 0.0541, Series Loss: 0.0034, Class Loss: 0.2498, Accuracy: 0.1605\n",
      "Epoch [181/4000], Discriminator Loss: 0.0888, Generator Loss: 0.0539, Series Loss: 0.0034, Class Loss: 0.2498, Accuracy: 0.1728\n",
      "Epoch [182/4000], Discriminator Loss: 0.0888, Generator Loss: 0.0543, Series Loss: 0.0033, Class Loss: 0.2497, Accuracy: 0.1728\n",
      "Epoch [183/4000], Discriminator Loss: 0.0883, Generator Loss: 0.0543, Series Loss: 0.0034, Class Loss: 0.2497, Accuracy: 0.1852\n",
      "Epoch [184/4000], Discriminator Loss: 0.0881, Generator Loss: 0.0543, Series Loss: 0.0032, Class Loss: 0.2497, Accuracy: 0.1790\n",
      "Epoch [185/4000], Discriminator Loss: 0.0882, Generator Loss: 0.0545, Series Loss: 0.0033, Class Loss: 0.2497, Accuracy: 0.1667\n",
      "Epoch [186/4000], Discriminator Loss: 0.0882, Generator Loss: 0.0545, Series Loss: 0.0033, Class Loss: 0.2497, Accuracy: 0.1790\n",
      "Epoch [187/4000], Discriminator Loss: 0.0882, Generator Loss: 0.0540, Series Loss: 0.0032, Class Loss: 0.2498, Accuracy: 0.1728\n",
      "Epoch [188/4000], Discriminator Loss: 0.0879, Generator Loss: 0.0542, Series Loss: 0.0033, Class Loss: 0.2497, Accuracy: 0.1667\n",
      "Epoch [189/4000], Discriminator Loss: 0.0881, Generator Loss: 0.0540, Series Loss: 0.0033, Class Loss: 0.2496, Accuracy: 0.1790\n",
      "Epoch [190/4000], Discriminator Loss: 0.0877, Generator Loss: 0.0542, Series Loss: 0.0032, Class Loss: 0.2497, Accuracy: 0.1728\n",
      "Epoch [191/4000], Discriminator Loss: 0.0882, Generator Loss: 0.0544, Series Loss: 0.0033, Class Loss: 0.2497, Accuracy: 0.1667\n",
      "Epoch [192/4000], Discriminator Loss: 0.0879, Generator Loss: 0.0544, Series Loss: 0.0032, Class Loss: 0.2496, Accuracy: 0.1790\n",
      "Epoch [193/4000], Discriminator Loss: 0.0881, Generator Loss: 0.0544, Series Loss: 0.0032, Class Loss: 0.2497, Accuracy: 0.1605\n",
      "Epoch [194/4000], Discriminator Loss: 0.0878, Generator Loss: 0.0545, Series Loss: 0.0032, Class Loss: 0.2497, Accuracy: 0.1605\n",
      "Epoch [195/4000], Discriminator Loss: 0.0874, Generator Loss: 0.0543, Series Loss: 0.0031, Class Loss: 0.2497, Accuracy: 0.1667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [196/4000], Discriminator Loss: 0.0878, Generator Loss: 0.0548, Series Loss: 0.0032, Class Loss: 0.2496, Accuracy: 0.1728\n",
      "Epoch [197/4000], Discriminator Loss: 0.0881, Generator Loss: 0.0546, Series Loss: 0.0032, Class Loss: 0.2497, Accuracy: 0.1728\n",
      "Epoch [198/4000], Discriminator Loss: 0.0870, Generator Loss: 0.0549, Series Loss: 0.0031, Class Loss: 0.2497, Accuracy: 0.1852\n",
      "Epoch [199/4000], Discriminator Loss: 0.0879, Generator Loss: 0.0547, Series Loss: 0.0031, Class Loss: 0.2498, Accuracy: 0.1728\n",
      "Epoch [200/4000], Discriminator Loss: 0.0879, Generator Loss: 0.0546, Series Loss: 0.0032, Class Loss: 0.2498, Accuracy: 0.1667\n",
      "Epoch [201/4000], Discriminator Loss: 0.0867, Generator Loss: 0.0548, Series Loss: 0.0032, Class Loss: 0.2496, Accuracy: 0.1728\n",
      "Epoch [202/4000], Discriminator Loss: 0.0873, Generator Loss: 0.0548, Series Loss: 0.0032, Class Loss: 0.2498, Accuracy: 0.1605\n",
      "Epoch [203/4000], Discriminator Loss: 0.0874, Generator Loss: 0.0546, Series Loss: 0.0032, Class Loss: 0.2496, Accuracy: 0.1728\n",
      "Epoch [204/4000], Discriminator Loss: 0.0876, Generator Loss: 0.0547, Series Loss: 0.0032, Class Loss: 0.2495, Accuracy: 0.1728\n",
      "Epoch [205/4000], Discriminator Loss: 0.0876, Generator Loss: 0.0548, Series Loss: 0.0031, Class Loss: 0.2498, Accuracy: 0.1728\n",
      "Epoch [206/4000], Discriminator Loss: 0.0882, Generator Loss: 0.0544, Series Loss: 0.0031, Class Loss: 0.2496, Accuracy: 0.1605\n",
      "Epoch [207/4000], Discriminator Loss: 0.0872, Generator Loss: 0.0546, Series Loss: 0.0032, Class Loss: 0.2496, Accuracy: 0.1667\n",
      "Epoch [208/4000], Discriminator Loss: 0.0870, Generator Loss: 0.0547, Series Loss: 0.0030, Class Loss: 0.2496, Accuracy: 0.1790\n",
      "Epoch [209/4000], Discriminator Loss: 0.0875, Generator Loss: 0.0549, Series Loss: 0.0031, Class Loss: 0.2497, Accuracy: 0.1605\n",
      "Epoch [210/4000], Discriminator Loss: 0.0869, Generator Loss: 0.0548, Series Loss: 0.0030, Class Loss: 0.2496, Accuracy: 0.1728\n",
      "Epoch [211/4000], Discriminator Loss: 0.0874, Generator Loss: 0.0550, Series Loss: 0.0030, Class Loss: 0.2495, Accuracy: 0.1667\n",
      "Epoch [212/4000], Discriminator Loss: 0.0871, Generator Loss: 0.0544, Series Loss: 0.0030, Class Loss: 0.2497, Accuracy: 0.1852\n",
      "Epoch [213/4000], Discriminator Loss: 0.0877, Generator Loss: 0.0544, Series Loss: 0.0031, Class Loss: 0.2496, Accuracy: 0.1728\n",
      "Epoch [214/4000], Discriminator Loss: 0.0875, Generator Loss: 0.0547, Series Loss: 0.0031, Class Loss: 0.2495, Accuracy: 0.1667\n",
      "Epoch [215/4000], Discriminator Loss: 0.0864, Generator Loss: 0.0549, Series Loss: 0.0030, Class Loss: 0.2496, Accuracy: 0.1605\n",
      "Epoch [216/4000], Discriminator Loss: 0.0874, Generator Loss: 0.0551, Series Loss: 0.0030, Class Loss: 0.2497, Accuracy: 0.1667\n",
      "Epoch [217/4000], Discriminator Loss: 0.0865, Generator Loss: 0.0550, Series Loss: 0.0030, Class Loss: 0.2497, Accuracy: 0.1605\n",
      "Epoch [218/4000], Discriminator Loss: 0.0874, Generator Loss: 0.0546, Series Loss: 0.0030, Class Loss: 0.2498, Accuracy: 0.1605\n",
      "Epoch [219/4000], Discriminator Loss: 0.0866, Generator Loss: 0.0551, Series Loss: 0.0028, Class Loss: 0.2497, Accuracy: 0.1543\n",
      "Epoch [220/4000], Discriminator Loss: 0.0871, Generator Loss: 0.0547, Series Loss: 0.0029, Class Loss: 0.2497, Accuracy: 0.1543\n",
      "Epoch [221/4000], Discriminator Loss: 0.0863, Generator Loss: 0.0550, Series Loss: 0.0030, Class Loss: 0.2497, Accuracy: 0.1543\n",
      "Epoch [222/4000], Discriminator Loss: 0.0866, Generator Loss: 0.0547, Series Loss: 0.0029, Class Loss: 0.2497, Accuracy: 0.1543\n",
      "Epoch [223/4000], Discriminator Loss: 0.0866, Generator Loss: 0.0546, Series Loss: 0.0029, Class Loss: 0.2497, Accuracy: 0.1543\n",
      "Epoch [224/4000], Discriminator Loss: 0.0872, Generator Loss: 0.0546, Series Loss: 0.0031, Class Loss: 0.2497, Accuracy: 0.1420\n",
      "Epoch [225/4000], Discriminator Loss: 0.0869, Generator Loss: 0.0550, Series Loss: 0.0030, Class Loss: 0.2497, Accuracy: 0.1481\n",
      "Epoch [226/4000], Discriminator Loss: 0.0871, Generator Loss: 0.0550, Series Loss: 0.0030, Class Loss: 0.2497, Accuracy: 0.1481\n",
      "Epoch [227/4000], Discriminator Loss: 0.0872, Generator Loss: 0.0551, Series Loss: 0.0029, Class Loss: 0.2496, Accuracy: 0.1605\n",
      "Epoch [228/4000], Discriminator Loss: 0.0867, Generator Loss: 0.0550, Series Loss: 0.0030, Class Loss: 0.2496, Accuracy: 0.1605\n",
      "Epoch [229/4000], Discriminator Loss: 0.0867, Generator Loss: 0.0544, Series Loss: 0.0030, Class Loss: 0.2497, Accuracy: 0.1358\n",
      "Epoch [230/4000], Discriminator Loss: 0.0868, Generator Loss: 0.0550, Series Loss: 0.0029, Class Loss: 0.2497, Accuracy: 0.1481\n",
      "Epoch [231/4000], Discriminator Loss: 0.0864, Generator Loss: 0.0546, Series Loss: 0.0029, Class Loss: 0.2497, Accuracy: 0.1420\n",
      "Epoch [232/4000], Discriminator Loss: 0.0877, Generator Loss: 0.0547, Series Loss: 0.0029, Class Loss: 0.2498, Accuracy: 0.1420\n",
      "Epoch [233/4000], Discriminator Loss: 0.0863, Generator Loss: 0.0550, Series Loss: 0.0030, Class Loss: 0.2497, Accuracy: 0.1420\n",
      "Epoch [234/4000], Discriminator Loss: 0.0865, Generator Loss: 0.0552, Series Loss: 0.0029, Class Loss: 0.2498, Accuracy: 0.1481\n",
      "Epoch [235/4000], Discriminator Loss: 0.0859, Generator Loss: 0.0556, Series Loss: 0.0029, Class Loss: 0.2496, Accuracy: 0.1358\n",
      "Epoch [236/4000], Discriminator Loss: 0.0871, Generator Loss: 0.0544, Series Loss: 0.0030, Class Loss: 0.2496, Accuracy: 0.1543\n",
      "Epoch [237/4000], Discriminator Loss: 0.0868, Generator Loss: 0.0551, Series Loss: 0.0030, Class Loss: 0.2497, Accuracy: 0.1296\n",
      "Epoch [238/4000], Discriminator Loss: 0.0861, Generator Loss: 0.0549, Series Loss: 0.0030, Class Loss: 0.2496, Accuracy: 0.1543\n",
      "Epoch [239/4000], Discriminator Loss: 0.0863, Generator Loss: 0.0553, Series Loss: 0.0029, Class Loss: 0.2496, Accuracy: 0.1420\n",
      "Epoch [240/4000], Discriminator Loss: 0.0866, Generator Loss: 0.0550, Series Loss: 0.0028, Class Loss: 0.2496, Accuracy: 0.1481\n",
      "Epoch [241/4000], Discriminator Loss: 0.0861, Generator Loss: 0.0552, Series Loss: 0.0029, Class Loss: 0.2497, Accuracy: 0.1481\n",
      "Epoch [242/4000], Discriminator Loss: 0.0865, Generator Loss: 0.0550, Series Loss: 0.0028, Class Loss: 0.2498, Accuracy: 0.1420\n",
      "Epoch [243/4000], Discriminator Loss: 0.0867, Generator Loss: 0.0550, Series Loss: 0.0029, Class Loss: 0.2496, Accuracy: 0.1605\n",
      "Epoch [244/4000], Discriminator Loss: 0.0865, Generator Loss: 0.0552, Series Loss: 0.0029, Class Loss: 0.2496, Accuracy: 0.1358\n",
      "Epoch [245/4000], Discriminator Loss: 0.0863, Generator Loss: 0.0553, Series Loss: 0.0030, Class Loss: 0.2498, Accuracy: 0.1481\n",
      "Epoch [246/4000], Discriminator Loss: 0.0863, Generator Loss: 0.0553, Series Loss: 0.0028, Class Loss: 0.2497, Accuracy: 0.1358\n",
      "Epoch [247/4000], Discriminator Loss: 0.0864, Generator Loss: 0.0549, Series Loss: 0.0029, Class Loss: 0.2497, Accuracy: 0.1481\n",
      "Epoch [248/4000], Discriminator Loss: 0.0862, Generator Loss: 0.0553, Series Loss: 0.0030, Class Loss: 0.2496, Accuracy: 0.1296\n",
      "Epoch [249/4000], Discriminator Loss: 0.0860, Generator Loss: 0.0557, Series Loss: 0.0030, Class Loss: 0.2497, Accuracy: 0.1420\n",
      "Epoch [250/4000], Discriminator Loss: 0.0860, Generator Loss: 0.0554, Series Loss: 0.0029, Class Loss: 0.2497, Accuracy: 0.1481\n",
      "Epoch [251/4000], Discriminator Loss: 0.0860, Generator Loss: 0.0554, Series Loss: 0.0030, Class Loss: 0.2496, Accuracy: 0.1420\n",
      "Epoch [252/4000], Discriminator Loss: 0.0857, Generator Loss: 0.0552, Series Loss: 0.0030, Class Loss: 0.2497, Accuracy: 0.1481\n",
      "Epoch [253/4000], Discriminator Loss: 0.0862, Generator Loss: 0.0555, Series Loss: 0.0029, Class Loss: 0.2498, Accuracy: 0.1481\n",
      "Epoch [254/4000], Discriminator Loss: 0.0861, Generator Loss: 0.0555, Series Loss: 0.0028, Class Loss: 0.2497, Accuracy: 0.1481\n",
      "Epoch [255/4000], Discriminator Loss: 0.0852, Generator Loss: 0.0555, Series Loss: 0.0030, Class Loss: 0.2498, Accuracy: 0.1358\n",
      "Epoch [256/4000], Discriminator Loss: 0.0854, Generator Loss: 0.0554, Series Loss: 0.0030, Class Loss: 0.2498, Accuracy: 0.1296\n",
      "Epoch [257/4000], Discriminator Loss: 0.0858, Generator Loss: 0.0552, Series Loss: 0.0031, Class Loss: 0.2497, Accuracy: 0.1358\n",
      "Epoch [258/4000], Discriminator Loss: 0.0858, Generator Loss: 0.0555, Series Loss: 0.0030, Class Loss: 0.2497, Accuracy: 0.1358\n",
      "Epoch [259/4000], Discriminator Loss: 0.0864, Generator Loss: 0.0551, Series Loss: 0.0030, Class Loss: 0.2496, Accuracy: 0.1481\n",
      "Epoch [260/4000], Discriminator Loss: 0.0861, Generator Loss: 0.0556, Series Loss: 0.0030, Class Loss: 0.2496, Accuracy: 0.1667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [261/4000], Discriminator Loss: 0.0852, Generator Loss: 0.0556, Series Loss: 0.0028, Class Loss: 0.2499, Accuracy: 0.1605\n",
      "Epoch [262/4000], Discriminator Loss: 0.0862, Generator Loss: 0.0555, Series Loss: 0.0030, Class Loss: 0.2498, Accuracy: 0.1481\n",
      "Epoch [263/4000], Discriminator Loss: 0.0864, Generator Loss: 0.0554, Series Loss: 0.0029, Class Loss: 0.2497, Accuracy: 0.1481\n",
      "Epoch [264/4000], Discriminator Loss: 0.0861, Generator Loss: 0.0554, Series Loss: 0.0029, Class Loss: 0.2497, Accuracy: 0.1296\n",
      "Epoch [265/4000], Discriminator Loss: 0.0860, Generator Loss: 0.0560, Series Loss: 0.0029, Class Loss: 0.2497, Accuracy: 0.1420\n",
      "Epoch [266/4000], Discriminator Loss: 0.0856, Generator Loss: 0.0558, Series Loss: 0.0031, Class Loss: 0.2498, Accuracy: 0.1667\n",
      "Epoch [267/4000], Discriminator Loss: 0.0857, Generator Loss: 0.0558, Series Loss: 0.0029, Class Loss: 0.2497, Accuracy: 0.1481\n",
      "Epoch [268/4000], Discriminator Loss: 0.0854, Generator Loss: 0.0552, Series Loss: 0.0029, Class Loss: 0.2497, Accuracy: 0.1420\n",
      "Epoch [269/4000], Discriminator Loss: 0.0860, Generator Loss: 0.0559, Series Loss: 0.0029, Class Loss: 0.2497, Accuracy: 0.1605\n",
      "Epoch [270/4000], Discriminator Loss: 0.0856, Generator Loss: 0.0558, Series Loss: 0.0029, Class Loss: 0.2497, Accuracy: 0.1605\n",
      "Epoch [271/4000], Discriminator Loss: 0.0856, Generator Loss: 0.0557, Series Loss: 0.0029, Class Loss: 0.2497, Accuracy: 0.1358\n",
      "Epoch [272/4000], Discriminator Loss: 0.0849, Generator Loss: 0.0561, Series Loss: 0.0029, Class Loss: 0.2497, Accuracy: 0.1420\n",
      "Epoch [273/4000], Discriminator Loss: 0.0852, Generator Loss: 0.0562, Series Loss: 0.0029, Class Loss: 0.2497, Accuracy: 0.1481\n",
      "Epoch [274/4000], Discriminator Loss: 0.0854, Generator Loss: 0.0558, Series Loss: 0.0029, Class Loss: 0.2497, Accuracy: 0.1358\n",
      "Epoch [275/4000], Discriminator Loss: 0.0859, Generator Loss: 0.0555, Series Loss: 0.0030, Class Loss: 0.2498, Accuracy: 0.1543\n",
      "Epoch [276/4000], Discriminator Loss: 0.0848, Generator Loss: 0.0561, Series Loss: 0.0029, Class Loss: 0.2499, Accuracy: 0.1358\n",
      "Epoch [277/4000], Discriminator Loss: 0.0855, Generator Loss: 0.0561, Series Loss: 0.0030, Class Loss: 0.2496, Accuracy: 0.1543\n",
      "Epoch [278/4000], Discriminator Loss: 0.0853, Generator Loss: 0.0558, Series Loss: 0.0030, Class Loss: 0.2496, Accuracy: 0.1728\n",
      "Epoch [279/4000], Discriminator Loss: 0.0846, Generator Loss: 0.0561, Series Loss: 0.0029, Class Loss: 0.2497, Accuracy: 0.1420\n",
      "Epoch [280/4000], Discriminator Loss: 0.0852, Generator Loss: 0.0563, Series Loss: 0.0031, Class Loss: 0.2497, Accuracy: 0.1235\n",
      "Epoch [281/4000], Discriminator Loss: 0.0854, Generator Loss: 0.0570, Series Loss: 0.0029, Class Loss: 0.2497, Accuracy: 0.1543\n",
      "Epoch [282/4000], Discriminator Loss: 0.0853, Generator Loss: 0.0565, Series Loss: 0.0029, Class Loss: 0.2496, Accuracy: 0.1296\n",
      "Epoch [283/4000], Discriminator Loss: 0.0852, Generator Loss: 0.0564, Series Loss: 0.0030, Class Loss: 0.2496, Accuracy: 0.1914\n",
      "Epoch [284/4000], Discriminator Loss: 0.0844, Generator Loss: 0.0565, Series Loss: 0.0029, Class Loss: 0.2497, Accuracy: 0.1667\n",
      "Epoch [285/4000], Discriminator Loss: 0.0849, Generator Loss: 0.0567, Series Loss: 0.0029, Class Loss: 0.2497, Accuracy: 0.1728\n",
      "Epoch [286/4000], Discriminator Loss: 0.0856, Generator Loss: 0.0561, Series Loss: 0.0029, Class Loss: 0.2496, Accuracy: 0.2099\n",
      "Epoch [287/4000], Discriminator Loss: 0.0850, Generator Loss: 0.0565, Series Loss: 0.0030, Class Loss: 0.2498, Accuracy: 0.1481\n",
      "Epoch [288/4000], Discriminator Loss: 0.0857, Generator Loss: 0.0563, Series Loss: 0.0030, Class Loss: 0.2496, Accuracy: 0.1358\n",
      "Epoch [289/4000], Discriminator Loss: 0.0854, Generator Loss: 0.0559, Series Loss: 0.0030, Class Loss: 0.2496, Accuracy: 0.2284\n",
      "Epoch [290/4000], Discriminator Loss: 0.0848, Generator Loss: 0.0568, Series Loss: 0.0031, Class Loss: 0.2499, Accuracy: 0.1975\n",
      "Epoch [291/4000], Discriminator Loss: 0.0850, Generator Loss: 0.0565, Series Loss: 0.0030, Class Loss: 0.2497, Accuracy: 0.1728\n",
      "Epoch [292/4000], Discriminator Loss: 0.0851, Generator Loss: 0.0564, Series Loss: 0.0030, Class Loss: 0.2496, Accuracy: 0.1852\n",
      "Epoch [293/4000], Discriminator Loss: 0.0848, Generator Loss: 0.0558, Series Loss: 0.0030, Class Loss: 0.2498, Accuracy: 0.2160\n",
      "Epoch [294/4000], Discriminator Loss: 0.0848, Generator Loss: 0.0568, Series Loss: 0.0030, Class Loss: 0.2497, Accuracy: 0.2222\n",
      "Epoch [295/4000], Discriminator Loss: 0.0849, Generator Loss: 0.0565, Series Loss: 0.0031, Class Loss: 0.2498, Accuracy: 0.1420\n",
      "Epoch [296/4000], Discriminator Loss: 0.0849, Generator Loss: 0.0563, Series Loss: 0.0030, Class Loss: 0.2498, Accuracy: 0.2284\n",
      "Epoch [297/4000], Discriminator Loss: 0.0853, Generator Loss: 0.0572, Series Loss: 0.0030, Class Loss: 0.2498, Accuracy: 0.1914\n",
      "Epoch [298/4000], Discriminator Loss: 0.0848, Generator Loss: 0.0570, Series Loss: 0.0029, Class Loss: 0.2498, Accuracy: 0.1728\n",
      "Epoch [299/4000], Discriminator Loss: 0.0846, Generator Loss: 0.0571, Series Loss: 0.0030, Class Loss: 0.2498, Accuracy: 0.2099\n",
      "Epoch [300/4000], Discriminator Loss: 0.0853, Generator Loss: 0.0571, Series Loss: 0.0030, Class Loss: 0.2498, Accuracy: 0.3272\n",
      "Epoch [301/4000], Discriminator Loss: 0.0849, Generator Loss: 0.0569, Series Loss: 0.0031, Class Loss: 0.2499, Accuracy: 0.1975\n",
      "Epoch [302/4000], Discriminator Loss: 0.0848, Generator Loss: 0.0563, Series Loss: 0.0031, Class Loss: 0.2497, Accuracy: 0.1728\n",
      "Epoch [303/4000], Discriminator Loss: 0.0847, Generator Loss: 0.0570, Series Loss: 0.0031, Class Loss: 0.2496, Accuracy: 0.2346\n",
      "Epoch [304/4000], Discriminator Loss: 0.0844, Generator Loss: 0.0570, Series Loss: 0.0030, Class Loss: 0.2495, Accuracy: 0.1728\n",
      "Epoch [305/4000], Discriminator Loss: 0.0845, Generator Loss: 0.0567, Series Loss: 0.0030, Class Loss: 0.2496, Accuracy: 0.1481\n",
      "Epoch [306/4000], Discriminator Loss: 0.0840, Generator Loss: 0.0567, Series Loss: 0.0030, Class Loss: 0.2497, Accuracy: 0.1605\n",
      "Epoch [307/4000], Discriminator Loss: 0.0847, Generator Loss: 0.0574, Series Loss: 0.0030, Class Loss: 0.2496, Accuracy: 0.1728\n",
      "Epoch [308/4000], Discriminator Loss: 0.0844, Generator Loss: 0.0569, Series Loss: 0.0032, Class Loss: 0.2497, Accuracy: 0.2407\n",
      "Epoch [309/4000], Discriminator Loss: 0.0850, Generator Loss: 0.0570, Series Loss: 0.0030, Class Loss: 0.2497, Accuracy: 0.2346\n",
      "Epoch [310/4000], Discriminator Loss: 0.0843, Generator Loss: 0.0569, Series Loss: 0.0031, Class Loss: 0.2497, Accuracy: 0.2037\n",
      "Epoch [311/4000], Discriminator Loss: 0.0846, Generator Loss: 0.0570, Series Loss: 0.0031, Class Loss: 0.2497, Accuracy: 0.1728\n",
      "Epoch [312/4000], Discriminator Loss: 0.0838, Generator Loss: 0.0577, Series Loss: 0.0031, Class Loss: 0.2495, Accuracy: 0.1667\n",
      "Epoch [313/4000], Discriminator Loss: 0.0845, Generator Loss: 0.0570, Series Loss: 0.0031, Class Loss: 0.2496, Accuracy: 0.1420\n",
      "Epoch [314/4000], Discriminator Loss: 0.0845, Generator Loss: 0.0569, Series Loss: 0.0031, Class Loss: 0.2497, Accuracy: 0.2099\n",
      "Epoch [315/4000], Discriminator Loss: 0.0851, Generator Loss: 0.0568, Series Loss: 0.0032, Class Loss: 0.2498, Accuracy: 0.2037\n",
      "Epoch [316/4000], Discriminator Loss: 0.0843, Generator Loss: 0.0571, Series Loss: 0.0031, Class Loss: 0.2498, Accuracy: 0.1420\n",
      "Epoch [317/4000], Discriminator Loss: 0.0841, Generator Loss: 0.0581, Series Loss: 0.0032, Class Loss: 0.2496, Accuracy: 0.1914\n",
      "Epoch [318/4000], Discriminator Loss: 0.0842, Generator Loss: 0.0568, Series Loss: 0.0032, Class Loss: 0.2495, Accuracy: 0.1235\n",
      "Epoch [319/4000], Discriminator Loss: 0.0850, Generator Loss: 0.0568, Series Loss: 0.0032, Class Loss: 0.2497, Accuracy: 0.1975\n",
      "Epoch [320/4000], Discriminator Loss: 0.0843, Generator Loss: 0.0581, Series Loss: 0.0031, Class Loss: 0.2497, Accuracy: 0.2531\n",
      "Epoch [321/4000], Discriminator Loss: 0.0842, Generator Loss: 0.0572, Series Loss: 0.0030, Class Loss: 0.2496, Accuracy: 0.1481\n",
      "Epoch [322/4000], Discriminator Loss: 0.0840, Generator Loss: 0.0571, Series Loss: 0.0032, Class Loss: 0.2497, Accuracy: 0.1667\n",
      "Epoch [323/4000], Discriminator Loss: 0.0839, Generator Loss: 0.0574, Series Loss: 0.0033, Class Loss: 0.2497, Accuracy: 0.1296\n",
      "Epoch [324/4000], Discriminator Loss: 0.0841, Generator Loss: 0.0578, Series Loss: 0.0031, Class Loss: 0.2496, Accuracy: 0.1605\n",
      "Epoch [325/4000], Discriminator Loss: 0.0841, Generator Loss: 0.0575, Series Loss: 0.0032, Class Loss: 0.2495, Accuracy: 0.2346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [326/4000], Discriminator Loss: 0.0843, Generator Loss: 0.0573, Series Loss: 0.0032, Class Loss: 0.2496, Accuracy: 0.2469\n",
      "Epoch [327/4000], Discriminator Loss: 0.0834, Generator Loss: 0.0573, Series Loss: 0.0033, Class Loss: 0.2497, Accuracy: 0.1296\n",
      "Epoch [328/4000], Discriminator Loss: 0.0842, Generator Loss: 0.0579, Series Loss: 0.0031, Class Loss: 0.2495, Accuracy: 0.2099\n",
      "Epoch [329/4000], Discriminator Loss: 0.0843, Generator Loss: 0.0575, Series Loss: 0.0032, Class Loss: 0.2495, Accuracy: 0.1049\n",
      "Epoch [330/4000], Discriminator Loss: 0.0842, Generator Loss: 0.0569, Series Loss: 0.0034, Class Loss: 0.2496, Accuracy: 0.1605\n",
      "Epoch [331/4000], Discriminator Loss: 0.0843, Generator Loss: 0.0578, Series Loss: 0.0033, Class Loss: 0.2498, Accuracy: 0.1481\n",
      "Epoch [332/4000], Discriminator Loss: 0.0843, Generator Loss: 0.0574, Series Loss: 0.0033, Class Loss: 0.2496, Accuracy: 0.1481\n",
      "Epoch [333/4000], Discriminator Loss: 0.0839, Generator Loss: 0.0577, Series Loss: 0.0033, Class Loss: 0.2496, Accuracy: 0.1173\n",
      "Epoch [334/4000], Discriminator Loss: 0.0843, Generator Loss: 0.0576, Series Loss: 0.0031, Class Loss: 0.2495, Accuracy: 0.1235\n",
      "Epoch [335/4000], Discriminator Loss: 0.0839, Generator Loss: 0.0568, Series Loss: 0.0033, Class Loss: 0.2496, Accuracy: 0.1420\n",
      "Epoch [336/4000], Discriminator Loss: 0.0836, Generator Loss: 0.0573, Series Loss: 0.0032, Class Loss: 0.2496, Accuracy: 0.1235\n",
      "Epoch [337/4000], Discriminator Loss: 0.0841, Generator Loss: 0.0571, Series Loss: 0.0033, Class Loss: 0.2496, Accuracy: 0.1543\n",
      "Epoch [338/4000], Discriminator Loss: 0.0851, Generator Loss: 0.0559, Series Loss: 0.0032, Class Loss: 0.2497, Accuracy: 0.1667\n",
      "Epoch [339/4000], Discriminator Loss: 0.0846, Generator Loss: 0.0563, Series Loss: 0.0031, Class Loss: 0.2497, Accuracy: 0.1790\n",
      "Epoch [340/4000], Discriminator Loss: 0.0848, Generator Loss: 0.0558, Series Loss: 0.0031, Class Loss: 0.2497, Accuracy: 0.1790\n",
      "Epoch [341/4000], Discriminator Loss: 0.0855, Generator Loss: 0.0552, Series Loss: 0.0031, Class Loss: 0.2496, Accuracy: 0.1543\n",
      "Epoch [342/4000], Discriminator Loss: 0.0850, Generator Loss: 0.0558, Series Loss: 0.0031, Class Loss: 0.2497, Accuracy: 0.2037\n",
      "Epoch [343/4000], Discriminator Loss: 0.0856, Generator Loss: 0.0551, Series Loss: 0.0030, Class Loss: 0.2496, Accuracy: 0.1975\n",
      "Epoch [344/4000], Discriminator Loss: 0.0846, Generator Loss: 0.0560, Series Loss: 0.0031, Class Loss: 0.2497, Accuracy: 0.2469\n",
      "Epoch [345/4000], Discriminator Loss: 0.0859, Generator Loss: 0.0549, Series Loss: 0.0032, Class Loss: 0.2498, Accuracy: 0.2284\n",
      "Epoch [346/4000], Discriminator Loss: 0.0847, Generator Loss: 0.0559, Series Loss: 0.0030, Class Loss: 0.2497, Accuracy: 0.2160\n",
      "Epoch [347/4000], Discriminator Loss: 0.0858, Generator Loss: 0.0550, Series Loss: 0.0032, Class Loss: 0.2497, Accuracy: 0.1728\n",
      "Epoch [348/4000], Discriminator Loss: 0.0860, Generator Loss: 0.0550, Series Loss: 0.0030, Class Loss: 0.2497, Accuracy: 0.1975\n",
      "Epoch [349/4000], Discriminator Loss: 0.0856, Generator Loss: 0.0554, Series Loss: 0.0032, Class Loss: 0.2497, Accuracy: 0.1975\n",
      "Epoch [350/4000], Discriminator Loss: 0.0864, Generator Loss: 0.0546, Series Loss: 0.0031, Class Loss: 0.2497, Accuracy: 0.2037\n",
      "Epoch [351/4000], Discriminator Loss: 0.0865, Generator Loss: 0.0547, Series Loss: 0.0032, Class Loss: 0.2496, Accuracy: 0.2284\n",
      "Epoch [352/4000], Discriminator Loss: 0.0861, Generator Loss: 0.0548, Series Loss: 0.0031, Class Loss: 0.2498, Accuracy: 0.1667\n",
      "Epoch [353/4000], Discriminator Loss: 0.0854, Generator Loss: 0.0556, Series Loss: 0.0032, Class Loss: 0.2496, Accuracy: 0.2901\n",
      "Epoch [354/4000], Discriminator Loss: 0.0863, Generator Loss: 0.0551, Series Loss: 0.0031, Class Loss: 0.2496, Accuracy: 0.2346\n",
      "Epoch [355/4000], Discriminator Loss: 0.0857, Generator Loss: 0.0548, Series Loss: 0.0031, Class Loss: 0.2496, Accuracy: 0.1914\n",
      "Epoch [356/4000], Discriminator Loss: 0.0857, Generator Loss: 0.0549, Series Loss: 0.0032, Class Loss: 0.2496, Accuracy: 0.2778\n",
      "Epoch [357/4000], Discriminator Loss: 0.0872, Generator Loss: 0.0546, Series Loss: 0.0032, Class Loss: 0.2496, Accuracy: 0.1543\n",
      "Epoch [358/4000], Discriminator Loss: 0.0863, Generator Loss: 0.0549, Series Loss: 0.0032, Class Loss: 0.2496, Accuracy: 0.2840\n",
      "Epoch [359/4000], Discriminator Loss: 0.0864, Generator Loss: 0.0548, Series Loss: 0.0032, Class Loss: 0.2496, Accuracy: 0.1852\n",
      "Epoch [360/4000], Discriminator Loss: 0.0874, Generator Loss: 0.0551, Series Loss: 0.0033, Class Loss: 0.2495, Accuracy: 0.2593\n",
      "Epoch [361/4000], Discriminator Loss: 0.0866, Generator Loss: 0.0549, Series Loss: 0.0034, Class Loss: 0.2497, Accuracy: 0.2901\n",
      "Epoch [362/4000], Discriminator Loss: 0.0876, Generator Loss: 0.0544, Series Loss: 0.0031, Class Loss: 0.2496, Accuracy: 0.2346\n",
      "Epoch [363/4000], Discriminator Loss: 0.0870, Generator Loss: 0.0551, Series Loss: 0.0032, Class Loss: 0.2495, Accuracy: 0.2654\n",
      "Epoch [364/4000], Discriminator Loss: 0.0864, Generator Loss: 0.0543, Series Loss: 0.0032, Class Loss: 0.2497, Accuracy: 0.2160\n",
      "Epoch [365/4000], Discriminator Loss: 0.0878, Generator Loss: 0.0543, Series Loss: 0.0034, Class Loss: 0.2496, Accuracy: 0.2469\n",
      "Epoch [366/4000], Discriminator Loss: 0.0875, Generator Loss: 0.0541, Series Loss: 0.0034, Class Loss: 0.2497, Accuracy: 0.3086\n",
      "Epoch [367/4000], Discriminator Loss: 0.0867, Generator Loss: 0.0546, Series Loss: 0.0034, Class Loss: 0.2496, Accuracy: 0.2531\n",
      "Epoch [368/4000], Discriminator Loss: 0.0873, Generator Loss: 0.0548, Series Loss: 0.0033, Class Loss: 0.2497, Accuracy: 0.2037\n",
      "Epoch [369/4000], Discriminator Loss: 0.0873, Generator Loss: 0.0549, Series Loss: 0.0033, Class Loss: 0.2497, Accuracy: 0.2593\n",
      "Epoch [370/4000], Discriminator Loss: 0.0868, Generator Loss: 0.0550, Series Loss: 0.0034, Class Loss: 0.2496, Accuracy: 0.2346\n",
      "Epoch [371/4000], Discriminator Loss: 0.0871, Generator Loss: 0.0545, Series Loss: 0.0034, Class Loss: 0.2495, Accuracy: 0.3333\n",
      "Epoch [372/4000], Discriminator Loss: 0.0867, Generator Loss: 0.0551, Series Loss: 0.0035, Class Loss: 0.2497, Accuracy: 0.2716\n",
      "Epoch [373/4000], Discriminator Loss: 0.0865, Generator Loss: 0.0541, Series Loss: 0.0035, Class Loss: 0.2496, Accuracy: 0.3025\n",
      "Epoch [374/4000], Discriminator Loss: 0.0875, Generator Loss: 0.0542, Series Loss: 0.0035, Class Loss: 0.2496, Accuracy: 0.3333\n",
      "Epoch [375/4000], Discriminator Loss: 0.0874, Generator Loss: 0.0549, Series Loss: 0.0034, Class Loss: 0.2495, Accuracy: 0.2654\n",
      "Epoch [376/4000], Discriminator Loss: 0.0874, Generator Loss: 0.0544, Series Loss: 0.0035, Class Loss: 0.2497, Accuracy: 0.2716\n",
      "Epoch [377/4000], Discriminator Loss: 0.0874, Generator Loss: 0.0552, Series Loss: 0.0035, Class Loss: 0.2497, Accuracy: 0.2716\n",
      "Epoch [378/4000], Discriminator Loss: 0.0864, Generator Loss: 0.0547, Series Loss: 0.0035, Class Loss: 0.2496, Accuracy: 0.2284\n",
      "Epoch [379/4000], Discriminator Loss: 0.0878, Generator Loss: 0.0551, Series Loss: 0.0036, Class Loss: 0.2498, Accuracy: 0.2901\n",
      "Epoch [380/4000], Discriminator Loss: 0.0875, Generator Loss: 0.0542, Series Loss: 0.0037, Class Loss: 0.2496, Accuracy: 0.3333\n",
      "Epoch [381/4000], Discriminator Loss: 0.0865, Generator Loss: 0.0560, Series Loss: 0.0035, Class Loss: 0.2498, Accuracy: 0.2160\n",
      "Epoch [382/4000], Discriminator Loss: 0.0879, Generator Loss: 0.0539, Series Loss: 0.0037, Class Loss: 0.2497, Accuracy: 0.3395\n",
      "Epoch [383/4000], Discriminator Loss: 0.0867, Generator Loss: 0.0548, Series Loss: 0.0036, Class Loss: 0.2496, Accuracy: 0.2716\n",
      "Epoch [384/4000], Discriminator Loss: 0.0866, Generator Loss: 0.0550, Series Loss: 0.0035, Class Loss: 0.2497, Accuracy: 0.2531\n",
      "Epoch [385/4000], Discriminator Loss: 0.0880, Generator Loss: 0.0543, Series Loss: 0.0036, Class Loss: 0.2497, Accuracy: 0.3889\n",
      "Epoch [386/4000], Discriminator Loss: 0.0870, Generator Loss: 0.0547, Series Loss: 0.0037, Class Loss: 0.2496, Accuracy: 0.3272\n",
      "Epoch [387/4000], Discriminator Loss: 0.0868, Generator Loss: 0.0551, Series Loss: 0.0038, Class Loss: 0.2496, Accuracy: 0.2778\n",
      "Epoch [388/4000], Discriminator Loss: 0.0871, Generator Loss: 0.0553, Series Loss: 0.0036, Class Loss: 0.2496, Accuracy: 0.2778\n",
      "Epoch [389/4000], Discriminator Loss: 0.0873, Generator Loss: 0.0553, Series Loss: 0.0039, Class Loss: 0.2498, Accuracy: 0.3333\n",
      "Epoch [390/4000], Discriminator Loss: 0.0885, Generator Loss: 0.0542, Series Loss: 0.0038, Class Loss: 0.2498, Accuracy: 0.2778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [391/4000], Discriminator Loss: 0.0883, Generator Loss: 0.0546, Series Loss: 0.0039, Class Loss: 0.2498, Accuracy: 0.3395\n",
      "Epoch [392/4000], Discriminator Loss: 0.0880, Generator Loss: 0.0540, Series Loss: 0.0039, Class Loss: 0.2496, Accuracy: 0.3148\n",
      "Epoch [393/4000], Discriminator Loss: 0.0884, Generator Loss: 0.0537, Series Loss: 0.0039, Class Loss: 0.2497, Accuracy: 0.3272\n",
      "Epoch [394/4000], Discriminator Loss: 0.0874, Generator Loss: 0.0547, Series Loss: 0.0038, Class Loss: 0.2496, Accuracy: 0.3333\n",
      "Epoch [395/4000], Discriminator Loss: 0.0881, Generator Loss: 0.0544, Series Loss: 0.0037, Class Loss: 0.2498, Accuracy: 0.3272\n",
      "Epoch [396/4000], Discriminator Loss: 0.0878, Generator Loss: 0.0542, Series Loss: 0.0039, Class Loss: 0.2497, Accuracy: 0.3395\n",
      "Epoch [397/4000], Discriminator Loss: 0.0874, Generator Loss: 0.0551, Series Loss: 0.0038, Class Loss: 0.2497, Accuracy: 0.3148\n",
      "Epoch [398/4000], Discriminator Loss: 0.0879, Generator Loss: 0.0551, Series Loss: 0.0037, Class Loss: 0.2497, Accuracy: 0.3457\n",
      "Epoch [399/4000], Discriminator Loss: 0.0871, Generator Loss: 0.0541, Series Loss: 0.0039, Class Loss: 0.2495, Accuracy: 0.2840\n",
      "Epoch [400/4000], Discriminator Loss: 0.0871, Generator Loss: 0.0547, Series Loss: 0.0039, Class Loss: 0.2497, Accuracy: 0.3827\n",
      "Epoch [401/4000], Discriminator Loss: 0.0877, Generator Loss: 0.0547, Series Loss: 0.0040, Class Loss: 0.2495, Accuracy: 0.2654\n",
      "Epoch [402/4000], Discriminator Loss: 0.0873, Generator Loss: 0.0546, Series Loss: 0.0040, Class Loss: 0.2497, Accuracy: 0.3642\n",
      "Epoch [403/4000], Discriminator Loss: 0.0867, Generator Loss: 0.0550, Series Loss: 0.0040, Class Loss: 0.2497, Accuracy: 0.3765\n",
      "Epoch [404/4000], Discriminator Loss: 0.0876, Generator Loss: 0.0545, Series Loss: 0.0039, Class Loss: 0.2498, Accuracy: 0.3457\n",
      "Epoch [405/4000], Discriminator Loss: 0.0883, Generator Loss: 0.0541, Series Loss: 0.0041, Class Loss: 0.2497, Accuracy: 0.4198\n",
      "Epoch [406/4000], Discriminator Loss: 0.0877, Generator Loss: 0.0548, Series Loss: 0.0040, Class Loss: 0.2496, Accuracy: 0.3951\n",
      "Epoch [407/4000], Discriminator Loss: 0.0880, Generator Loss: 0.0549, Series Loss: 0.0040, Class Loss: 0.2497, Accuracy: 0.3827\n",
      "Epoch [408/4000], Discriminator Loss: 0.0878, Generator Loss: 0.0543, Series Loss: 0.0041, Class Loss: 0.2497, Accuracy: 0.4012\n",
      "Epoch [409/4000], Discriminator Loss: 0.0879, Generator Loss: 0.0547, Series Loss: 0.0041, Class Loss: 0.2497, Accuracy: 0.4815\n",
      "Epoch [410/4000], Discriminator Loss: 0.0876, Generator Loss: 0.0555, Series Loss: 0.0041, Class Loss: 0.2496, Accuracy: 0.4877\n",
      "Epoch [411/4000], Discriminator Loss: 0.0875, Generator Loss: 0.0546, Series Loss: 0.0040, Class Loss: 0.2497, Accuracy: 0.3642\n",
      "Epoch [412/4000], Discriminator Loss: 0.0880, Generator Loss: 0.0548, Series Loss: 0.0040, Class Loss: 0.2496, Accuracy: 0.4321\n",
      "Epoch [413/4000], Discriminator Loss: 0.0877, Generator Loss: 0.0548, Series Loss: 0.0041, Class Loss: 0.2496, Accuracy: 0.4568\n",
      "Epoch [414/4000], Discriminator Loss: 0.0877, Generator Loss: 0.0543, Series Loss: 0.0040, Class Loss: 0.2498, Accuracy: 0.2963\n",
      "Epoch [415/4000], Discriminator Loss: 0.0874, Generator Loss: 0.0549, Series Loss: 0.0041, Class Loss: 0.2497, Accuracy: 0.2840\n",
      "Epoch [416/4000], Discriminator Loss: 0.0892, Generator Loss: 0.0553, Series Loss: 0.0041, Class Loss: 0.2497, Accuracy: 0.4815\n",
      "Epoch [417/4000], Discriminator Loss: 0.0879, Generator Loss: 0.0558, Series Loss: 0.0040, Class Loss: 0.2497, Accuracy: 0.3333\n",
      "Epoch [418/4000], Discriminator Loss: 0.0880, Generator Loss: 0.0545, Series Loss: 0.0040, Class Loss: 0.2497, Accuracy: 0.3086\n",
      "Epoch [419/4000], Discriminator Loss: 0.0884, Generator Loss: 0.0551, Series Loss: 0.0040, Class Loss: 0.2496, Accuracy: 0.3765\n",
      "Epoch [420/4000], Discriminator Loss: 0.0873, Generator Loss: 0.0550, Series Loss: 0.0042, Class Loss: 0.2497, Accuracy: 0.3086\n",
      "Epoch [421/4000], Discriminator Loss: 0.0861, Generator Loss: 0.0551, Series Loss: 0.0041, Class Loss: 0.2496, Accuracy: 0.3704\n",
      "Epoch [422/4000], Discriminator Loss: 0.0875, Generator Loss: 0.0550, Series Loss: 0.0044, Class Loss: 0.2498, Accuracy: 0.4444\n",
      "Epoch [423/4000], Discriminator Loss: 0.0874, Generator Loss: 0.0555, Series Loss: 0.0042, Class Loss: 0.2495, Accuracy: 0.4198\n",
      "Epoch [424/4000], Discriminator Loss: 0.0875, Generator Loss: 0.0557, Series Loss: 0.0043, Class Loss: 0.2495, Accuracy: 0.4198\n",
      "Epoch [425/4000], Discriminator Loss: 0.0878, Generator Loss: 0.0550, Series Loss: 0.0043, Class Loss: 0.2498, Accuracy: 0.4444\n",
      "Epoch [426/4000], Discriminator Loss: 0.0870, Generator Loss: 0.0550, Series Loss: 0.0045, Class Loss: 0.2498, Accuracy: 0.3827\n",
      "Epoch [427/4000], Discriminator Loss: 0.0879, Generator Loss: 0.0551, Series Loss: 0.0042, Class Loss: 0.2497, Accuracy: 0.4259\n",
      "Epoch [428/4000], Discriminator Loss: 0.0872, Generator Loss: 0.0550, Series Loss: 0.0045, Class Loss: 0.2496, Accuracy: 0.4321\n",
      "Epoch [429/4000], Discriminator Loss: 0.0870, Generator Loss: 0.0548, Series Loss: 0.0043, Class Loss: 0.2497, Accuracy: 0.3951\n",
      "Epoch [430/4000], Discriminator Loss: 0.0865, Generator Loss: 0.0556, Series Loss: 0.0042, Class Loss: 0.2497, Accuracy: 0.4136\n",
      "Epoch [431/4000], Discriminator Loss: 0.0867, Generator Loss: 0.0553, Series Loss: 0.0043, Class Loss: 0.2496, Accuracy: 0.4444\n",
      "Epoch [432/4000], Discriminator Loss: 0.0873, Generator Loss: 0.0554, Series Loss: 0.0042, Class Loss: 0.2495, Accuracy: 0.3148\n",
      "Epoch [433/4000], Discriminator Loss: 0.0878, Generator Loss: 0.0552, Series Loss: 0.0043, Class Loss: 0.2497, Accuracy: 0.3889\n",
      "Epoch [434/4000], Discriminator Loss: 0.0871, Generator Loss: 0.0561, Series Loss: 0.0042, Class Loss: 0.2496, Accuracy: 0.3519\n",
      "Epoch [435/4000], Discriminator Loss: 0.0874, Generator Loss: 0.0553, Series Loss: 0.0044, Class Loss: 0.2497, Accuracy: 0.4259\n",
      "Epoch [436/4000], Discriminator Loss: 0.0875, Generator Loss: 0.0558, Series Loss: 0.0043, Class Loss: 0.2496, Accuracy: 0.3333\n",
      "Epoch [437/4000], Discriminator Loss: 0.0862, Generator Loss: 0.0560, Series Loss: 0.0043, Class Loss: 0.2497, Accuracy: 0.3889\n",
      "Epoch [438/4000], Discriminator Loss: 0.0874, Generator Loss: 0.0556, Series Loss: 0.0044, Class Loss: 0.2497, Accuracy: 0.4444\n",
      "Epoch [439/4000], Discriminator Loss: 0.0869, Generator Loss: 0.0557, Series Loss: 0.0042, Class Loss: 0.2497, Accuracy: 0.4136\n",
      "Epoch [440/4000], Discriminator Loss: 0.0866, Generator Loss: 0.0561, Series Loss: 0.0045, Class Loss: 0.2496, Accuracy: 0.4321\n",
      "Epoch [441/4000], Discriminator Loss: 0.0866, Generator Loss: 0.0563, Series Loss: 0.0044, Class Loss: 0.2495, Accuracy: 0.4568\n",
      "Epoch [442/4000], Discriminator Loss: 0.0874, Generator Loss: 0.0561, Series Loss: 0.0043, Class Loss: 0.2494, Accuracy: 0.4259\n",
      "Epoch [443/4000], Discriminator Loss: 0.0868, Generator Loss: 0.0567, Series Loss: 0.0043, Class Loss: 0.2496, Accuracy: 0.3519\n",
      "Epoch [444/4000], Discriminator Loss: 0.0873, Generator Loss: 0.0551, Series Loss: 0.0044, Class Loss: 0.2495, Accuracy: 0.5494\n",
      "Epoch [445/4000], Discriminator Loss: 0.0886, Generator Loss: 0.0551, Series Loss: 0.0044, Class Loss: 0.2495, Accuracy: 0.5494\n",
      "Epoch [446/4000], Discriminator Loss: 0.0871, Generator Loss: 0.0565, Series Loss: 0.0045, Class Loss: 0.2496, Accuracy: 0.4506\n",
      "Epoch [447/4000], Discriminator Loss: 0.0879, Generator Loss: 0.0562, Series Loss: 0.0042, Class Loss: 0.2494, Accuracy: 0.4691\n",
      "Epoch [448/4000], Discriminator Loss: 0.0871, Generator Loss: 0.0564, Series Loss: 0.0044, Class Loss: 0.2496, Accuracy: 0.4877\n",
      "Epoch [449/4000], Discriminator Loss: 0.0865, Generator Loss: 0.0556, Series Loss: 0.0044, Class Loss: 0.2496, Accuracy: 0.5185\n",
      "Epoch [450/4000], Discriminator Loss: 0.0872, Generator Loss: 0.0565, Series Loss: 0.0044, Class Loss: 0.2496, Accuracy: 0.5185\n",
      "Epoch [451/4000], Discriminator Loss: 0.0862, Generator Loss: 0.0558, Series Loss: 0.0044, Class Loss: 0.2496, Accuracy: 0.5247\n",
      "Epoch [452/4000], Discriminator Loss: 0.0865, Generator Loss: 0.0556, Series Loss: 0.0046, Class Loss: 0.2496, Accuracy: 0.5494\n",
      "Epoch [453/4000], Discriminator Loss: 0.0873, Generator Loss: 0.0564, Series Loss: 0.0045, Class Loss: 0.2496, Accuracy: 0.4691\n",
      "Epoch [454/4000], Discriminator Loss: 0.0862, Generator Loss: 0.0565, Series Loss: 0.0045, Class Loss: 0.2496, Accuracy: 0.4877\n",
      "Epoch [455/4000], Discriminator Loss: 0.0866, Generator Loss: 0.0572, Series Loss: 0.0045, Class Loss: 0.2495, Accuracy: 0.4753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [456/4000], Discriminator Loss: 0.0868, Generator Loss: 0.0561, Series Loss: 0.0046, Class Loss: 0.2495, Accuracy: 0.5123\n",
      "Epoch [457/4000], Discriminator Loss: 0.0862, Generator Loss: 0.0568, Series Loss: 0.0045, Class Loss: 0.2495, Accuracy: 0.4938\n",
      "Epoch [458/4000], Discriminator Loss: 0.0866, Generator Loss: 0.0568, Series Loss: 0.0046, Class Loss: 0.2495, Accuracy: 0.5432\n",
      "Epoch [459/4000], Discriminator Loss: 0.0868, Generator Loss: 0.0559, Series Loss: 0.0045, Class Loss: 0.2496, Accuracy: 0.5679\n",
      "Epoch [460/4000], Discriminator Loss: 0.0867, Generator Loss: 0.0558, Series Loss: 0.0045, Class Loss: 0.2497, Accuracy: 0.5494\n",
      "Epoch [461/4000], Discriminator Loss: 0.0866, Generator Loss: 0.0567, Series Loss: 0.0045, Class Loss: 0.2497, Accuracy: 0.5185\n",
      "Epoch [462/4000], Discriminator Loss: 0.0868, Generator Loss: 0.0566, Series Loss: 0.0045, Class Loss: 0.2496, Accuracy: 0.5679\n",
      "Epoch [463/4000], Discriminator Loss: 0.0868, Generator Loss: 0.0563, Series Loss: 0.0046, Class Loss: 0.2495, Accuracy: 0.5123\n",
      "Epoch [464/4000], Discriminator Loss: 0.0854, Generator Loss: 0.0569, Series Loss: 0.0047, Class Loss: 0.2496, Accuracy: 0.4753\n",
      "Epoch [465/4000], Discriminator Loss: 0.0866, Generator Loss: 0.0563, Series Loss: 0.0046, Class Loss: 0.2496, Accuracy: 0.5370\n",
      "Epoch [466/4000], Discriminator Loss: 0.0862, Generator Loss: 0.0566, Series Loss: 0.0046, Class Loss: 0.2496, Accuracy: 0.4938\n",
      "Epoch [467/4000], Discriminator Loss: 0.0863, Generator Loss: 0.0567, Series Loss: 0.0045, Class Loss: 0.2496, Accuracy: 0.5185\n",
      "Epoch [468/4000], Discriminator Loss: 0.0866, Generator Loss: 0.0565, Series Loss: 0.0045, Class Loss: 0.2496, Accuracy: 0.4938\n",
      "Epoch [469/4000], Discriminator Loss: 0.0865, Generator Loss: 0.0562, Series Loss: 0.0046, Class Loss: 0.2496, Accuracy: 0.5988\n",
      "Epoch [470/4000], Discriminator Loss: 0.0861, Generator Loss: 0.0566, Series Loss: 0.0046, Class Loss: 0.2495, Accuracy: 0.4259\n",
      "Epoch [471/4000], Discriminator Loss: 0.0856, Generator Loss: 0.0576, Series Loss: 0.0046, Class Loss: 0.2495, Accuracy: 0.4506\n",
      "Epoch [472/4000], Discriminator Loss: 0.0862, Generator Loss: 0.0575, Series Loss: 0.0044, Class Loss: 0.2495, Accuracy: 0.4877\n",
      "Epoch [473/4000], Discriminator Loss: 0.0855, Generator Loss: 0.0569, Series Loss: 0.0045, Class Loss: 0.2495, Accuracy: 0.4506\n",
      "Epoch [474/4000], Discriminator Loss: 0.0862, Generator Loss: 0.0567, Series Loss: 0.0046, Class Loss: 0.2496, Accuracy: 0.4383\n",
      "Epoch [475/4000], Discriminator Loss: 0.0857, Generator Loss: 0.0581, Series Loss: 0.0047, Class Loss: 0.2496, Accuracy: 0.4444\n",
      "Epoch [476/4000], Discriminator Loss: 0.0860, Generator Loss: 0.0569, Series Loss: 0.0047, Class Loss: 0.2494, Accuracy: 0.3457\n",
      "Epoch [477/4000], Discriminator Loss: 0.0863, Generator Loss: 0.0577, Series Loss: 0.0045, Class Loss: 0.2495, Accuracy: 0.4259\n",
      "Epoch [478/4000], Discriminator Loss: 0.0849, Generator Loss: 0.0578, Series Loss: 0.0046, Class Loss: 0.2495, Accuracy: 0.3765\n",
      "Epoch [479/4000], Discriminator Loss: 0.0862, Generator Loss: 0.0574, Series Loss: 0.0047, Class Loss: 0.2496, Accuracy: 0.3704\n",
      "Epoch [480/4000], Discriminator Loss: 0.0863, Generator Loss: 0.0570, Series Loss: 0.0045, Class Loss: 0.2495, Accuracy: 0.4568\n",
      "Epoch [481/4000], Discriminator Loss: 0.0852, Generator Loss: 0.0576, Series Loss: 0.0047, Class Loss: 0.2495, Accuracy: 0.4691\n",
      "Epoch [482/4000], Discriminator Loss: 0.0858, Generator Loss: 0.0568, Series Loss: 0.0047, Class Loss: 0.2494, Accuracy: 0.3580\n",
      "Epoch [483/4000], Discriminator Loss: 0.0861, Generator Loss: 0.0577, Series Loss: 0.0047, Class Loss: 0.2495, Accuracy: 0.4815\n",
      "Epoch [484/4000], Discriminator Loss: 0.0854, Generator Loss: 0.0577, Series Loss: 0.0045, Class Loss: 0.2494, Accuracy: 0.3519\n",
      "Epoch [485/4000], Discriminator Loss: 0.0854, Generator Loss: 0.0577, Series Loss: 0.0047, Class Loss: 0.2494, Accuracy: 0.2346\n",
      "Epoch [486/4000], Discriminator Loss: 0.0857, Generator Loss: 0.0579, Series Loss: 0.0047, Class Loss: 0.2494, Accuracy: 0.2469\n",
      "Epoch [487/4000], Discriminator Loss: 0.0859, Generator Loss: 0.0574, Series Loss: 0.0047, Class Loss: 0.2494, Accuracy: 0.3333\n",
      "Epoch [488/4000], Discriminator Loss: 0.0860, Generator Loss: 0.0576, Series Loss: 0.0047, Class Loss: 0.2495, Accuracy: 0.3765\n",
      "Epoch [489/4000], Discriminator Loss: 0.0857, Generator Loss: 0.0577, Series Loss: 0.0046, Class Loss: 0.2495, Accuracy: 0.3765\n",
      "Epoch [490/4000], Discriminator Loss: 0.0845, Generator Loss: 0.0587, Series Loss: 0.0045, Class Loss: 0.2493, Accuracy: 0.2716\n",
      "Epoch [491/4000], Discriminator Loss: 0.0849, Generator Loss: 0.0581, Series Loss: 0.0047, Class Loss: 0.2492, Accuracy: 0.2407\n",
      "Epoch [492/4000], Discriminator Loss: 0.0852, Generator Loss: 0.0581, Series Loss: 0.0047, Class Loss: 0.2493, Accuracy: 0.1605\n",
      "Epoch [493/4000], Discriminator Loss: 0.0853, Generator Loss: 0.0578, Series Loss: 0.0047, Class Loss: 0.2493, Accuracy: 0.1852\n",
      "Epoch [494/4000], Discriminator Loss: 0.0855, Generator Loss: 0.0579, Series Loss: 0.0047, Class Loss: 0.2493, Accuracy: 0.1852\n",
      "Epoch [495/4000], Discriminator Loss: 0.0852, Generator Loss: 0.0580, Series Loss: 0.0047, Class Loss: 0.2492, Accuracy: 0.2901\n",
      "Epoch [496/4000], Discriminator Loss: 0.0854, Generator Loss: 0.0574, Series Loss: 0.0048, Class Loss: 0.2493, Accuracy: 0.2531\n",
      "Epoch [497/4000], Discriminator Loss: 0.0851, Generator Loss: 0.0583, Series Loss: 0.0048, Class Loss: 0.2494, Accuracy: 0.2407\n",
      "Epoch [498/4000], Discriminator Loss: 0.0848, Generator Loss: 0.0581, Series Loss: 0.0047, Class Loss: 0.2493, Accuracy: 0.1914\n",
      "Epoch [499/4000], Discriminator Loss: 0.0851, Generator Loss: 0.0579, Series Loss: 0.0047, Class Loss: 0.2492, Accuracy: 0.2037\n",
      "Epoch [500/4000], Discriminator Loss: 0.0848, Generator Loss: 0.0581, Series Loss: 0.0047, Class Loss: 0.2493, Accuracy: 0.1481\n",
      "Epoch [501/4000], Discriminator Loss: 0.0853, Generator Loss: 0.0580, Series Loss: 0.0045, Class Loss: 0.2493, Accuracy: 0.1543\n",
      "Epoch [502/4000], Discriminator Loss: 0.0855, Generator Loss: 0.0580, Series Loss: 0.0046, Class Loss: 0.2494, Accuracy: 0.1790\n",
      "Epoch [503/4000], Discriminator Loss: 0.0859, Generator Loss: 0.0579, Series Loss: 0.0046, Class Loss: 0.2493, Accuracy: 0.1420\n",
      "Epoch [504/4000], Discriminator Loss: 0.0856, Generator Loss: 0.0577, Series Loss: 0.0046, Class Loss: 0.2494, Accuracy: 0.1296\n",
      "Epoch [505/4000], Discriminator Loss: 0.0852, Generator Loss: 0.0580, Series Loss: 0.0047, Class Loss: 0.2493, Accuracy: 0.1543\n",
      "Epoch [506/4000], Discriminator Loss: 0.0852, Generator Loss: 0.0580, Series Loss: 0.0046, Class Loss: 0.2492, Accuracy: 0.1790\n",
      "Epoch [507/4000], Discriminator Loss: 0.0850, Generator Loss: 0.0580, Series Loss: 0.0049, Class Loss: 0.2494, Accuracy: 0.1358\n",
      "Epoch [508/4000], Discriminator Loss: 0.0852, Generator Loss: 0.0579, Series Loss: 0.0047, Class Loss: 0.2493, Accuracy: 0.1605\n",
      "Epoch [509/4000], Discriminator Loss: 0.0859, Generator Loss: 0.0581, Series Loss: 0.0049, Class Loss: 0.2492, Accuracy: 0.1358\n",
      "Epoch [510/4000], Discriminator Loss: 0.0856, Generator Loss: 0.0570, Series Loss: 0.0047, Class Loss: 0.2493, Accuracy: 0.1605\n",
      "Epoch [511/4000], Discriminator Loss: 0.0850, Generator Loss: 0.0579, Series Loss: 0.0048, Class Loss: 0.2492, Accuracy: 0.1481\n",
      "Epoch [512/4000], Discriminator Loss: 0.0858, Generator Loss: 0.0578, Series Loss: 0.0048, Class Loss: 0.2492, Accuracy: 0.1543\n",
      "Epoch [513/4000], Discriminator Loss: 0.0857, Generator Loss: 0.0581, Series Loss: 0.0047, Class Loss: 0.2492, Accuracy: 0.1235\n",
      "Epoch [514/4000], Discriminator Loss: 0.0861, Generator Loss: 0.0577, Series Loss: 0.0047, Class Loss: 0.2493, Accuracy: 0.1481\n",
      "Epoch [515/4000], Discriminator Loss: 0.0854, Generator Loss: 0.0580, Series Loss: 0.0048, Class Loss: 0.2492, Accuracy: 0.1358\n",
      "Epoch [516/4000], Discriminator Loss: 0.0850, Generator Loss: 0.0575, Series Loss: 0.0047, Class Loss: 0.2495, Accuracy: 0.1358\n",
      "Epoch [517/4000], Discriminator Loss: 0.0855, Generator Loss: 0.0585, Series Loss: 0.0047, Class Loss: 0.2490, Accuracy: 0.1481\n",
      "Epoch [518/4000], Discriminator Loss: 0.0862, Generator Loss: 0.0574, Series Loss: 0.0048, Class Loss: 0.2491, Accuracy: 0.1296\n",
      "Epoch [519/4000], Discriminator Loss: 0.0861, Generator Loss: 0.0577, Series Loss: 0.0048, Class Loss: 0.2491, Accuracy: 0.1605\n",
      "Epoch [520/4000], Discriminator Loss: 0.0861, Generator Loss: 0.0577, Series Loss: 0.0048, Class Loss: 0.2491, Accuracy: 0.1420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [521/4000], Discriminator Loss: 0.0855, Generator Loss: 0.0577, Series Loss: 0.0046, Class Loss: 0.2493, Accuracy: 0.1420\n",
      "Epoch [522/4000], Discriminator Loss: 0.0862, Generator Loss: 0.0574, Series Loss: 0.0047, Class Loss: 0.2492, Accuracy: 0.1235\n",
      "Epoch [523/4000], Discriminator Loss: 0.0862, Generator Loss: 0.0571, Series Loss: 0.0048, Class Loss: 0.2494, Accuracy: 0.1358\n",
      "Epoch [524/4000], Discriminator Loss: 0.0857, Generator Loss: 0.0576, Series Loss: 0.0048, Class Loss: 0.2491, Accuracy: 0.1358\n",
      "Epoch [525/4000], Discriminator Loss: 0.0864, Generator Loss: 0.0579, Series Loss: 0.0047, Class Loss: 0.2492, Accuracy: 0.1296\n",
      "Epoch [526/4000], Discriminator Loss: 0.0860, Generator Loss: 0.0576, Series Loss: 0.0047, Class Loss: 0.2494, Accuracy: 0.1358\n",
      "Epoch [527/4000], Discriminator Loss: 0.0863, Generator Loss: 0.0576, Series Loss: 0.0046, Class Loss: 0.2491, Accuracy: 0.1420\n",
      "Epoch [528/4000], Discriminator Loss: 0.0866, Generator Loss: 0.0576, Series Loss: 0.0047, Class Loss: 0.2492, Accuracy: 0.1358\n",
      "Epoch [529/4000], Discriminator Loss: 0.0861, Generator Loss: 0.0577, Series Loss: 0.0048, Class Loss: 0.2492, Accuracy: 0.1111\n",
      "Epoch [530/4000], Discriminator Loss: 0.0874, Generator Loss: 0.0573, Series Loss: 0.0046, Class Loss: 0.2491, Accuracy: 0.1111\n",
      "Epoch [531/4000], Discriminator Loss: 0.0866, Generator Loss: 0.0576, Series Loss: 0.0047, Class Loss: 0.2491, Accuracy: 0.1235\n",
      "Epoch [532/4000], Discriminator Loss: 0.0866, Generator Loss: 0.0575, Series Loss: 0.0047, Class Loss: 0.2491, Accuracy: 0.1481\n",
      "Epoch [533/4000], Discriminator Loss: 0.0869, Generator Loss: 0.0571, Series Loss: 0.0045, Class Loss: 0.2491, Accuracy: 0.1358\n",
      "Epoch [534/4000], Discriminator Loss: 0.0868, Generator Loss: 0.0569, Series Loss: 0.0045, Class Loss: 0.2492, Accuracy: 0.1173\n",
      "Epoch [535/4000], Discriminator Loss: 0.0866, Generator Loss: 0.0570, Series Loss: 0.0045, Class Loss: 0.2492, Accuracy: 0.1173\n",
      "Epoch [536/4000], Discriminator Loss: 0.0872, Generator Loss: 0.0572, Series Loss: 0.0044, Class Loss: 0.2493, Accuracy: 0.0926\n",
      "Epoch [537/4000], Discriminator Loss: 0.0873, Generator Loss: 0.0570, Series Loss: 0.0043, Class Loss: 0.2495, Accuracy: 0.1235\n",
      "Epoch [538/4000], Discriminator Loss: 0.0870, Generator Loss: 0.0569, Series Loss: 0.0044, Class Loss: 0.2491, Accuracy: 0.1235\n",
      "Epoch [539/4000], Discriminator Loss: 0.0873, Generator Loss: 0.0566, Series Loss: 0.0043, Class Loss: 0.2492, Accuracy: 0.1111\n",
      "Epoch [540/4000], Discriminator Loss: 0.0872, Generator Loss: 0.0570, Series Loss: 0.0044, Class Loss: 0.2493, Accuracy: 0.1111\n",
      "Epoch [541/4000], Discriminator Loss: 0.0880, Generator Loss: 0.0570, Series Loss: 0.0043, Class Loss: 0.2490, Accuracy: 0.1173\n",
      "Epoch [542/4000], Discriminator Loss: 0.0878, Generator Loss: 0.0567, Series Loss: 0.0042, Class Loss: 0.2493, Accuracy: 0.0926\n",
      "Epoch [543/4000], Discriminator Loss: 0.0876, Generator Loss: 0.0567, Series Loss: 0.0043, Class Loss: 0.2490, Accuracy: 0.1358\n",
      "Epoch [544/4000], Discriminator Loss: 0.0875, Generator Loss: 0.0563, Series Loss: 0.0042, Class Loss: 0.2493, Accuracy: 0.0864\n",
      "Epoch [545/4000], Discriminator Loss: 0.0872, Generator Loss: 0.0563, Series Loss: 0.0042, Class Loss: 0.2493, Accuracy: 0.0988\n",
      "Epoch [546/4000], Discriminator Loss: 0.0881, Generator Loss: 0.0566, Series Loss: 0.0042, Class Loss: 0.2492, Accuracy: 0.1173\n",
      "Epoch [547/4000], Discriminator Loss: 0.0871, Generator Loss: 0.0567, Series Loss: 0.0041, Class Loss: 0.2490, Accuracy: 0.1111\n",
      "Epoch [548/4000], Discriminator Loss: 0.0867, Generator Loss: 0.0566, Series Loss: 0.0041, Class Loss: 0.2493, Accuracy: 0.0988\n",
      "Epoch [549/4000], Discriminator Loss: 0.0874, Generator Loss: 0.0566, Series Loss: 0.0040, Class Loss: 0.2492, Accuracy: 0.0864\n",
      "Epoch [550/4000], Discriminator Loss: 0.0876, Generator Loss: 0.0568, Series Loss: 0.0041, Class Loss: 0.2492, Accuracy: 0.0988\n",
      "Epoch [551/4000], Discriminator Loss: 0.0869, Generator Loss: 0.0564, Series Loss: 0.0041, Class Loss: 0.2492, Accuracy: 0.1049\n",
      "Epoch [552/4000], Discriminator Loss: 0.0871, Generator Loss: 0.0561, Series Loss: 0.0039, Class Loss: 0.2491, Accuracy: 0.0864\n",
      "Epoch [553/4000], Discriminator Loss: 0.0878, Generator Loss: 0.0564, Series Loss: 0.0041, Class Loss: 0.2493, Accuracy: 0.0679\n",
      "Epoch [554/4000], Discriminator Loss: 0.0876, Generator Loss: 0.0569, Series Loss: 0.0041, Class Loss: 0.2492, Accuracy: 0.0679\n",
      "Epoch [555/4000], Discriminator Loss: 0.0875, Generator Loss: 0.0566, Series Loss: 0.0040, Class Loss: 0.2492, Accuracy: 0.0864\n",
      "Epoch [556/4000], Discriminator Loss: 0.0874, Generator Loss: 0.0566, Series Loss: 0.0041, Class Loss: 0.2492, Accuracy: 0.0741\n",
      "Epoch [557/4000], Discriminator Loss: 0.0869, Generator Loss: 0.0568, Series Loss: 0.0040, Class Loss: 0.2492, Accuracy: 0.0802\n",
      "Epoch [558/4000], Discriminator Loss: 0.0871, Generator Loss: 0.0569, Series Loss: 0.0039, Class Loss: 0.2492, Accuracy: 0.0802\n",
      "Epoch [559/4000], Discriminator Loss: 0.0874, Generator Loss: 0.0567, Series Loss: 0.0041, Class Loss: 0.2493, Accuracy: 0.0741\n",
      "Epoch [560/4000], Discriminator Loss: 0.0878, Generator Loss: 0.0566, Series Loss: 0.0040, Class Loss: 0.2494, Accuracy: 0.0741\n",
      "Epoch [561/4000], Discriminator Loss: 0.0875, Generator Loss: 0.0564, Series Loss: 0.0041, Class Loss: 0.2494, Accuracy: 0.0802\n",
      "Epoch [562/4000], Discriminator Loss: 0.0877, Generator Loss: 0.0562, Series Loss: 0.0040, Class Loss: 0.2495, Accuracy: 0.0802\n",
      "Epoch [563/4000], Discriminator Loss: 0.0870, Generator Loss: 0.0566, Series Loss: 0.0040, Class Loss: 0.2492, Accuracy: 0.0802\n",
      "Epoch [564/4000], Discriminator Loss: 0.0878, Generator Loss: 0.0563, Series Loss: 0.0039, Class Loss: 0.2492, Accuracy: 0.0864\n",
      "Epoch [565/4000], Discriminator Loss: 0.0879, Generator Loss: 0.0566, Series Loss: 0.0039, Class Loss: 0.2493, Accuracy: 0.0802\n",
      "Epoch [566/4000], Discriminator Loss: 0.0873, Generator Loss: 0.0565, Series Loss: 0.0039, Class Loss: 0.2492, Accuracy: 0.0926\n",
      "Epoch [567/4000], Discriminator Loss: 0.0883, Generator Loss: 0.0563, Series Loss: 0.0040, Class Loss: 0.2494, Accuracy: 0.0741\n",
      "Epoch [568/4000], Discriminator Loss: 0.0885, Generator Loss: 0.0565, Series Loss: 0.0040, Class Loss: 0.2492, Accuracy: 0.1049\n",
      "Epoch [569/4000], Discriminator Loss: 0.0869, Generator Loss: 0.0565, Series Loss: 0.0039, Class Loss: 0.2493, Accuracy: 0.0988\n",
      "Epoch [570/4000], Discriminator Loss: 0.0874, Generator Loss: 0.0570, Series Loss: 0.0039, Class Loss: 0.2494, Accuracy: 0.0741\n",
      "Epoch [571/4000], Discriminator Loss: 0.0869, Generator Loss: 0.0565, Series Loss: 0.0039, Class Loss: 0.2492, Accuracy: 0.0926\n",
      "Epoch [572/4000], Discriminator Loss: 0.0878, Generator Loss: 0.0565, Series Loss: 0.0039, Class Loss: 0.2494, Accuracy: 0.0864\n",
      "Epoch [573/4000], Discriminator Loss: 0.0873, Generator Loss: 0.0566, Series Loss: 0.0039, Class Loss: 0.2492, Accuracy: 0.0988\n",
      "Epoch [574/4000], Discriminator Loss: 0.0875, Generator Loss: 0.0564, Series Loss: 0.0039, Class Loss: 0.2493, Accuracy: 0.0988\n",
      "Epoch [575/4000], Discriminator Loss: 0.0870, Generator Loss: 0.0566, Series Loss: 0.0039, Class Loss: 0.2495, Accuracy: 0.0679\n",
      "Epoch [576/4000], Discriminator Loss: 0.0874, Generator Loss: 0.0566, Series Loss: 0.0039, Class Loss: 0.2493, Accuracy: 0.0864\n",
      "Epoch [577/4000], Discriminator Loss: 0.0871, Generator Loss: 0.0569, Series Loss: 0.0039, Class Loss: 0.2495, Accuracy: 0.0741\n",
      "Epoch [578/4000], Discriminator Loss: 0.0870, Generator Loss: 0.0564, Series Loss: 0.0039, Class Loss: 0.2493, Accuracy: 0.0741\n",
      "Epoch [579/4000], Discriminator Loss: 0.0873, Generator Loss: 0.0567, Series Loss: 0.0039, Class Loss: 0.2494, Accuracy: 0.0864\n",
      "Epoch [580/4000], Discriminator Loss: 0.0867, Generator Loss: 0.0566, Series Loss: 0.0038, Class Loss: 0.2493, Accuracy: 0.0926\n",
      "Epoch [581/4000], Discriminator Loss: 0.0876, Generator Loss: 0.0563, Series Loss: 0.0039, Class Loss: 0.2492, Accuracy: 0.0802\n",
      "Epoch [582/4000], Discriminator Loss: 0.0872, Generator Loss: 0.0566, Series Loss: 0.0041, Class Loss: 0.2492, Accuracy: 0.0864\n",
      "Epoch [583/4000], Discriminator Loss: 0.0875, Generator Loss: 0.0567, Series Loss: 0.0041, Class Loss: 0.2491, Accuracy: 0.1111\n",
      "Epoch [584/4000], Discriminator Loss: 0.0871, Generator Loss: 0.0568, Series Loss: 0.0040, Class Loss: 0.2492, Accuracy: 0.0988\n",
      "Epoch [585/4000], Discriminator Loss: 0.0878, Generator Loss: 0.0571, Series Loss: 0.0040, Class Loss: 0.2492, Accuracy: 0.0988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [586/4000], Discriminator Loss: 0.0869, Generator Loss: 0.0569, Series Loss: 0.0040, Class Loss: 0.2494, Accuracy: 0.0926\n",
      "Epoch [587/4000], Discriminator Loss: 0.0871, Generator Loss: 0.0567, Series Loss: 0.0041, Class Loss: 0.2493, Accuracy: 0.0802\n",
      "Epoch [588/4000], Discriminator Loss: 0.0867, Generator Loss: 0.0567, Series Loss: 0.0040, Class Loss: 0.2494, Accuracy: 0.0864\n",
      "Epoch [589/4000], Discriminator Loss: 0.0879, Generator Loss: 0.0564, Series Loss: 0.0040, Class Loss: 0.2494, Accuracy: 0.0741\n",
      "Epoch [590/4000], Discriminator Loss: 0.0874, Generator Loss: 0.0568, Series Loss: 0.0041, Class Loss: 0.2494, Accuracy: 0.0802\n",
      "Epoch [591/4000], Discriminator Loss: 0.0875, Generator Loss: 0.0568, Series Loss: 0.0040, Class Loss: 0.2492, Accuracy: 0.0988\n",
      "Epoch [592/4000], Discriminator Loss: 0.0872, Generator Loss: 0.0569, Series Loss: 0.0040, Class Loss: 0.2492, Accuracy: 0.0802\n",
      "Epoch [593/4000], Discriminator Loss: 0.0869, Generator Loss: 0.0569, Series Loss: 0.0042, Class Loss: 0.2492, Accuracy: 0.0802\n",
      "Epoch [594/4000], Discriminator Loss: 0.0874, Generator Loss: 0.0569, Series Loss: 0.0041, Class Loss: 0.2493, Accuracy: 0.0864\n",
      "Epoch [595/4000], Discriminator Loss: 0.0863, Generator Loss: 0.0569, Series Loss: 0.0041, Class Loss: 0.2494, Accuracy: 0.0864\n",
      "Epoch [596/4000], Discriminator Loss: 0.0861, Generator Loss: 0.0569, Series Loss: 0.0041, Class Loss: 0.2493, Accuracy: 0.0988\n",
      "Epoch [597/4000], Discriminator Loss: 0.0870, Generator Loss: 0.0566, Series Loss: 0.0041, Class Loss: 0.2494, Accuracy: 0.0926\n",
      "Epoch [598/4000], Discriminator Loss: 0.0867, Generator Loss: 0.0566, Series Loss: 0.0042, Class Loss: 0.2492, Accuracy: 0.0741\n",
      "Epoch [599/4000], Discriminator Loss: 0.0870, Generator Loss: 0.0567, Series Loss: 0.0041, Class Loss: 0.2493, Accuracy: 0.0926\n",
      "Epoch [600/4000], Discriminator Loss: 0.0877, Generator Loss: 0.0568, Series Loss: 0.0042, Class Loss: 0.2495, Accuracy: 0.0864\n",
      "Epoch [601/4000], Discriminator Loss: 0.0868, Generator Loss: 0.0568, Series Loss: 0.0042, Class Loss: 0.2494, Accuracy: 0.0741\n",
      "Epoch [602/4000], Discriminator Loss: 0.0869, Generator Loss: 0.0569, Series Loss: 0.0043, Class Loss: 0.2493, Accuracy: 0.0864\n",
      "Epoch [603/4000], Discriminator Loss: 0.0864, Generator Loss: 0.0565, Series Loss: 0.0043, Class Loss: 0.2493, Accuracy: 0.0864\n",
      "Epoch [604/4000], Discriminator Loss: 0.0873, Generator Loss: 0.0569, Series Loss: 0.0043, Class Loss: 0.2494, Accuracy: 0.0864\n",
      "Epoch [605/4000], Discriminator Loss: 0.0874, Generator Loss: 0.0568, Series Loss: 0.0043, Class Loss: 0.2492, Accuracy: 0.0988\n",
      "Epoch [606/4000], Discriminator Loss: 0.0872, Generator Loss: 0.0567, Series Loss: 0.0043, Class Loss: 0.2494, Accuracy: 0.0864\n",
      "Epoch [607/4000], Discriminator Loss: 0.0874, Generator Loss: 0.0567, Series Loss: 0.0043, Class Loss: 0.2493, Accuracy: 0.0926\n",
      "Epoch [608/4000], Discriminator Loss: 0.0862, Generator Loss: 0.0570, Series Loss: 0.0042, Class Loss: 0.2493, Accuracy: 0.0988\n",
      "Epoch [609/4000], Discriminator Loss: 0.0866, Generator Loss: 0.0567, Series Loss: 0.0043, Class Loss: 0.2492, Accuracy: 0.0926\n",
      "Epoch [610/4000], Discriminator Loss: 0.0873, Generator Loss: 0.0572, Series Loss: 0.0043, Class Loss: 0.2494, Accuracy: 0.0926\n",
      "Epoch [611/4000], Discriminator Loss: 0.0866, Generator Loss: 0.0566, Series Loss: 0.0043, Class Loss: 0.2493, Accuracy: 0.0802\n",
      "Epoch [612/4000], Discriminator Loss: 0.0868, Generator Loss: 0.0562, Series Loss: 0.0041, Class Loss: 0.2493, Accuracy: 0.0926\n",
      "Epoch [613/4000], Discriminator Loss: 0.0871, Generator Loss: 0.0564, Series Loss: 0.0043, Class Loss: 0.2494, Accuracy: 0.0864\n",
      "Epoch [614/4000], Discriminator Loss: 0.0867, Generator Loss: 0.0571, Series Loss: 0.0043, Class Loss: 0.2492, Accuracy: 0.0926\n",
      "Epoch [615/4000], Discriminator Loss: 0.0867, Generator Loss: 0.0572, Series Loss: 0.0043, Class Loss: 0.2494, Accuracy: 0.0926\n",
      "Epoch [616/4000], Discriminator Loss: 0.0872, Generator Loss: 0.0566, Series Loss: 0.0044, Class Loss: 0.2493, Accuracy: 0.1049\n",
      "Epoch [617/4000], Discriminator Loss: 0.0869, Generator Loss: 0.0570, Series Loss: 0.0044, Class Loss: 0.2493, Accuracy: 0.0864\n",
      "Epoch [618/4000], Discriminator Loss: 0.0870, Generator Loss: 0.0567, Series Loss: 0.0044, Class Loss: 0.2495, Accuracy: 0.0741\n",
      "Epoch [619/4000], Discriminator Loss: 0.0871, Generator Loss: 0.0571, Series Loss: 0.0043, Class Loss: 0.2493, Accuracy: 0.0988\n",
      "Epoch [620/4000], Discriminator Loss: 0.0858, Generator Loss: 0.0563, Series Loss: 0.0044, Class Loss: 0.2493, Accuracy: 0.0741\n",
      "Epoch [621/4000], Discriminator Loss: 0.0875, Generator Loss: 0.0563, Series Loss: 0.0045, Class Loss: 0.2494, Accuracy: 0.0864\n",
      "Epoch [622/4000], Discriminator Loss: 0.0866, Generator Loss: 0.0569, Series Loss: 0.0043, Class Loss: 0.2494, Accuracy: 0.0864\n",
      "Epoch [623/4000], Discriminator Loss: 0.0871, Generator Loss: 0.0565, Series Loss: 0.0045, Class Loss: 0.2493, Accuracy: 0.0864\n",
      "Epoch [624/4000], Discriminator Loss: 0.0867, Generator Loss: 0.0572, Series Loss: 0.0044, Class Loss: 0.2493, Accuracy: 0.0864\n",
      "Epoch [625/4000], Discriminator Loss: 0.0874, Generator Loss: 0.0572, Series Loss: 0.0045, Class Loss: 0.2494, Accuracy: 0.0988\n",
      "Epoch [626/4000], Discriminator Loss: 0.0870, Generator Loss: 0.0567, Series Loss: 0.0044, Class Loss: 0.2492, Accuracy: 0.0802\n",
      "Epoch [627/4000], Discriminator Loss: 0.0868, Generator Loss: 0.0564, Series Loss: 0.0046, Class Loss: 0.2492, Accuracy: 0.0926\n",
      "Epoch [628/4000], Discriminator Loss: 0.0868, Generator Loss: 0.0571, Series Loss: 0.0046, Class Loss: 0.2494, Accuracy: 0.0802\n",
      "Epoch [629/4000], Discriminator Loss: 0.0862, Generator Loss: 0.0577, Series Loss: 0.0047, Class Loss: 0.2493, Accuracy: 0.0802\n",
      "Epoch [630/4000], Discriminator Loss: 0.0868, Generator Loss: 0.0569, Series Loss: 0.0045, Class Loss: 0.2493, Accuracy: 0.0926\n",
      "Epoch [631/4000], Discriminator Loss: 0.0873, Generator Loss: 0.0569, Series Loss: 0.0046, Class Loss: 0.2493, Accuracy: 0.0802\n",
      "Epoch [632/4000], Discriminator Loss: 0.0868, Generator Loss: 0.0566, Series Loss: 0.0047, Class Loss: 0.2495, Accuracy: 0.0802\n",
      "Epoch [633/4000], Discriminator Loss: 0.0868, Generator Loss: 0.0570, Series Loss: 0.0046, Class Loss: 0.2494, Accuracy: 0.0988\n",
      "Epoch [634/4000], Discriminator Loss: 0.0863, Generator Loss: 0.0569, Series Loss: 0.0047, Class Loss: 0.2492, Accuracy: 0.1049\n",
      "Epoch [635/4000], Discriminator Loss: 0.0864, Generator Loss: 0.0575, Series Loss: 0.0047, Class Loss: 0.2493, Accuracy: 0.0864\n",
      "Epoch [636/4000], Discriminator Loss: 0.0868, Generator Loss: 0.0570, Series Loss: 0.0047, Class Loss: 0.2496, Accuracy: 0.0802\n",
      "Epoch [637/4000], Discriminator Loss: 0.0864, Generator Loss: 0.0568, Series Loss: 0.0045, Class Loss: 0.2493, Accuracy: 0.0802\n",
      "Epoch [638/4000], Discriminator Loss: 0.0858, Generator Loss: 0.0573, Series Loss: 0.0047, Class Loss: 0.2493, Accuracy: 0.0926\n",
      "Epoch [639/4000], Discriminator Loss: 0.0865, Generator Loss: 0.0569, Series Loss: 0.0047, Class Loss: 0.2493, Accuracy: 0.0802\n",
      "Epoch [640/4000], Discriminator Loss: 0.0865, Generator Loss: 0.0573, Series Loss: 0.0048, Class Loss: 0.2495, Accuracy: 0.0802\n",
      "Epoch [641/4000], Discriminator Loss: 0.0861, Generator Loss: 0.0577, Series Loss: 0.0047, Class Loss: 0.2493, Accuracy: 0.0926\n",
      "Epoch [642/4000], Discriminator Loss: 0.0860, Generator Loss: 0.0571, Series Loss: 0.0047, Class Loss: 0.2493, Accuracy: 0.0926\n",
      "Epoch [643/4000], Discriminator Loss: 0.0862, Generator Loss: 0.0571, Series Loss: 0.0048, Class Loss: 0.2494, Accuracy: 0.0741\n",
      "Epoch [644/4000], Discriminator Loss: 0.0865, Generator Loss: 0.0569, Series Loss: 0.0046, Class Loss: 0.2494, Accuracy: 0.0926\n",
      "Epoch [645/4000], Discriminator Loss: 0.0863, Generator Loss: 0.0573, Series Loss: 0.0047, Class Loss: 0.2493, Accuracy: 0.0864\n",
      "Epoch [646/4000], Discriminator Loss: 0.0865, Generator Loss: 0.0568, Series Loss: 0.0048, Class Loss: 0.2493, Accuracy: 0.0802\n",
      "Epoch [647/4000], Discriminator Loss: 0.0870, Generator Loss: 0.0567, Series Loss: 0.0047, Class Loss: 0.2493, Accuracy: 0.0988\n",
      "Epoch [648/4000], Discriminator Loss: 0.0863, Generator Loss: 0.0571, Series Loss: 0.0048, Class Loss: 0.2495, Accuracy: 0.0617\n",
      "Epoch [649/4000], Discriminator Loss: 0.0873, Generator Loss: 0.0570, Series Loss: 0.0049, Class Loss: 0.2493, Accuracy: 0.0802\n",
      "Epoch [650/4000], Discriminator Loss: 0.0867, Generator Loss: 0.0568, Series Loss: 0.0048, Class Loss: 0.2493, Accuracy: 0.0741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [651/4000], Discriminator Loss: 0.0877, Generator Loss: 0.0570, Series Loss: 0.0049, Class Loss: 0.2492, Accuracy: 0.0741\n",
      "Epoch [652/4000], Discriminator Loss: 0.0866, Generator Loss: 0.0576, Series Loss: 0.0049, Class Loss: 0.2492, Accuracy: 0.0556\n",
      "Epoch [653/4000], Discriminator Loss: 0.0870, Generator Loss: 0.0570, Series Loss: 0.0049, Class Loss: 0.2495, Accuracy: 0.0741\n",
      "Epoch [654/4000], Discriminator Loss: 0.0866, Generator Loss: 0.0573, Series Loss: 0.0049, Class Loss: 0.2494, Accuracy: 0.0802\n",
      "Epoch [655/4000], Discriminator Loss: 0.0873, Generator Loss: 0.0568, Series Loss: 0.0049, Class Loss: 0.2493, Accuracy: 0.0617\n",
      "Epoch [656/4000], Discriminator Loss: 0.0869, Generator Loss: 0.0570, Series Loss: 0.0050, Class Loss: 0.2492, Accuracy: 0.0988\n",
      "Epoch [657/4000], Discriminator Loss: 0.0872, Generator Loss: 0.0573, Series Loss: 0.0051, Class Loss: 0.2493, Accuracy: 0.0617\n",
      "Epoch [658/4000], Discriminator Loss: 0.0869, Generator Loss: 0.0575, Series Loss: 0.0050, Class Loss: 0.2493, Accuracy: 0.0802\n",
      "Epoch [659/4000], Discriminator Loss: 0.0866, Generator Loss: 0.0576, Series Loss: 0.0050, Class Loss: 0.2493, Accuracy: 0.0802\n",
      "Epoch [660/4000], Discriminator Loss: 0.0875, Generator Loss: 0.0573, Series Loss: 0.0051, Class Loss: 0.2493, Accuracy: 0.0679\n",
      "Epoch [661/4000], Discriminator Loss: 0.0874, Generator Loss: 0.0571, Series Loss: 0.0052, Class Loss: 0.2492, Accuracy: 0.0741\n",
      "Epoch [662/4000], Discriminator Loss: 0.0874, Generator Loss: 0.0572, Series Loss: 0.0052, Class Loss: 0.2491, Accuracy: 0.0617\n",
      "Epoch [663/4000], Discriminator Loss: 0.0870, Generator Loss: 0.0575, Series Loss: 0.0052, Class Loss: 0.2492, Accuracy: 0.0679\n",
      "Epoch [664/4000], Discriminator Loss: 0.0880, Generator Loss: 0.0572, Series Loss: 0.0052, Class Loss: 0.2492, Accuracy: 0.0988\n",
      "Epoch [665/4000], Discriminator Loss: 0.0864, Generator Loss: 0.0577, Series Loss: 0.0052, Class Loss: 0.2493, Accuracy: 0.0802\n",
      "Epoch [666/4000], Discriminator Loss: 0.0874, Generator Loss: 0.0575, Series Loss: 0.0052, Class Loss: 0.2493, Accuracy: 0.0864\n",
      "Epoch [667/4000], Discriminator Loss: 0.0868, Generator Loss: 0.0575, Series Loss: 0.0052, Class Loss: 0.2493, Accuracy: 0.0802\n",
      "Epoch [668/4000], Discriminator Loss: 0.0867, Generator Loss: 0.0577, Series Loss: 0.0052, Class Loss: 0.2494, Accuracy: 0.0741\n",
      "Epoch [669/4000], Discriminator Loss: 0.0870, Generator Loss: 0.0572, Series Loss: 0.0052, Class Loss: 0.2491, Accuracy: 0.0864\n",
      "Epoch [670/4000], Discriminator Loss: 0.0869, Generator Loss: 0.0576, Series Loss: 0.0054, Class Loss: 0.2490, Accuracy: 0.0741\n",
      "Epoch [671/4000], Discriminator Loss: 0.0872, Generator Loss: 0.0577, Series Loss: 0.0052, Class Loss: 0.2493, Accuracy: 0.0679\n",
      "Epoch [672/4000], Discriminator Loss: 0.0873, Generator Loss: 0.0578, Series Loss: 0.0053, Class Loss: 0.2493, Accuracy: 0.0741\n",
      "Epoch [673/4000], Discriminator Loss: 0.0880, Generator Loss: 0.0568, Series Loss: 0.0053, Class Loss: 0.2493, Accuracy: 0.0926\n",
      "Epoch [674/4000], Discriminator Loss: 0.0871, Generator Loss: 0.0577, Series Loss: 0.0054, Class Loss: 0.2493, Accuracy: 0.0741\n",
      "Epoch [675/4000], Discriminator Loss: 0.0869, Generator Loss: 0.0575, Series Loss: 0.0053, Class Loss: 0.2492, Accuracy: 0.0864\n",
      "Epoch [676/4000], Discriminator Loss: 0.0877, Generator Loss: 0.0577, Series Loss: 0.0055, Class Loss: 0.2491, Accuracy: 0.0802\n",
      "Epoch [677/4000], Discriminator Loss: 0.0875, Generator Loss: 0.0577, Series Loss: 0.0055, Class Loss: 0.2493, Accuracy: 0.0617\n",
      "Epoch [678/4000], Discriminator Loss: 0.0877, Generator Loss: 0.0581, Series Loss: 0.0054, Class Loss: 0.2493, Accuracy: 0.0679\n",
      "Epoch [679/4000], Discriminator Loss: 0.0878, Generator Loss: 0.0574, Series Loss: 0.0055, Class Loss: 0.2494, Accuracy: 0.0741\n",
      "Epoch [680/4000], Discriminator Loss: 0.0873, Generator Loss: 0.0577, Series Loss: 0.0055, Class Loss: 0.2492, Accuracy: 0.0864\n",
      "Epoch [681/4000], Discriminator Loss: 0.0886, Generator Loss: 0.0573, Series Loss: 0.0056, Class Loss: 0.2493, Accuracy: 0.0679\n",
      "Epoch [682/4000], Discriminator Loss: 0.0878, Generator Loss: 0.0574, Series Loss: 0.0055, Class Loss: 0.2493, Accuracy: 0.0802\n",
      "Epoch [683/4000], Discriminator Loss: 0.0874, Generator Loss: 0.0577, Series Loss: 0.0056, Class Loss: 0.2492, Accuracy: 0.0741\n",
      "Epoch [684/4000], Discriminator Loss: 0.0880, Generator Loss: 0.0575, Series Loss: 0.0055, Class Loss: 0.2491, Accuracy: 0.0741\n",
      "Epoch [685/4000], Discriminator Loss: 0.0873, Generator Loss: 0.0584, Series Loss: 0.0055, Class Loss: 0.2493, Accuracy: 0.0617\n",
      "Epoch [686/4000], Discriminator Loss: 0.0876, Generator Loss: 0.0575, Series Loss: 0.0056, Class Loss: 0.2493, Accuracy: 0.0802\n",
      "Epoch [687/4000], Discriminator Loss: 0.0880, Generator Loss: 0.0572, Series Loss: 0.0055, Class Loss: 0.2495, Accuracy: 0.0617\n",
      "Epoch [688/4000], Discriminator Loss: 0.0872, Generator Loss: 0.0572, Series Loss: 0.0057, Class Loss: 0.2492, Accuracy: 0.0556\n",
      "Epoch [689/4000], Discriminator Loss: 0.0879, Generator Loss: 0.0574, Series Loss: 0.0058, Class Loss: 0.2494, Accuracy: 0.0802\n",
      "Epoch [690/4000], Discriminator Loss: 0.0883, Generator Loss: 0.0576, Series Loss: 0.0058, Class Loss: 0.2493, Accuracy: 0.0679\n",
      "Epoch [691/4000], Discriminator Loss: 0.0874, Generator Loss: 0.0578, Series Loss: 0.0058, Class Loss: 0.2492, Accuracy: 0.0988\n",
      "Epoch [692/4000], Discriminator Loss: 0.0882, Generator Loss: 0.0570, Series Loss: 0.0058, Class Loss: 0.2492, Accuracy: 0.0741\n",
      "Epoch [693/4000], Discriminator Loss: 0.0888, Generator Loss: 0.0571, Series Loss: 0.0057, Class Loss: 0.2491, Accuracy: 0.0741\n",
      "Epoch [694/4000], Discriminator Loss: 0.0879, Generator Loss: 0.0576, Series Loss: 0.0058, Class Loss: 0.2493, Accuracy: 0.0802\n",
      "Epoch [695/4000], Discriminator Loss: 0.0877, Generator Loss: 0.0578, Series Loss: 0.0058, Class Loss: 0.2492, Accuracy: 0.0741\n",
      "Epoch [696/4000], Discriminator Loss: 0.0883, Generator Loss: 0.0575, Series Loss: 0.0058, Class Loss: 0.2493, Accuracy: 0.0679\n",
      "Epoch [697/4000], Discriminator Loss: 0.0879, Generator Loss: 0.0578, Series Loss: 0.0058, Class Loss: 0.2492, Accuracy: 0.0802\n",
      "Epoch [698/4000], Discriminator Loss: 0.0879, Generator Loss: 0.0573, Series Loss: 0.0058, Class Loss: 0.2491, Accuracy: 0.0679\n",
      "Epoch [699/4000], Discriminator Loss: 0.0881, Generator Loss: 0.0576, Series Loss: 0.0058, Class Loss: 0.2492, Accuracy: 0.0741\n",
      "Epoch [700/4000], Discriminator Loss: 0.0874, Generator Loss: 0.0576, Series Loss: 0.0057, Class Loss: 0.2493, Accuracy: 0.0741\n",
      "Epoch [701/4000], Discriminator Loss: 0.0879, Generator Loss: 0.0576, Series Loss: 0.0058, Class Loss: 0.2494, Accuracy: 0.0864\n",
      "Epoch [702/4000], Discriminator Loss: 0.0884, Generator Loss: 0.0577, Series Loss: 0.0057, Class Loss: 0.2493, Accuracy: 0.0864\n",
      "Epoch [703/4000], Discriminator Loss: 0.0882, Generator Loss: 0.0573, Series Loss: 0.0057, Class Loss: 0.2493, Accuracy: 0.0864\n",
      "Epoch [704/4000], Discriminator Loss: 0.0881, Generator Loss: 0.0580, Series Loss: 0.0058, Class Loss: 0.2493, Accuracy: 0.0617\n",
      "Epoch [705/4000], Discriminator Loss: 0.0884, Generator Loss: 0.0573, Series Loss: 0.0059, Class Loss: 0.2492, Accuracy: 0.0741\n",
      "Epoch [706/4000], Discriminator Loss: 0.0883, Generator Loss: 0.0574, Series Loss: 0.0058, Class Loss: 0.2492, Accuracy: 0.0679\n",
      "Epoch [707/4000], Discriminator Loss: 0.0877, Generator Loss: 0.0571, Series Loss: 0.0058, Class Loss: 0.2494, Accuracy: 0.0802\n",
      "Epoch [708/4000], Discriminator Loss: 0.0885, Generator Loss: 0.0573, Series Loss: 0.0059, Class Loss: 0.2494, Accuracy: 0.0556\n",
      "Epoch [709/4000], Discriminator Loss: 0.0879, Generator Loss: 0.0577, Series Loss: 0.0059, Class Loss: 0.2493, Accuracy: 0.0741\n",
      "Epoch [710/4000], Discriminator Loss: 0.0889, Generator Loss: 0.0573, Series Loss: 0.0061, Class Loss: 0.2494, Accuracy: 0.0864\n",
      "Epoch [711/4000], Discriminator Loss: 0.0882, Generator Loss: 0.0572, Series Loss: 0.0059, Class Loss: 0.2493, Accuracy: 0.0679\n",
      "Epoch [712/4000], Discriminator Loss: 0.0876, Generator Loss: 0.0578, Series Loss: 0.0059, Class Loss: 0.2494, Accuracy: 0.0802\n",
      "Epoch [713/4000], Discriminator Loss: 0.0879, Generator Loss: 0.0580, Series Loss: 0.0059, Class Loss: 0.2493, Accuracy: 0.0617\n",
      "Epoch [714/4000], Discriminator Loss: 0.0885, Generator Loss: 0.0565, Series Loss: 0.0061, Class Loss: 0.2491, Accuracy: 0.0617\n",
      "Epoch [715/4000], Discriminator Loss: 0.0885, Generator Loss: 0.0577, Series Loss: 0.0060, Class Loss: 0.2492, Accuracy: 0.0556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [716/4000], Discriminator Loss: 0.0883, Generator Loss: 0.0573, Series Loss: 0.0060, Class Loss: 0.2493, Accuracy: 0.0741\n",
      "Epoch [717/4000], Discriminator Loss: 0.0892, Generator Loss: 0.0575, Series Loss: 0.0061, Class Loss: 0.2494, Accuracy: 0.0556\n",
      "Epoch [718/4000], Discriminator Loss: 0.0891, Generator Loss: 0.0574, Series Loss: 0.0061, Class Loss: 0.2494, Accuracy: 0.0617\n",
      "Epoch [719/4000], Discriminator Loss: 0.0891, Generator Loss: 0.0569, Series Loss: 0.0061, Class Loss: 0.2492, Accuracy: 0.0617\n",
      "Epoch [720/4000], Discriminator Loss: 0.0897, Generator Loss: 0.0567, Series Loss: 0.0061, Class Loss: 0.2492, Accuracy: 0.0741\n",
      "Epoch [721/4000], Discriminator Loss: 0.0891, Generator Loss: 0.0575, Series Loss: 0.0062, Class Loss: 0.2492, Accuracy: 0.0741\n",
      "Epoch [722/4000], Discriminator Loss: 0.0891, Generator Loss: 0.0567, Series Loss: 0.0061, Class Loss: 0.2492, Accuracy: 0.0802\n",
      "Epoch [723/4000], Discriminator Loss: 0.0886, Generator Loss: 0.0573, Series Loss: 0.0061, Class Loss: 0.2492, Accuracy: 0.0864\n",
      "Epoch [724/4000], Discriminator Loss: 0.0884, Generator Loss: 0.0577, Series Loss: 0.0063, Class Loss: 0.2492, Accuracy: 0.0864\n",
      "Epoch [725/4000], Discriminator Loss: 0.0888, Generator Loss: 0.0577, Series Loss: 0.0062, Class Loss: 0.2491, Accuracy: 0.0679\n",
      "Epoch [726/4000], Discriminator Loss: 0.0886, Generator Loss: 0.0579, Series Loss: 0.0063, Class Loss: 0.2493, Accuracy: 0.0679\n",
      "Epoch [727/4000], Discriminator Loss: 0.0896, Generator Loss: 0.0571, Series Loss: 0.0063, Class Loss: 0.2491, Accuracy: 0.0679\n",
      "Epoch [728/4000], Discriminator Loss: 0.0882, Generator Loss: 0.0578, Series Loss: 0.0062, Class Loss: 0.2492, Accuracy: 0.0617\n",
      "Epoch [729/4000], Discriminator Loss: 0.0897, Generator Loss: 0.0571, Series Loss: 0.0064, Class Loss: 0.2491, Accuracy: 0.0926\n",
      "Epoch [730/4000], Discriminator Loss: 0.0905, Generator Loss: 0.0573, Series Loss: 0.0065, Class Loss: 0.2492, Accuracy: 0.0741\n",
      "Epoch [731/4000], Discriminator Loss: 0.0894, Generator Loss: 0.0578, Series Loss: 0.0063, Class Loss: 0.2493, Accuracy: 0.0741\n",
      "Epoch [732/4000], Discriminator Loss: 0.0905, Generator Loss: 0.0570, Series Loss: 0.0064, Class Loss: 0.2492, Accuracy: 0.0679\n",
      "Epoch [733/4000], Discriminator Loss: 0.0895, Generator Loss: 0.0582, Series Loss: 0.0064, Class Loss: 0.2492, Accuracy: 0.0802\n",
      "Epoch [734/4000], Discriminator Loss: 0.0891, Generator Loss: 0.0569, Series Loss: 0.0063, Class Loss: 0.2492, Accuracy: 0.0802\n",
      "Epoch [735/4000], Discriminator Loss: 0.0890, Generator Loss: 0.0581, Series Loss: 0.0064, Class Loss: 0.2492, Accuracy: 0.0864\n",
      "Epoch [736/4000], Discriminator Loss: 0.0895, Generator Loss: 0.0573, Series Loss: 0.0064, Class Loss: 0.2492, Accuracy: 0.0988\n",
      "Epoch [737/4000], Discriminator Loss: 0.0895, Generator Loss: 0.0579, Series Loss: 0.0065, Class Loss: 0.2492, Accuracy: 0.0802\n",
      "Epoch [738/4000], Discriminator Loss: 0.0895, Generator Loss: 0.0575, Series Loss: 0.0064, Class Loss: 0.2493, Accuracy: 0.0926\n",
      "Epoch [739/4000], Discriminator Loss: 0.0897, Generator Loss: 0.0575, Series Loss: 0.0065, Class Loss: 0.2492, Accuracy: 0.0864\n",
      "Epoch [740/4000], Discriminator Loss: 0.0891, Generator Loss: 0.0581, Series Loss: 0.0064, Class Loss: 0.2493, Accuracy: 0.0802\n",
      "Epoch [741/4000], Discriminator Loss: 0.0911, Generator Loss: 0.0577, Series Loss: 0.0064, Class Loss: 0.2492, Accuracy: 0.0926\n",
      "Epoch [742/4000], Discriminator Loss: 0.0896, Generator Loss: 0.0574, Series Loss: 0.0065, Class Loss: 0.2493, Accuracy: 0.0741\n",
      "Epoch [743/4000], Discriminator Loss: 0.0893, Generator Loss: 0.0586, Series Loss: 0.0064, Class Loss: 0.2492, Accuracy: 0.0802\n",
      "Epoch [744/4000], Discriminator Loss: 0.0905, Generator Loss: 0.0569, Series Loss: 0.0066, Class Loss: 0.2492, Accuracy: 0.0926\n",
      "Epoch [745/4000], Discriminator Loss: 0.0902, Generator Loss: 0.0576, Series Loss: 0.0068, Class Loss: 0.2493, Accuracy: 0.0988\n",
      "Epoch [746/4000], Discriminator Loss: 0.0899, Generator Loss: 0.0578, Series Loss: 0.0066, Class Loss: 0.2494, Accuracy: 0.0741\n",
      "Epoch [747/4000], Discriminator Loss: 0.0886, Generator Loss: 0.0583, Series Loss: 0.0066, Class Loss: 0.2492, Accuracy: 0.0864\n",
      "Epoch [748/4000], Discriminator Loss: 0.0896, Generator Loss: 0.0572, Series Loss: 0.0067, Class Loss: 0.2493, Accuracy: 0.1049\n",
      "Epoch [749/4000], Discriminator Loss: 0.0909, Generator Loss: 0.0566, Series Loss: 0.0068, Class Loss: 0.2492, Accuracy: 0.0864\n",
      "Epoch [750/4000], Discriminator Loss: 0.0909, Generator Loss: 0.0568, Series Loss: 0.0068, Class Loss: 0.2491, Accuracy: 0.0741\n",
      "Epoch [751/4000], Discriminator Loss: 0.0901, Generator Loss: 0.0578, Series Loss: 0.0068, Class Loss: 0.2494, Accuracy: 0.0926\n",
      "Epoch [752/4000], Discriminator Loss: 0.0897, Generator Loss: 0.0581, Series Loss: 0.0068, Class Loss: 0.2494, Accuracy: 0.0741\n",
      "Epoch [753/4000], Discriminator Loss: 0.0899, Generator Loss: 0.0575, Series Loss: 0.0067, Class Loss: 0.2493, Accuracy: 0.0741\n",
      "Epoch [754/4000], Discriminator Loss: 0.0905, Generator Loss: 0.0565, Series Loss: 0.0068, Class Loss: 0.2492, Accuracy: 0.0926\n",
      "Epoch [755/4000], Discriminator Loss: 0.0916, Generator Loss: 0.0572, Series Loss: 0.0068, Class Loss: 0.2490, Accuracy: 0.0741\n",
      "Epoch [756/4000], Discriminator Loss: 0.0911, Generator Loss: 0.0578, Series Loss: 0.0067, Class Loss: 0.2491, Accuracy: 0.0926\n",
      "Epoch [757/4000], Discriminator Loss: 0.0896, Generator Loss: 0.0576, Series Loss: 0.0067, Class Loss: 0.2492, Accuracy: 0.0988\n",
      "Epoch [758/4000], Discriminator Loss: 0.0907, Generator Loss: 0.0576, Series Loss: 0.0067, Class Loss: 0.2493, Accuracy: 0.0988\n",
      "Epoch [759/4000], Discriminator Loss: 0.0904, Generator Loss: 0.0577, Series Loss: 0.0067, Class Loss: 0.2492, Accuracy: 0.0802\n",
      "Epoch [760/4000], Discriminator Loss: 0.0914, Generator Loss: 0.0575, Series Loss: 0.0069, Class Loss: 0.2490, Accuracy: 0.0802\n",
      "Epoch [761/4000], Discriminator Loss: 0.0902, Generator Loss: 0.0580, Series Loss: 0.0068, Class Loss: 0.2492, Accuracy: 0.0864\n",
      "Epoch [762/4000], Discriminator Loss: 0.0911, Generator Loss: 0.0571, Series Loss: 0.0067, Class Loss: 0.2492, Accuracy: 0.0864\n",
      "Epoch [763/4000], Discriminator Loss: 0.0896, Generator Loss: 0.0584, Series Loss: 0.0067, Class Loss: 0.2492, Accuracy: 0.0617\n",
      "Epoch [764/4000], Discriminator Loss: 0.0903, Generator Loss: 0.0575, Series Loss: 0.0069, Class Loss: 0.2491, Accuracy: 0.0802\n",
      "Epoch [765/4000], Discriminator Loss: 0.0903, Generator Loss: 0.0574, Series Loss: 0.0068, Class Loss: 0.2493, Accuracy: 0.0741\n",
      "Epoch [766/4000], Discriminator Loss: 0.0900, Generator Loss: 0.0572, Series Loss: 0.0069, Class Loss: 0.2493, Accuracy: 0.0741\n",
      "Epoch [767/4000], Discriminator Loss: 0.0911, Generator Loss: 0.0573, Series Loss: 0.0069, Class Loss: 0.2492, Accuracy: 0.0864\n",
      "Epoch [768/4000], Discriminator Loss: 0.0909, Generator Loss: 0.0570, Series Loss: 0.0067, Class Loss: 0.2493, Accuracy: 0.0802\n",
      "Epoch [769/4000], Discriminator Loss: 0.0903, Generator Loss: 0.0572, Series Loss: 0.0068, Class Loss: 0.2492, Accuracy: 0.0864\n",
      "Epoch [770/4000], Discriminator Loss: 0.0918, Generator Loss: 0.0568, Series Loss: 0.0070, Class Loss: 0.2491, Accuracy: 0.0864\n",
      "Epoch [771/4000], Discriminator Loss: 0.0918, Generator Loss: 0.0570, Series Loss: 0.0070, Class Loss: 0.2492, Accuracy: 0.0926\n",
      "Epoch [772/4000], Discriminator Loss: 0.0911, Generator Loss: 0.0576, Series Loss: 0.0068, Class Loss: 0.2491, Accuracy: 0.0741\n",
      "Epoch [773/4000], Discriminator Loss: 0.0922, Generator Loss: 0.0567, Series Loss: 0.0071, Class Loss: 0.2491, Accuracy: 0.0988\n",
      "Epoch [774/4000], Discriminator Loss: 0.0909, Generator Loss: 0.0579, Series Loss: 0.0071, Class Loss: 0.2492, Accuracy: 0.0617\n",
      "Epoch [775/4000], Discriminator Loss: 0.0922, Generator Loss: 0.0569, Series Loss: 0.0072, Class Loss: 0.2490, Accuracy: 0.0802\n",
      "Epoch [776/4000], Discriminator Loss: 0.0912, Generator Loss: 0.0576, Series Loss: 0.0070, Class Loss: 0.2490, Accuracy: 0.1111\n",
      "Epoch [777/4000], Discriminator Loss: 0.0907, Generator Loss: 0.0581, Series Loss: 0.0071, Class Loss: 0.2492, Accuracy: 0.0741\n",
      "Epoch [778/4000], Discriminator Loss: 0.0917, Generator Loss: 0.0572, Series Loss: 0.0073, Class Loss: 0.2493, Accuracy: 0.0802\n",
      "Epoch [779/4000], Discriminator Loss: 0.0913, Generator Loss: 0.0580, Series Loss: 0.0072, Class Loss: 0.2492, Accuracy: 0.0864\n",
      "Epoch [780/4000], Discriminator Loss: 0.0913, Generator Loss: 0.0574, Series Loss: 0.0071, Class Loss: 0.2491, Accuracy: 0.0988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [781/4000], Discriminator Loss: 0.0901, Generator Loss: 0.0583, Series Loss: 0.0071, Class Loss: 0.2491, Accuracy: 0.0802\n",
      "Epoch [782/4000], Discriminator Loss: 0.0909, Generator Loss: 0.0576, Series Loss: 0.0072, Class Loss: 0.2492, Accuracy: 0.0679\n",
      "Epoch [783/4000], Discriminator Loss: 0.0908, Generator Loss: 0.0579, Series Loss: 0.0072, Class Loss: 0.2492, Accuracy: 0.0802\n",
      "Epoch [784/4000], Discriminator Loss: 0.0913, Generator Loss: 0.0570, Series Loss: 0.0073, Class Loss: 0.2494, Accuracy: 0.0617\n",
      "Epoch [785/4000], Discriminator Loss: 0.0914, Generator Loss: 0.0578, Series Loss: 0.0073, Class Loss: 0.2493, Accuracy: 0.0802\n",
      "Epoch [786/4000], Discriminator Loss: 0.0906, Generator Loss: 0.0575, Series Loss: 0.0074, Class Loss: 0.2493, Accuracy: 0.0802\n",
      "Epoch [787/4000], Discriminator Loss: 0.0920, Generator Loss: 0.0577, Series Loss: 0.0074, Class Loss: 0.2491, Accuracy: 0.0679\n",
      "Epoch [788/4000], Discriminator Loss: 0.0904, Generator Loss: 0.0575, Series Loss: 0.0075, Class Loss: 0.2491, Accuracy: 0.0617\n",
      "Epoch [789/4000], Discriminator Loss: 0.0917, Generator Loss: 0.0574, Series Loss: 0.0075, Class Loss: 0.2493, Accuracy: 0.0864\n",
      "Epoch [790/4000], Discriminator Loss: 0.0917, Generator Loss: 0.0574, Series Loss: 0.0074, Class Loss: 0.2492, Accuracy: 0.0864\n",
      "Epoch [791/4000], Discriminator Loss: 0.0915, Generator Loss: 0.0572, Series Loss: 0.0074, Class Loss: 0.2492, Accuracy: 0.0864\n",
      "Epoch [792/4000], Discriminator Loss: 0.0912, Generator Loss: 0.0576, Series Loss: 0.0075, Class Loss: 0.2492, Accuracy: 0.0802\n",
      "Epoch [793/4000], Discriminator Loss: 0.0924, Generator Loss: 0.0572, Series Loss: 0.0074, Class Loss: 0.2493, Accuracy: 0.0802\n",
      "Epoch [794/4000], Discriminator Loss: 0.0915, Generator Loss: 0.0574, Series Loss: 0.0076, Class Loss: 0.2492, Accuracy: 0.0741\n",
      "Epoch [795/4000], Discriminator Loss: 0.0916, Generator Loss: 0.0571, Series Loss: 0.0076, Class Loss: 0.2490, Accuracy: 0.0741\n",
      "Epoch [796/4000], Discriminator Loss: 0.0916, Generator Loss: 0.0574, Series Loss: 0.0077, Class Loss: 0.2490, Accuracy: 0.0802\n",
      "Epoch [797/4000], Discriminator Loss: 0.0922, Generator Loss: 0.0570, Series Loss: 0.0076, Class Loss: 0.2490, Accuracy: 0.0617\n",
      "Epoch [798/4000], Discriminator Loss: 0.0921, Generator Loss: 0.0571, Series Loss: 0.0075, Class Loss: 0.2491, Accuracy: 0.0988\n",
      "Epoch [799/4000], Discriminator Loss: 0.0926, Generator Loss: 0.0569, Series Loss: 0.0078, Class Loss: 0.2491, Accuracy: 0.0494\n",
      "Epoch [800/4000], Discriminator Loss: 0.0923, Generator Loss: 0.0577, Series Loss: 0.0077, Class Loss: 0.2492, Accuracy: 0.0864\n",
      "Epoch [801/4000], Discriminator Loss: 0.0921, Generator Loss: 0.0576, Series Loss: 0.0077, Class Loss: 0.2491, Accuracy: 0.0926\n",
      "Epoch [802/4000], Discriminator Loss: 0.0927, Generator Loss: 0.0574, Series Loss: 0.0077, Class Loss: 0.2489, Accuracy: 0.0679\n",
      "Epoch [803/4000], Discriminator Loss: 0.0927, Generator Loss: 0.0572, Series Loss: 0.0078, Class Loss: 0.2492, Accuracy: 0.0864\n",
      "Epoch [804/4000], Discriminator Loss: 0.0926, Generator Loss: 0.0569, Series Loss: 0.0078, Class Loss: 0.2492, Accuracy: 0.0679\n",
      "Epoch [805/4000], Discriminator Loss: 0.0923, Generator Loss: 0.0568, Series Loss: 0.0078, Class Loss: 0.2492, Accuracy: 0.0679\n",
      "Epoch [806/4000], Discriminator Loss: 0.0914, Generator Loss: 0.0577, Series Loss: 0.0079, Class Loss: 0.2491, Accuracy: 0.0926\n",
      "Epoch [807/4000], Discriminator Loss: 0.0932, Generator Loss: 0.0573, Series Loss: 0.0081, Class Loss: 0.2491, Accuracy: 0.0926\n",
      "Epoch [808/4000], Discriminator Loss: 0.0926, Generator Loss: 0.0575, Series Loss: 0.0079, Class Loss: 0.2490, Accuracy: 0.0679\n",
      "Epoch [809/4000], Discriminator Loss: 0.0919, Generator Loss: 0.0576, Series Loss: 0.0077, Class Loss: 0.2492, Accuracy: 0.0802\n",
      "Epoch [810/4000], Discriminator Loss: 0.0918, Generator Loss: 0.0572, Series Loss: 0.0082, Class Loss: 0.2491, Accuracy: 0.0741\n",
      "Epoch [811/4000], Discriminator Loss: 0.0923, Generator Loss: 0.0577, Series Loss: 0.0083, Class Loss: 0.2492, Accuracy: 0.0679\n",
      "Epoch [812/4000], Discriminator Loss: 0.0927, Generator Loss: 0.0576, Series Loss: 0.0083, Class Loss: 0.2492, Accuracy: 0.0617\n",
      "Epoch [813/4000], Discriminator Loss: 0.0918, Generator Loss: 0.0575, Series Loss: 0.0080, Class Loss: 0.2493, Accuracy: 0.0617\n",
      "Epoch [814/4000], Discriminator Loss: 0.0918, Generator Loss: 0.0576, Series Loss: 0.0082, Class Loss: 0.2491, Accuracy: 0.0556\n",
      "Epoch [815/4000], Discriminator Loss: 0.0934, Generator Loss: 0.0568, Series Loss: 0.0083, Class Loss: 0.2492, Accuracy: 0.0679\n",
      "Epoch [816/4000], Discriminator Loss: 0.0922, Generator Loss: 0.0573, Series Loss: 0.0083, Class Loss: 0.2490, Accuracy: 0.0741\n",
      "Epoch [817/4000], Discriminator Loss: 0.0920, Generator Loss: 0.0575, Series Loss: 0.0085, Class Loss: 0.2491, Accuracy: 0.0802\n",
      "Epoch [818/4000], Discriminator Loss: 0.0934, Generator Loss: 0.0570, Series Loss: 0.0085, Class Loss: 0.2492, Accuracy: 0.0432\n",
      "Epoch [819/4000], Discriminator Loss: 0.0932, Generator Loss: 0.0570, Series Loss: 0.0086, Class Loss: 0.2492, Accuracy: 0.0617\n",
      "Epoch [820/4000], Discriminator Loss: 0.0927, Generator Loss: 0.0572, Series Loss: 0.0085, Class Loss: 0.2492, Accuracy: 0.0556\n",
      "Epoch [821/4000], Discriminator Loss: 0.0933, Generator Loss: 0.0572, Series Loss: 0.0087, Class Loss: 0.2491, Accuracy: 0.0494\n",
      "Epoch [822/4000], Discriminator Loss: 0.0932, Generator Loss: 0.0569, Series Loss: 0.0085, Class Loss: 0.2493, Accuracy: 0.0617\n",
      "Epoch [823/4000], Discriminator Loss: 0.0933, Generator Loss: 0.0572, Series Loss: 0.0087, Class Loss: 0.2491, Accuracy: 0.0370\n",
      "Epoch [824/4000], Discriminator Loss: 0.0933, Generator Loss: 0.0567, Series Loss: 0.0084, Class Loss: 0.2493, Accuracy: 0.0494\n",
      "Epoch [825/4000], Discriminator Loss: 0.0933, Generator Loss: 0.0572, Series Loss: 0.0087, Class Loss: 0.2492, Accuracy: 0.0617\n",
      "Epoch [826/4000], Discriminator Loss: 0.0934, Generator Loss: 0.0570, Series Loss: 0.0086, Class Loss: 0.2491, Accuracy: 0.0494\n",
      "Epoch [827/4000], Discriminator Loss: 0.0933, Generator Loss: 0.0569, Series Loss: 0.0086, Class Loss: 0.2491, Accuracy: 0.0494\n",
      "Epoch [828/4000], Discriminator Loss: 0.0936, Generator Loss: 0.0570, Series Loss: 0.0087, Class Loss: 0.2492, Accuracy: 0.0617\n",
      "Epoch [829/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0567, Series Loss: 0.0087, Class Loss: 0.2490, Accuracy: 0.0741\n",
      "Epoch [830/4000], Discriminator Loss: 0.0933, Generator Loss: 0.0571, Series Loss: 0.0086, Class Loss: 0.2491, Accuracy: 0.0556\n",
      "Epoch [831/4000], Discriminator Loss: 0.0923, Generator Loss: 0.0573, Series Loss: 0.0087, Class Loss: 0.2491, Accuracy: 0.0432\n",
      "Epoch [832/4000], Discriminator Loss: 0.0936, Generator Loss: 0.0569, Series Loss: 0.0086, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [833/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0566, Series Loss: 0.0089, Class Loss: 0.2490, Accuracy: 0.0679\n",
      "Epoch [834/4000], Discriminator Loss: 0.0954, Generator Loss: 0.0563, Series Loss: 0.0090, Class Loss: 0.2491, Accuracy: 0.0556\n",
      "Epoch [835/4000], Discriminator Loss: 0.0935, Generator Loss: 0.0572, Series Loss: 0.0089, Class Loss: 0.2493, Accuracy: 0.0432\n",
      "Epoch [836/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0566, Series Loss: 0.0090, Class Loss: 0.2491, Accuracy: 0.0617\n",
      "Epoch [837/4000], Discriminator Loss: 0.0937, Generator Loss: 0.0567, Series Loss: 0.0088, Class Loss: 0.2493, Accuracy: 0.0432\n",
      "Epoch [838/4000], Discriminator Loss: 0.0935, Generator Loss: 0.0572, Series Loss: 0.0087, Class Loss: 0.2492, Accuracy: 0.0494\n",
      "Epoch [839/4000], Discriminator Loss: 0.0935, Generator Loss: 0.0572, Series Loss: 0.0089, Class Loss: 0.2492, Accuracy: 0.0432\n",
      "Epoch [840/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0568, Series Loss: 0.0090, Class Loss: 0.2491, Accuracy: 0.0370\n",
      "Epoch [841/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0567, Series Loss: 0.0089, Class Loss: 0.2491, Accuracy: 0.0617\n",
      "Epoch [842/4000], Discriminator Loss: 0.0939, Generator Loss: 0.0573, Series Loss: 0.0089, Class Loss: 0.2491, Accuracy: 0.0432\n",
      "Epoch [843/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0563, Series Loss: 0.0089, Class Loss: 0.2492, Accuracy: 0.0494\n",
      "Epoch [844/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0566, Series Loss: 0.0090, Class Loss: 0.2492, Accuracy: 0.0556\n",
      "Epoch [845/4000], Discriminator Loss: 0.0936, Generator Loss: 0.0573, Series Loss: 0.0091, Class Loss: 0.2492, Accuracy: 0.0309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [846/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0572, Series Loss: 0.0091, Class Loss: 0.2493, Accuracy: 0.0370\n",
      "Epoch [847/4000], Discriminator Loss: 0.0939, Generator Loss: 0.0573, Series Loss: 0.0091, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [848/4000], Discriminator Loss: 0.0938, Generator Loss: 0.0569, Series Loss: 0.0090, Class Loss: 0.2492, Accuracy: 0.0432\n",
      "Epoch [849/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0576, Series Loss: 0.0093, Class Loss: 0.2493, Accuracy: 0.0370\n",
      "Epoch [850/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0567, Series Loss: 0.0090, Class Loss: 0.2491, Accuracy: 0.0432\n",
      "Epoch [851/4000], Discriminator Loss: 0.0937, Generator Loss: 0.0570, Series Loss: 0.0090, Class Loss: 0.2491, Accuracy: 0.0370\n",
      "Epoch [852/4000], Discriminator Loss: 0.0935, Generator Loss: 0.0577, Series Loss: 0.0092, Class Loss: 0.2493, Accuracy: 0.0432\n",
      "Epoch [853/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0569, Series Loss: 0.0089, Class Loss: 0.2492, Accuracy: 0.0370\n",
      "Epoch [854/4000], Discriminator Loss: 0.0938, Generator Loss: 0.0575, Series Loss: 0.0090, Class Loss: 0.2491, Accuracy: 0.0494\n",
      "Epoch [855/4000], Discriminator Loss: 0.0936, Generator Loss: 0.0576, Series Loss: 0.0091, Class Loss: 0.2491, Accuracy: 0.0494\n",
      "Epoch [856/4000], Discriminator Loss: 0.0949, Generator Loss: 0.0569, Series Loss: 0.0092, Class Loss: 0.2492, Accuracy: 0.0370\n",
      "Epoch [857/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0575, Series Loss: 0.0090, Class Loss: 0.2492, Accuracy: 0.0617\n",
      "Epoch [858/4000], Discriminator Loss: 0.0952, Generator Loss: 0.0567, Series Loss: 0.0090, Class Loss: 0.2491, Accuracy: 0.0432\n",
      "Epoch [859/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0573, Series Loss: 0.0091, Class Loss: 0.2491, Accuracy: 0.0309\n",
      "Epoch [860/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0570, Series Loss: 0.0090, Class Loss: 0.2493, Accuracy: 0.0370\n",
      "Epoch [861/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0569, Series Loss: 0.0091, Class Loss: 0.2492, Accuracy: 0.0556\n",
      "Epoch [862/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0568, Series Loss: 0.0089, Class Loss: 0.2492, Accuracy: 0.0432\n",
      "Epoch [863/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0567, Series Loss: 0.0089, Class Loss: 0.2492, Accuracy: 0.0494\n",
      "Epoch [864/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0570, Series Loss: 0.0089, Class Loss: 0.2493, Accuracy: 0.0494\n",
      "Epoch [865/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0573, Series Loss: 0.0092, Class Loss: 0.2492, Accuracy: 0.0494\n",
      "Epoch [866/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0570, Series Loss: 0.0090, Class Loss: 0.2492, Accuracy: 0.0309\n",
      "Epoch [867/4000], Discriminator Loss: 0.0933, Generator Loss: 0.0573, Series Loss: 0.0090, Class Loss: 0.2492, Accuracy: 0.0185\n",
      "Epoch [868/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0574, Series Loss: 0.0090, Class Loss: 0.2492, Accuracy: 0.0556\n",
      "Epoch [869/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0573, Series Loss: 0.0090, Class Loss: 0.2492, Accuracy: 0.0617\n",
      "Epoch [870/4000], Discriminator Loss: 0.0937, Generator Loss: 0.0570, Series Loss: 0.0089, Class Loss: 0.2491, Accuracy: 0.0494\n",
      "Epoch [871/4000], Discriminator Loss: 0.0935, Generator Loss: 0.0572, Series Loss: 0.0088, Class Loss: 0.2491, Accuracy: 0.0556\n",
      "Epoch [872/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0568, Series Loss: 0.0091, Class Loss: 0.2491, Accuracy: 0.0370\n",
      "Epoch [873/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0572, Series Loss: 0.0090, Class Loss: 0.2493, Accuracy: 0.0370\n",
      "Epoch [874/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0570, Series Loss: 0.0091, Class Loss: 0.2492, Accuracy: 0.0370\n",
      "Epoch [875/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0570, Series Loss: 0.0090, Class Loss: 0.2493, Accuracy: 0.0432\n",
      "Epoch [876/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0568, Series Loss: 0.0090, Class Loss: 0.2493, Accuracy: 0.0309\n",
      "Epoch [877/4000], Discriminator Loss: 0.0939, Generator Loss: 0.0574, Series Loss: 0.0090, Class Loss: 0.2492, Accuracy: 0.0556\n",
      "Epoch [878/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0567, Series Loss: 0.0091, Class Loss: 0.2493, Accuracy: 0.0432\n",
      "Epoch [879/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0572, Series Loss: 0.0092, Class Loss: 0.2491, Accuracy: 0.0370\n",
      "Epoch [880/4000], Discriminator Loss: 0.0950, Generator Loss: 0.0569, Series Loss: 0.0092, Class Loss: 0.2493, Accuracy: 0.0494\n",
      "Epoch [881/4000], Discriminator Loss: 0.0934, Generator Loss: 0.0579, Series Loss: 0.0092, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [882/4000], Discriminator Loss: 0.0936, Generator Loss: 0.0578, Series Loss: 0.0091, Class Loss: 0.2491, Accuracy: 0.0370\n",
      "Epoch [883/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0571, Series Loss: 0.0091, Class Loss: 0.2492, Accuracy: 0.0494\n",
      "Epoch [884/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0577, Series Loss: 0.0094, Class Loss: 0.2491, Accuracy: 0.0494\n",
      "Epoch [885/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0574, Series Loss: 0.0090, Class Loss: 0.2492, Accuracy: 0.0494\n",
      "Epoch [886/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0574, Series Loss: 0.0091, Class Loss: 0.2492, Accuracy: 0.0494\n",
      "Epoch [887/4000], Discriminator Loss: 0.0939, Generator Loss: 0.0575, Series Loss: 0.0091, Class Loss: 0.2492, Accuracy: 0.0556\n",
      "Epoch [888/4000], Discriminator Loss: 0.0938, Generator Loss: 0.0577, Series Loss: 0.0090, Class Loss: 0.2492, Accuracy: 0.0370\n",
      "Epoch [889/4000], Discriminator Loss: 0.0938, Generator Loss: 0.0578, Series Loss: 0.0092, Class Loss: 0.2491, Accuracy: 0.0556\n",
      "Epoch [890/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0570, Series Loss: 0.0091, Class Loss: 0.2492, Accuracy: 0.0556\n",
      "Epoch [891/4000], Discriminator Loss: 0.0950, Generator Loss: 0.0570, Series Loss: 0.0092, Class Loss: 0.2491, Accuracy: 0.0370\n",
      "Epoch [892/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0574, Series Loss: 0.0093, Class Loss: 0.2491, Accuracy: 0.0556\n",
      "Epoch [893/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0570, Series Loss: 0.0092, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [894/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0575, Series Loss: 0.0092, Class Loss: 0.2491, Accuracy: 0.0494\n",
      "Epoch [895/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0576, Series Loss: 0.0092, Class Loss: 0.2491, Accuracy: 0.0432\n",
      "Epoch [896/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0568, Series Loss: 0.0093, Class Loss: 0.2491, Accuracy: 0.0432\n",
      "Epoch [897/4000], Discriminator Loss: 0.0951, Generator Loss: 0.0570, Series Loss: 0.0091, Class Loss: 0.2491, Accuracy: 0.0309\n",
      "Epoch [898/4000], Discriminator Loss: 0.0951, Generator Loss: 0.0576, Series Loss: 0.0092, Class Loss: 0.2492, Accuracy: 0.0679\n",
      "Epoch [899/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0573, Series Loss: 0.0092, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [900/4000], Discriminator Loss: 0.0954, Generator Loss: 0.0564, Series Loss: 0.0092, Class Loss: 0.2491, Accuracy: 0.0617\n",
      "Epoch [901/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0583, Series Loss: 0.0093, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [902/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0572, Series Loss: 0.0094, Class Loss: 0.2492, Accuracy: 0.0432\n",
      "Epoch [903/4000], Discriminator Loss: 0.0950, Generator Loss: 0.0571, Series Loss: 0.0093, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [904/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0574, Series Loss: 0.0092, Class Loss: 0.2490, Accuracy: 0.0617\n",
      "Epoch [905/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0574, Series Loss: 0.0093, Class Loss: 0.2491, Accuracy: 0.0494\n",
      "Epoch [906/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0576, Series Loss: 0.0093, Class Loss: 0.2491, Accuracy: 0.0370\n",
      "Epoch [907/4000], Discriminator Loss: 0.0937, Generator Loss: 0.0584, Series Loss: 0.0094, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [908/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0574, Series Loss: 0.0092, Class Loss: 0.2492, Accuracy: 0.0370\n",
      "Epoch [909/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0578, Series Loss: 0.0093, Class Loss: 0.2491, Accuracy: 0.0494\n",
      "Epoch [910/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0575, Series Loss: 0.0092, Class Loss: 0.2490, Accuracy: 0.0556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [911/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0587, Series Loss: 0.0095, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [912/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0577, Series Loss: 0.0093, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [913/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0573, Series Loss: 0.0093, Class Loss: 0.2492, Accuracy: 0.0617\n",
      "Epoch [914/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0577, Series Loss: 0.0094, Class Loss: 0.2492, Accuracy: 0.0432\n",
      "Epoch [915/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0569, Series Loss: 0.0093, Class Loss: 0.2492, Accuracy: 0.0494\n",
      "Epoch [916/4000], Discriminator Loss: 0.0949, Generator Loss: 0.0574, Series Loss: 0.0094, Class Loss: 0.2491, Accuracy: 0.0309\n",
      "Epoch [917/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0576, Series Loss: 0.0095, Class Loss: 0.2490, Accuracy: 0.0309\n",
      "Epoch [918/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0576, Series Loss: 0.0095, Class Loss: 0.2491, Accuracy: 0.0370\n",
      "Epoch [919/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0579, Series Loss: 0.0094, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [920/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0576, Series Loss: 0.0095, Class Loss: 0.2491, Accuracy: 0.0185\n",
      "Epoch [921/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0574, Series Loss: 0.0093, Class Loss: 0.2491, Accuracy: 0.0247\n",
      "Epoch [922/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0576, Series Loss: 0.0093, Class Loss: 0.2492, Accuracy: 0.0494\n",
      "Epoch [923/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0576, Series Loss: 0.0095, Class Loss: 0.2491, Accuracy: 0.0556\n",
      "Epoch [924/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0579, Series Loss: 0.0095, Class Loss: 0.2491, Accuracy: 0.0432\n",
      "Epoch [925/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0577, Series Loss: 0.0094, Class Loss: 0.2490, Accuracy: 0.0679\n",
      "Epoch [926/4000], Discriminator Loss: 0.0950, Generator Loss: 0.0577, Series Loss: 0.0095, Class Loss: 0.2491, Accuracy: 0.0432\n",
      "Epoch [927/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0578, Series Loss: 0.0094, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [928/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0577, Series Loss: 0.0095, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [929/4000], Discriminator Loss: 0.0949, Generator Loss: 0.0575, Series Loss: 0.0094, Class Loss: 0.2490, Accuracy: 0.0679\n",
      "Epoch [930/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0576, Series Loss: 0.0095, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [931/4000], Discriminator Loss: 0.0939, Generator Loss: 0.0581, Series Loss: 0.0095, Class Loss: 0.2491, Accuracy: 0.0432\n",
      "Epoch [932/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0582, Series Loss: 0.0097, Class Loss: 0.2492, Accuracy: 0.0494\n",
      "Epoch [933/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0578, Series Loss: 0.0096, Class Loss: 0.2491, Accuracy: 0.0617\n",
      "Epoch [934/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0575, Series Loss: 0.0093, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [935/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0574, Series Loss: 0.0095, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [936/4000], Discriminator Loss: 0.0949, Generator Loss: 0.0575, Series Loss: 0.0094, Class Loss: 0.2491, Accuracy: 0.0309\n",
      "Epoch [937/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0575, Series Loss: 0.0095, Class Loss: 0.2491, Accuracy: 0.0370\n",
      "Epoch [938/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0572, Series Loss: 0.0095, Class Loss: 0.2492, Accuracy: 0.0247\n",
      "Epoch [939/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0579, Series Loss: 0.0095, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [940/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0580, Series Loss: 0.0096, Class Loss: 0.2490, Accuracy: 0.0309\n",
      "Epoch [941/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0578, Series Loss: 0.0095, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [942/4000], Discriminator Loss: 0.0939, Generator Loss: 0.0584, Series Loss: 0.0097, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [943/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0581, Series Loss: 0.0095, Class Loss: 0.2490, Accuracy: 0.0309\n",
      "Epoch [944/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0575, Series Loss: 0.0094, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [945/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0580, Series Loss: 0.0093, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [946/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0575, Series Loss: 0.0094, Class Loss: 0.2491, Accuracy: 0.0370\n",
      "Epoch [947/4000], Discriminator Loss: 0.0937, Generator Loss: 0.0583, Series Loss: 0.0095, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [948/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0580, Series Loss: 0.0096, Class Loss: 0.2491, Accuracy: 0.0309\n",
      "Epoch [949/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0581, Series Loss: 0.0095, Class Loss: 0.2490, Accuracy: 0.0247\n",
      "Epoch [950/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0578, Series Loss: 0.0097, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [951/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0577, Series Loss: 0.0096, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [952/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0583, Series Loss: 0.0095, Class Loss: 0.2488, Accuracy: 0.0370\n",
      "Epoch [953/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0583, Series Loss: 0.0094, Class Loss: 0.2491, Accuracy: 0.0309\n",
      "Epoch [954/4000], Discriminator Loss: 0.0935, Generator Loss: 0.0584, Series Loss: 0.0097, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [955/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0578, Series Loss: 0.0094, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [956/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0581, Series Loss: 0.0097, Class Loss: 0.2490, Accuracy: 0.0309\n",
      "Epoch [957/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0581, Series Loss: 0.0095, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [958/4000], Discriminator Loss: 0.0937, Generator Loss: 0.0581, Series Loss: 0.0098, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [959/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0580, Series Loss: 0.0096, Class Loss: 0.2490, Accuracy: 0.0247\n",
      "Epoch [960/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0578, Series Loss: 0.0095, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [961/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0582, Series Loss: 0.0095, Class Loss: 0.2491, Accuracy: 0.0432\n",
      "Epoch [962/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0581, Series Loss: 0.0097, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [963/4000], Discriminator Loss: 0.0937, Generator Loss: 0.0580, Series Loss: 0.0095, Class Loss: 0.2491, Accuracy: 0.0494\n",
      "Epoch [964/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0582, Series Loss: 0.0094, Class Loss: 0.2491, Accuracy: 0.0494\n",
      "Epoch [965/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0580, Series Loss: 0.0093, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [966/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0580, Series Loss: 0.0093, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [967/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0584, Series Loss: 0.0095, Class Loss: 0.2491, Accuracy: 0.0370\n",
      "Epoch [968/4000], Discriminator Loss: 0.0936, Generator Loss: 0.0584, Series Loss: 0.0095, Class Loss: 0.2491, Accuracy: 0.0432\n",
      "Epoch [969/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0583, Series Loss: 0.0094, Class Loss: 0.2491, Accuracy: 0.0370\n",
      "Epoch [970/4000], Discriminator Loss: 0.0935, Generator Loss: 0.0580, Series Loss: 0.0094, Class Loss: 0.2490, Accuracy: 0.0309\n",
      "Epoch [971/4000], Discriminator Loss: 0.0934, Generator Loss: 0.0591, Series Loss: 0.0096, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [972/4000], Discriminator Loss: 0.0935, Generator Loss: 0.0586, Series Loss: 0.0097, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [973/4000], Discriminator Loss: 0.0939, Generator Loss: 0.0584, Series Loss: 0.0097, Class Loss: 0.2490, Accuracy: 0.0309\n",
      "Epoch [974/4000], Discriminator Loss: 0.0935, Generator Loss: 0.0585, Series Loss: 0.0095, Class Loss: 0.2491, Accuracy: 0.0309\n",
      "Epoch [975/4000], Discriminator Loss: 0.0934, Generator Loss: 0.0584, Series Loss: 0.0094, Class Loss: 0.2492, Accuracy: 0.0309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [976/4000], Discriminator Loss: 0.0938, Generator Loss: 0.0581, Series Loss: 0.0094, Class Loss: 0.2491, Accuracy: 0.0247\n",
      "Epoch [977/4000], Discriminator Loss: 0.0936, Generator Loss: 0.0586, Series Loss: 0.0094, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [978/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0581, Series Loss: 0.0093, Class Loss: 0.2491, Accuracy: 0.0370\n",
      "Epoch [979/4000], Discriminator Loss: 0.0938, Generator Loss: 0.0583, Series Loss: 0.0095, Class Loss: 0.2491, Accuracy: 0.0309\n",
      "Epoch [980/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0585, Series Loss: 0.0095, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [981/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0586, Series Loss: 0.0095, Class Loss: 0.2491, Accuracy: 0.0370\n",
      "Epoch [982/4000], Discriminator Loss: 0.0931, Generator Loss: 0.0593, Series Loss: 0.0096, Class Loss: 0.2491, Accuracy: 0.0494\n",
      "Epoch [983/4000], Discriminator Loss: 0.0930, Generator Loss: 0.0590, Series Loss: 0.0095, Class Loss: 0.2491, Accuracy: 0.0309\n",
      "Epoch [984/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0581, Series Loss: 0.0094, Class Loss: 0.2490, Accuracy: 0.0247\n",
      "Epoch [985/4000], Discriminator Loss: 0.0934, Generator Loss: 0.0586, Series Loss: 0.0094, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [986/4000], Discriminator Loss: 0.0933, Generator Loss: 0.0588, Series Loss: 0.0095, Class Loss: 0.2492, Accuracy: 0.0309\n",
      "Epoch [987/4000], Discriminator Loss: 0.0936, Generator Loss: 0.0584, Series Loss: 0.0094, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [988/4000], Discriminator Loss: 0.0936, Generator Loss: 0.0583, Series Loss: 0.0096, Class Loss: 0.2491, Accuracy: 0.0247\n",
      "Epoch [989/4000], Discriminator Loss: 0.0939, Generator Loss: 0.0588, Series Loss: 0.0096, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [990/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0583, Series Loss: 0.0096, Class Loss: 0.2492, Accuracy: 0.0185\n",
      "Epoch [991/4000], Discriminator Loss: 0.0937, Generator Loss: 0.0589, Series Loss: 0.0096, Class Loss: 0.2492, Accuracy: 0.0185\n",
      "Epoch [992/4000], Discriminator Loss: 0.0934, Generator Loss: 0.0590, Series Loss: 0.0096, Class Loss: 0.2491, Accuracy: 0.0309\n",
      "Epoch [993/4000], Discriminator Loss: 0.0934, Generator Loss: 0.0591, Series Loss: 0.0095, Class Loss: 0.2492, Accuracy: 0.0247\n",
      "Epoch [994/4000], Discriminator Loss: 0.0935, Generator Loss: 0.0587, Series Loss: 0.0095, Class Loss: 0.2492, Accuracy: 0.0494\n",
      "Epoch [995/4000], Discriminator Loss: 0.0936, Generator Loss: 0.0584, Series Loss: 0.0095, Class Loss: 0.2492, Accuracy: 0.0309\n",
      "Epoch [996/4000], Discriminator Loss: 0.0937, Generator Loss: 0.0582, Series Loss: 0.0096, Class Loss: 0.2492, Accuracy: 0.0370\n",
      "Epoch [997/4000], Discriminator Loss: 0.0935, Generator Loss: 0.0591, Series Loss: 0.0097, Class Loss: 0.2493, Accuracy: 0.0247\n",
      "Epoch [998/4000], Discriminator Loss: 0.0935, Generator Loss: 0.0589, Series Loss: 0.0095, Class Loss: 0.2492, Accuracy: 0.0247\n",
      "Epoch [999/4000], Discriminator Loss: 0.0934, Generator Loss: 0.0588, Series Loss: 0.0096, Class Loss: 0.2491, Accuracy: 0.0185\n",
      "Epoch [1000/4000], Discriminator Loss: 0.0938, Generator Loss: 0.0589, Series Loss: 0.0096, Class Loss: 0.2492, Accuracy: 0.0309\n",
      "Epoch [1001/4000], Discriminator Loss: 0.0936, Generator Loss: 0.0587, Series Loss: 0.0095, Class Loss: 0.2490, Accuracy: 0.0309\n",
      "Epoch [1002/4000], Discriminator Loss: 0.0934, Generator Loss: 0.0588, Series Loss: 0.0096, Class Loss: 0.2492, Accuracy: 0.0247\n",
      "Epoch [1003/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0583, Series Loss: 0.0096, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [1004/4000], Discriminator Loss: 0.0937, Generator Loss: 0.0584, Series Loss: 0.0095, Class Loss: 0.2492, Accuracy: 0.0370\n",
      "Epoch [1005/4000], Discriminator Loss: 0.0932, Generator Loss: 0.0588, Series Loss: 0.0094, Class Loss: 0.2493, Accuracy: 0.0370\n",
      "Epoch [1006/4000], Discriminator Loss: 0.0938, Generator Loss: 0.0584, Series Loss: 0.0097, Class Loss: 0.2491, Accuracy: 0.0370\n",
      "Epoch [1007/4000], Discriminator Loss: 0.0935, Generator Loss: 0.0588, Series Loss: 0.0095, Class Loss: 0.2492, Accuracy: 0.0432\n",
      "Epoch [1008/4000], Discriminator Loss: 0.0937, Generator Loss: 0.0587, Series Loss: 0.0095, Class Loss: 0.2491, Accuracy: 0.0494\n",
      "Epoch [1009/4000], Discriminator Loss: 0.0936, Generator Loss: 0.0589, Series Loss: 0.0094, Class Loss: 0.2492, Accuracy: 0.0309\n",
      "Epoch [1010/4000], Discriminator Loss: 0.0932, Generator Loss: 0.0593, Series Loss: 0.0095, Class Loss: 0.2492, Accuracy: 0.0432\n",
      "Epoch [1011/4000], Discriminator Loss: 0.0939, Generator Loss: 0.0587, Series Loss: 0.0094, Class Loss: 0.2492, Accuracy: 0.0247\n",
      "Epoch [1012/4000], Discriminator Loss: 0.0939, Generator Loss: 0.0583, Series Loss: 0.0094, Class Loss: 0.2491, Accuracy: 0.0370\n",
      "Epoch [1013/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0583, Series Loss: 0.0094, Class Loss: 0.2491, Accuracy: 0.0370\n",
      "Epoch [1014/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0588, Series Loss: 0.0096, Class Loss: 0.2491, Accuracy: 0.0432\n",
      "Epoch [1015/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0582, Series Loss: 0.0094, Class Loss: 0.2493, Accuracy: 0.0432\n",
      "Epoch [1016/4000], Discriminator Loss: 0.0934, Generator Loss: 0.0586, Series Loss: 0.0095, Class Loss: 0.2492, Accuracy: 0.0247\n",
      "Epoch [1017/4000], Discriminator Loss: 0.0935, Generator Loss: 0.0585, Series Loss: 0.0094, Class Loss: 0.2491, Accuracy: 0.0370\n",
      "Epoch [1018/4000], Discriminator Loss: 0.0937, Generator Loss: 0.0588, Series Loss: 0.0095, Class Loss: 0.2490, Accuracy: 0.0309\n",
      "Epoch [1019/4000], Discriminator Loss: 0.0937, Generator Loss: 0.0580, Series Loss: 0.0093, Class Loss: 0.2490, Accuracy: 0.0309\n",
      "Epoch [1020/4000], Discriminator Loss: 0.0934, Generator Loss: 0.0585, Series Loss: 0.0095, Class Loss: 0.2491, Accuracy: 0.0432\n",
      "Epoch [1021/4000], Discriminator Loss: 0.0929, Generator Loss: 0.0587, Series Loss: 0.0093, Class Loss: 0.2492, Accuracy: 0.0432\n",
      "Epoch [1022/4000], Discriminator Loss: 0.0935, Generator Loss: 0.0588, Series Loss: 0.0095, Class Loss: 0.2492, Accuracy: 0.0247\n",
      "Epoch [1023/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0587, Series Loss: 0.0095, Class Loss: 0.2493, Accuracy: 0.0370\n",
      "Epoch [1024/4000], Discriminator Loss: 0.0937, Generator Loss: 0.0588, Series Loss: 0.0093, Class Loss: 0.2491, Accuracy: 0.0432\n",
      "Epoch [1025/4000], Discriminator Loss: 0.0937, Generator Loss: 0.0588, Series Loss: 0.0094, Class Loss: 0.2491, Accuracy: 0.0556\n",
      "Epoch [1026/4000], Discriminator Loss: 0.0936, Generator Loss: 0.0590, Series Loss: 0.0094, Class Loss: 0.2492, Accuracy: 0.0309\n",
      "Epoch [1027/4000], Discriminator Loss: 0.0936, Generator Loss: 0.0586, Series Loss: 0.0093, Class Loss: 0.2491, Accuracy: 0.0247\n",
      "Epoch [1028/4000], Discriminator Loss: 0.0933, Generator Loss: 0.0584, Series Loss: 0.0094, Class Loss: 0.2491, Accuracy: 0.0185\n",
      "Epoch [1029/4000], Discriminator Loss: 0.0933, Generator Loss: 0.0588, Series Loss: 0.0094, Class Loss: 0.2492, Accuracy: 0.0370\n",
      "Epoch [1030/4000], Discriminator Loss: 0.0931, Generator Loss: 0.0589, Series Loss: 0.0094, Class Loss: 0.2492, Accuracy: 0.0309\n",
      "Epoch [1031/4000], Discriminator Loss: 0.0934, Generator Loss: 0.0588, Series Loss: 0.0095, Class Loss: 0.2491, Accuracy: 0.0432\n",
      "Epoch [1032/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0583, Series Loss: 0.0092, Class Loss: 0.2493, Accuracy: 0.0247\n",
      "Epoch [1033/4000], Discriminator Loss: 0.0935, Generator Loss: 0.0588, Series Loss: 0.0093, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1034/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0582, Series Loss: 0.0094, Class Loss: 0.2493, Accuracy: 0.0432\n",
      "Epoch [1035/4000], Discriminator Loss: 0.0938, Generator Loss: 0.0580, Series Loss: 0.0092, Class Loss: 0.2490, Accuracy: 0.0309\n",
      "Epoch [1036/4000], Discriminator Loss: 0.0938, Generator Loss: 0.0583, Series Loss: 0.0094, Class Loss: 0.2491, Accuracy: 0.0370\n",
      "Epoch [1037/4000], Discriminator Loss: 0.0933, Generator Loss: 0.0583, Series Loss: 0.0091, Class Loss: 0.2492, Accuracy: 0.0309\n",
      "Epoch [1038/4000], Discriminator Loss: 0.0935, Generator Loss: 0.0588, Series Loss: 0.0092, Class Loss: 0.2492, Accuracy: 0.0494\n",
      "Epoch [1039/4000], Discriminator Loss: 0.0938, Generator Loss: 0.0582, Series Loss: 0.0090, Class Loss: 0.2492, Accuracy: 0.0370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1040/4000], Discriminator Loss: 0.0936, Generator Loss: 0.0585, Series Loss: 0.0094, Class Loss: 0.2492, Accuracy: 0.0309\n",
      "Epoch [1041/4000], Discriminator Loss: 0.0934, Generator Loss: 0.0585, Series Loss: 0.0091, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1042/4000], Discriminator Loss: 0.0936, Generator Loss: 0.0584, Series Loss: 0.0092, Class Loss: 0.2491, Accuracy: 0.0494\n",
      "Epoch [1043/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0583, Series Loss: 0.0092, Class Loss: 0.2493, Accuracy: 0.0309\n",
      "Epoch [1044/4000], Discriminator Loss: 0.0934, Generator Loss: 0.0585, Series Loss: 0.0092, Class Loss: 0.2491, Accuracy: 0.0309\n",
      "Epoch [1045/4000], Discriminator Loss: 0.0932, Generator Loss: 0.0587, Series Loss: 0.0093, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [1046/4000], Discriminator Loss: 0.0937, Generator Loss: 0.0580, Series Loss: 0.0090, Class Loss: 0.2492, Accuracy: 0.0247\n",
      "Epoch [1047/4000], Discriminator Loss: 0.0934, Generator Loss: 0.0584, Series Loss: 0.0091, Class Loss: 0.2491, Accuracy: 0.0185\n",
      "Epoch [1048/4000], Discriminator Loss: 0.0937, Generator Loss: 0.0583, Series Loss: 0.0092, Class Loss: 0.2491, Accuracy: 0.0247\n",
      "Epoch [1049/4000], Discriminator Loss: 0.0936, Generator Loss: 0.0582, Series Loss: 0.0092, Class Loss: 0.2491, Accuracy: 0.0309\n",
      "Epoch [1050/4000], Discriminator Loss: 0.0935, Generator Loss: 0.0586, Series Loss: 0.0093, Class Loss: 0.2492, Accuracy: 0.0247\n",
      "Epoch [1051/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0583, Series Loss: 0.0094, Class Loss: 0.2493, Accuracy: 0.0370\n",
      "Epoch [1052/4000], Discriminator Loss: 0.0939, Generator Loss: 0.0582, Series Loss: 0.0090, Class Loss: 0.2491, Accuracy: 0.0617\n",
      "Epoch [1053/4000], Discriminator Loss: 0.0937, Generator Loss: 0.0578, Series Loss: 0.0089, Class Loss: 0.2491, Accuracy: 0.0309\n",
      "Epoch [1054/4000], Discriminator Loss: 0.0932, Generator Loss: 0.0587, Series Loss: 0.0092, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [1055/4000], Discriminator Loss: 0.0939, Generator Loss: 0.0583, Series Loss: 0.0091, Class Loss: 0.2490, Accuracy: 0.0309\n",
      "Epoch [1056/4000], Discriminator Loss: 0.0931, Generator Loss: 0.0584, Series Loss: 0.0092, Class Loss: 0.2491, Accuracy: 0.0309\n",
      "Epoch [1057/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0581, Series Loss: 0.0091, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1058/4000], Discriminator Loss: 0.0939, Generator Loss: 0.0581, Series Loss: 0.0090, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1059/4000], Discriminator Loss: 0.0936, Generator Loss: 0.0589, Series Loss: 0.0090, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1060/4000], Discriminator Loss: 0.0938, Generator Loss: 0.0582, Series Loss: 0.0092, Class Loss: 0.2491, Accuracy: 0.0370\n",
      "Epoch [1061/4000], Discriminator Loss: 0.0936, Generator Loss: 0.0581, Series Loss: 0.0089, Class Loss: 0.2491, Accuracy: 0.0370\n",
      "Epoch [1062/4000], Discriminator Loss: 0.0937, Generator Loss: 0.0582, Series Loss: 0.0089, Class Loss: 0.2491, Accuracy: 0.0370\n",
      "Epoch [1063/4000], Discriminator Loss: 0.0936, Generator Loss: 0.0580, Series Loss: 0.0090, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1064/4000], Discriminator Loss: 0.0949, Generator Loss: 0.0574, Series Loss: 0.0089, Class Loss: 0.2491, Accuracy: 0.0370\n",
      "Epoch [1065/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0578, Series Loss: 0.0088, Class Loss: 0.2490, Accuracy: 0.0617\n",
      "Epoch [1066/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0583, Series Loss: 0.0091, Class Loss: 0.2491, Accuracy: 0.0432\n",
      "Epoch [1067/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0579, Series Loss: 0.0088, Class Loss: 0.2491, Accuracy: 0.0309\n",
      "Epoch [1068/4000], Discriminator Loss: 0.0937, Generator Loss: 0.0582, Series Loss: 0.0089, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [1069/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0575, Series Loss: 0.0088, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [1070/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0578, Series Loss: 0.0089, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1071/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0580, Series Loss: 0.0088, Class Loss: 0.2491, Accuracy: 0.0309\n",
      "Epoch [1072/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0576, Series Loss: 0.0089, Class Loss: 0.2491, Accuracy: 0.0432\n",
      "Epoch [1073/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0575, Series Loss: 0.0088, Class Loss: 0.2491, Accuracy: 0.0370\n",
      "Epoch [1074/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0576, Series Loss: 0.0088, Class Loss: 0.2490, Accuracy: 0.0309\n",
      "Epoch [1075/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0578, Series Loss: 0.0089, Class Loss: 0.2491, Accuracy: 0.0370\n",
      "Epoch [1076/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0578, Series Loss: 0.0087, Class Loss: 0.2492, Accuracy: 0.0309\n",
      "Epoch [1077/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0576, Series Loss: 0.0087, Class Loss: 0.2490, Accuracy: 0.0617\n",
      "Epoch [1078/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0577, Series Loss: 0.0089, Class Loss: 0.2493, Accuracy: 0.0370\n",
      "Epoch [1079/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0568, Series Loss: 0.0086, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [1080/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0574, Series Loss: 0.0086, Class Loss: 0.2492, Accuracy: 0.0309\n",
      "Epoch [1081/4000], Discriminator Loss: 0.0939, Generator Loss: 0.0575, Series Loss: 0.0087, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1082/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0571, Series Loss: 0.0086, Class Loss: 0.2490, Accuracy: 0.0247\n",
      "Epoch [1083/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0573, Series Loss: 0.0086, Class Loss: 0.2490, Accuracy: 0.0247\n",
      "Epoch [1084/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0572, Series Loss: 0.0086, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1085/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0572, Series Loss: 0.0086, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1086/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0574, Series Loss: 0.0087, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [1087/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0571, Series Loss: 0.0084, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [1088/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0574, Series Loss: 0.0086, Class Loss: 0.2491, Accuracy: 0.0309\n",
      "Epoch [1089/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0572, Series Loss: 0.0085, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1090/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0576, Series Loss: 0.0086, Class Loss: 0.2490, Accuracy: 0.0309\n",
      "Epoch [1091/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0571, Series Loss: 0.0085, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1092/4000], Discriminator Loss: 0.0952, Generator Loss: 0.0575, Series Loss: 0.0086, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [1093/4000], Discriminator Loss: 0.0949, Generator Loss: 0.0571, Series Loss: 0.0085, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1094/4000], Discriminator Loss: 0.0951, Generator Loss: 0.0568, Series Loss: 0.0085, Class Loss: 0.2491, Accuracy: 0.0370\n",
      "Epoch [1095/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0574, Series Loss: 0.0084, Class Loss: 0.2491, Accuracy: 0.0247\n",
      "Epoch [1096/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0574, Series Loss: 0.0085, Class Loss: 0.2491, Accuracy: 0.0370\n",
      "Epoch [1097/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0570, Series Loss: 0.0083, Class Loss: 0.2491, Accuracy: 0.0370\n",
      "Epoch [1098/4000], Discriminator Loss: 0.0951, Generator Loss: 0.0569, Series Loss: 0.0084, Class Loss: 0.2491, Accuracy: 0.0309\n",
      "Epoch [1099/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0569, Series Loss: 0.0083, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [1100/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0570, Series Loss: 0.0082, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1101/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0570, Series Loss: 0.0083, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1102/4000], Discriminator Loss: 0.0950, Generator Loss: 0.0569, Series Loss: 0.0084, Class Loss: 0.2492, Accuracy: 0.0370\n",
      "Epoch [1103/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0573, Series Loss: 0.0084, Class Loss: 0.2490, Accuracy: 0.0309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1104/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0568, Series Loss: 0.0084, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1105/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0568, Series Loss: 0.0081, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1106/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0569, Series Loss: 0.0081, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1107/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0569, Series Loss: 0.0081, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1108/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0568, Series Loss: 0.0081, Class Loss: 0.2492, Accuracy: 0.0309\n",
      "Epoch [1109/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0570, Series Loss: 0.0082, Class Loss: 0.2490, Accuracy: 0.0309\n",
      "Epoch [1110/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0572, Series Loss: 0.0081, Class Loss: 0.2491, Accuracy: 0.0494\n",
      "Epoch [1111/4000], Discriminator Loss: 0.0949, Generator Loss: 0.0569, Series Loss: 0.0081, Class Loss: 0.2492, Accuracy: 0.0432\n",
      "Epoch [1112/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0569, Series Loss: 0.0082, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1113/4000], Discriminator Loss: 0.0951, Generator Loss: 0.0569, Series Loss: 0.0080, Class Loss: 0.2489, Accuracy: 0.0309\n",
      "Epoch [1114/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0571, Series Loss: 0.0080, Class Loss: 0.2490, Accuracy: 0.0679\n",
      "Epoch [1115/4000], Discriminator Loss: 0.0952, Generator Loss: 0.0566, Series Loss: 0.0080, Class Loss: 0.2491, Accuracy: 0.0309\n",
      "Epoch [1116/4000], Discriminator Loss: 0.0949, Generator Loss: 0.0565, Series Loss: 0.0079, Class Loss: 0.2492, Accuracy: 0.0247\n",
      "Epoch [1117/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0568, Series Loss: 0.0078, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1118/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0569, Series Loss: 0.0078, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1119/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0569, Series Loss: 0.0078, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1120/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0570, Series Loss: 0.0078, Class Loss: 0.2489, Accuracy: 0.0309\n",
      "Epoch [1121/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0574, Series Loss: 0.0078, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1122/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0566, Series Loss: 0.0078, Class Loss: 0.2490, Accuracy: 0.0309\n",
      "Epoch [1123/4000], Discriminator Loss: 0.0949, Generator Loss: 0.0564, Series Loss: 0.0077, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1124/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0568, Series Loss: 0.0078, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1125/4000], Discriminator Loss: 0.0950, Generator Loss: 0.0563, Series Loss: 0.0076, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1126/4000], Discriminator Loss: 0.0939, Generator Loss: 0.0569, Series Loss: 0.0077, Class Loss: 0.2490, Accuracy: 0.0247\n",
      "Epoch [1127/4000], Discriminator Loss: 0.0950, Generator Loss: 0.0563, Series Loss: 0.0076, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1128/4000], Discriminator Loss: 0.0949, Generator Loss: 0.0568, Series Loss: 0.0077, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1129/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0571, Series Loss: 0.0078, Class Loss: 0.2489, Accuracy: 0.0309\n",
      "Epoch [1130/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0573, Series Loss: 0.0077, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1131/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0572, Series Loss: 0.0076, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1132/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0572, Series Loss: 0.0076, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1133/4000], Discriminator Loss: 0.0936, Generator Loss: 0.0575, Series Loss: 0.0077, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1134/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0564, Series Loss: 0.0076, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1135/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0563, Series Loss: 0.0077, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [1136/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0566, Series Loss: 0.0077, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [1137/4000], Discriminator Loss: 0.0938, Generator Loss: 0.0568, Series Loss: 0.0075, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1138/4000], Discriminator Loss: 0.0939, Generator Loss: 0.0567, Series Loss: 0.0075, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1139/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0570, Series Loss: 0.0076, Class Loss: 0.2491, Accuracy: 0.0494\n",
      "Epoch [1140/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0566, Series Loss: 0.0076, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1141/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0568, Series Loss: 0.0076, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1142/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0565, Series Loss: 0.0074, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1143/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0568, Series Loss: 0.0077, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1144/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0565, Series Loss: 0.0076, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1145/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0571, Series Loss: 0.0076, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [1146/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0563, Series Loss: 0.0074, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1147/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0571, Series Loss: 0.0076, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1148/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0568, Series Loss: 0.0077, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1149/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0568, Series Loss: 0.0076, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [1150/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0569, Series Loss: 0.0076, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1151/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0571, Series Loss: 0.0076, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [1152/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0567, Series Loss: 0.0075, Class Loss: 0.2490, Accuracy: 0.0247\n",
      "Epoch [1153/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0570, Series Loss: 0.0075, Class Loss: 0.2491, Accuracy: 0.0309\n",
      "Epoch [1154/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0568, Series Loss: 0.0073, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1155/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0567, Series Loss: 0.0074, Class Loss: 0.2490, Accuracy: 0.0247\n",
      "Epoch [1156/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0567, Series Loss: 0.0074, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [1157/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0565, Series Loss: 0.0073, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1158/4000], Discriminator Loss: 0.0939, Generator Loss: 0.0570, Series Loss: 0.0073, Class Loss: 0.2491, Accuracy: 0.0370\n",
      "Epoch [1159/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0570, Series Loss: 0.0074, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1160/4000], Discriminator Loss: 0.0938, Generator Loss: 0.0573, Series Loss: 0.0074, Class Loss: 0.2491, Accuracy: 0.0494\n",
      "Epoch [1161/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0567, Series Loss: 0.0073, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1162/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0565, Series Loss: 0.0073, Class Loss: 0.2491, Accuracy: 0.0432\n",
      "Epoch [1163/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0569, Series Loss: 0.0073, Class Loss: 0.2488, Accuracy: 0.0370\n",
      "Epoch [1164/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0567, Series Loss: 0.0074, Class Loss: 0.2489, Accuracy: 0.0309\n",
      "Epoch [1165/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0571, Series Loss: 0.0075, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1166/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0569, Series Loss: 0.0072, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1167/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0570, Series Loss: 0.0075, Class Loss: 0.2490, Accuracy: 0.0494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1168/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0572, Series Loss: 0.0075, Class Loss: 0.2491, Accuracy: 0.0370\n",
      "Epoch [1169/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0573, Series Loss: 0.0075, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1170/4000], Discriminator Loss: 0.0949, Generator Loss: 0.0569, Series Loss: 0.0075, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1171/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0570, Series Loss: 0.0076, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1172/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0574, Series Loss: 0.0076, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1173/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0572, Series Loss: 0.0075, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1174/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0569, Series Loss: 0.0074, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1175/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0572, Series Loss: 0.0074, Class Loss: 0.2490, Accuracy: 0.0309\n",
      "Epoch [1176/4000], Discriminator Loss: 0.0938, Generator Loss: 0.0571, Series Loss: 0.0075, Class Loss: 0.2491, Accuracy: 0.0494\n",
      "Epoch [1177/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0568, Series Loss: 0.0074, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1178/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0570, Series Loss: 0.0075, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1179/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0568, Series Loss: 0.0073, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1180/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0571, Series Loss: 0.0073, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1181/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0573, Series Loss: 0.0075, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1182/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0573, Series Loss: 0.0074, Class Loss: 0.2491, Accuracy: 0.0370\n",
      "Epoch [1183/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0569, Series Loss: 0.0075, Class Loss: 0.2490, Accuracy: 0.0309\n",
      "Epoch [1184/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0571, Series Loss: 0.0074, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [1185/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0573, Series Loss: 0.0074, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1186/4000], Discriminator Loss: 0.0939, Generator Loss: 0.0576, Series Loss: 0.0075, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1187/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0574, Series Loss: 0.0075, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1188/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0567, Series Loss: 0.0072, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [1189/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0566, Series Loss: 0.0073, Class Loss: 0.2490, Accuracy: 0.0309\n",
      "Epoch [1190/4000], Discriminator Loss: 0.0939, Generator Loss: 0.0572, Series Loss: 0.0072, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1191/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0570, Series Loss: 0.0073, Class Loss: 0.2489, Accuracy: 0.0309\n",
      "Epoch [1192/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0572, Series Loss: 0.0074, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1193/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0576, Series Loss: 0.0075, Class Loss: 0.2490, Accuracy: 0.0185\n",
      "Epoch [1194/4000], Discriminator Loss: 0.0936, Generator Loss: 0.0578, Series Loss: 0.0073, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1195/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0574, Series Loss: 0.0073, Class Loss: 0.2491, Accuracy: 0.0432\n",
      "Epoch [1196/4000], Discriminator Loss: 0.0935, Generator Loss: 0.0577, Series Loss: 0.0073, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1197/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0577, Series Loss: 0.0075, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1198/4000], Discriminator Loss: 0.0937, Generator Loss: 0.0572, Series Loss: 0.0073, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1199/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0573, Series Loss: 0.0075, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1200/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0569, Series Loss: 0.0074, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [1201/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0569, Series Loss: 0.0074, Class Loss: 0.2490, Accuracy: 0.0309\n",
      "Epoch [1202/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0569, Series Loss: 0.0073, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1203/4000], Discriminator Loss: 0.0939, Generator Loss: 0.0576, Series Loss: 0.0074, Class Loss: 0.2488, Accuracy: 0.0309\n",
      "Epoch [1204/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0576, Series Loss: 0.0075, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1205/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0573, Series Loss: 0.0074, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1206/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0578, Series Loss: 0.0076, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1207/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0576, Series Loss: 0.0074, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1208/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0575, Series Loss: 0.0076, Class Loss: 0.2488, Accuracy: 0.0370\n",
      "Epoch [1209/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0579, Series Loss: 0.0076, Class Loss: 0.2491, Accuracy: 0.0494\n",
      "Epoch [1210/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0575, Series Loss: 0.0076, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1211/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0573, Series Loss: 0.0074, Class Loss: 0.2491, Accuracy: 0.0432\n",
      "Epoch [1212/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0574, Series Loss: 0.0075, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1213/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0578, Series Loss: 0.0075, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1214/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0579, Series Loss: 0.0074, Class Loss: 0.2491, Accuracy: 0.0309\n",
      "Epoch [1215/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0580, Series Loss: 0.0076, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1216/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0577, Series Loss: 0.0074, Class Loss: 0.2491, Accuracy: 0.0309\n",
      "Epoch [1217/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0580, Series Loss: 0.0076, Class Loss: 0.2490, Accuracy: 0.0679\n",
      "Epoch [1218/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0575, Series Loss: 0.0074, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [1219/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0574, Series Loss: 0.0077, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1220/4000], Discriminator Loss: 0.0949, Generator Loss: 0.0569, Series Loss: 0.0075, Class Loss: 0.2490, Accuracy: 0.0309\n",
      "Epoch [1221/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0582, Series Loss: 0.0076, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [1222/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0576, Series Loss: 0.0075, Class Loss: 0.2488, Accuracy: 0.0370\n",
      "Epoch [1223/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0578, Series Loss: 0.0075, Class Loss: 0.2490, Accuracy: 0.0309\n",
      "Epoch [1224/4000], Discriminator Loss: 0.0950, Generator Loss: 0.0577, Series Loss: 0.0077, Class Loss: 0.2492, Accuracy: 0.0370\n",
      "Epoch [1225/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0582, Series Loss: 0.0077, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [1226/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0578, Series Loss: 0.0076, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1227/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0582, Series Loss: 0.0077, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1228/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0580, Series Loss: 0.0076, Class Loss: 0.2489, Accuracy: 0.0247\n",
      "Epoch [1229/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0582, Series Loss: 0.0078, Class Loss: 0.2489, Accuracy: 0.0123\n",
      "Epoch [1230/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0581, Series Loss: 0.0077, Class Loss: 0.2489, Accuracy: 0.0309\n",
      "Epoch [1231/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0579, Series Loss: 0.0076, Class Loss: 0.2490, Accuracy: 0.0309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1232/4000], Discriminator Loss: 0.0939, Generator Loss: 0.0580, Series Loss: 0.0077, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [1233/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0580, Series Loss: 0.0078, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1234/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0579, Series Loss: 0.0078, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1235/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0583, Series Loss: 0.0078, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [1236/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0578, Series Loss: 0.0077, Class Loss: 0.2489, Accuracy: 0.0309\n",
      "Epoch [1237/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0580, Series Loss: 0.0077, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1238/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0581, Series Loss: 0.0078, Class Loss: 0.2489, Accuracy: 0.0679\n",
      "Epoch [1239/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0583, Series Loss: 0.0078, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1240/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0581, Series Loss: 0.0076, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1241/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0581, Series Loss: 0.0078, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1242/4000], Discriminator Loss: 0.0949, Generator Loss: 0.0585, Series Loss: 0.0079, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [1243/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0583, Series Loss: 0.0078, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1244/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0580, Series Loss: 0.0079, Class Loss: 0.2490, Accuracy: 0.0309\n",
      "Epoch [1245/4000], Discriminator Loss: 0.0950, Generator Loss: 0.0581, Series Loss: 0.0077, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1246/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0584, Series Loss: 0.0078, Class Loss: 0.2489, Accuracy: 0.0185\n",
      "Epoch [1247/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0586, Series Loss: 0.0080, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1248/4000], Discriminator Loss: 0.0950, Generator Loss: 0.0582, Series Loss: 0.0080, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [1249/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0584, Series Loss: 0.0078, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [1250/4000], Discriminator Loss: 0.0950, Generator Loss: 0.0584, Series Loss: 0.0080, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1251/4000], Discriminator Loss: 0.0950, Generator Loss: 0.0582, Series Loss: 0.0080, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [1252/4000], Discriminator Loss: 0.0949, Generator Loss: 0.0584, Series Loss: 0.0079, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1253/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0585, Series Loss: 0.0079, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1254/4000], Discriminator Loss: 0.0953, Generator Loss: 0.0580, Series Loss: 0.0078, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1255/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0581, Series Loss: 0.0078, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1256/4000], Discriminator Loss: 0.0949, Generator Loss: 0.0581, Series Loss: 0.0077, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1257/4000], Discriminator Loss: 0.0954, Generator Loss: 0.0579, Series Loss: 0.0078, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1258/4000], Discriminator Loss: 0.0952, Generator Loss: 0.0578, Series Loss: 0.0080, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [1259/4000], Discriminator Loss: 0.0949, Generator Loss: 0.0585, Series Loss: 0.0080, Class Loss: 0.2489, Accuracy: 0.0309\n",
      "Epoch [1260/4000], Discriminator Loss: 0.0949, Generator Loss: 0.0580, Series Loss: 0.0079, Class Loss: 0.2489, Accuracy: 0.0309\n",
      "Epoch [1261/4000], Discriminator Loss: 0.0949, Generator Loss: 0.0578, Series Loss: 0.0078, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1262/4000], Discriminator Loss: 0.0950, Generator Loss: 0.0582, Series Loss: 0.0078, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [1263/4000], Discriminator Loss: 0.0952, Generator Loss: 0.0579, Series Loss: 0.0079, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1264/4000], Discriminator Loss: 0.0958, Generator Loss: 0.0575, Series Loss: 0.0078, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1265/4000], Discriminator Loss: 0.0955, Generator Loss: 0.0580, Series Loss: 0.0078, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1266/4000], Discriminator Loss: 0.0955, Generator Loss: 0.0584, Series Loss: 0.0080, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1267/4000], Discriminator Loss: 0.0953, Generator Loss: 0.0582, Series Loss: 0.0080, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1268/4000], Discriminator Loss: 0.0954, Generator Loss: 0.0584, Series Loss: 0.0080, Class Loss: 0.2488, Accuracy: 0.0370\n",
      "Epoch [1269/4000], Discriminator Loss: 0.0956, Generator Loss: 0.0581, Series Loss: 0.0078, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1270/4000], Discriminator Loss: 0.0950, Generator Loss: 0.0581, Series Loss: 0.0079, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1271/4000], Discriminator Loss: 0.0952, Generator Loss: 0.0585, Series Loss: 0.0081, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1272/4000], Discriminator Loss: 0.0953, Generator Loss: 0.0582, Series Loss: 0.0080, Class Loss: 0.2489, Accuracy: 0.0679\n",
      "Epoch [1273/4000], Discriminator Loss: 0.0954, Generator Loss: 0.0579, Series Loss: 0.0080, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [1274/4000], Discriminator Loss: 0.0958, Generator Loss: 0.0575, Series Loss: 0.0078, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1275/4000], Discriminator Loss: 0.0955, Generator Loss: 0.0583, Series Loss: 0.0080, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [1276/4000], Discriminator Loss: 0.0954, Generator Loss: 0.0580, Series Loss: 0.0079, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1277/4000], Discriminator Loss: 0.0954, Generator Loss: 0.0583, Series Loss: 0.0080, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1278/4000], Discriminator Loss: 0.0953, Generator Loss: 0.0583, Series Loss: 0.0080, Class Loss: 0.2491, Accuracy: 0.0370\n",
      "Epoch [1279/4000], Discriminator Loss: 0.0956, Generator Loss: 0.0580, Series Loss: 0.0081, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1280/4000], Discriminator Loss: 0.0954, Generator Loss: 0.0582, Series Loss: 0.0080, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [1281/4000], Discriminator Loss: 0.0955, Generator Loss: 0.0583, Series Loss: 0.0081, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1282/4000], Discriminator Loss: 0.0952, Generator Loss: 0.0584, Series Loss: 0.0080, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [1283/4000], Discriminator Loss: 0.0953, Generator Loss: 0.0583, Series Loss: 0.0080, Class Loss: 0.2491, Accuracy: 0.0494\n",
      "Epoch [1284/4000], Discriminator Loss: 0.0952, Generator Loss: 0.0585, Series Loss: 0.0082, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1285/4000], Discriminator Loss: 0.0960, Generator Loss: 0.0582, Series Loss: 0.0081, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [1286/4000], Discriminator Loss: 0.0958, Generator Loss: 0.0581, Series Loss: 0.0080, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [1287/4000], Discriminator Loss: 0.0951, Generator Loss: 0.0586, Series Loss: 0.0080, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [1288/4000], Discriminator Loss: 0.0953, Generator Loss: 0.0584, Series Loss: 0.0081, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1289/4000], Discriminator Loss: 0.0959, Generator Loss: 0.0582, Series Loss: 0.0081, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1290/4000], Discriminator Loss: 0.0961, Generator Loss: 0.0578, Series Loss: 0.0081, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [1291/4000], Discriminator Loss: 0.0958, Generator Loss: 0.0584, Series Loss: 0.0082, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1292/4000], Discriminator Loss: 0.0957, Generator Loss: 0.0581, Series Loss: 0.0082, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [1293/4000], Discriminator Loss: 0.0955, Generator Loss: 0.0587, Series Loss: 0.0080, Class Loss: 0.2489, Accuracy: 0.0309\n",
      "Epoch [1294/4000], Discriminator Loss: 0.0958, Generator Loss: 0.0579, Series Loss: 0.0080, Class Loss: 0.2488, Accuracy: 0.0370\n",
      "Epoch [1295/4000], Discriminator Loss: 0.0962, Generator Loss: 0.0579, Series Loss: 0.0081, Class Loss: 0.2489, Accuracy: 0.0494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1296/4000], Discriminator Loss: 0.0968, Generator Loss: 0.0579, Series Loss: 0.0082, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [1297/4000], Discriminator Loss: 0.0960, Generator Loss: 0.0583, Series Loss: 0.0081, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1298/4000], Discriminator Loss: 0.0959, Generator Loss: 0.0585, Series Loss: 0.0083, Class Loss: 0.2488, Accuracy: 0.0370\n",
      "Epoch [1299/4000], Discriminator Loss: 0.0960, Generator Loss: 0.0586, Series Loss: 0.0081, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1300/4000], Discriminator Loss: 0.0962, Generator Loss: 0.0584, Series Loss: 0.0082, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1301/4000], Discriminator Loss: 0.0961, Generator Loss: 0.0586, Series Loss: 0.0083, Class Loss: 0.2490, Accuracy: 0.0247\n",
      "Epoch [1302/4000], Discriminator Loss: 0.0964, Generator Loss: 0.0586, Series Loss: 0.0083, Class Loss: 0.2491, Accuracy: 0.0432\n",
      "Epoch [1303/4000], Discriminator Loss: 0.0963, Generator Loss: 0.0585, Series Loss: 0.0081, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [1304/4000], Discriminator Loss: 0.0957, Generator Loss: 0.0585, Series Loss: 0.0082, Class Loss: 0.2489, Accuracy: 0.0309\n",
      "Epoch [1305/4000], Discriminator Loss: 0.0959, Generator Loss: 0.0585, Series Loss: 0.0081, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1306/4000], Discriminator Loss: 0.0960, Generator Loss: 0.0586, Series Loss: 0.0081, Class Loss: 0.2489, Accuracy: 0.0309\n",
      "Epoch [1307/4000], Discriminator Loss: 0.0960, Generator Loss: 0.0585, Series Loss: 0.0082, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [1308/4000], Discriminator Loss: 0.0959, Generator Loss: 0.0583, Series Loss: 0.0081, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1309/4000], Discriminator Loss: 0.0962, Generator Loss: 0.0582, Series Loss: 0.0081, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [1310/4000], Discriminator Loss: 0.0956, Generator Loss: 0.0585, Series Loss: 0.0081, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [1311/4000], Discriminator Loss: 0.0960, Generator Loss: 0.0580, Series Loss: 0.0080, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1312/4000], Discriminator Loss: 0.0961, Generator Loss: 0.0581, Series Loss: 0.0081, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1313/4000], Discriminator Loss: 0.0960, Generator Loss: 0.0582, Series Loss: 0.0080, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1314/4000], Discriminator Loss: 0.0960, Generator Loss: 0.0585, Series Loss: 0.0080, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1315/4000], Discriminator Loss: 0.0962, Generator Loss: 0.0586, Series Loss: 0.0083, Class Loss: 0.2491, Accuracy: 0.0370\n",
      "Epoch [1316/4000], Discriminator Loss: 0.0962, Generator Loss: 0.0583, Series Loss: 0.0081, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1317/4000], Discriminator Loss: 0.0960, Generator Loss: 0.0585, Series Loss: 0.0081, Class Loss: 0.2491, Accuracy: 0.0494\n",
      "Epoch [1318/4000], Discriminator Loss: 0.0960, Generator Loss: 0.0584, Series Loss: 0.0080, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1319/4000], Discriminator Loss: 0.0960, Generator Loss: 0.0583, Series Loss: 0.0081, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [1320/4000], Discriminator Loss: 0.0957, Generator Loss: 0.0583, Series Loss: 0.0080, Class Loss: 0.2488, Accuracy: 0.0185\n",
      "Epoch [1321/4000], Discriminator Loss: 0.0957, Generator Loss: 0.0586, Series Loss: 0.0080, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1322/4000], Discriminator Loss: 0.0961, Generator Loss: 0.0582, Series Loss: 0.0080, Class Loss: 0.2491, Accuracy: 0.0309\n",
      "Epoch [1323/4000], Discriminator Loss: 0.0959, Generator Loss: 0.0588, Series Loss: 0.0082, Class Loss: 0.2490, Accuracy: 0.0309\n",
      "Epoch [1324/4000], Discriminator Loss: 0.0959, Generator Loss: 0.0585, Series Loss: 0.0081, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1325/4000], Discriminator Loss: 0.0959, Generator Loss: 0.0586, Series Loss: 0.0080, Class Loss: 0.2491, Accuracy: 0.0309\n",
      "Epoch [1326/4000], Discriminator Loss: 0.0960, Generator Loss: 0.0580, Series Loss: 0.0081, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1327/4000], Discriminator Loss: 0.0957, Generator Loss: 0.0586, Series Loss: 0.0082, Class Loss: 0.2488, Accuracy: 0.0309\n",
      "Epoch [1328/4000], Discriminator Loss: 0.0959, Generator Loss: 0.0587, Series Loss: 0.0081, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [1329/4000], Discriminator Loss: 0.0960, Generator Loss: 0.0583, Series Loss: 0.0081, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1330/4000], Discriminator Loss: 0.0960, Generator Loss: 0.0581, Series Loss: 0.0081, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [1331/4000], Discriminator Loss: 0.0960, Generator Loss: 0.0580, Series Loss: 0.0079, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1332/4000], Discriminator Loss: 0.0957, Generator Loss: 0.0590, Series Loss: 0.0081, Class Loss: 0.2489, Accuracy: 0.0309\n",
      "Epoch [1333/4000], Discriminator Loss: 0.0961, Generator Loss: 0.0583, Series Loss: 0.0081, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1334/4000], Discriminator Loss: 0.0961, Generator Loss: 0.0581, Series Loss: 0.0080, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [1335/4000], Discriminator Loss: 0.0955, Generator Loss: 0.0586, Series Loss: 0.0081, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [1336/4000], Discriminator Loss: 0.0963, Generator Loss: 0.0581, Series Loss: 0.0081, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [1337/4000], Discriminator Loss: 0.0961, Generator Loss: 0.0585, Series Loss: 0.0079, Class Loss: 0.2490, Accuracy: 0.0741\n",
      "Epoch [1338/4000], Discriminator Loss: 0.0961, Generator Loss: 0.0585, Series Loss: 0.0082, Class Loss: 0.2490, Accuracy: 0.0679\n",
      "Epoch [1339/4000], Discriminator Loss: 0.0960, Generator Loss: 0.0585, Series Loss: 0.0081, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [1340/4000], Discriminator Loss: 0.0958, Generator Loss: 0.0585, Series Loss: 0.0080, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1341/4000], Discriminator Loss: 0.0956, Generator Loss: 0.0590, Series Loss: 0.0080, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1342/4000], Discriminator Loss: 0.0958, Generator Loss: 0.0589, Series Loss: 0.0081, Class Loss: 0.2491, Accuracy: 0.0309\n",
      "Epoch [1343/4000], Discriminator Loss: 0.0959, Generator Loss: 0.0590, Series Loss: 0.0082, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [1344/4000], Discriminator Loss: 0.0957, Generator Loss: 0.0589, Series Loss: 0.0080, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1345/4000], Discriminator Loss: 0.0956, Generator Loss: 0.0589, Series Loss: 0.0081, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1346/4000], Discriminator Loss: 0.0957, Generator Loss: 0.0586, Series Loss: 0.0080, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1347/4000], Discriminator Loss: 0.0958, Generator Loss: 0.0586, Series Loss: 0.0080, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1348/4000], Discriminator Loss: 0.0958, Generator Loss: 0.0586, Series Loss: 0.0080, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [1349/4000], Discriminator Loss: 0.0955, Generator Loss: 0.0588, Series Loss: 0.0080, Class Loss: 0.2491, Accuracy: 0.0494\n",
      "Epoch [1350/4000], Discriminator Loss: 0.0959, Generator Loss: 0.0587, Series Loss: 0.0081, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1351/4000], Discriminator Loss: 0.0955, Generator Loss: 0.0585, Series Loss: 0.0080, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [1352/4000], Discriminator Loss: 0.0954, Generator Loss: 0.0583, Series Loss: 0.0080, Class Loss: 0.2490, Accuracy: 0.0309\n",
      "Epoch [1353/4000], Discriminator Loss: 0.0954, Generator Loss: 0.0588, Series Loss: 0.0081, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1354/4000], Discriminator Loss: 0.0954, Generator Loss: 0.0583, Series Loss: 0.0078, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1355/4000], Discriminator Loss: 0.0954, Generator Loss: 0.0588, Series Loss: 0.0080, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1356/4000], Discriminator Loss: 0.0958, Generator Loss: 0.0584, Series Loss: 0.0079, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1357/4000], Discriminator Loss: 0.0957, Generator Loss: 0.0585, Series Loss: 0.0079, Class Loss: 0.2488, Accuracy: 0.0370\n",
      "Epoch [1358/4000], Discriminator Loss: 0.0955, Generator Loss: 0.0589, Series Loss: 0.0080, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1359/4000], Discriminator Loss: 0.0953, Generator Loss: 0.0588, Series Loss: 0.0079, Class Loss: 0.2488, Accuracy: 0.0432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1360/4000], Discriminator Loss: 0.0956, Generator Loss: 0.0588, Series Loss: 0.0080, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [1361/4000], Discriminator Loss: 0.0956, Generator Loss: 0.0585, Series Loss: 0.0079, Class Loss: 0.2490, Accuracy: 0.0309\n",
      "Epoch [1362/4000], Discriminator Loss: 0.0955, Generator Loss: 0.0588, Series Loss: 0.0079, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1363/4000], Discriminator Loss: 0.0956, Generator Loss: 0.0586, Series Loss: 0.0081, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1364/4000], Discriminator Loss: 0.0953, Generator Loss: 0.0585, Series Loss: 0.0079, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [1365/4000], Discriminator Loss: 0.0951, Generator Loss: 0.0583, Series Loss: 0.0078, Class Loss: 0.2490, Accuracy: 0.0309\n",
      "Epoch [1366/4000], Discriminator Loss: 0.0955, Generator Loss: 0.0585, Series Loss: 0.0078, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [1367/4000], Discriminator Loss: 0.0953, Generator Loss: 0.0584, Series Loss: 0.0079, Class Loss: 0.2490, Accuracy: 0.0309\n",
      "Epoch [1368/4000], Discriminator Loss: 0.0952, Generator Loss: 0.0583, Series Loss: 0.0078, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [1369/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0587, Series Loss: 0.0078, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [1370/4000], Discriminator Loss: 0.0956, Generator Loss: 0.0581, Series Loss: 0.0079, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1371/4000], Discriminator Loss: 0.0951, Generator Loss: 0.0584, Series Loss: 0.0077, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1372/4000], Discriminator Loss: 0.0951, Generator Loss: 0.0587, Series Loss: 0.0078, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1373/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0591, Series Loss: 0.0078, Class Loss: 0.2490, Accuracy: 0.0679\n",
      "Epoch [1374/4000], Discriminator Loss: 0.0951, Generator Loss: 0.0584, Series Loss: 0.0077, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [1375/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0587, Series Loss: 0.0077, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1376/4000], Discriminator Loss: 0.0950, Generator Loss: 0.0582, Series Loss: 0.0076, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1377/4000], Discriminator Loss: 0.0956, Generator Loss: 0.0580, Series Loss: 0.0079, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1378/4000], Discriminator Loss: 0.0951, Generator Loss: 0.0583, Series Loss: 0.0078, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [1379/4000], Discriminator Loss: 0.0952, Generator Loss: 0.0586, Series Loss: 0.0077, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [1380/4000], Discriminator Loss: 0.0950, Generator Loss: 0.0584, Series Loss: 0.0076, Class Loss: 0.2490, Accuracy: 0.0617\n",
      "Epoch [1381/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0585, Series Loss: 0.0077, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [1382/4000], Discriminator Loss: 0.0950, Generator Loss: 0.0583, Series Loss: 0.0077, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1383/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0584, Series Loss: 0.0076, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1384/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0584, Series Loss: 0.0077, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1385/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0583, Series Loss: 0.0077, Class Loss: 0.2487, Accuracy: 0.0370\n",
      "Epoch [1386/4000], Discriminator Loss: 0.0950, Generator Loss: 0.0583, Series Loss: 0.0077, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1387/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0583, Series Loss: 0.0076, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1388/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0583, Series Loss: 0.0075, Class Loss: 0.2490, Accuracy: 0.0247\n",
      "Epoch [1389/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0584, Series Loss: 0.0075, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [1390/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0585, Series Loss: 0.0075, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1391/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0585, Series Loss: 0.0077, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1392/4000], Discriminator Loss: 0.0950, Generator Loss: 0.0581, Series Loss: 0.0075, Class Loss: 0.2490, Accuracy: 0.0679\n",
      "Epoch [1393/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0582, Series Loss: 0.0075, Class Loss: 0.2491, Accuracy: 0.0494\n",
      "Epoch [1394/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0587, Series Loss: 0.0076, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [1395/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0581, Series Loss: 0.0076, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [1396/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0584, Series Loss: 0.0077, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1397/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0584, Series Loss: 0.0077, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [1398/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0584, Series Loss: 0.0075, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [1399/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0585, Series Loss: 0.0075, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1400/4000], Discriminator Loss: 0.0949, Generator Loss: 0.0580, Series Loss: 0.0074, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [1401/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0583, Series Loss: 0.0075, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1402/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0585, Series Loss: 0.0075, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1403/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0581, Series Loss: 0.0073, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [1404/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0583, Series Loss: 0.0075, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [1405/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0582, Series Loss: 0.0075, Class Loss: 0.2489, Accuracy: 0.0741\n",
      "Epoch [1406/4000], Discriminator Loss: 0.0952, Generator Loss: 0.0584, Series Loss: 0.0076, Class Loss: 0.2490, Accuracy: 0.0247\n",
      "Epoch [1407/4000], Discriminator Loss: 0.0949, Generator Loss: 0.0580, Series Loss: 0.0074, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1408/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0585, Series Loss: 0.0076, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1409/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0582, Series Loss: 0.0074, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1410/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0579, Series Loss: 0.0074, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [1411/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0580, Series Loss: 0.0073, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1412/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0580, Series Loss: 0.0074, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [1413/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0580, Series Loss: 0.0074, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [1414/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0581, Series Loss: 0.0074, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1415/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0581, Series Loss: 0.0072, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [1416/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0583, Series Loss: 0.0073, Class Loss: 0.2490, Accuracy: 0.0864\n",
      "Epoch [1417/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0580, Series Loss: 0.0072, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1418/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0580, Series Loss: 0.0071, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1419/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0582, Series Loss: 0.0072, Class Loss: 0.2489, Accuracy: 0.0309\n",
      "Epoch [1420/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0582, Series Loss: 0.0072, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1421/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0586, Series Loss: 0.0073, Class Loss: 0.2490, Accuracy: 0.0309\n",
      "Epoch [1422/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0581, Series Loss: 0.0073, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1423/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0582, Series Loss: 0.0072, Class Loss: 0.2489, Accuracy: 0.0309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1424/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0584, Series Loss: 0.0071, Class Loss: 0.2489, Accuracy: 0.0864\n",
      "Epoch [1425/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0582, Series Loss: 0.0071, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1426/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0579, Series Loss: 0.0071, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1427/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0575, Series Loss: 0.0070, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [1428/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0577, Series Loss: 0.0071, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1429/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0576, Series Loss: 0.0069, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1430/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0575, Series Loss: 0.0070, Class Loss: 0.2490, Accuracy: 0.0617\n",
      "Epoch [1431/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0579, Series Loss: 0.0071, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1432/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0578, Series Loss: 0.0071, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1433/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0578, Series Loss: 0.0070, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1434/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0577, Series Loss: 0.0071, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1435/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0582, Series Loss: 0.0072, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [1436/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0576, Series Loss: 0.0072, Class Loss: 0.2489, Accuracy: 0.0679\n",
      "Epoch [1437/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0579, Series Loss: 0.0072, Class Loss: 0.2489, Accuracy: 0.0741\n",
      "Epoch [1438/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0580, Series Loss: 0.0070, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1439/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0576, Series Loss: 0.0070, Class Loss: 0.2489, Accuracy: 0.0741\n",
      "Epoch [1440/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0577, Series Loss: 0.0071, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [1441/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0577, Series Loss: 0.0071, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [1442/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0577, Series Loss: 0.0070, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1443/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0579, Series Loss: 0.0070, Class Loss: 0.2489, Accuracy: 0.0679\n",
      "Epoch [1444/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0580, Series Loss: 0.0071, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1445/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0581, Series Loss: 0.0070, Class Loss: 0.2490, Accuracy: 0.0617\n",
      "Epoch [1446/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0577, Series Loss: 0.0069, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1447/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0581, Series Loss: 0.0071, Class Loss: 0.2489, Accuracy: 0.0741\n",
      "Epoch [1448/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0576, Series Loss: 0.0070, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1449/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0575, Series Loss: 0.0070, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1450/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0576, Series Loss: 0.0070, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1451/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0576, Series Loss: 0.0069, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1452/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0579, Series Loss: 0.0070, Class Loss: 0.2489, Accuracy: 0.0741\n",
      "Epoch [1453/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0578, Series Loss: 0.0070, Class Loss: 0.2489, Accuracy: 0.0802\n",
      "Epoch [1454/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0576, Series Loss: 0.0070, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [1455/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0576, Series Loss: 0.0069, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [1456/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0578, Series Loss: 0.0070, Class Loss: 0.2490, Accuracy: 0.0617\n",
      "Epoch [1457/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0574, Series Loss: 0.0070, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1458/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0573, Series Loss: 0.0068, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1459/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0575, Series Loss: 0.0068, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1460/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0576, Series Loss: 0.0068, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1461/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0577, Series Loss: 0.0068, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [1462/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0580, Series Loss: 0.0070, Class Loss: 0.2488, Accuracy: 0.0864\n",
      "Epoch [1463/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0582, Series Loss: 0.0070, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [1464/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0579, Series Loss: 0.0070, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [1465/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0578, Series Loss: 0.0069, Class Loss: 0.2490, Accuracy: 0.0741\n",
      "Epoch [1466/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0576, Series Loss: 0.0068, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1467/4000], Discriminator Loss: 0.0949, Generator Loss: 0.0578, Series Loss: 0.0069, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1468/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0580, Series Loss: 0.0069, Class Loss: 0.2491, Accuracy: 0.0370\n",
      "Epoch [1469/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0574, Series Loss: 0.0068, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [1470/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0575, Series Loss: 0.0068, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [1471/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0571, Series Loss: 0.0069, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1472/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0574, Series Loss: 0.0068, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1473/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0574, Series Loss: 0.0068, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1474/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0573, Series Loss: 0.0067, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1475/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0576, Series Loss: 0.0067, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1476/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0573, Series Loss: 0.0068, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [1477/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0576, Series Loss: 0.0069, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [1478/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0573, Series Loss: 0.0069, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [1479/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0573, Series Loss: 0.0069, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1480/4000], Discriminator Loss: 0.0949, Generator Loss: 0.0574, Series Loss: 0.0068, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [1481/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0577, Series Loss: 0.0069, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1482/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0578, Series Loss: 0.0069, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [1483/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0577, Series Loss: 0.0068, Class Loss: 0.2489, Accuracy: 0.0802\n",
      "Epoch [1484/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0572, Series Loss: 0.0067, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [1485/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0575, Series Loss: 0.0068, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [1486/4000], Discriminator Loss: 0.0952, Generator Loss: 0.0570, Series Loss: 0.0068, Class Loss: 0.2491, Accuracy: 0.0494\n",
      "Epoch [1487/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0576, Series Loss: 0.0069, Class Loss: 0.2489, Accuracy: 0.0494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1488/4000], Discriminator Loss: 0.0950, Generator Loss: 0.0573, Series Loss: 0.0067, Class Loss: 0.2490, Accuracy: 0.0617\n",
      "Epoch [1489/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0572, Series Loss: 0.0067, Class Loss: 0.2488, Accuracy: 0.0370\n",
      "Epoch [1490/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0579, Series Loss: 0.0069, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1491/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0574, Series Loss: 0.0067, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1492/4000], Discriminator Loss: 0.0949, Generator Loss: 0.0571, Series Loss: 0.0068, Class Loss: 0.2489, Accuracy: 0.0309\n",
      "Epoch [1493/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0571, Series Loss: 0.0068, Class Loss: 0.2491, Accuracy: 0.0432\n",
      "Epoch [1494/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0572, Series Loss: 0.0068, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1495/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0571, Series Loss: 0.0066, Class Loss: 0.2490, Accuracy: 0.0617\n",
      "Epoch [1496/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0574, Series Loss: 0.0067, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1497/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0577, Series Loss: 0.0067, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1498/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0576, Series Loss: 0.0068, Class Loss: 0.2489, Accuracy: 0.0247\n",
      "Epoch [1499/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0575, Series Loss: 0.0069, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [1500/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0572, Series Loss: 0.0067, Class Loss: 0.2489, Accuracy: 0.0309\n",
      "Epoch [1501/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0575, Series Loss: 0.0069, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [1502/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0575, Series Loss: 0.0069, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1503/4000], Discriminator Loss: 0.0949, Generator Loss: 0.0573, Series Loss: 0.0069, Class Loss: 0.2489, Accuracy: 0.0247\n",
      "Epoch [1504/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0571, Series Loss: 0.0067, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1505/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0578, Series Loss: 0.0069, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1506/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0576, Series Loss: 0.0069, Class Loss: 0.2490, Accuracy: 0.0309\n",
      "Epoch [1507/4000], Discriminator Loss: 0.0949, Generator Loss: 0.0575, Series Loss: 0.0067, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [1508/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0574, Series Loss: 0.0067, Class Loss: 0.2488, Accuracy: 0.0247\n",
      "Epoch [1509/4000], Discriminator Loss: 0.0949, Generator Loss: 0.0576, Series Loss: 0.0070, Class Loss: 0.2489, Accuracy: 0.0309\n",
      "Epoch [1510/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0575, Series Loss: 0.0069, Class Loss: 0.2489, Accuracy: 0.0309\n",
      "Epoch [1511/4000], Discriminator Loss: 0.0949, Generator Loss: 0.0573, Series Loss: 0.0068, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [1512/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0575, Series Loss: 0.0067, Class Loss: 0.2490, Accuracy: 0.0309\n",
      "Epoch [1513/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0574, Series Loss: 0.0068, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [1514/4000], Discriminator Loss: 0.0952, Generator Loss: 0.0572, Series Loss: 0.0069, Class Loss: 0.2490, Accuracy: 0.0309\n",
      "Epoch [1515/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0575, Series Loss: 0.0068, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1516/4000], Discriminator Loss: 0.0949, Generator Loss: 0.0575, Series Loss: 0.0068, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1517/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0576, Series Loss: 0.0068, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1518/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0577, Series Loss: 0.0068, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1519/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0574, Series Loss: 0.0068, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1520/4000], Discriminator Loss: 0.0951, Generator Loss: 0.0568, Series Loss: 0.0069, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1521/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0572, Series Loss: 0.0068, Class Loss: 0.2490, Accuracy: 0.0309\n",
      "Epoch [1522/4000], Discriminator Loss: 0.0951, Generator Loss: 0.0575, Series Loss: 0.0067, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1523/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0578, Series Loss: 0.0068, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [1524/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0578, Series Loss: 0.0069, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [1525/4000], Discriminator Loss: 0.0950, Generator Loss: 0.0575, Series Loss: 0.0069, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1526/4000], Discriminator Loss: 0.0949, Generator Loss: 0.0577, Series Loss: 0.0069, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1527/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0575, Series Loss: 0.0067, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1528/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0581, Series Loss: 0.0070, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [1529/4000], Discriminator Loss: 0.0949, Generator Loss: 0.0573, Series Loss: 0.0068, Class Loss: 0.2490, Accuracy: 0.0247\n",
      "Epoch [1530/4000], Discriminator Loss: 0.0949, Generator Loss: 0.0577, Series Loss: 0.0069, Class Loss: 0.2490, Accuracy: 0.0309\n",
      "Epoch [1531/4000], Discriminator Loss: 0.0951, Generator Loss: 0.0574, Series Loss: 0.0068, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1532/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0581, Series Loss: 0.0069, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1533/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0577, Series Loss: 0.0068, Class Loss: 0.2490, Accuracy: 0.0309\n",
      "Epoch [1534/4000], Discriminator Loss: 0.0950, Generator Loss: 0.0575, Series Loss: 0.0069, Class Loss: 0.2490, Accuracy: 0.0185\n",
      "Epoch [1535/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0575, Series Loss: 0.0068, Class Loss: 0.2491, Accuracy: 0.0370\n",
      "Epoch [1536/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0573, Series Loss: 0.0067, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1537/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0578, Series Loss: 0.0068, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1538/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0577, Series Loss: 0.0067, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1539/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0573, Series Loss: 0.0067, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1540/4000], Discriminator Loss: 0.0952, Generator Loss: 0.0572, Series Loss: 0.0068, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [1541/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0576, Series Loss: 0.0067, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1542/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0578, Series Loss: 0.0067, Class Loss: 0.2490, Accuracy: 0.0247\n",
      "Epoch [1543/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0574, Series Loss: 0.0067, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1544/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0573, Series Loss: 0.0067, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [1545/4000], Discriminator Loss: 0.0949, Generator Loss: 0.0573, Series Loss: 0.0067, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1546/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0578, Series Loss: 0.0067, Class Loss: 0.2489, Accuracy: 0.0309\n",
      "Epoch [1547/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0575, Series Loss: 0.0068, Class Loss: 0.2490, Accuracy: 0.0309\n",
      "Epoch [1548/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0576, Series Loss: 0.0068, Class Loss: 0.2489, Accuracy: 0.0309\n",
      "Epoch [1549/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0574, Series Loss: 0.0068, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1550/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0574, Series Loss: 0.0068, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1551/4000], Discriminator Loss: 0.0951, Generator Loss: 0.0570, Series Loss: 0.0068, Class Loss: 0.2492, Accuracy: 0.0370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1552/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0573, Series Loss: 0.0068, Class Loss: 0.2490, Accuracy: 0.0309\n",
      "Epoch [1553/4000], Discriminator Loss: 0.0949, Generator Loss: 0.0574, Series Loss: 0.0068, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [1554/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0575, Series Loss: 0.0068, Class Loss: 0.2491, Accuracy: 0.0185\n",
      "Epoch [1555/4000], Discriminator Loss: 0.0950, Generator Loss: 0.0572, Series Loss: 0.0067, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1556/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0574, Series Loss: 0.0066, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [1557/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0573, Series Loss: 0.0066, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1558/4000], Discriminator Loss: 0.0949, Generator Loss: 0.0574, Series Loss: 0.0067, Class Loss: 0.2489, Accuracy: 0.0309\n",
      "Epoch [1559/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0579, Series Loss: 0.0068, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1560/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0576, Series Loss: 0.0068, Class Loss: 0.2491, Accuracy: 0.0309\n",
      "Epoch [1561/4000], Discriminator Loss: 0.0949, Generator Loss: 0.0571, Series Loss: 0.0067, Class Loss: 0.2489, Accuracy: 0.0679\n",
      "Epoch [1562/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0572, Series Loss: 0.0067, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [1563/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0574, Series Loss: 0.0066, Class Loss: 0.2489, Accuracy: 0.0309\n",
      "Epoch [1564/4000], Discriminator Loss: 0.0950, Generator Loss: 0.0573, Series Loss: 0.0067, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [1565/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0572, Series Loss: 0.0066, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1566/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0573, Series Loss: 0.0067, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [1567/4000], Discriminator Loss: 0.0949, Generator Loss: 0.0570, Series Loss: 0.0067, Class Loss: 0.2490, Accuracy: 0.0247\n",
      "Epoch [1568/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0573, Series Loss: 0.0067, Class Loss: 0.2491, Accuracy: 0.0370\n",
      "Epoch [1569/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0572, Series Loss: 0.0066, Class Loss: 0.2491, Accuracy: 0.0432\n",
      "Epoch [1570/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0572, Series Loss: 0.0067, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [1571/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0573, Series Loss: 0.0066, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1572/4000], Discriminator Loss: 0.0950, Generator Loss: 0.0571, Series Loss: 0.0066, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1573/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0572, Series Loss: 0.0067, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [1574/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0574, Series Loss: 0.0067, Class Loss: 0.2490, Accuracy: 0.0309\n",
      "Epoch [1575/4000], Discriminator Loss: 0.0952, Generator Loss: 0.0570, Series Loss: 0.0066, Class Loss: 0.2490, Accuracy: 0.0247\n",
      "Epoch [1576/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0573, Series Loss: 0.0067, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [1577/4000], Discriminator Loss: 0.0949, Generator Loss: 0.0573, Series Loss: 0.0067, Class Loss: 0.2488, Accuracy: 0.0370\n",
      "Epoch [1578/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0571, Series Loss: 0.0065, Class Loss: 0.2490, Accuracy: 0.0309\n",
      "Epoch [1579/4000], Discriminator Loss: 0.0950, Generator Loss: 0.0571, Series Loss: 0.0066, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1580/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0574, Series Loss: 0.0067, Class Loss: 0.2490, Accuracy: 0.0309\n",
      "Epoch [1581/4000], Discriminator Loss: 0.0949, Generator Loss: 0.0574, Series Loss: 0.0066, Class Loss: 0.2489, Accuracy: 0.0309\n",
      "Epoch [1582/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0575, Series Loss: 0.0066, Class Loss: 0.2490, Accuracy: 0.0185\n",
      "Epoch [1583/4000], Discriminator Loss: 0.0949, Generator Loss: 0.0568, Series Loss: 0.0065, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1584/4000], Discriminator Loss: 0.0949, Generator Loss: 0.0570, Series Loss: 0.0066, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [1585/4000], Discriminator Loss: 0.0949, Generator Loss: 0.0570, Series Loss: 0.0066, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [1586/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0571, Series Loss: 0.0065, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1587/4000], Discriminator Loss: 0.0950, Generator Loss: 0.0568, Series Loss: 0.0065, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1588/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0572, Series Loss: 0.0065, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1589/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0571, Series Loss: 0.0065, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [1590/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0569, Series Loss: 0.0065, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1591/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0565, Series Loss: 0.0064, Class Loss: 0.2490, Accuracy: 0.0309\n",
      "Epoch [1592/4000], Discriminator Loss: 0.0949, Generator Loss: 0.0569, Series Loss: 0.0065, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1593/4000], Discriminator Loss: 0.0950, Generator Loss: 0.0568, Series Loss: 0.0065, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [1594/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0568, Series Loss: 0.0063, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [1595/4000], Discriminator Loss: 0.0950, Generator Loss: 0.0567, Series Loss: 0.0064, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1596/4000], Discriminator Loss: 0.0949, Generator Loss: 0.0572, Series Loss: 0.0066, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1597/4000], Discriminator Loss: 0.0951, Generator Loss: 0.0571, Series Loss: 0.0066, Class Loss: 0.2489, Accuracy: 0.0309\n",
      "Epoch [1598/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0574, Series Loss: 0.0065, Class Loss: 0.2490, Accuracy: 0.0309\n",
      "Epoch [1599/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0573, Series Loss: 0.0064, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1600/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0570, Series Loss: 0.0064, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [1601/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0571, Series Loss: 0.0065, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1602/4000], Discriminator Loss: 0.0949, Generator Loss: 0.0568, Series Loss: 0.0064, Class Loss: 0.2491, Accuracy: 0.0247\n",
      "Epoch [1603/4000], Discriminator Loss: 0.0949, Generator Loss: 0.0571, Series Loss: 0.0064, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1604/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0574, Series Loss: 0.0065, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [1605/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0572, Series Loss: 0.0065, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1606/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0573, Series Loss: 0.0065, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [1607/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0572, Series Loss: 0.0064, Class Loss: 0.2489, Accuracy: 0.0309\n",
      "Epoch [1608/4000], Discriminator Loss: 0.0949, Generator Loss: 0.0567, Series Loss: 0.0064, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1609/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0568, Series Loss: 0.0063, Class Loss: 0.2489, Accuracy: 0.0309\n",
      "Epoch [1610/4000], Discriminator Loss: 0.0949, Generator Loss: 0.0570, Series Loss: 0.0064, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [1611/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0572, Series Loss: 0.0063, Class Loss: 0.2489, Accuracy: 0.0309\n",
      "Epoch [1612/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0569, Series Loss: 0.0063, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1613/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0568, Series Loss: 0.0063, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1614/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0569, Series Loss: 0.0064, Class Loss: 0.2490, Accuracy: 0.0679\n",
      "Epoch [1615/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0568, Series Loss: 0.0063, Class Loss: 0.2490, Accuracy: 0.0556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1616/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0568, Series Loss: 0.0064, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [1617/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0569, Series Loss: 0.0064, Class Loss: 0.2489, Accuracy: 0.0309\n",
      "Epoch [1618/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0569, Series Loss: 0.0064, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1619/4000], Discriminator Loss: 0.0949, Generator Loss: 0.0567, Series Loss: 0.0063, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1620/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0569, Series Loss: 0.0064, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1621/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0565, Series Loss: 0.0062, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1622/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0569, Series Loss: 0.0063, Class Loss: 0.2490, Accuracy: 0.0247\n",
      "Epoch [1623/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0565, Series Loss: 0.0061, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1624/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0567, Series Loss: 0.0063, Class Loss: 0.2490, Accuracy: 0.0309\n",
      "Epoch [1625/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0566, Series Loss: 0.0063, Class Loss: 0.2490, Accuracy: 0.0617\n",
      "Epoch [1626/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0569, Series Loss: 0.0064, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1627/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0565, Series Loss: 0.0062, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [1628/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0564, Series Loss: 0.0062, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [1629/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0565, Series Loss: 0.0063, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1630/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0567, Series Loss: 0.0063, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1631/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0566, Series Loss: 0.0062, Class Loss: 0.2489, Accuracy: 0.0679\n",
      "Epoch [1632/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0567, Series Loss: 0.0063, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1633/4000], Discriminator Loss: 0.0949, Generator Loss: 0.0568, Series Loss: 0.0063, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1634/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0569, Series Loss: 0.0064, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [1635/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0571, Series Loss: 0.0063, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1636/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0567, Series Loss: 0.0063, Class Loss: 0.2491, Accuracy: 0.0370\n",
      "Epoch [1637/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0565, Series Loss: 0.0063, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [1638/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0568, Series Loss: 0.0063, Class Loss: 0.2491, Accuracy: 0.0370\n",
      "Epoch [1639/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0565, Series Loss: 0.0063, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1640/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0569, Series Loss: 0.0063, Class Loss: 0.2490, Accuracy: 0.0679\n",
      "Epoch [1641/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0568, Series Loss: 0.0063, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1642/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0571, Series Loss: 0.0063, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1643/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0569, Series Loss: 0.0062, Class Loss: 0.2489, Accuracy: 0.0741\n",
      "Epoch [1644/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0567, Series Loss: 0.0063, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1645/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0567, Series Loss: 0.0062, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1646/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0568, Series Loss: 0.0062, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1647/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0569, Series Loss: 0.0062, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1648/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0569, Series Loss: 0.0062, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [1649/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0568, Series Loss: 0.0061, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1650/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0567, Series Loss: 0.0062, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [1651/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0569, Series Loss: 0.0062, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1652/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0565, Series Loss: 0.0062, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1653/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0567, Series Loss: 0.0061, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [1654/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0568, Series Loss: 0.0061, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1655/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0568, Series Loss: 0.0062, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1656/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0568, Series Loss: 0.0062, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1657/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0569, Series Loss: 0.0062, Class Loss: 0.2488, Accuracy: 0.0741\n",
      "Epoch [1658/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0570, Series Loss: 0.0063, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1659/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0569, Series Loss: 0.0062, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [1660/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0568, Series Loss: 0.0062, Class Loss: 0.2489, Accuracy: 0.0247\n",
      "Epoch [1661/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0564, Series Loss: 0.0062, Class Loss: 0.2489, Accuracy: 0.0309\n",
      "Epoch [1662/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0563, Series Loss: 0.0062, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [1663/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0567, Series Loss: 0.0062, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [1664/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0566, Series Loss: 0.0061, Class Loss: 0.2490, Accuracy: 0.0247\n",
      "Epoch [1665/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0567, Series Loss: 0.0062, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [1666/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0568, Series Loss: 0.0062, Class Loss: 0.2490, Accuracy: 0.0309\n",
      "Epoch [1667/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0567, Series Loss: 0.0061, Class Loss: 0.2489, Accuracy: 0.0309\n",
      "Epoch [1668/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0566, Series Loss: 0.0061, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [1669/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0567, Series Loss: 0.0061, Class Loss: 0.2490, Accuracy: 0.0617\n",
      "Epoch [1670/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0569, Series Loss: 0.0061, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1671/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0565, Series Loss: 0.0061, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1672/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0563, Series Loss: 0.0061, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [1673/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0566, Series Loss: 0.0061, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1674/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0566, Series Loss: 0.0061, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1675/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0566, Series Loss: 0.0062, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [1676/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0563, Series Loss: 0.0061, Class Loss: 0.2489, Accuracy: 0.0741\n",
      "Epoch [1677/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0568, Series Loss: 0.0061, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1678/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0566, Series Loss: 0.0061, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1679/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0567, Series Loss: 0.0061, Class Loss: 0.2489, Accuracy: 0.0556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1680/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0565, Series Loss: 0.0061, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [1681/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0565, Series Loss: 0.0061, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1682/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0566, Series Loss: 0.0061, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1683/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0565, Series Loss: 0.0062, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [1684/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0563, Series Loss: 0.0061, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [1685/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0562, Series Loss: 0.0060, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [1686/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0566, Series Loss: 0.0061, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1687/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0566, Series Loss: 0.0060, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [1688/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0563, Series Loss: 0.0060, Class Loss: 0.2488, Accuracy: 0.0741\n",
      "Epoch [1689/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0566, Series Loss: 0.0061, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1690/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0564, Series Loss: 0.0061, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [1691/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0565, Series Loss: 0.0061, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1692/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0565, Series Loss: 0.0060, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1693/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0564, Series Loss: 0.0060, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1694/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0566, Series Loss: 0.0060, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1695/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0567, Series Loss: 0.0060, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1696/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0565, Series Loss: 0.0060, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1697/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0570, Series Loss: 0.0061, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1698/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0568, Series Loss: 0.0060, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1699/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0565, Series Loss: 0.0060, Class Loss: 0.2488, Accuracy: 0.0741\n",
      "Epoch [1700/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0567, Series Loss: 0.0061, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [1701/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0567, Series Loss: 0.0061, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [1702/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0563, Series Loss: 0.0059, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [1703/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0565, Series Loss: 0.0061, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [1704/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0565, Series Loss: 0.0061, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [1705/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0563, Series Loss: 0.0060, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [1706/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0564, Series Loss: 0.0060, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [1707/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0561, Series Loss: 0.0060, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [1708/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0560, Series Loss: 0.0058, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [1709/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0567, Series Loss: 0.0060, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1710/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0565, Series Loss: 0.0060, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1711/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0562, Series Loss: 0.0060, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1712/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0567, Series Loss: 0.0060, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1713/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0563, Series Loss: 0.0059, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [1714/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0564, Series Loss: 0.0059, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [1715/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0562, Series Loss: 0.0059, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1716/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0562, Series Loss: 0.0059, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1717/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0560, Series Loss: 0.0059, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1718/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0562, Series Loss: 0.0059, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1719/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0561, Series Loss: 0.0059, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [1720/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0564, Series Loss: 0.0058, Class Loss: 0.2490, Accuracy: 0.0309\n",
      "Epoch [1721/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0560, Series Loss: 0.0058, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1722/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0563, Series Loss: 0.0059, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [1723/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0560, Series Loss: 0.0059, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [1724/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0561, Series Loss: 0.0060, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1725/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0560, Series Loss: 0.0059, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [1726/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0561, Series Loss: 0.0059, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [1727/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0560, Series Loss: 0.0059, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1728/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0561, Series Loss: 0.0059, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [1729/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0559, Series Loss: 0.0058, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [1730/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0562, Series Loss: 0.0059, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [1731/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0562, Series Loss: 0.0059, Class Loss: 0.2488, Accuracy: 0.0370\n",
      "Epoch [1732/4000], Discriminator Loss: 0.0949, Generator Loss: 0.0559, Series Loss: 0.0058, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [1733/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0565, Series Loss: 0.0059, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1734/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0559, Series Loss: 0.0058, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [1735/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0561, Series Loss: 0.0059, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [1736/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0560, Series Loss: 0.0059, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1737/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0562, Series Loss: 0.0060, Class Loss: 0.2489, Accuracy: 0.0309\n",
      "Epoch [1738/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0562, Series Loss: 0.0059, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [1739/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0561, Series Loss: 0.0058, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [1740/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0562, Series Loss: 0.0059, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1741/4000], Discriminator Loss: 0.0948, Generator Loss: 0.0560, Series Loss: 0.0058, Class Loss: 0.2490, Accuracy: 0.0617\n",
      "Epoch [1742/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0564, Series Loss: 0.0058, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1743/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0561, Series Loss: 0.0058, Class Loss: 0.2489, Accuracy: 0.0802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1744/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0558, Series Loss: 0.0058, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [1745/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0562, Series Loss: 0.0058, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [1746/4000], Discriminator Loss: 0.0947, Generator Loss: 0.0560, Series Loss: 0.0058, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1747/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0561, Series Loss: 0.0057, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [1748/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0564, Series Loss: 0.0058, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1749/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0564, Series Loss: 0.0059, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1750/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0561, Series Loss: 0.0058, Class Loss: 0.2489, Accuracy: 0.0309\n",
      "Epoch [1751/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0560, Series Loss: 0.0058, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [1752/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0560, Series Loss: 0.0058, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1753/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0561, Series Loss: 0.0058, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1754/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0562, Series Loss: 0.0056, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [1755/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0562, Series Loss: 0.0057, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [1756/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0563, Series Loss: 0.0058, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [1757/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0562, Series Loss: 0.0058, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1758/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0562, Series Loss: 0.0058, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [1759/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0562, Series Loss: 0.0057, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1760/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0563, Series Loss: 0.0058, Class Loss: 0.2489, Accuracy: 0.0309\n",
      "Epoch [1761/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0564, Series Loss: 0.0058, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1762/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0560, Series Loss: 0.0057, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1763/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0559, Series Loss: 0.0057, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [1764/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0557, Series Loss: 0.0056, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1765/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0561, Series Loss: 0.0057, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [1766/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0564, Series Loss: 0.0057, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1767/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0561, Series Loss: 0.0056, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1768/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0562, Series Loss: 0.0057, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [1769/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0561, Series Loss: 0.0056, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1770/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0559, Series Loss: 0.0056, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [1771/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0561, Series Loss: 0.0056, Class Loss: 0.2489, Accuracy: 0.0679\n",
      "Epoch [1772/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0559, Series Loss: 0.0056, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1773/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0558, Series Loss: 0.0056, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [1774/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0559, Series Loss: 0.0056, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [1775/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0558, Series Loss: 0.0055, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1776/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0560, Series Loss: 0.0055, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1777/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0561, Series Loss: 0.0056, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [1778/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0561, Series Loss: 0.0055, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1779/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0558, Series Loss: 0.0055, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1780/4000], Discriminator Loss: 0.0939, Generator Loss: 0.0559, Series Loss: 0.0056, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1781/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0559, Series Loss: 0.0055, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [1782/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0560, Series Loss: 0.0056, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1783/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0560, Series Loss: 0.0055, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1784/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0560, Series Loss: 0.0056, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [1785/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0561, Series Loss: 0.0055, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [1786/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0562, Series Loss: 0.0056, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1787/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0560, Series Loss: 0.0056, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [1788/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0562, Series Loss: 0.0057, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1789/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0560, Series Loss: 0.0055, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1790/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0562, Series Loss: 0.0056, Class Loss: 0.2491, Accuracy: 0.0370\n",
      "Epoch [1791/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0563, Series Loss: 0.0056, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [1792/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0564, Series Loss: 0.0056, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1793/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0563, Series Loss: 0.0057, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1794/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0561, Series Loss: 0.0056, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [1795/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0562, Series Loss: 0.0057, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1796/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0559, Series Loss: 0.0055, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [1797/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0558, Series Loss: 0.0056, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1798/4000], Discriminator Loss: 0.0939, Generator Loss: 0.0560, Series Loss: 0.0056, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [1799/4000], Discriminator Loss: 0.0938, Generator Loss: 0.0560, Series Loss: 0.0056, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [1800/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0559, Series Loss: 0.0056, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1801/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0558, Series Loss: 0.0055, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1802/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0558, Series Loss: 0.0056, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1803/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0558, Series Loss: 0.0055, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [1804/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0559, Series Loss: 0.0056, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1805/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0560, Series Loss: 0.0055, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1806/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0561, Series Loss: 0.0055, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [1807/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0561, Series Loss: 0.0055, Class Loss: 0.2490, Accuracy: 0.0309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1808/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0560, Series Loss: 0.0056, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1809/4000], Discriminator Loss: 0.0937, Generator Loss: 0.0562, Series Loss: 0.0056, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [1810/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0559, Series Loss: 0.0056, Class Loss: 0.2489, Accuracy: 0.0741\n",
      "Epoch [1811/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0561, Series Loss: 0.0055, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1812/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0558, Series Loss: 0.0056, Class Loss: 0.2491, Accuracy: 0.0370\n",
      "Epoch [1813/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0558, Series Loss: 0.0056, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1814/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0557, Series Loss: 0.0056, Class Loss: 0.2490, Accuracy: 0.0617\n",
      "Epoch [1815/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0558, Series Loss: 0.0056, Class Loss: 0.2491, Accuracy: 0.0494\n",
      "Epoch [1816/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0559, Series Loss: 0.0055, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [1817/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0558, Series Loss: 0.0055, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1818/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0556, Series Loss: 0.0056, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [1819/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0558, Series Loss: 0.0056, Class Loss: 0.2491, Accuracy: 0.0247\n",
      "Epoch [1820/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0558, Series Loss: 0.0055, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1821/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0560, Series Loss: 0.0055, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1822/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0561, Series Loss: 0.0055, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1823/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0558, Series Loss: 0.0055, Class Loss: 0.2489, Accuracy: 0.0679\n",
      "Epoch [1824/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0560, Series Loss: 0.0055, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [1825/4000], Discriminator Loss: 0.0939, Generator Loss: 0.0562, Series Loss: 0.0055, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [1826/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0559, Series Loss: 0.0055, Class Loss: 0.2489, Accuracy: 0.0185\n",
      "Epoch [1827/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0557, Series Loss: 0.0055, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1828/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0561, Series Loss: 0.0056, Class Loss: 0.2490, Accuracy: 0.0617\n",
      "Epoch [1829/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0559, Series Loss: 0.0056, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1830/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0558, Series Loss: 0.0055, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1831/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0559, Series Loss: 0.0056, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1832/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0561, Series Loss: 0.0055, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1833/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0560, Series Loss: 0.0055, Class Loss: 0.2491, Accuracy: 0.0617\n",
      "Epoch [1834/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0558, Series Loss: 0.0055, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [1835/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0559, Series Loss: 0.0056, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1836/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0559, Series Loss: 0.0056, Class Loss: 0.2489, Accuracy: 0.0309\n",
      "Epoch [1837/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0559, Series Loss: 0.0055, Class Loss: 0.2490, Accuracy: 0.0679\n",
      "Epoch [1838/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0558, Series Loss: 0.0054, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1839/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0558, Series Loss: 0.0055, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [1840/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0559, Series Loss: 0.0054, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [1841/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0558, Series Loss: 0.0055, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [1842/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0557, Series Loss: 0.0055, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1843/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0558, Series Loss: 0.0054, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1844/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0555, Series Loss: 0.0054, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1845/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0556, Series Loss: 0.0053, Class Loss: 0.2488, Accuracy: 0.0741\n",
      "Epoch [1846/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0558, Series Loss: 0.0054, Class Loss: 0.2489, Accuracy: 0.0309\n",
      "Epoch [1847/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0557, Series Loss: 0.0055, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [1848/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0559, Series Loss: 0.0054, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [1849/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0555, Series Loss: 0.0054, Class Loss: 0.2490, Accuracy: 0.0309\n",
      "Epoch [1850/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0557, Series Loss: 0.0056, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1851/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0557, Series Loss: 0.0055, Class Loss: 0.2490, Accuracy: 0.0679\n",
      "Epoch [1852/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0558, Series Loss: 0.0055, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1853/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0556, Series Loss: 0.0055, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1854/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0554, Series Loss: 0.0055, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1855/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0553, Series Loss: 0.0054, Class Loss: 0.2490, Accuracy: 0.0309\n",
      "Epoch [1856/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0555, Series Loss: 0.0054, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [1857/4000], Discriminator Loss: 0.0939, Generator Loss: 0.0555, Series Loss: 0.0054, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1858/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0555, Series Loss: 0.0054, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1859/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0557, Series Loss: 0.0054, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1860/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0559, Series Loss: 0.0054, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [1861/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0560, Series Loss: 0.0055, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1862/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0557, Series Loss: 0.0055, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1863/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0559, Series Loss: 0.0055, Class Loss: 0.2491, Accuracy: 0.0494\n",
      "Epoch [1864/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0559, Series Loss: 0.0055, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1865/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0557, Series Loss: 0.0055, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [1866/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0557, Series Loss: 0.0055, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1867/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0558, Series Loss: 0.0055, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1868/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0556, Series Loss: 0.0054, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1869/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0557, Series Loss: 0.0054, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1870/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0559, Series Loss: 0.0055, Class Loss: 0.2490, Accuracy: 0.0679\n",
      "Epoch [1871/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0558, Series Loss: 0.0054, Class Loss: 0.2490, Accuracy: 0.0556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1872/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0559, Series Loss: 0.0054, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1873/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0558, Series Loss: 0.0054, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1874/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0556, Series Loss: 0.0054, Class Loss: 0.2490, Accuracy: 0.0617\n",
      "Epoch [1875/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0556, Series Loss: 0.0054, Class Loss: 0.2491, Accuracy: 0.0370\n",
      "Epoch [1876/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0554, Series Loss: 0.0054, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1877/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0552, Series Loss: 0.0053, Class Loss: 0.2491, Accuracy: 0.0432\n",
      "Epoch [1878/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0556, Series Loss: 0.0054, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1879/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0556, Series Loss: 0.0053, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1880/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0557, Series Loss: 0.0052, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1881/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0559, Series Loss: 0.0053, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1882/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0556, Series Loss: 0.0053, Class Loss: 0.2491, Accuracy: 0.0432\n",
      "Epoch [1883/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0559, Series Loss: 0.0054, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1884/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0557, Series Loss: 0.0053, Class Loss: 0.2489, Accuracy: 0.0679\n",
      "Epoch [1885/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0555, Series Loss: 0.0053, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [1886/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0556, Series Loss: 0.0053, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [1887/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0555, Series Loss: 0.0054, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1888/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0556, Series Loss: 0.0053, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1889/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0554, Series Loss: 0.0053, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [1890/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0553, Series Loss: 0.0052, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1891/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0556, Series Loss: 0.0054, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1892/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0554, Series Loss: 0.0052, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1893/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0555, Series Loss: 0.0053, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1894/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0554, Series Loss: 0.0053, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1895/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0552, Series Loss: 0.0053, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1896/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0553, Series Loss: 0.0052, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1897/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0556, Series Loss: 0.0053, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1898/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0556, Series Loss: 0.0052, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [1899/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0557, Series Loss: 0.0053, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [1900/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0554, Series Loss: 0.0053, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1901/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0553, Series Loss: 0.0053, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1902/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0551, Series Loss: 0.0052, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1903/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0552, Series Loss: 0.0052, Class Loss: 0.2488, Accuracy: 0.0370\n",
      "Epoch [1904/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0551, Series Loss: 0.0051, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [1905/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0554, Series Loss: 0.0053, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [1906/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0552, Series Loss: 0.0052, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1907/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0554, Series Loss: 0.0052, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1908/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0557, Series Loss: 0.0052, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1909/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0555, Series Loss: 0.0052, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [1910/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0552, Series Loss: 0.0051, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1911/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0555, Series Loss: 0.0052, Class Loss: 0.2489, Accuracy: 0.0309\n",
      "Epoch [1912/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0552, Series Loss: 0.0051, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1913/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0551, Series Loss: 0.0052, Class Loss: 0.2489, Accuracy: 0.0309\n",
      "Epoch [1914/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0553, Series Loss: 0.0052, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1915/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0554, Series Loss: 0.0052, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1916/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0557, Series Loss: 0.0052, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1917/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0555, Series Loss: 0.0053, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1918/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0555, Series Loss: 0.0053, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1919/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0557, Series Loss: 0.0053, Class Loss: 0.2488, Accuracy: 0.0309\n",
      "Epoch [1920/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0556, Series Loss: 0.0053, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1921/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0553, Series Loss: 0.0053, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1922/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0551, Series Loss: 0.0052, Class Loss: 0.2488, Accuracy: 0.0741\n",
      "Epoch [1923/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0553, Series Loss: 0.0052, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1924/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0554, Series Loss: 0.0052, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1925/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0556, Series Loss: 0.0053, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1926/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0554, Series Loss: 0.0052, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1927/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0555, Series Loss: 0.0052, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1928/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0555, Series Loss: 0.0051, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1929/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0555, Series Loss: 0.0052, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1930/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0556, Series Loss: 0.0052, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1931/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0556, Series Loss: 0.0052, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1932/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0557, Series Loss: 0.0052, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [1933/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0557, Series Loss: 0.0052, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [1934/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0557, Series Loss: 0.0052, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1935/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0554, Series Loss: 0.0052, Class Loss: 0.2489, Accuracy: 0.0432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1936/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0551, Series Loss: 0.0052, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [1937/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0555, Series Loss: 0.0052, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1938/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0553, Series Loss: 0.0052, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1939/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0555, Series Loss: 0.0052, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [1940/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0555, Series Loss: 0.0052, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1941/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0553, Series Loss: 0.0051, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [1942/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0555, Series Loss: 0.0051, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [1943/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0553, Series Loss: 0.0051, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [1944/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0556, Series Loss: 0.0052, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [1945/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0554, Series Loss: 0.0052, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1946/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0552, Series Loss: 0.0051, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1947/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0554, Series Loss: 0.0051, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [1948/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0554, Series Loss: 0.0051, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1949/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0551, Series Loss: 0.0051, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [1950/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0552, Series Loss: 0.0051, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1951/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0553, Series Loss: 0.0051, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1952/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0553, Series Loss: 0.0051, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1953/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0553, Series Loss: 0.0051, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1954/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0552, Series Loss: 0.0050, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [1955/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0551, Series Loss: 0.0051, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [1956/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0552, Series Loss: 0.0051, Class Loss: 0.2490, Accuracy: 0.0309\n",
      "Epoch [1957/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0552, Series Loss: 0.0051, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1958/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0548, Series Loss: 0.0051, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [1959/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0550, Series Loss: 0.0051, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1960/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0551, Series Loss: 0.0052, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [1961/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0553, Series Loss: 0.0051, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [1962/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0554, Series Loss: 0.0051, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1963/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0552, Series Loss: 0.0051, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [1964/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0552, Series Loss: 0.0050, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [1965/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0551, Series Loss: 0.0051, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1966/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0554, Series Loss: 0.0052, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [1967/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0553, Series Loss: 0.0052, Class Loss: 0.2490, Accuracy: 0.0309\n",
      "Epoch [1968/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0553, Series Loss: 0.0053, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1969/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0550, Series Loss: 0.0051, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [1970/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0554, Series Loss: 0.0052, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1971/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0552, Series Loss: 0.0052, Class Loss: 0.2488, Accuracy: 0.0370\n",
      "Epoch [1972/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0555, Series Loss: 0.0052, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1973/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0552, Series Loss: 0.0052, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1974/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0551, Series Loss: 0.0051, Class Loss: 0.2490, Accuracy: 0.0309\n",
      "Epoch [1975/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0553, Series Loss: 0.0051, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [1976/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0553, Series Loss: 0.0050, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [1977/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0551, Series Loss: 0.0050, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [1978/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0552, Series Loss: 0.0050, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1979/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0550, Series Loss: 0.0050, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1980/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0552, Series Loss: 0.0050, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [1981/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0555, Series Loss: 0.0051, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [1982/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0549, Series Loss: 0.0050, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [1983/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0551, Series Loss: 0.0051, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [1984/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0551, Series Loss: 0.0050, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [1985/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0552, Series Loss: 0.0050, Class Loss: 0.2487, Accuracy: 0.0741\n",
      "Epoch [1986/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0552, Series Loss: 0.0050, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1987/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0552, Series Loss: 0.0051, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [1988/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0553, Series Loss: 0.0051, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [1989/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0551, Series Loss: 0.0050, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [1990/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0548, Series Loss: 0.0050, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [1991/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0551, Series Loss: 0.0050, Class Loss: 0.2488, Accuracy: 0.0370\n",
      "Epoch [1992/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0553, Series Loss: 0.0050, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [1993/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0551, Series Loss: 0.0049, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [1994/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0553, Series Loss: 0.0051, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1995/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0551, Series Loss: 0.0050, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [1996/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0552, Series Loss: 0.0050, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [1997/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0553, Series Loss: 0.0050, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [1998/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0554, Series Loss: 0.0050, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [1999/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0553, Series Loss: 0.0050, Class Loss: 0.2490, Accuracy: 0.0370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2000/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0551, Series Loss: 0.0050, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [2001/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0553, Series Loss: 0.0050, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2002/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0552, Series Loss: 0.0050, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2003/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0551, Series Loss: 0.0049, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [2004/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0551, Series Loss: 0.0050, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2005/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0550, Series Loss: 0.0049, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [2006/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0556, Series Loss: 0.0051, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [2007/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0552, Series Loss: 0.0050, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [2008/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0553, Series Loss: 0.0051, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [2009/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0551, Series Loss: 0.0050, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [2010/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0552, Series Loss: 0.0050, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2011/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0550, Series Loss: 0.0049, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [2012/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0548, Series Loss: 0.0049, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2013/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0549, Series Loss: 0.0050, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2014/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0548, Series Loss: 0.0049, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2015/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0549, Series Loss: 0.0049, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2016/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0551, Series Loss: 0.0049, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2017/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0551, Series Loss: 0.0049, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [2018/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0553, Series Loss: 0.0048, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [2019/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0552, Series Loss: 0.0048, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2020/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0551, Series Loss: 0.0049, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2021/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0550, Series Loss: 0.0049, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2022/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0550, Series Loss: 0.0049, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2023/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0550, Series Loss: 0.0049, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2024/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0551, Series Loss: 0.0049, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2025/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0551, Series Loss: 0.0049, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2026/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0549, Series Loss: 0.0049, Class Loss: 0.2491, Accuracy: 0.0432\n",
      "Epoch [2027/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0552, Series Loss: 0.0050, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2028/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0551, Series Loss: 0.0050, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [2029/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0550, Series Loss: 0.0049, Class Loss: 0.2488, Accuracy: 0.0370\n",
      "Epoch [2030/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0548, Series Loss: 0.0049, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2031/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0548, Series Loss: 0.0049, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2032/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0548, Series Loss: 0.0048, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2033/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0549, Series Loss: 0.0048, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [2034/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0553, Series Loss: 0.0049, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2035/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0549, Series Loss: 0.0048, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2036/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0549, Series Loss: 0.0049, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2037/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0549, Series Loss: 0.0048, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2038/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0550, Series Loss: 0.0049, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2039/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0547, Series Loss: 0.0049, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2040/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0549, Series Loss: 0.0049, Class Loss: 0.2489, Accuracy: 0.0741\n",
      "Epoch [2041/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0550, Series Loss: 0.0049, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2042/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0550, Series Loss: 0.0048, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [2043/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0552, Series Loss: 0.0049, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2044/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0552, Series Loss: 0.0049, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [2045/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0547, Series Loss: 0.0048, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [2046/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0549, Series Loss: 0.0049, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [2047/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0549, Series Loss: 0.0049, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2048/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0549, Series Loss: 0.0048, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2049/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0550, Series Loss: 0.0049, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [2050/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0551, Series Loss: 0.0049, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [2051/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0551, Series Loss: 0.0049, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2052/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0550, Series Loss: 0.0048, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2053/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0550, Series Loss: 0.0049, Class Loss: 0.2489, Accuracy: 0.0679\n",
      "Epoch [2054/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0550, Series Loss: 0.0048, Class Loss: 0.2489, Accuracy: 0.0679\n",
      "Epoch [2055/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0548, Series Loss: 0.0048, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2056/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0551, Series Loss: 0.0049, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2057/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0550, Series Loss: 0.0048, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2058/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0550, Series Loss: 0.0048, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2059/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0550, Series Loss: 0.0048, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2060/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0548, Series Loss: 0.0047, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2061/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0548, Series Loss: 0.0048, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2062/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0549, Series Loss: 0.0048, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2063/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0548, Series Loss: 0.0048, Class Loss: 0.2489, Accuracy: 0.0617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2064/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0551, Series Loss: 0.0048, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2065/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0547, Series Loss: 0.0048, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [2066/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0547, Series Loss: 0.0048, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2067/4000], Discriminator Loss: 0.0939, Generator Loss: 0.0549, Series Loss: 0.0049, Class Loss: 0.2488, Accuracy: 0.0741\n",
      "Epoch [2068/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0548, Series Loss: 0.0049, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2069/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0546, Series Loss: 0.0048, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2070/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0546, Series Loss: 0.0048, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2071/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0546, Series Loss: 0.0048, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2072/4000], Discriminator Loss: 0.0939, Generator Loss: 0.0548, Series Loss: 0.0047, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2073/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0548, Series Loss: 0.0048, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2074/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0547, Series Loss: 0.0048, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [2075/4000], Discriminator Loss: 0.0938, Generator Loss: 0.0546, Series Loss: 0.0048, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2076/4000], Discriminator Loss: 0.0938, Generator Loss: 0.0547, Series Loss: 0.0048, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [2077/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0546, Series Loss: 0.0047, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2078/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0547, Series Loss: 0.0047, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2079/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0547, Series Loss: 0.0048, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [2080/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0548, Series Loss: 0.0048, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2081/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0548, Series Loss: 0.0048, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [2082/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0547, Series Loss: 0.0049, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2083/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0548, Series Loss: 0.0050, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2084/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0547, Series Loss: 0.0050, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2085/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0548, Series Loss: 0.0049, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2086/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0547, Series Loss: 0.0048, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2087/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0548, Series Loss: 0.0049, Class Loss: 0.2489, Accuracy: 0.0679\n",
      "Epoch [2088/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0547, Series Loss: 0.0049, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [2089/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0545, Series Loss: 0.0049, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2090/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0546, Series Loss: 0.0049, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [2091/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0545, Series Loss: 0.0048, Class Loss: 0.2489, Accuracy: 0.0679\n",
      "Epoch [2092/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0546, Series Loss: 0.0048, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [2093/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0546, Series Loss: 0.0048, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2094/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0545, Series Loss: 0.0047, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2095/4000], Discriminator Loss: 0.0939, Generator Loss: 0.0548, Series Loss: 0.0047, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [2096/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0548, Series Loss: 0.0047, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2097/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0549, Series Loss: 0.0047, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2098/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0546, Series Loss: 0.0046, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [2099/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0548, Series Loss: 0.0047, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2100/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0544, Series Loss: 0.0046, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2101/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0545, Series Loss: 0.0047, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [2102/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0548, Series Loss: 0.0046, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2103/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0545, Series Loss: 0.0047, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [2104/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0543, Series Loss: 0.0047, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [2105/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0547, Series Loss: 0.0048, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2106/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0548, Series Loss: 0.0047, Class Loss: 0.2490, Accuracy: 0.0617\n",
      "Epoch [2107/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0546, Series Loss: 0.0047, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2108/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0543, Series Loss: 0.0047, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [2109/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0545, Series Loss: 0.0048, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [2110/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0545, Series Loss: 0.0047, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2111/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0546, Series Loss: 0.0048, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [2112/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0546, Series Loss: 0.0047, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [2113/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0548, Series Loss: 0.0048, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2114/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0547, Series Loss: 0.0047, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [2115/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0546, Series Loss: 0.0048, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [2116/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0545, Series Loss: 0.0048, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [2117/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0546, Series Loss: 0.0047, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2118/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0547, Series Loss: 0.0047, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2119/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0546, Series Loss: 0.0048, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2120/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0550, Series Loss: 0.0048, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2121/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0547, Series Loss: 0.0047, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2122/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0547, Series Loss: 0.0048, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2123/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0546, Series Loss: 0.0048, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [2124/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0546, Series Loss: 0.0047, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2125/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0547, Series Loss: 0.0047, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2126/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0548, Series Loss: 0.0047, Class Loss: 0.2489, Accuracy: 0.0679\n",
      "Epoch [2127/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0546, Series Loss: 0.0046, Class Loss: 0.2489, Accuracy: 0.0494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2128/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0544, Series Loss: 0.0046, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2129/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0545, Series Loss: 0.0047, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2130/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0545, Series Loss: 0.0046, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [2131/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0546, Series Loss: 0.0046, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2132/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0544, Series Loss: 0.0046, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2133/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0545, Series Loss: 0.0047, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2134/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0545, Series Loss: 0.0046, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2135/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0546, Series Loss: 0.0046, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2136/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0547, Series Loss: 0.0047, Class Loss: 0.2487, Accuracy: 0.0741\n",
      "Epoch [2137/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0544, Series Loss: 0.0047, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [2138/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0546, Series Loss: 0.0047, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [2139/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0546, Series Loss: 0.0047, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [2140/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0546, Series Loss: 0.0046, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2141/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0547, Series Loss: 0.0046, Class Loss: 0.2490, Accuracy: 0.0679\n",
      "Epoch [2142/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0544, Series Loss: 0.0047, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2143/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0546, Series Loss: 0.0047, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [2144/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0547, Series Loss: 0.0047, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2145/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0544, Series Loss: 0.0046, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2146/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0547, Series Loss: 0.0047, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2147/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0545, Series Loss: 0.0047, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2148/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0546, Series Loss: 0.0047, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [2149/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0545, Series Loss: 0.0046, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [2150/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0545, Series Loss: 0.0045, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2151/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0545, Series Loss: 0.0046, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [2152/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0546, Series Loss: 0.0046, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2153/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0547, Series Loss: 0.0046, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2154/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0546, Series Loss: 0.0046, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2155/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0547, Series Loss: 0.0047, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2156/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0547, Series Loss: 0.0046, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2157/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0544, Series Loss: 0.0045, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [2158/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0543, Series Loss: 0.0046, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2159/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0542, Series Loss: 0.0045, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2160/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0547, Series Loss: 0.0046, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2161/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0547, Series Loss: 0.0046, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2162/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0547, Series Loss: 0.0045, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2163/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0548, Series Loss: 0.0046, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2164/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0545, Series Loss: 0.0045, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [2165/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0547, Series Loss: 0.0046, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2166/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0544, Series Loss: 0.0046, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2167/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0545, Series Loss: 0.0046, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2168/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0544, Series Loss: 0.0047, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [2169/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0545, Series Loss: 0.0046, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2170/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0541, Series Loss: 0.0047, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2171/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0541, Series Loss: 0.0046, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2172/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0544, Series Loss: 0.0045, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2173/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0545, Series Loss: 0.0045, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [2174/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0546, Series Loss: 0.0046, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2175/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0547, Series Loss: 0.0046, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2176/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0544, Series Loss: 0.0045, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2177/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0546, Series Loss: 0.0046, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2178/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0545, Series Loss: 0.0046, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2179/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0545, Series Loss: 0.0046, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [2180/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0545, Series Loss: 0.0046, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2181/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0544, Series Loss: 0.0046, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2182/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0544, Series Loss: 0.0045, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [2183/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0545, Series Loss: 0.0045, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [2184/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0546, Series Loss: 0.0045, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2185/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0546, Series Loss: 0.0045, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2186/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0546, Series Loss: 0.0045, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [2187/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0544, Series Loss: 0.0044, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2188/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0545, Series Loss: 0.0045, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [2189/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0543, Series Loss: 0.0045, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2190/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0542, Series Loss: 0.0045, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2191/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0541, Series Loss: 0.0046, Class Loss: 0.2488, Accuracy: 0.0556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2192/4000], Discriminator Loss: 0.0939, Generator Loss: 0.0542, Series Loss: 0.0044, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [2193/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0543, Series Loss: 0.0045, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2194/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0545, Series Loss: 0.0045, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2195/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0544, Series Loss: 0.0045, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2196/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0545, Series Loss: 0.0046, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [2197/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0546, Series Loss: 0.0046, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2198/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0548, Series Loss: 0.0047, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [2199/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0547, Series Loss: 0.0046, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2200/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0546, Series Loss: 0.0047, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2201/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0547, Series Loss: 0.0047, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [2202/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0548, Series Loss: 0.0047, Class Loss: 0.2492, Accuracy: 0.0432\n",
      "Epoch [2203/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0546, Series Loss: 0.0046, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [2204/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0547, Series Loss: 0.0046, Class Loss: 0.2491, Accuracy: 0.0432\n",
      "Epoch [2205/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0544, Series Loss: 0.0046, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [2206/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0545, Series Loss: 0.0047, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2207/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0546, Series Loss: 0.0047, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2208/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0544, Series Loss: 0.0045, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2209/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0543, Series Loss: 0.0045, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2210/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0543, Series Loss: 0.0045, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2211/4000], Discriminator Loss: 0.0939, Generator Loss: 0.0547, Series Loss: 0.0046, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [2212/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0545, Series Loss: 0.0044, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2213/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0544, Series Loss: 0.0044, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [2214/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0546, Series Loss: 0.0044, Class Loss: 0.2490, Accuracy: 0.0309\n",
      "Epoch [2215/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0543, Series Loss: 0.0044, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2216/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0544, Series Loss: 0.0045, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2217/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0546, Series Loss: 0.0046, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [2218/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0542, Series Loss: 0.0045, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2219/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0542, Series Loss: 0.0045, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2220/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0544, Series Loss: 0.0046, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [2221/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0543, Series Loss: 0.0045, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2222/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0545, Series Loss: 0.0045, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [2223/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0546, Series Loss: 0.0045, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [2224/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0546, Series Loss: 0.0045, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2225/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0546, Series Loss: 0.0046, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [2226/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0543, Series Loss: 0.0045, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2227/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0541, Series Loss: 0.0046, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2228/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0544, Series Loss: 0.0046, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2229/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0542, Series Loss: 0.0045, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [2230/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0543, Series Loss: 0.0046, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2231/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0542, Series Loss: 0.0046, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2232/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0545, Series Loss: 0.0046, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2233/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0545, Series Loss: 0.0045, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [2234/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0545, Series Loss: 0.0046, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2235/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0544, Series Loss: 0.0045, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2236/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0542, Series Loss: 0.0045, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [2237/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0543, Series Loss: 0.0045, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2238/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0544, Series Loss: 0.0046, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [2239/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0542, Series Loss: 0.0045, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [2240/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0544, Series Loss: 0.0045, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [2241/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0545, Series Loss: 0.0045, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2242/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0544, Series Loss: 0.0045, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [2243/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0545, Series Loss: 0.0045, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2244/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0543, Series Loss: 0.0045, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [2245/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0543, Series Loss: 0.0045, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [2246/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0542, Series Loss: 0.0045, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2247/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0542, Series Loss: 0.0044, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [2248/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0545, Series Loss: 0.0044, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [2249/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0546, Series Loss: 0.0045, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [2250/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0546, Series Loss: 0.0045, Class Loss: 0.2490, Accuracy: 0.0617\n",
      "Epoch [2251/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0546, Series Loss: 0.0046, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2252/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0542, Series Loss: 0.0045, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2253/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0543, Series Loss: 0.0045, Class Loss: 0.2489, Accuracy: 0.0679\n",
      "Epoch [2254/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0543, Series Loss: 0.0045, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2255/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0542, Series Loss: 0.0045, Class Loss: 0.2488, Accuracy: 0.0679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2256/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0542, Series Loss: 0.0045, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2257/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0540, Series Loss: 0.0045, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2258/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0543, Series Loss: 0.0045, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [2259/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0543, Series Loss: 0.0045, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [2260/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0544, Series Loss: 0.0045, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2261/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0544, Series Loss: 0.0044, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2262/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0543, Series Loss: 0.0044, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2263/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0544, Series Loss: 0.0046, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [2264/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0542, Series Loss: 0.0045, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2265/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0543, Series Loss: 0.0045, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2266/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0544, Series Loss: 0.0045, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2267/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0543, Series Loss: 0.0045, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2268/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0542, Series Loss: 0.0045, Class Loss: 0.2489, Accuracy: 0.0679\n",
      "Epoch [2269/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0542, Series Loss: 0.0045, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2270/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0542, Series Loss: 0.0044, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2271/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0544, Series Loss: 0.0045, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2272/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0542, Series Loss: 0.0044, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2273/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0543, Series Loss: 0.0045, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [2274/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0542, Series Loss: 0.0045, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2275/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0542, Series Loss: 0.0045, Class Loss: 0.2489, Accuracy: 0.0679\n",
      "Epoch [2276/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0542, Series Loss: 0.0044, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [2277/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0544, Series Loss: 0.0044, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2278/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0541, Series Loss: 0.0045, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2279/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0540, Series Loss: 0.0044, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [2280/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0540, Series Loss: 0.0045, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2281/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0540, Series Loss: 0.0044, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [2282/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0540, Series Loss: 0.0044, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2283/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0542, Series Loss: 0.0044, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2284/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0544, Series Loss: 0.0044, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2285/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0545, Series Loss: 0.0044, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2286/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0543, Series Loss: 0.0044, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2287/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0545, Series Loss: 0.0045, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [2288/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0542, Series Loss: 0.0044, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2289/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0539, Series Loss: 0.0045, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [2290/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0540, Series Loss: 0.0044, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2291/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0540, Series Loss: 0.0045, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2292/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0542, Series Loss: 0.0045, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [2293/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0538, Series Loss: 0.0045, Class Loss: 0.2489, Accuracy: 0.0679\n",
      "Epoch [2294/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0539, Series Loss: 0.0044, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2295/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0540, Series Loss: 0.0044, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [2296/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0541, Series Loss: 0.0044, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [2297/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0541, Series Loss: 0.0044, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2298/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0542, Series Loss: 0.0043, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2299/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0543, Series Loss: 0.0044, Class Loss: 0.2489, Accuracy: 0.0741\n",
      "Epoch [2300/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0540, Series Loss: 0.0043, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [2301/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0540, Series Loss: 0.0043, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2302/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0539, Series Loss: 0.0043, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2303/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0539, Series Loss: 0.0043, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2304/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0540, Series Loss: 0.0043, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2305/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0540, Series Loss: 0.0044, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [2306/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0540, Series Loss: 0.0043, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2307/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0539, Series Loss: 0.0043, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2308/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0540, Series Loss: 0.0044, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2309/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0539, Series Loss: 0.0043, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2310/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0540, Series Loss: 0.0044, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2311/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0539, Series Loss: 0.0044, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [2312/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0539, Series Loss: 0.0044, Class Loss: 0.2490, Accuracy: 0.0679\n",
      "Epoch [2313/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0541, Series Loss: 0.0044, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2314/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0539, Series Loss: 0.0044, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [2315/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0539, Series Loss: 0.0044, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [2316/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0539, Series Loss: 0.0044, Class Loss: 0.2490, Accuracy: 0.0617\n",
      "Epoch [2317/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0541, Series Loss: 0.0044, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [2318/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0539, Series Loss: 0.0044, Class Loss: 0.2491, Accuracy: 0.0494\n",
      "Epoch [2319/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0540, Series Loss: 0.0044, Class Loss: 0.2488, Accuracy: 0.0617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2320/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0540, Series Loss: 0.0044, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [2321/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0541, Series Loss: 0.0044, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2322/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0541, Series Loss: 0.0044, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [2323/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0538, Series Loss: 0.0043, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2324/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0540, Series Loss: 0.0044, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2325/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0539, Series Loss: 0.0043, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2326/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0540, Series Loss: 0.0043, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2327/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0537, Series Loss: 0.0043, Class Loss: 0.2490, Accuracy: 0.0617\n",
      "Epoch [2328/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0535, Series Loss: 0.0043, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2329/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0534, Series Loss: 0.0042, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2330/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0537, Series Loss: 0.0043, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [2331/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0536, Series Loss: 0.0041, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2332/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0539, Series Loss: 0.0041, Class Loss: 0.2490, Accuracy: 0.0617\n",
      "Epoch [2333/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0542, Series Loss: 0.0042, Class Loss: 0.2490, Accuracy: 0.0679\n",
      "Epoch [2334/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0542, Series Loss: 0.0042, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2335/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0540, Series Loss: 0.0042, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2336/4000], Discriminator Loss: 0.0939, Generator Loss: 0.0540, Series Loss: 0.0043, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2337/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0540, Series Loss: 0.0043, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [2338/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0538, Series Loss: 0.0043, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [2339/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0540, Series Loss: 0.0043, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2340/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0540, Series Loss: 0.0043, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2341/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0541, Series Loss: 0.0044, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [2342/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0541, Series Loss: 0.0045, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2343/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0539, Series Loss: 0.0044, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [2344/4000], Discriminator Loss: 0.0946, Generator Loss: 0.0541, Series Loss: 0.0044, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [2345/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0544, Series Loss: 0.0044, Class Loss: 0.2489, Accuracy: 0.0679\n",
      "Epoch [2346/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0542, Series Loss: 0.0044, Class Loss: 0.2489, Accuracy: 0.0741\n",
      "Epoch [2347/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0541, Series Loss: 0.0044, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2348/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0541, Series Loss: 0.0044, Class Loss: 0.2490, Accuracy: 0.0679\n",
      "Epoch [2349/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0543, Series Loss: 0.0044, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2350/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0542, Series Loss: 0.0043, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2351/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0541, Series Loss: 0.0044, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2352/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0537, Series Loss: 0.0044, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2353/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0537, Series Loss: 0.0043, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2354/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0536, Series Loss: 0.0042, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2355/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0539, Series Loss: 0.0042, Class Loss: 0.2489, Accuracy: 0.0679\n",
      "Epoch [2356/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0539, Series Loss: 0.0042, Class Loss: 0.2490, Accuracy: 0.0617\n",
      "Epoch [2357/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0538, Series Loss: 0.0042, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2358/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0538, Series Loss: 0.0043, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2359/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0539, Series Loss: 0.0043, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2360/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0540, Series Loss: 0.0043, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2361/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0539, Series Loss: 0.0042, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2362/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0541, Series Loss: 0.0043, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [2363/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0543, Series Loss: 0.0043, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2364/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0542, Series Loss: 0.0043, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [2365/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0540, Series Loss: 0.0043, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2366/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0540, Series Loss: 0.0044, Class Loss: 0.2488, Accuracy: 0.0741\n",
      "Epoch [2367/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0540, Series Loss: 0.0044, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2368/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0540, Series Loss: 0.0044, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2369/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0540, Series Loss: 0.0043, Class Loss: 0.2490, Accuracy: 0.0617\n",
      "Epoch [2370/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0541, Series Loss: 0.0044, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [2371/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0542, Series Loss: 0.0044, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2372/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0542, Series Loss: 0.0044, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [2373/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0539, Series Loss: 0.0044, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2374/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0539, Series Loss: 0.0043, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2375/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0540, Series Loss: 0.0043, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2376/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0540, Series Loss: 0.0043, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [2377/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0539, Series Loss: 0.0043, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2378/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0540, Series Loss: 0.0043, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [2379/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0539, Series Loss: 0.0043, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2380/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0537, Series Loss: 0.0042, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2381/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0536, Series Loss: 0.0042, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2382/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0536, Series Loss: 0.0042, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [2383/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0537, Series Loss: 0.0042, Class Loss: 0.2488, Accuracy: 0.0494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2384/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0540, Series Loss: 0.0042, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2385/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0541, Series Loss: 0.0042, Class Loss: 0.2490, Accuracy: 0.0617\n",
      "Epoch [2386/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0541, Series Loss: 0.0042, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [2387/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0539, Series Loss: 0.0042, Class Loss: 0.2488, Accuracy: 0.0741\n",
      "Epoch [2388/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0538, Series Loss: 0.0043, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2389/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0537, Series Loss: 0.0042, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2390/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0541, Series Loss: 0.0043, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2391/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0540, Series Loss: 0.0043, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2392/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0540, Series Loss: 0.0044, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2393/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0540, Series Loss: 0.0043, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2394/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0540, Series Loss: 0.0044, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2395/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0541, Series Loss: 0.0043, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2396/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0541, Series Loss: 0.0043, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2397/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0541, Series Loss: 0.0044, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2398/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0537, Series Loss: 0.0043, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [2399/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0536, Series Loss: 0.0043, Class Loss: 0.2489, Accuracy: 0.0679\n",
      "Epoch [2400/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0538, Series Loss: 0.0042, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2401/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0536, Series Loss: 0.0043, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2402/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0538, Series Loss: 0.0043, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2403/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0539, Series Loss: 0.0042, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2404/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0540, Series Loss: 0.0042, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [2405/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0538, Series Loss: 0.0042, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2406/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0539, Series Loss: 0.0042, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [2407/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0541, Series Loss: 0.0043, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2408/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0539, Series Loss: 0.0042, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2409/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0538, Series Loss: 0.0042, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [2410/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0541, Series Loss: 0.0043, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [2411/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0540, Series Loss: 0.0042, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2412/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0539, Series Loss: 0.0042, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2413/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0539, Series Loss: 0.0042, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2414/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0540, Series Loss: 0.0042, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2415/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0540, Series Loss: 0.0042, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [2416/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0537, Series Loss: 0.0042, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [2417/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0538, Series Loss: 0.0042, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2418/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0537, Series Loss: 0.0042, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [2419/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0535, Series Loss: 0.0042, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2420/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0535, Series Loss: 0.0042, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2421/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0534, Series Loss: 0.0042, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [2422/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0536, Series Loss: 0.0042, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2423/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0537, Series Loss: 0.0042, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [2424/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0538, Series Loss: 0.0041, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [2425/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0539, Series Loss: 0.0041, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2426/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0541, Series Loss: 0.0042, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2427/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0541, Series Loss: 0.0042, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2428/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0540, Series Loss: 0.0042, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2429/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0541, Series Loss: 0.0042, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [2430/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0539, Series Loss: 0.0042, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [2431/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0539, Series Loss: 0.0042, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2432/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0538, Series Loss: 0.0042, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [2433/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0537, Series Loss: 0.0042, Class Loss: 0.2490, Accuracy: 0.0617\n",
      "Epoch [2434/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0537, Series Loss: 0.0042, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2435/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0538, Series Loss: 0.0042, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [2436/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0536, Series Loss: 0.0042, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [2437/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0539, Series Loss: 0.0042, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2438/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0539, Series Loss: 0.0041, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2439/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0538, Series Loss: 0.0041, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2440/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0539, Series Loss: 0.0042, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2441/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0539, Series Loss: 0.0041, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2442/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0537, Series Loss: 0.0041, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2443/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0535, Series Loss: 0.0041, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2444/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0534, Series Loss: 0.0041, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [2445/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0535, Series Loss: 0.0042, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2446/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0538, Series Loss: 0.0041, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [2447/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0538, Series Loss: 0.0041, Class Loss: 0.2488, Accuracy: 0.0556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2448/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0540, Series Loss: 0.0041, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2449/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0537, Series Loss: 0.0041, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2450/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0536, Series Loss: 0.0041, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2451/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0537, Series Loss: 0.0042, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [2452/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0537, Series Loss: 0.0041, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [2453/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0538, Series Loss: 0.0042, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2454/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0537, Series Loss: 0.0042, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2455/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0538, Series Loss: 0.0041, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2456/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0539, Series Loss: 0.0042, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [2457/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0539, Series Loss: 0.0042, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2458/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0540, Series Loss: 0.0042, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2459/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0540, Series Loss: 0.0042, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2460/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0539, Series Loss: 0.0041, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2461/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0539, Series Loss: 0.0042, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [2462/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0541, Series Loss: 0.0043, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2463/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0540, Series Loss: 0.0042, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [2464/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0539, Series Loss: 0.0041, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2465/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0540, Series Loss: 0.0042, Class Loss: 0.2486, Accuracy: 0.0617\n",
      "Epoch [2466/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0536, Series Loss: 0.0041, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2467/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0535, Series Loss: 0.0041, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [2468/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0535, Series Loss: 0.0041, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2469/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0536, Series Loss: 0.0040, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2470/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0539, Series Loss: 0.0041, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2471/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0537, Series Loss: 0.0040, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2472/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0537, Series Loss: 0.0040, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2473/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0536, Series Loss: 0.0039, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2474/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0538, Series Loss: 0.0039, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [2475/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0539, Series Loss: 0.0041, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [2476/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0537, Series Loss: 0.0040, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2477/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0538, Series Loss: 0.0040, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [2478/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0537, Series Loss: 0.0040, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [2479/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0539, Series Loss: 0.0041, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2480/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0540, Series Loss: 0.0041, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2481/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0539, Series Loss: 0.0040, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [2482/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0538, Series Loss: 0.0040, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2483/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0541, Series Loss: 0.0041, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2484/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0540, Series Loss: 0.0041, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2485/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0542, Series Loss: 0.0042, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [2486/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0540, Series Loss: 0.0043, Class Loss: 0.2487, Accuracy: 0.0741\n",
      "Epoch [2487/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0538, Series Loss: 0.0041, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2488/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0537, Series Loss: 0.0041, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2489/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0536, Series Loss: 0.0042, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2490/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0535, Series Loss: 0.0041, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2491/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0537, Series Loss: 0.0041, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [2492/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0539, Series Loss: 0.0040, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2493/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0539, Series Loss: 0.0041, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2494/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0536, Series Loss: 0.0040, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [2495/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0534, Series Loss: 0.0040, Class Loss: 0.2486, Accuracy: 0.0741\n",
      "Epoch [2496/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0535, Series Loss: 0.0040, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [2497/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0533, Series Loss: 0.0040, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [2498/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0535, Series Loss: 0.0039, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2499/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0537, Series Loss: 0.0039, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2500/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0537, Series Loss: 0.0039, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [2501/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0539, Series Loss: 0.0039, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2502/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0539, Series Loss: 0.0039, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2503/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0539, Series Loss: 0.0039, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2504/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0538, Series Loss: 0.0040, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2505/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0538, Series Loss: 0.0039, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2506/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0536, Series Loss: 0.0040, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [2507/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0538, Series Loss: 0.0041, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2508/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0535, Series Loss: 0.0040, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [2509/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0537, Series Loss: 0.0041, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2510/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0537, Series Loss: 0.0041, Class Loss: 0.2489, Accuracy: 0.0741\n",
      "Epoch [2511/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0536, Series Loss: 0.0041, Class Loss: 0.2487, Accuracy: 0.0556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2512/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0538, Series Loss: 0.0041, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [2513/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0538, Series Loss: 0.0041, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2514/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0538, Series Loss: 0.0041, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [2515/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0538, Series Loss: 0.0041, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [2516/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0537, Series Loss: 0.0041, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2517/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0536, Series Loss: 0.0041, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2518/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0538, Series Loss: 0.0041, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2519/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0538, Series Loss: 0.0040, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [2520/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0537, Series Loss: 0.0040, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2521/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0540, Series Loss: 0.0040, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2522/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0538, Series Loss: 0.0040, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [2523/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0538, Series Loss: 0.0040, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2524/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0538, Series Loss: 0.0041, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2525/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0535, Series Loss: 0.0039, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2526/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0538, Series Loss: 0.0040, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2527/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0537, Series Loss: 0.0039, Class Loss: 0.2488, Accuracy: 0.0309\n",
      "Epoch [2528/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0536, Series Loss: 0.0040, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [2529/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0538, Series Loss: 0.0039, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [2530/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0538, Series Loss: 0.0039, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2531/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0539, Series Loss: 0.0039, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2532/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0538, Series Loss: 0.0040, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [2533/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0539, Series Loss: 0.0039, Class Loss: 0.2489, Accuracy: 0.0679\n",
      "Epoch [2534/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0539, Series Loss: 0.0040, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2535/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0538, Series Loss: 0.0040, Class Loss: 0.2486, Accuracy: 0.0679\n",
      "Epoch [2536/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0538, Series Loss: 0.0040, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2537/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0536, Series Loss: 0.0040, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2538/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0535, Series Loss: 0.0039, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2539/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0535, Series Loss: 0.0040, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [2540/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0536, Series Loss: 0.0040, Class Loss: 0.2489, Accuracy: 0.0741\n",
      "Epoch [2541/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0537, Series Loss: 0.0040, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2542/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0537, Series Loss: 0.0040, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [2543/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0536, Series Loss: 0.0040, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [2544/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0537, Series Loss: 0.0040, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2545/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0538, Series Loss: 0.0040, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2546/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0538, Series Loss: 0.0040, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2547/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0539, Series Loss: 0.0040, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [2548/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0538, Series Loss: 0.0040, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2549/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0538, Series Loss: 0.0039, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [2550/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0535, Series Loss: 0.0040, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2551/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0536, Series Loss: 0.0040, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2552/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0539, Series Loss: 0.0040, Class Loss: 0.2489, Accuracy: 0.0679\n",
      "Epoch [2553/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0537, Series Loss: 0.0040, Class Loss: 0.2489, Accuracy: 0.0679\n",
      "Epoch [2554/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0536, Series Loss: 0.0040, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [2555/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0538, Series Loss: 0.0039, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [2556/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0541, Series Loss: 0.0040, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [2557/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0540, Series Loss: 0.0040, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2558/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0539, Series Loss: 0.0039, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2559/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0537, Series Loss: 0.0039, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [2560/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0538, Series Loss: 0.0039, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [2561/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0538, Series Loss: 0.0039, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2562/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0537, Series Loss: 0.0039, Class Loss: 0.2489, Accuracy: 0.0309\n",
      "Epoch [2563/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0538, Series Loss: 0.0039, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2564/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0538, Series Loss: 0.0039, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [2565/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0538, Series Loss: 0.0039, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2566/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0537, Series Loss: 0.0039, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2567/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0535, Series Loss: 0.0039, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2568/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0538, Series Loss: 0.0039, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2569/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0537, Series Loss: 0.0039, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2570/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0539, Series Loss: 0.0040, Class Loss: 0.2488, Accuracy: 0.0741\n",
      "Epoch [2571/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0539, Series Loss: 0.0040, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2572/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0538, Series Loss: 0.0040, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2573/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0538, Series Loss: 0.0040, Class Loss: 0.2488, Accuracy: 0.0741\n",
      "Epoch [2574/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0537, Series Loss: 0.0040, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [2575/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0538, Series Loss: 0.0040, Class Loss: 0.2487, Accuracy: 0.0494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2576/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0538, Series Loss: 0.0041, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [2577/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0537, Series Loss: 0.0040, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2578/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0539, Series Loss: 0.0040, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2579/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0540, Series Loss: 0.0040, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2580/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0541, Series Loss: 0.0040, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2581/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0539, Series Loss: 0.0040, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2582/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0538, Series Loss: 0.0040, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2583/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0539, Series Loss: 0.0039, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2584/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0539, Series Loss: 0.0039, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [2585/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0537, Series Loss: 0.0039, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [2586/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0538, Series Loss: 0.0039, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2587/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0540, Series Loss: 0.0039, Class Loss: 0.2488, Accuracy: 0.0741\n",
      "Epoch [2588/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0538, Series Loss: 0.0038, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2589/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0538, Series Loss: 0.0039, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [2590/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0536, Series Loss: 0.0039, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [2591/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0536, Series Loss: 0.0039, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2592/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0536, Series Loss: 0.0039, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [2593/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0536, Series Loss: 0.0039, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2594/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0537, Series Loss: 0.0039, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [2595/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0538, Series Loss: 0.0039, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2596/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0536, Series Loss: 0.0039, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2597/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0536, Series Loss: 0.0039, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2598/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0535, Series Loss: 0.0039, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2599/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0535, Series Loss: 0.0039, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2600/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0535, Series Loss: 0.0039, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2601/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0536, Series Loss: 0.0038, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2602/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0537, Series Loss: 0.0038, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2603/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0536, Series Loss: 0.0039, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2604/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0536, Series Loss: 0.0038, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [2605/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0539, Series Loss: 0.0039, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2606/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0538, Series Loss: 0.0039, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2607/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0539, Series Loss: 0.0039, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2608/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0540, Series Loss: 0.0039, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2609/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0539, Series Loss: 0.0039, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [2610/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0538, Series Loss: 0.0039, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2611/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0538, Series Loss: 0.0039, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2612/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0538, Series Loss: 0.0040, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2613/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0538, Series Loss: 0.0039, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2614/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0537, Series Loss: 0.0039, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2615/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0538, Series Loss: 0.0040, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2616/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0537, Series Loss: 0.0039, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [2617/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0540, Series Loss: 0.0040, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2618/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0539, Series Loss: 0.0039, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2619/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0539, Series Loss: 0.0039, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2620/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0536, Series Loss: 0.0040, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2621/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0539, Series Loss: 0.0039, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2622/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0538, Series Loss: 0.0039, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2623/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0538, Series Loss: 0.0039, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [2624/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0538, Series Loss: 0.0039, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [2625/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0537, Series Loss: 0.0038, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [2626/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0540, Series Loss: 0.0039, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2627/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0539, Series Loss: 0.0038, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [2628/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0539, Series Loss: 0.0038, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2629/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0536, Series Loss: 0.0037, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2630/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0534, Series Loss: 0.0038, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2631/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0534, Series Loss: 0.0038, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2632/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0535, Series Loss: 0.0039, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2633/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0536, Series Loss: 0.0038, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2634/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0536, Series Loss: 0.0038, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2635/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0536, Series Loss: 0.0038, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [2636/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0534, Series Loss: 0.0038, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [2637/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0535, Series Loss: 0.0038, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2638/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0539, Series Loss: 0.0038, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2639/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0537, Series Loss: 0.0038, Class Loss: 0.2487, Accuracy: 0.0679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2640/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0538, Series Loss: 0.0039, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2641/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0538, Series Loss: 0.0039, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2642/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0538, Series Loss: 0.0039, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [2643/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0534, Series Loss: 0.0038, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2644/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0532, Series Loss: 0.0038, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2645/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0533, Series Loss: 0.0038, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2646/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0534, Series Loss: 0.0039, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [2647/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0535, Series Loss: 0.0038, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2648/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0538, Series Loss: 0.0038, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2649/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0541, Series Loss: 0.0039, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [2650/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0537, Series Loss: 0.0038, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2651/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0536, Series Loss: 0.0039, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2652/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0537, Series Loss: 0.0039, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2653/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0536, Series Loss: 0.0038, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2654/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0538, Series Loss: 0.0039, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [2655/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0536, Series Loss: 0.0039, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2656/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0535, Series Loss: 0.0038, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2657/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0536, Series Loss: 0.0038, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2658/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0536, Series Loss: 0.0038, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2659/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0536, Series Loss: 0.0038, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [2660/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0538, Series Loss: 0.0038, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2661/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0536, Series Loss: 0.0038, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2662/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0537, Series Loss: 0.0038, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2663/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0535, Series Loss: 0.0038, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2664/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0535, Series Loss: 0.0038, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2665/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0536, Series Loss: 0.0038, Class Loss: 0.2487, Accuracy: 0.0432\n",
      "Epoch [2666/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0537, Series Loss: 0.0038, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2667/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0536, Series Loss: 0.0038, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2668/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0534, Series Loss: 0.0037, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [2669/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0537, Series Loss: 0.0038, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2670/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0535, Series Loss: 0.0038, Class Loss: 0.2487, Accuracy: 0.0432\n",
      "Epoch [2671/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0537, Series Loss: 0.0038, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [2672/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0536, Series Loss: 0.0038, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [2673/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0536, Series Loss: 0.0038, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2674/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0536, Series Loss: 0.0038, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2675/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0536, Series Loss: 0.0038, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [2676/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0537, Series Loss: 0.0038, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2677/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0536, Series Loss: 0.0038, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2678/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0534, Series Loss: 0.0038, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [2679/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0535, Series Loss: 0.0038, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [2680/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0537, Series Loss: 0.0039, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2681/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0537, Series Loss: 0.0038, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [2682/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0538, Series Loss: 0.0038, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2683/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0538, Series Loss: 0.0038, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2684/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0538, Series Loss: 0.0038, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2685/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0537, Series Loss: 0.0038, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2686/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0538, Series Loss: 0.0039, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2687/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0536, Series Loss: 0.0038, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [2688/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0537, Series Loss: 0.0038, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [2689/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0537, Series Loss: 0.0038, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2690/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0535, Series Loss: 0.0037, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [2691/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0533, Series Loss: 0.0038, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2692/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0534, Series Loss: 0.0037, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [2693/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0535, Series Loss: 0.0037, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2694/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0535, Series Loss: 0.0037, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [2695/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0537, Series Loss: 0.0037, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2696/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0534, Series Loss: 0.0037, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2697/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0535, Series Loss: 0.0038, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [2698/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0536, Series Loss: 0.0038, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2699/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0535, Series Loss: 0.0037, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2700/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0534, Series Loss: 0.0037, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [2701/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0535, Series Loss: 0.0037, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2702/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0535, Series Loss: 0.0037, Class Loss: 0.2487, Accuracy: 0.0432\n",
      "Epoch [2703/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0534, Series Loss: 0.0037, Class Loss: 0.2489, Accuracy: 0.0494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2704/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0534, Series Loss: 0.0038, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2705/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0535, Series Loss: 0.0037, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2706/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0536, Series Loss: 0.0038, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2707/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0536, Series Loss: 0.0037, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2708/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0535, Series Loss: 0.0037, Class Loss: 0.2486, Accuracy: 0.0617\n",
      "Epoch [2709/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0535, Series Loss: 0.0038, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2710/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0535, Series Loss: 0.0037, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2711/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0537, Series Loss: 0.0038, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [2712/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0538, Series Loss: 0.0038, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [2713/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0538, Series Loss: 0.0038, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2714/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0535, Series Loss: 0.0038, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [2715/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0536, Series Loss: 0.0038, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2716/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0534, Series Loss: 0.0037, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [2717/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0535, Series Loss: 0.0038, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2718/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0532, Series Loss: 0.0038, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [2719/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0532, Series Loss: 0.0037, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2720/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0533, Series Loss: 0.0037, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [2721/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0533, Series Loss: 0.0037, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2722/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0535, Series Loss: 0.0037, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2723/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0534, Series Loss: 0.0037, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [2724/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0534, Series Loss: 0.0037, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2725/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0533, Series Loss: 0.0037, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2726/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0533, Series Loss: 0.0036, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [2727/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0534, Series Loss: 0.0037, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [2728/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0534, Series Loss: 0.0036, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2729/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0536, Series Loss: 0.0037, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2730/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0537, Series Loss: 0.0037, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2731/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0537, Series Loss: 0.0037, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [2732/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0536, Series Loss: 0.0037, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [2733/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0535, Series Loss: 0.0037, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [2734/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0535, Series Loss: 0.0037, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2735/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0536, Series Loss: 0.0037, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [2736/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0536, Series Loss: 0.0037, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [2737/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0537, Series Loss: 0.0038, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2738/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0537, Series Loss: 0.0038, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2739/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0536, Series Loss: 0.0038, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2740/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0536, Series Loss: 0.0037, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2741/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0537, Series Loss: 0.0038, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2742/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0538, Series Loss: 0.0038, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2743/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0536, Series Loss: 0.0037, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2744/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0535, Series Loss: 0.0038, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2745/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0533, Series Loss: 0.0037, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2746/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0533, Series Loss: 0.0037, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2747/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0534, Series Loss: 0.0037, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2748/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0534, Series Loss: 0.0036, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2749/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0536, Series Loss: 0.0036, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2750/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0537, Series Loss: 0.0036, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2751/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0537, Series Loss: 0.0036, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2752/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0535, Series Loss: 0.0036, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2753/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0533, Series Loss: 0.0036, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2754/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0534, Series Loss: 0.0036, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2755/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0533, Series Loss: 0.0036, Class Loss: 0.2487, Accuracy: 0.0432\n",
      "Epoch [2756/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0532, Series Loss: 0.0035, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2757/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0534, Series Loss: 0.0036, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2758/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0533, Series Loss: 0.0036, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2759/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0533, Series Loss: 0.0036, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [2760/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0532, Series Loss: 0.0036, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2761/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0532, Series Loss: 0.0037, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2762/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0532, Series Loss: 0.0037, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [2763/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0534, Series Loss: 0.0036, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2764/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0534, Series Loss: 0.0037, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [2765/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0535, Series Loss: 0.0038, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2766/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0533, Series Loss: 0.0037, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2767/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0532, Series Loss: 0.0037, Class Loss: 0.2487, Accuracy: 0.0556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2768/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0536, Series Loss: 0.0037, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [2769/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0538, Series Loss: 0.0038, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2770/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0537, Series Loss: 0.0037, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2771/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0535, Series Loss: 0.0037, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [2772/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0535, Series Loss: 0.0038, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2773/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0535, Series Loss: 0.0037, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2774/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0535, Series Loss: 0.0036, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2775/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0535, Series Loss: 0.0036, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2776/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0534, Series Loss: 0.0036, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2777/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0534, Series Loss: 0.0037, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [2778/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0534, Series Loss: 0.0036, Class Loss: 0.2489, Accuracy: 0.0679\n",
      "Epoch [2779/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0534, Series Loss: 0.0035, Class Loss: 0.2489, Accuracy: 0.0679\n",
      "Epoch [2780/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0534, Series Loss: 0.0036, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [2781/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0533, Series Loss: 0.0036, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [2782/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0534, Series Loss: 0.0035, Class Loss: 0.2486, Accuracy: 0.0617\n",
      "Epoch [2783/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0533, Series Loss: 0.0035, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [2784/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0534, Series Loss: 0.0035, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [2785/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0533, Series Loss: 0.0035, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2786/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0536, Series Loss: 0.0036, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [2787/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0534, Series Loss: 0.0035, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2788/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0533, Series Loss: 0.0035, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2789/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0532, Series Loss: 0.0035, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2790/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0531, Series Loss: 0.0036, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [2791/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0531, Series Loss: 0.0036, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2792/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0533, Series Loss: 0.0036, Class Loss: 0.2488, Accuracy: 0.0370\n",
      "Epoch [2793/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0533, Series Loss: 0.0036, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2794/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0535, Series Loss: 0.0037, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2795/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0534, Series Loss: 0.0037, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2796/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0535, Series Loss: 0.0037, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2797/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0534, Series Loss: 0.0037, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2798/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0535, Series Loss: 0.0037, Class Loss: 0.2490, Accuracy: 0.0556\n",
      "Epoch [2799/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0534, Series Loss: 0.0037, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [2800/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0533, Series Loss: 0.0037, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [2801/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0534, Series Loss: 0.0037, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [2802/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0535, Series Loss: 0.0037, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [2803/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0535, Series Loss: 0.0036, Class Loss: 0.2487, Accuracy: 0.0432\n",
      "Epoch [2804/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0534, Series Loss: 0.0036, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2805/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0531, Series Loss: 0.0036, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2806/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0530, Series Loss: 0.0036, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [2807/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0532, Series Loss: 0.0035, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2808/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0532, Series Loss: 0.0035, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2809/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0533, Series Loss: 0.0035, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2810/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0535, Series Loss: 0.0035, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [2811/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0534, Series Loss: 0.0035, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2812/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0533, Series Loss: 0.0035, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2813/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0531, Series Loss: 0.0034, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2814/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0532, Series Loss: 0.0034, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2815/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0533, Series Loss: 0.0034, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2816/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0534, Series Loss: 0.0035, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [2817/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0535, Series Loss: 0.0035, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2818/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0532, Series Loss: 0.0035, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2819/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0532, Series Loss: 0.0036, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [2820/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0531, Series Loss: 0.0035, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [2821/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0533, Series Loss: 0.0037, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2822/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0533, Series Loss: 0.0036, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [2823/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0533, Series Loss: 0.0036, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2824/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0534, Series Loss: 0.0037, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2825/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0533, Series Loss: 0.0037, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2826/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0531, Series Loss: 0.0037, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [2827/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0532, Series Loss: 0.0037, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2828/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0531, Series Loss: 0.0037, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [2829/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0529, Series Loss: 0.0036, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2830/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0531, Series Loss: 0.0036, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2831/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0534, Series Loss: 0.0036, Class Loss: 0.2488, Accuracy: 0.0617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2832/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0536, Series Loss: 0.0035, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2833/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0538, Series Loss: 0.0035, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [2834/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0534, Series Loss: 0.0034, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [2835/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0533, Series Loss: 0.0035, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2836/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0531, Series Loss: 0.0034, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2837/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0531, Series Loss: 0.0034, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2838/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0533, Series Loss: 0.0034, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2839/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0532, Series Loss: 0.0034, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2840/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0531, Series Loss: 0.0034, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2841/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0530, Series Loss: 0.0034, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [2842/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0531, Series Loss: 0.0034, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [2843/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0532, Series Loss: 0.0034, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [2844/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0534, Series Loss: 0.0035, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2845/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0532, Series Loss: 0.0035, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2846/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0531, Series Loss: 0.0035, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [2847/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0532, Series Loss: 0.0035, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2848/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0530, Series Loss: 0.0035, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [2849/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0531, Series Loss: 0.0036, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2850/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0532, Series Loss: 0.0035, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2851/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0533, Series Loss: 0.0036, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2852/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0533, Series Loss: 0.0036, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [2853/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0532, Series Loss: 0.0036, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [2854/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0532, Series Loss: 0.0036, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2855/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0530, Series Loss: 0.0036, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2856/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0530, Series Loss: 0.0036, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [2857/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0531, Series Loss: 0.0035, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2858/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0531, Series Loss: 0.0035, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2859/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0531, Series Loss: 0.0035, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2860/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0532, Series Loss: 0.0035, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2861/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0532, Series Loss: 0.0035, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [2862/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0531, Series Loss: 0.0034, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [2863/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0530, Series Loss: 0.0035, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [2864/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0531, Series Loss: 0.0035, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2865/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0529, Series Loss: 0.0034, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2866/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0530, Series Loss: 0.0034, Class Loss: 0.2490, Accuracy: 0.0679\n",
      "Epoch [2867/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0531, Series Loss: 0.0034, Class Loss: 0.2488, Accuracy: 0.0741\n",
      "Epoch [2868/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0532, Series Loss: 0.0034, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2869/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0534, Series Loss: 0.0034, Class Loss: 0.2487, Accuracy: 0.0432\n",
      "Epoch [2870/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0534, Series Loss: 0.0034, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [2871/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0533, Series Loss: 0.0034, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [2872/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0533, Series Loss: 0.0035, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [2873/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0532, Series Loss: 0.0035, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2874/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0533, Series Loss: 0.0036, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [2875/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0531, Series Loss: 0.0035, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2876/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0531, Series Loss: 0.0036, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2877/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0531, Series Loss: 0.0036, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [2878/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0532, Series Loss: 0.0036, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2879/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0533, Series Loss: 0.0036, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2880/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0531, Series Loss: 0.0036, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2881/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0530, Series Loss: 0.0035, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2882/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0529, Series Loss: 0.0035, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [2883/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0530, Series Loss: 0.0035, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [2884/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0531, Series Loss: 0.0035, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2885/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0532, Series Loss: 0.0034, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [2886/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0534, Series Loss: 0.0034, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [2887/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0535, Series Loss: 0.0034, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [2888/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0534, Series Loss: 0.0034, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2889/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0531, Series Loss: 0.0034, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2890/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0531, Series Loss: 0.0034, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2891/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0531, Series Loss: 0.0034, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [2892/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0531, Series Loss: 0.0034, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [2893/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0531, Series Loss: 0.0033, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2894/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0531, Series Loss: 0.0034, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2895/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0529, Series Loss: 0.0033, Class Loss: 0.2488, Accuracy: 0.0556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2896/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0529, Series Loss: 0.0033, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2897/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0529, Series Loss: 0.0034, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [2898/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0530, Series Loss: 0.0034, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [2899/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0531, Series Loss: 0.0034, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [2900/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0532, Series Loss: 0.0034, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2901/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0533, Series Loss: 0.0035, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [2902/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0533, Series Loss: 0.0035, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [2903/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0532, Series Loss: 0.0035, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [2904/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0532, Series Loss: 0.0035, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2905/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0531, Series Loss: 0.0036, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [2906/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0532, Series Loss: 0.0035, Class Loss: 0.2486, Accuracy: 0.0556\n",
      "Epoch [2907/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0532, Series Loss: 0.0036, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [2908/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0532, Series Loss: 0.0036, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2909/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0530, Series Loss: 0.0036, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2910/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0528, Series Loss: 0.0035, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2911/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0528, Series Loss: 0.0035, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [2912/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0529, Series Loss: 0.0035, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [2913/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0531, Series Loss: 0.0034, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2914/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0533, Series Loss: 0.0034, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [2915/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0532, Series Loss: 0.0034, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2916/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0532, Series Loss: 0.0035, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2917/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0530, Series Loss: 0.0033, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2918/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0529, Series Loss: 0.0034, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [2919/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0530, Series Loss: 0.0034, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [2920/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0530, Series Loss: 0.0034, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2921/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0531, Series Loss: 0.0034, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [2922/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0530, Series Loss: 0.0033, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2923/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0531, Series Loss: 0.0034, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [2924/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0528, Series Loss: 0.0033, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [2925/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0529, Series Loss: 0.0034, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2926/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0529, Series Loss: 0.0034, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2927/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0529, Series Loss: 0.0034, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2928/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0528, Series Loss: 0.0034, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [2929/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0530, Series Loss: 0.0034, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2930/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0530, Series Loss: 0.0035, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [2931/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0532, Series Loss: 0.0035, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [2932/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0531, Series Loss: 0.0035, Class Loss: 0.2487, Accuracy: 0.0432\n",
      "Epoch [2933/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0532, Series Loss: 0.0035, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [2934/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0531, Series Loss: 0.0035, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [2935/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0531, Series Loss: 0.0035, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2936/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0531, Series Loss: 0.0035, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [2937/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0529, Series Loss: 0.0035, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2938/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0529, Series Loss: 0.0035, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2939/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0530, Series Loss: 0.0035, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2940/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0532, Series Loss: 0.0034, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2941/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0532, Series Loss: 0.0035, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2942/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0534, Series Loss: 0.0035, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [2943/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0534, Series Loss: 0.0034, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2944/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0534, Series Loss: 0.0035, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2945/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0533, Series Loss: 0.0035, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2946/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0533, Series Loss: 0.0034, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [2947/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0531, Series Loss: 0.0033, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [2948/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0532, Series Loss: 0.0033, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2949/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0533, Series Loss: 0.0034, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [2950/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0531, Series Loss: 0.0033, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2951/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0530, Series Loss: 0.0034, Class Loss: 0.2487, Accuracy: 0.0432\n",
      "Epoch [2952/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0531, Series Loss: 0.0033, Class Loss: 0.2486, Accuracy: 0.0741\n",
      "Epoch [2953/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0530, Series Loss: 0.0033, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [2954/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0529, Series Loss: 0.0033, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2955/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0529, Series Loss: 0.0033, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [2956/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0528, Series Loss: 0.0034, Class Loss: 0.2489, Accuracy: 0.0679\n",
      "Epoch [2957/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0529, Series Loss: 0.0034, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [2958/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0530, Series Loss: 0.0034, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2959/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0530, Series Loss: 0.0034, Class Loss: 0.2489, Accuracy: 0.0556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2960/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0532, Series Loss: 0.0034, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2961/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0532, Series Loss: 0.0035, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2962/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0531, Series Loss: 0.0034, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2963/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0531, Series Loss: 0.0034, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2964/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0530, Series Loss: 0.0034, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [2965/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0529, Series Loss: 0.0034, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [2966/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0529, Series Loss: 0.0035, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [2967/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0531, Series Loss: 0.0034, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2968/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0532, Series Loss: 0.0035, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2969/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0532, Series Loss: 0.0034, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2970/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0531, Series Loss: 0.0034, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [2971/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0529, Series Loss: 0.0034, Class Loss: 0.2487, Accuracy: 0.0432\n",
      "Epoch [2972/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0528, Series Loss: 0.0034, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [2973/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0529, Series Loss: 0.0033, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [2974/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0530, Series Loss: 0.0033, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2975/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0531, Series Loss: 0.0033, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2976/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0530, Series Loss: 0.0033, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2977/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0530, Series Loss: 0.0033, Class Loss: 0.2487, Accuracy: 0.0741\n",
      "Epoch [2978/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0530, Series Loss: 0.0033, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2979/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0530, Series Loss: 0.0033, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2980/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0529, Series Loss: 0.0032, Class Loss: 0.2487, Accuracy: 0.0432\n",
      "Epoch [2981/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0530, Series Loss: 0.0033, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [2982/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0532, Series Loss: 0.0033, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [2983/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0532, Series Loss: 0.0033, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2984/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0531, Series Loss: 0.0033, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [2985/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0530, Series Loss: 0.0034, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [2986/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0529, Series Loss: 0.0034, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [2987/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0529, Series Loss: 0.0034, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [2988/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0530, Series Loss: 0.0034, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2989/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0532, Series Loss: 0.0034, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [2990/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0532, Series Loss: 0.0034, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2991/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0531, Series Loss: 0.0035, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2992/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0530, Series Loss: 0.0034, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [2993/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0528, Series Loss: 0.0034, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [2994/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0528, Series Loss: 0.0034, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2995/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0528, Series Loss: 0.0033, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2996/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0528, Series Loss: 0.0034, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [2997/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0527, Series Loss: 0.0033, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [2998/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0528, Series Loss: 0.0033, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [2999/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0526, Series Loss: 0.0033, Class Loss: 0.2488, Accuracy: 0.0370\n",
      "Epoch [3000/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0526, Series Loss: 0.0033, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [3001/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0526, Series Loss: 0.0033, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3002/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0526, Series Loss: 0.0032, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3003/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0528, Series Loss: 0.0033, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3004/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0527, Series Loss: 0.0032, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [3005/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0528, Series Loss: 0.0032, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3006/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0529, Series Loss: 0.0032, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [3007/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0530, Series Loss: 0.0032, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [3008/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0527, Series Loss: 0.0033, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3009/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0526, Series Loss: 0.0033, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3010/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0528, Series Loss: 0.0033, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [3011/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0528, Series Loss: 0.0032, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [3012/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0529, Series Loss: 0.0033, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3013/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0530, Series Loss: 0.0033, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [3014/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0530, Series Loss: 0.0033, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [3015/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0532, Series Loss: 0.0034, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3016/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0530, Series Loss: 0.0033, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [3017/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0530, Series Loss: 0.0034, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [3018/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0529, Series Loss: 0.0034, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [3019/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0527, Series Loss: 0.0034, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [3020/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0530, Series Loss: 0.0034, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [3021/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0531, Series Loss: 0.0034, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3022/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0532, Series Loss: 0.0034, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [3023/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0531, Series Loss: 0.0033, Class Loss: 0.2488, Accuracy: 0.0556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3024/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0532, Series Loss: 0.0034, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3025/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0530, Series Loss: 0.0033, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [3026/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0531, Series Loss: 0.0033, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3027/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0529, Series Loss: 0.0033, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3028/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0528, Series Loss: 0.0033, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3029/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0528, Series Loss: 0.0033, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3030/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0529, Series Loss: 0.0032, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [3031/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0530, Series Loss: 0.0033, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3032/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0527, Series Loss: 0.0032, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3033/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0528, Series Loss: 0.0032, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3034/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0527, Series Loss: 0.0032, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3035/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0527, Series Loss: 0.0032, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3036/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0527, Series Loss: 0.0032, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [3037/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0528, Series Loss: 0.0031, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3038/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0529, Series Loss: 0.0032, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3039/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0532, Series Loss: 0.0032, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3040/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0534, Series Loss: 0.0033, Class Loss: 0.2487, Accuracy: 0.0741\n",
      "Epoch [3041/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0532, Series Loss: 0.0032, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [3042/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0531, Series Loss: 0.0033, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3043/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0528, Series Loss: 0.0033, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [3044/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0528, Series Loss: 0.0033, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [3045/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0527, Series Loss: 0.0033, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3046/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0527, Series Loss: 0.0034, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3047/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0528, Series Loss: 0.0034, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3048/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0530, Series Loss: 0.0034, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3049/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0530, Series Loss: 0.0034, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [3050/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0528, Series Loss: 0.0033, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3051/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0529, Series Loss: 0.0034, Class Loss: 0.2488, Accuracy: 0.0741\n",
      "Epoch [3052/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0528, Series Loss: 0.0034, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3053/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0525, Series Loss: 0.0033, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3054/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0526, Series Loss: 0.0033, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [3055/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0525, Series Loss: 0.0032, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [3056/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0526, Series Loss: 0.0032, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3057/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0528, Series Loss: 0.0033, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [3058/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0530, Series Loss: 0.0032, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [3059/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0531, Series Loss: 0.0032, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3060/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0532, Series Loss: 0.0032, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3061/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0531, Series Loss: 0.0032, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [3062/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0529, Series Loss: 0.0032, Class Loss: 0.2489, Accuracy: 0.0679\n",
      "Epoch [3063/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0526, Series Loss: 0.0031, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [3064/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0526, Series Loss: 0.0032, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3065/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0525, Series Loss: 0.0032, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3066/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0525, Series Loss: 0.0032, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [3067/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0525, Series Loss: 0.0032, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3068/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0526, Series Loss: 0.0032, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3069/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0529, Series Loss: 0.0032, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [3070/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0529, Series Loss: 0.0032, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [3071/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0529, Series Loss: 0.0032, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3072/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0530, Series Loss: 0.0033, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [3073/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0530, Series Loss: 0.0034, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3074/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0530, Series Loss: 0.0034, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3075/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0528, Series Loss: 0.0033, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [3076/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0527, Series Loss: 0.0033, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [3077/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0528, Series Loss: 0.0034, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3078/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0528, Series Loss: 0.0034, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3079/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0526, Series Loss: 0.0033, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [3080/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0525, Series Loss: 0.0033, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3081/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0526, Series Loss: 0.0033, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3082/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0525, Series Loss: 0.0033, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3083/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0526, Series Loss: 0.0033, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [3084/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0527, Series Loss: 0.0032, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3085/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0528, Series Loss: 0.0032, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [3086/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0529, Series Loss: 0.0032, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3087/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0530, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3088/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0531, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [3089/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0530, Series Loss: 0.0031, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3090/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0526, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3091/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0525, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3092/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0526, Series Loss: 0.0031, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [3093/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0528, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3094/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0528, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3095/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0529, Series Loss: 0.0031, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [3096/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0529, Series Loss: 0.0032, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [3097/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0529, Series Loss: 0.0032, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [3098/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0529, Series Loss: 0.0032, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [3099/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0528, Series Loss: 0.0032, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3100/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0528, Series Loss: 0.0033, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3101/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0528, Series Loss: 0.0033, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3102/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0528, Series Loss: 0.0033, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3103/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0529, Series Loss: 0.0033, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [3104/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0530, Series Loss: 0.0034, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [3105/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0530, Series Loss: 0.0033, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3106/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0529, Series Loss: 0.0034, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [3107/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0527, Series Loss: 0.0033, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [3108/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0526, Series Loss: 0.0033, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3109/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0527, Series Loss: 0.0033, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [3110/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0527, Series Loss: 0.0033, Class Loss: 0.2490, Accuracy: 0.0494\n",
      "Epoch [3111/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0527, Series Loss: 0.0032, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3112/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0528, Series Loss: 0.0032, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3113/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0527, Series Loss: 0.0032, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3114/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0528, Series Loss: 0.0032, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3115/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0528, Series Loss: 0.0032, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3116/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0528, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3117/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0527, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3118/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0528, Series Loss: 0.0031, Class Loss: 0.2486, Accuracy: 0.0679\n",
      "Epoch [3119/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0528, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3120/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0530, Series Loss: 0.0031, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3121/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0530, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3122/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0529, Series Loss: 0.0031, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [3123/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0531, Series Loss: 0.0032, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [3124/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0529, Series Loss: 0.0031, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3125/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0528, Series Loss: 0.0032, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3126/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0527, Series Loss: 0.0032, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3127/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0527, Series Loss: 0.0032, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [3128/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0526, Series Loss: 0.0032, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [3129/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0525, Series Loss: 0.0032, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [3130/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0526, Series Loss: 0.0032, Class Loss: 0.2489, Accuracy: 0.0370\n",
      "Epoch [3131/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0527, Series Loss: 0.0032, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [3132/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0527, Series Loss: 0.0032, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [3133/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0528, Series Loss: 0.0032, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [3134/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0529, Series Loss: 0.0032, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3135/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0530, Series Loss: 0.0032, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3136/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0529, Series Loss: 0.0032, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [3137/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0529, Series Loss: 0.0032, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3138/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0529, Series Loss: 0.0032, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3139/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0527, Series Loss: 0.0032, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3140/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0526, Series Loss: 0.0032, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3141/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0526, Series Loss: 0.0032, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [3142/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0526, Series Loss: 0.0031, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [3143/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0527, Series Loss: 0.0031, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [3144/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0529, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3145/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0530, Series Loss: 0.0031, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [3146/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0529, Series Loss: 0.0031, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3147/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0530, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [3148/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0529, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3149/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0529, Series Loss: 0.0031, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [3150/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0528, Series Loss: 0.0032, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3151/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0527, Series Loss: 0.0032, Class Loss: 0.2489, Accuracy: 0.0617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3152/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0526, Series Loss: 0.0031, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3153/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0528, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3154/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0529, Series Loss: 0.0032, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [3155/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0528, Series Loss: 0.0032, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [3156/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0527, Series Loss: 0.0032, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [3157/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0527, Series Loss: 0.0032, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3158/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0527, Series Loss: 0.0032, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3159/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0527, Series Loss: 0.0032, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3160/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0527, Series Loss: 0.0032, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3161/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0527, Series Loss: 0.0032, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [3162/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0527, Series Loss: 0.0032, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [3163/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0527, Series Loss: 0.0032, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3164/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0527, Series Loss: 0.0031, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [3165/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0528, Series Loss: 0.0031, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3166/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0530, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3167/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0530, Series Loss: 0.0032, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3168/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0529, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0370\n",
      "Epoch [3169/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0530, Series Loss: 0.0032, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [3170/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0529, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3171/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0528, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3172/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0529, Series Loss: 0.0032, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3173/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0528, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3174/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0529, Series Loss: 0.0031, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [3175/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0527, Series Loss: 0.0031, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3176/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0526, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3177/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0525, Series Loss: 0.0031, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3178/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0526, Series Loss: 0.0031, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3179/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0526, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3180/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0527, Series Loss: 0.0031, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [3181/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0530, Series Loss: 0.0032, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3182/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0530, Series Loss: 0.0031, Class Loss: 0.2487, Accuracy: 0.0741\n",
      "Epoch [3183/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0528, Series Loss: 0.0031, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3184/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0526, Series Loss: 0.0032, Class Loss: 0.2488, Accuracy: 0.0741\n",
      "Epoch [3185/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0526, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3186/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0527, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3187/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0528, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [3188/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0529, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3189/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0529, Series Loss: 0.0031, Class Loss: 0.2487, Accuracy: 0.0432\n",
      "Epoch [3190/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0526, Series Loss: 0.0032, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [3191/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0525, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [3192/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0526, Series Loss: 0.0031, Class Loss: 0.2486, Accuracy: 0.0617\n",
      "Epoch [3193/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0525, Series Loss: 0.0031, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3194/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0524, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3195/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0526, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3196/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0527, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3197/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0529, Series Loss: 0.0032, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3198/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0526, Series Loss: 0.0031, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3199/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0526, Series Loss: 0.0031, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [3200/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0524, Series Loss: 0.0030, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3201/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0526, Series Loss: 0.0030, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3202/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0526, Series Loss: 0.0031, Class Loss: 0.2486, Accuracy: 0.0679\n",
      "Epoch [3203/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0527, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3204/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0530, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3205/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0531, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [3206/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0531, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3207/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0531, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3208/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0530, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3209/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0528, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3210/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0527, Series Loss: 0.0031, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3211/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0528, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [3212/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0527, Series Loss: 0.0031, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3213/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0527, Series Loss: 0.0032, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3214/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0528, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3215/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0528, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3216/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0528, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3217/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0529, Series Loss: 0.0031, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3218/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0529, Series Loss: 0.0031, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3219/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0528, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [3220/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0529, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [3221/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0527, Series Loss: 0.0030, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [3222/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0526, Series Loss: 0.0030, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3223/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0527, Series Loss: 0.0031, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [3224/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0528, Series Loss: 0.0030, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3225/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0527, Series Loss: 0.0030, Class Loss: 0.2486, Accuracy: 0.0556\n",
      "Epoch [3226/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0527, Series Loss: 0.0030, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3227/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0528, Series Loss: 0.0030, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3228/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0529, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [3229/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0528, Series Loss: 0.0031, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3230/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0528, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3231/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0530, Series Loss: 0.0032, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3232/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0529, Series Loss: 0.0031, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3233/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0527, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3234/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0528, Series Loss: 0.0032, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3235/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0528, Series Loss: 0.0031, Class Loss: 0.2490, Accuracy: 0.0370\n",
      "Epoch [3236/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0528, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3237/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0529, Series Loss: 0.0031, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3238/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0529, Series Loss: 0.0031, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3239/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0528, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3240/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0527, Series Loss: 0.0031, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [3241/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0525, Series Loss: 0.0030, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3242/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0526, Series Loss: 0.0031, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3243/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0528, Series Loss: 0.0030, Class Loss: 0.2488, Accuracy: 0.0741\n",
      "Epoch [3244/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0530, Series Loss: 0.0030, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3245/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0529, Series Loss: 0.0030, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3246/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0528, Series Loss: 0.0030, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [3247/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0528, Series Loss: 0.0030, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3248/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0528, Series Loss: 0.0030, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3249/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0525, Series Loss: 0.0029, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3250/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0524, Series Loss: 0.0030, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3251/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0029, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3252/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0525, Series Loss: 0.0030, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3253/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0527, Series Loss: 0.0030, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [3254/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0528, Series Loss: 0.0030, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3255/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0529, Series Loss: 0.0030, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [3256/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0528, Series Loss: 0.0031, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3257/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0524, Series Loss: 0.0031, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [3258/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0523, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3259/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0523, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3260/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0524, Series Loss: 0.0031, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [3261/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0526, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3262/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0526, Series Loss: 0.0031, Class Loss: 0.2487, Accuracy: 0.0432\n",
      "Epoch [3263/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0526, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3264/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0528, Series Loss: 0.0030, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3265/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0529, Series Loss: 0.0030, Class Loss: 0.2487, Accuracy: 0.0741\n",
      "Epoch [3266/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0529, Series Loss: 0.0031, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3267/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0526, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [3268/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0528, Series Loss: 0.0030, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3269/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0528, Series Loss: 0.0030, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3270/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0528, Series Loss: 0.0030, Class Loss: 0.2486, Accuracy: 0.0432\n",
      "Epoch [3271/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0527, Series Loss: 0.0030, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3272/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0527, Series Loss: 0.0030, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3273/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0527, Series Loss: 0.0030, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3274/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0526, Series Loss: 0.0030, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3275/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0527, Series Loss: 0.0030, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [3276/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0529, Series Loss: 0.0030, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [3277/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0531, Series Loss: 0.0031, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3278/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0531, Series Loss: 0.0030, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3279/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0530, Series Loss: 0.0030, Class Loss: 0.2488, Accuracy: 0.0432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3280/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0528, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3281/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0526, Series Loss: 0.0031, Class Loss: 0.2487, Accuracy: 0.0432\n",
      "Epoch [3282/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0525, Series Loss: 0.0030, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [3283/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0526, Series Loss: 0.0030, Class Loss: 0.2487, Accuracy: 0.0370\n",
      "Epoch [3284/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0528, Series Loss: 0.0030, Class Loss: 0.2488, Accuracy: 0.0370\n",
      "Epoch [3285/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0529, Series Loss: 0.0030, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3286/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0528, Series Loss: 0.0030, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [3287/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0527, Series Loss: 0.0030, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3288/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0527, Series Loss: 0.0030, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [3289/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0526, Series Loss: 0.0030, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3290/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0527, Series Loss: 0.0030, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3291/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0525, Series Loss: 0.0030, Class Loss: 0.2487, Accuracy: 0.0741\n",
      "Epoch [3292/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0525, Series Loss: 0.0030, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3293/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0525, Series Loss: 0.0030, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3294/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0527, Series Loss: 0.0030, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3295/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0528, Series Loss: 0.0030, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [3296/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0529, Series Loss: 0.0030, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [3297/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0530, Series Loss: 0.0030, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3298/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0528, Series Loss: 0.0030, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [3299/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0527, Series Loss: 0.0031, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3300/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0529, Series Loss: 0.0030, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3301/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0529, Series Loss: 0.0030, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3302/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0530, Series Loss: 0.0030, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [3303/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0529, Series Loss: 0.0030, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3304/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0529, Series Loss: 0.0030, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3305/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0529, Series Loss: 0.0030, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3306/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0531, Series Loss: 0.0030, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3307/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0530, Series Loss: 0.0030, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3308/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0528, Series Loss: 0.0030, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3309/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0527, Series Loss: 0.0030, Class Loss: 0.2488, Accuracy: 0.0370\n",
      "Epoch [3310/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0526, Series Loss: 0.0030, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3311/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0030, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3312/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0524, Series Loss: 0.0030, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3313/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0525, Series Loss: 0.0029, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3314/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0526, Series Loss: 0.0029, Class Loss: 0.2486, Accuracy: 0.0494\n",
      "Epoch [3315/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0528, Series Loss: 0.0030, Class Loss: 0.2487, Accuracy: 0.0432\n",
      "Epoch [3316/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0527, Series Loss: 0.0029, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3317/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0526, Series Loss: 0.0029, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3318/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0526, Series Loss: 0.0029, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3319/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0526, Series Loss: 0.0030, Class Loss: 0.2487, Accuracy: 0.0741\n",
      "Epoch [3320/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0526, Series Loss: 0.0030, Class Loss: 0.2487, Accuracy: 0.0432\n",
      "Epoch [3321/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0529, Series Loss: 0.0030, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3322/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0529, Series Loss: 0.0029, Class Loss: 0.2489, Accuracy: 0.0617\n",
      "Epoch [3323/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0529, Series Loss: 0.0030, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3324/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0528, Series Loss: 0.0030, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3325/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0528, Series Loss: 0.0030, Class Loss: 0.2486, Accuracy: 0.0617\n",
      "Epoch [3326/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0527, Series Loss: 0.0030, Class Loss: 0.2486, Accuracy: 0.0679\n",
      "Epoch [3327/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0527, Series Loss: 0.0030, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [3328/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0527, Series Loss: 0.0030, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3329/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0529, Series Loss: 0.0031, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3330/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0526, Series Loss: 0.0030, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3331/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0526, Series Loss: 0.0030, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3332/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0524, Series Loss: 0.0029, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3333/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0525, Series Loss: 0.0030, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [3334/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0524, Series Loss: 0.0029, Class Loss: 0.2486, Accuracy: 0.0556\n",
      "Epoch [3335/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0526, Series Loss: 0.0030, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3336/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0527, Series Loss: 0.0029, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3337/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0528, Series Loss: 0.0029, Class Loss: 0.2487, Accuracy: 0.0432\n",
      "Epoch [3338/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0529, Series Loss: 0.0029, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3339/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0528, Series Loss: 0.0029, Class Loss: 0.2488, Accuracy: 0.0741\n",
      "Epoch [3340/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0527, Series Loss: 0.0029, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [3341/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0525, Series Loss: 0.0029, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3342/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0525, Series Loss: 0.0029, Class Loss: 0.2487, Accuracy: 0.0432\n",
      "Epoch [3343/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0526, Series Loss: 0.0029, Class Loss: 0.2487, Accuracy: 0.0679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3344/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0525, Series Loss: 0.0029, Class Loss: 0.2486, Accuracy: 0.0556\n",
      "Epoch [3345/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0526, Series Loss: 0.0029, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3346/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0528, Series Loss: 0.0029, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3347/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0529, Series Loss: 0.0029, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [3348/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0528, Series Loss: 0.0029, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3349/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0527, Series Loss: 0.0029, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [3350/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0526, Series Loss: 0.0030, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3351/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0526, Series Loss: 0.0030, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3352/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0525, Series Loss: 0.0030, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3353/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0525, Series Loss: 0.0029, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [3354/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0524, Series Loss: 0.0029, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3355/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0525, Series Loss: 0.0029, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3356/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0527, Series Loss: 0.0030, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3357/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0525, Series Loss: 0.0029, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3358/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0525, Series Loss: 0.0029, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3359/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0525, Series Loss: 0.0029, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3360/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0526, Series Loss: 0.0029, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3361/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0527, Series Loss: 0.0029, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3362/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0527, Series Loss: 0.0028, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3363/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0526, Series Loss: 0.0028, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3364/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0526, Series Loss: 0.0028, Class Loss: 0.2487, Accuracy: 0.0370\n",
      "Epoch [3365/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0527, Series Loss: 0.0028, Class Loss: 0.2488, Accuracy: 0.0741\n",
      "Epoch [3366/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0526, Series Loss: 0.0029, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3367/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0524, Series Loss: 0.0029, Class Loss: 0.2487, Accuracy: 0.0432\n",
      "Epoch [3368/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0029, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [3369/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0525, Series Loss: 0.0029, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3370/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0524, Series Loss: 0.0029, Class Loss: 0.2486, Accuracy: 0.0617\n",
      "Epoch [3371/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0525, Series Loss: 0.0029, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [3372/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0525, Series Loss: 0.0029, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3373/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0527, Series Loss: 0.0029, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [3374/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0526, Series Loss: 0.0029, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3375/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0528, Series Loss: 0.0030, Class Loss: 0.2486, Accuracy: 0.0556\n",
      "Epoch [3376/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0527, Series Loss: 0.0029, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3377/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0526, Series Loss: 0.0030, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3378/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0527, Series Loss: 0.0029, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3379/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0527, Series Loss: 0.0029, Class Loss: 0.2486, Accuracy: 0.0494\n",
      "Epoch [3380/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0526, Series Loss: 0.0030, Class Loss: 0.2486, Accuracy: 0.0617\n",
      "Epoch [3381/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0527, Series Loss: 0.0029, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3382/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0525, Series Loss: 0.0029, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [3383/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0526, Series Loss: 0.0029, Class Loss: 0.2487, Accuracy: 0.0432\n",
      "Epoch [3384/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0526, Series Loss: 0.0029, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3385/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0526, Series Loss: 0.0028, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3386/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0524, Series Loss: 0.0028, Class Loss: 0.2486, Accuracy: 0.0617\n",
      "Epoch [3387/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0525, Series Loss: 0.0029, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3388/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0524, Series Loss: 0.0029, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3389/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0525, Series Loss: 0.0028, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3390/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0525, Series Loss: 0.0028, Class Loss: 0.2486, Accuracy: 0.0741\n",
      "Epoch [3391/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0525, Series Loss: 0.0028, Class Loss: 0.2486, Accuracy: 0.0617\n",
      "Epoch [3392/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0526, Series Loss: 0.0028, Class Loss: 0.2487, Accuracy: 0.0432\n",
      "Epoch [3393/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0526, Series Loss: 0.0029, Class Loss: 0.2487, Accuracy: 0.0432\n",
      "Epoch [3394/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0524, Series Loss: 0.0029, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3395/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0524, Series Loss: 0.0029, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3396/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0524, Series Loss: 0.0029, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3397/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0522, Series Loss: 0.0029, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3398/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0522, Series Loss: 0.0029, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [3399/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0524, Series Loss: 0.0029, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3400/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0526, Series Loss: 0.0029, Class Loss: 0.2486, Accuracy: 0.0556\n",
      "Epoch [3401/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0526, Series Loss: 0.0029, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [3402/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0527, Series Loss: 0.0030, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3403/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0525, Series Loss: 0.0029, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [3404/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0029, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3405/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0524, Series Loss: 0.0029, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3406/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0527, Series Loss: 0.0029, Class Loss: 0.2486, Accuracy: 0.0556\n",
      "Epoch [3407/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0527, Series Loss: 0.0029, Class Loss: 0.2487, Accuracy: 0.0556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3408/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0525, Series Loss: 0.0029, Class Loss: 0.2486, Accuracy: 0.0617\n",
      "Epoch [3409/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0524, Series Loss: 0.0029, Class Loss: 0.2486, Accuracy: 0.0741\n",
      "Epoch [3410/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0525, Series Loss: 0.0028, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3411/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0525, Series Loss: 0.0028, Class Loss: 0.2486, Accuracy: 0.0556\n",
      "Epoch [3412/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0527, Series Loss: 0.0028, Class Loss: 0.2487, Accuracy: 0.0370\n",
      "Epoch [3413/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0528, Series Loss: 0.0029, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3414/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0526, Series Loss: 0.0028, Class Loss: 0.2486, Accuracy: 0.0617\n",
      "Epoch [3415/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0526, Series Loss: 0.0028, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3416/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0525, Series Loss: 0.0028, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3417/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0525, Series Loss: 0.0028, Class Loss: 0.2487, Accuracy: 0.0432\n",
      "Epoch [3418/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0526, Series Loss: 0.0028, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3419/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0526, Series Loss: 0.0028, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3420/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0525, Series Loss: 0.0028, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3421/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0525, Series Loss: 0.0028, Class Loss: 0.2486, Accuracy: 0.0556\n",
      "Epoch [3422/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0028, Class Loss: 0.2486, Accuracy: 0.0494\n",
      "Epoch [3423/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0522, Series Loss: 0.0028, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3424/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0521, Series Loss: 0.0028, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3425/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0522, Series Loss: 0.0028, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3426/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0524, Series Loss: 0.0028, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3427/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0028, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3428/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0522, Series Loss: 0.0028, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3429/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0522, Series Loss: 0.0028, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [3430/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0028, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3431/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0524, Series Loss: 0.0028, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3432/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0527, Series Loss: 0.0028, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3433/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0529, Series Loss: 0.0028, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3434/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0527, Series Loss: 0.0028, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3435/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0525, Series Loss: 0.0028, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [3436/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0525, Series Loss: 0.0028, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3437/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0525, Series Loss: 0.0029, Class Loss: 0.2486, Accuracy: 0.0617\n",
      "Epoch [3438/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0523, Series Loss: 0.0028, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3439/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0029, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3440/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0028, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3441/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0524, Series Loss: 0.0028, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3442/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0524, Series Loss: 0.0028, Class Loss: 0.2487, Accuracy: 0.0432\n",
      "Epoch [3443/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0524, Series Loss: 0.0028, Class Loss: 0.2486, Accuracy: 0.0617\n",
      "Epoch [3444/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0527, Series Loss: 0.0029, Class Loss: 0.2486, Accuracy: 0.0679\n",
      "Epoch [3445/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0527, Series Loss: 0.0028, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3446/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0525, Series Loss: 0.0028, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3447/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0525, Series Loss: 0.0028, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3448/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0527, Series Loss: 0.0028, Class Loss: 0.2487, Accuracy: 0.0432\n",
      "Epoch [3449/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0528, Series Loss: 0.0028, Class Loss: 0.2487, Accuracy: 0.0370\n",
      "Epoch [3450/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0526, Series Loss: 0.0028, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3451/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0524, Series Loss: 0.0028, Class Loss: 0.2486, Accuracy: 0.0494\n",
      "Epoch [3452/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0523, Series Loss: 0.0029, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3453/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0522, Series Loss: 0.0028, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3454/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0522, Series Loss: 0.0028, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3455/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0524, Series Loss: 0.0029, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3456/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0525, Series Loss: 0.0029, Class Loss: 0.2486, Accuracy: 0.0679\n",
      "Epoch [3457/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0524, Series Loss: 0.0029, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [3458/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0523, Series Loss: 0.0028, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3459/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0028, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3460/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0524, Series Loss: 0.0028, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3461/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0523, Series Loss: 0.0028, Class Loss: 0.2487, Accuracy: 0.0432\n",
      "Epoch [3462/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0524, Series Loss: 0.0028, Class Loss: 0.2486, Accuracy: 0.0617\n",
      "Epoch [3463/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0524, Series Loss: 0.0028, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3464/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0524, Series Loss: 0.0028, Class Loss: 0.2486, Accuracy: 0.0617\n",
      "Epoch [3465/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0027, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [3466/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0525, Series Loss: 0.0028, Class Loss: 0.2486, Accuracy: 0.0556\n",
      "Epoch [3467/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0525, Series Loss: 0.0028, Class Loss: 0.2486, Accuracy: 0.0494\n",
      "Epoch [3468/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0525, Series Loss: 0.0028, Class Loss: 0.2486, Accuracy: 0.0617\n",
      "Epoch [3469/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0524, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3470/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0027, Class Loss: 0.2486, Accuracy: 0.0494\n",
      "Epoch [3471/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0521, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3472/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0521, Series Loss: 0.0027, Class Loss: 0.2485, Accuracy: 0.0741\n",
      "Epoch [3473/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0520, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3474/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0521, Series Loss: 0.0027, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3475/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0522, Series Loss: 0.0027, Class Loss: 0.2486, Accuracy: 0.0556\n",
      "Epoch [3476/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0522, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0432\n",
      "Epoch [3477/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0525, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3478/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0526, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3479/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0526, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3480/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0524, Series Loss: 0.0028, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3481/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0522, Series Loss: 0.0028, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3482/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0520, Series Loss: 0.0028, Class Loss: 0.2486, Accuracy: 0.0556\n",
      "Epoch [3483/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0520, Series Loss: 0.0028, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3484/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0520, Series Loss: 0.0028, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3485/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0520, Series Loss: 0.0028, Class Loss: 0.2486, Accuracy: 0.0556\n",
      "Epoch [3486/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0521, Series Loss: 0.0028, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [3487/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0521, Series Loss: 0.0028, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3488/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0028, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [3489/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0525, Series Loss: 0.0028, Class Loss: 0.2487, Accuracy: 0.0432\n",
      "Epoch [3490/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0526, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3491/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0527, Series Loss: 0.0028, Class Loss: 0.2486, Accuracy: 0.0617\n",
      "Epoch [3492/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0527, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3493/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0526, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3494/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0027, Class Loss: 0.2486, Accuracy: 0.0494\n",
      "Epoch [3495/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0522, Series Loss: 0.0027, Class Loss: 0.2486, Accuracy: 0.0617\n",
      "Epoch [3496/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0027, Class Loss: 0.2486, Accuracy: 0.0494\n",
      "Epoch [3497/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0525, Series Loss: 0.0027, Class Loss: 0.2486, Accuracy: 0.0556\n",
      "Epoch [3498/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0526, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3499/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0527, Series Loss: 0.0027, Class Loss: 0.2486, Accuracy: 0.0556\n",
      "Epoch [3500/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0526, Series Loss: 0.0027, Class Loss: 0.2486, Accuracy: 0.0679\n",
      "Epoch [3501/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0526, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [3502/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0525, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0370\n",
      "Epoch [3503/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0522, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0741\n",
      "Epoch [3504/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0520, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3505/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0519, Series Loss: 0.0027, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3506/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0518, Series Loss: 0.0027, Class Loss: 0.2485, Accuracy: 0.0617\n",
      "Epoch [3507/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0521, Series Loss: 0.0027, Class Loss: 0.2486, Accuracy: 0.0617\n",
      "Epoch [3508/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0524, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3509/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0027, Class Loss: 0.2486, Accuracy: 0.0617\n",
      "Epoch [3510/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0521, Series Loss: 0.0027, Class Loss: 0.2486, Accuracy: 0.0617\n",
      "Epoch [3511/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0520, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0432\n",
      "Epoch [3512/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0520, Series Loss: 0.0027, Class Loss: 0.2486, Accuracy: 0.0494\n",
      "Epoch [3513/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0520, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3514/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0027, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [3515/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0523, Series Loss: 0.0027, Class Loss: 0.2486, Accuracy: 0.0556\n",
      "Epoch [3516/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0522, Series Loss: 0.0028, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3517/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0521, Series Loss: 0.0027, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3518/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0519, Series Loss: 0.0028, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3519/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0521, Series Loss: 0.0028, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3520/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0521, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0741\n",
      "Epoch [3521/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0522, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3522/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0028, Class Loss: 0.2486, Accuracy: 0.0617\n",
      "Epoch [3523/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0027, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3524/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0526, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3525/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0526, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3526/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0524, Series Loss: 0.0027, Class Loss: 0.2486, Accuracy: 0.0617\n",
      "Epoch [3527/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0027, Class Loss: 0.2486, Accuracy: 0.0494\n",
      "Epoch [3528/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0525, Series Loss: 0.0027, Class Loss: 0.2486, Accuracy: 0.0556\n",
      "Epoch [3529/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0027, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3530/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0522, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3531/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0522, Series Loss: 0.0027, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [3532/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0524, Series Loss: 0.0027, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3533/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0523, Series Loss: 0.0027, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3534/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0524, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3535/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0522, Series Loss: 0.0027, Class Loss: 0.2488, Accuracy: 0.0617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3536/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0521, Series Loss: 0.0027, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3537/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0522, Series Loss: 0.0027, Class Loss: 0.2486, Accuracy: 0.0741\n",
      "Epoch [3538/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0523, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3539/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0524, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3540/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0523, Series Loss: 0.0027, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [3541/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0524, Series Loss: 0.0028, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3542/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0525, Series Loss: 0.0028, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3543/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0526, Series Loss: 0.0028, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3544/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0525, Series Loss: 0.0028, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3545/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0523, Series Loss: 0.0028, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3546/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0523, Series Loss: 0.0028, Class Loss: 0.2486, Accuracy: 0.0679\n",
      "Epoch [3547/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0523, Series Loss: 0.0028, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3548/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0522, Series Loss: 0.0028, Class Loss: 0.2487, Accuracy: 0.0432\n",
      "Epoch [3549/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0521, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3550/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0521, Series Loss: 0.0027, Class Loss: 0.2486, Accuracy: 0.0617\n",
      "Epoch [3551/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0522, Series Loss: 0.0027, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3552/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0521, Series Loss: 0.0026, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3553/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0522, Series Loss: 0.0026, Class Loss: 0.2486, Accuracy: 0.0617\n",
      "Epoch [3554/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0523, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3555/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0523, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [3556/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0522, Series Loss: 0.0026, Class Loss: 0.2486, Accuracy: 0.0617\n",
      "Epoch [3557/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0522, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3558/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0522, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3559/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0522, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [3560/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0523, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3561/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0027, Class Loss: 0.2486, Accuracy: 0.0679\n",
      "Epoch [3562/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0524, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3563/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0524, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0741\n",
      "Epoch [3564/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0522, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3565/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0521, Series Loss: 0.0028, Class Loss: 0.2488, Accuracy: 0.0370\n",
      "Epoch [3566/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0519, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0741\n",
      "Epoch [3567/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0519, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0741\n",
      "Epoch [3568/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0518, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3569/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0518, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3570/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0519, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [3571/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0521, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3572/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0521, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0802\n",
      "Epoch [3573/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0521, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3574/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0522, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3575/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0522, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3576/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0522, Series Loss: 0.0026, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [3577/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0026, Class Loss: 0.2486, Accuracy: 0.0679\n",
      "Epoch [3578/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0524, Series Loss: 0.0026, Class Loss: 0.2486, Accuracy: 0.0617\n",
      "Epoch [3579/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0526, Series Loss: 0.0026, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3580/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0524, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [3581/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0522, Series Loss: 0.0026, Class Loss: 0.2486, Accuracy: 0.0494\n",
      "Epoch [3582/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0522, Series Loss: 0.0027, Class Loss: 0.2486, Accuracy: 0.0494\n",
      "Epoch [3583/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0522, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3584/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0027, Class Loss: 0.2486, Accuracy: 0.0494\n",
      "Epoch [3585/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0522, Series Loss: 0.0027, Class Loss: 0.2486, Accuracy: 0.0556\n",
      "Epoch [3586/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0027, Class Loss: 0.2486, Accuracy: 0.0556\n",
      "Epoch [3587/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0027, Class Loss: 0.2486, Accuracy: 0.0556\n",
      "Epoch [3588/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3589/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0524, Series Loss: 0.0027, Class Loss: 0.2486, Accuracy: 0.0617\n",
      "Epoch [3590/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0522, Series Loss: 0.0028, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3591/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0520, Series Loss: 0.0027, Class Loss: 0.2486, Accuracy: 0.0617\n",
      "Epoch [3592/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0519, Series Loss: 0.0027, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [3593/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0519, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0741\n",
      "Epoch [3594/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0520, Series Loss: 0.0027, Class Loss: 0.2486, Accuracy: 0.0494\n",
      "Epoch [3595/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0520, Series Loss: 0.0027, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3596/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0521, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0370\n",
      "Epoch [3597/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0520, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3598/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0519, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3599/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0520, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3600/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0522, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [3601/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0522, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3602/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0523, Series Loss: 0.0026, Class Loss: 0.2486, Accuracy: 0.0617\n",
      "Epoch [3603/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0523, Series Loss: 0.0026, Class Loss: 0.2486, Accuracy: 0.0556\n",
      "Epoch [3604/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0026, Class Loss: 0.2485, Accuracy: 0.0617\n",
      "Epoch [3605/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0523, Series Loss: 0.0026, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3606/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0521, Series Loss: 0.0027, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [3607/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0520, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3608/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0521, Series Loss: 0.0027, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3609/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0027, Class Loss: 0.2488, Accuracy: 0.0741\n",
      "Epoch [3610/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0524, Series Loss: 0.0028, Class Loss: 0.2486, Accuracy: 0.0617\n",
      "Epoch [3611/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0523, Series Loss: 0.0027, Class Loss: 0.2486, Accuracy: 0.0741\n",
      "Epoch [3612/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0028, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3613/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0522, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3614/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0521, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3615/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0522, Series Loss: 0.0027, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3616/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0520, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3617/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0520, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3618/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0521, Series Loss: 0.0027, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3619/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0522, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3620/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0522, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3621/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0524, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3622/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0026, Class Loss: 0.2486, Accuracy: 0.0556\n",
      "Epoch [3623/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0522, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3624/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0520, Series Loss: 0.0026, Class Loss: 0.2486, Accuracy: 0.0556\n",
      "Epoch [3625/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0522, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0741\n",
      "Epoch [3626/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0524, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3627/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0524, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0741\n",
      "Epoch [3628/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0524, Series Loss: 0.0026, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3629/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0521, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0802\n",
      "Epoch [3630/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0521, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [3631/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0521, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [3632/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0521, Series Loss: 0.0026, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3633/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0521, Series Loss: 0.0026, Class Loss: 0.2486, Accuracy: 0.0741\n",
      "Epoch [3634/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0522, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3635/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0521, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3636/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0522, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3637/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0523, Series Loss: 0.0027, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3638/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0524, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0432\n",
      "Epoch [3639/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0523, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3640/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0524, Series Loss: 0.0027, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3641/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0524, Series Loss: 0.0027, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [3642/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0523, Series Loss: 0.0027, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3643/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0524, Series Loss: 0.0028, Class Loss: 0.2488, Accuracy: 0.0370\n",
      "Epoch [3644/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0523, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [3645/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0027, Class Loss: 0.2486, Accuracy: 0.0617\n",
      "Epoch [3646/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0522, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3647/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0026, Class Loss: 0.2488, Accuracy: 0.0370\n",
      "Epoch [3648/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0524, Series Loss: 0.0026, Class Loss: 0.2486, Accuracy: 0.0741\n",
      "Epoch [3649/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0025, Class Loss: 0.2486, Accuracy: 0.0617\n",
      "Epoch [3650/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0025, Class Loss: 0.2488, Accuracy: 0.0370\n",
      "Epoch [3651/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0521, Series Loss: 0.0025, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3652/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0522, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3653/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0524, Series Loss: 0.0025, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3654/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0525, Series Loss: 0.0025, Class Loss: 0.2486, Accuracy: 0.0679\n",
      "Epoch [3655/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0524, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0741\n",
      "Epoch [3656/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0026, Class Loss: 0.2486, Accuracy: 0.0617\n",
      "Epoch [3657/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0524, Series Loss: 0.0026, Class Loss: 0.2486, Accuracy: 0.0556\n",
      "Epoch [3658/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0522, Series Loss: 0.0026, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3659/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0522, Series Loss: 0.0027, Class Loss: 0.2486, Accuracy: 0.0556\n",
      "Epoch [3660/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0520, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3661/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0519, Series Loss: 0.0027, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3662/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0518, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3663/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0520, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3664/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0519, Series Loss: 0.0027, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3665/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0521, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0802\n",
      "Epoch [3666/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0520, Series Loss: 0.0027, Class Loss: 0.2486, Accuracy: 0.0679\n",
      "Epoch [3667/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0520, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [3668/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0521, Series Loss: 0.0027, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3669/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0521, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3670/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0523, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3671/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0523, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0741\n",
      "Epoch [3672/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0522, Series Loss: 0.0025, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3673/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0522, Series Loss: 0.0025, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3674/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0522, Series Loss: 0.0025, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3675/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0522, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [3676/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0524, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3677/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3678/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0521, Series Loss: 0.0026, Class Loss: 0.2486, Accuracy: 0.0617\n",
      "Epoch [3679/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0518, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [3680/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0516, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3681/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0517, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0741\n",
      "Epoch [3682/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0519, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3683/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0520, Series Loss: 0.0026, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3684/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0522, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3685/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0523, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3686/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0525, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3687/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0525, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3688/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0523, Series Loss: 0.0027, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3689/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0521, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3690/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0519, Series Loss: 0.0026, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [3691/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0522, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0432\n",
      "Epoch [3692/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0522, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3693/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0522, Series Loss: 0.0026, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3694/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3695/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0520, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0802\n",
      "Epoch [3696/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0521, Series Loss: 0.0025, Class Loss: 0.2489, Accuracy: 0.0741\n",
      "Epoch [3697/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0522, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3698/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3699/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0521, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3700/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0520, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0432\n",
      "Epoch [3701/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0520, Series Loss: 0.0025, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3702/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0522, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [3703/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0522, Series Loss: 0.0025, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3704/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0520, Series Loss: 0.0025, Class Loss: 0.2488, Accuracy: 0.0370\n",
      "Epoch [3705/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0518, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0741\n",
      "Epoch [3706/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0519, Series Loss: 0.0026, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [3707/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0519, Series Loss: 0.0025, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3708/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0521, Series Loss: 0.0026, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3709/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0521, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0802\n",
      "Epoch [3710/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0522, Series Loss: 0.0026, Class Loss: 0.2488, Accuracy: 0.0741\n",
      "Epoch [3711/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0523, Series Loss: 0.0026, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [3712/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0523, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [3713/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0523, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3714/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0525, Series Loss: 0.0027, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [3715/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0525, Series Loss: 0.0026, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3716/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0522, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0741\n",
      "Epoch [3717/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0523, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3718/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0026, Class Loss: 0.2486, Accuracy: 0.0617\n",
      "Epoch [3719/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0521, Series Loss: 0.0026, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3720/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0521, Series Loss: 0.0025, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3721/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0522, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3722/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0025, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [3723/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0523, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0741\n",
      "Epoch [3724/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0524, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3725/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0524, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [3726/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0025, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [3727/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0523, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3728/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3729/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0525, Series Loss: 0.0025, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [3730/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0526, Series Loss: 0.0026, Class Loss: 0.2486, Accuracy: 0.0679\n",
      "Epoch [3731/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0524, Series Loss: 0.0026, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3732/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0521, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3733/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0521, Series Loss: 0.0026, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3734/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3735/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3736/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0522, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3737/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0521, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0432\n",
      "Epoch [3738/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0521, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0741\n",
      "Epoch [3739/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0520, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3740/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0521, Series Loss: 0.0026, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [3741/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0522, Series Loss: 0.0026, Class Loss: 0.2486, Accuracy: 0.0617\n",
      "Epoch [3742/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0523, Series Loss: 0.0025, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3743/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0524, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3744/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3745/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0025, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3746/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0525, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [3747/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0527, Series Loss: 0.0025, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [3748/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0526, Series Loss: 0.0025, Class Loss: 0.2486, Accuracy: 0.0494\n",
      "Epoch [3749/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0525, Series Loss: 0.0025, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3750/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0524, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3751/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0523, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0432\n",
      "Epoch [3752/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0521, Series Loss: 0.0025, Class Loss: 0.2486, Accuracy: 0.0617\n",
      "Epoch [3753/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0521, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3754/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0522, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [3755/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0521, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0741\n",
      "Epoch [3756/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0520, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3757/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0520, Series Loss: 0.0026, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [3758/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0520, Series Loss: 0.0026, Class Loss: 0.2486, Accuracy: 0.0679\n",
      "Epoch [3759/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0520, Series Loss: 0.0025, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3760/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0522, Series Loss: 0.0025, Class Loss: 0.2486, Accuracy: 0.0741\n",
      "Epoch [3761/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0521, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [3762/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0520, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [3763/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0520, Series Loss: 0.0025, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3764/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0520, Series Loss: 0.0024, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3765/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0522, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0741\n",
      "Epoch [3766/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0522, Series Loss: 0.0025, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3767/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0522, Series Loss: 0.0025, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3768/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0523, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0741\n",
      "Epoch [3769/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0522, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [3770/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0521, Series Loss: 0.0025, Class Loss: 0.2490, Accuracy: 0.0432\n",
      "Epoch [3771/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0521, Series Loss: 0.0025, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3772/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0522, Series Loss: 0.0025, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3773/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0524, Series Loss: 0.0026, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3774/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0526, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3775/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0525, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3776/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0525, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [3777/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0524, Series Loss: 0.0026, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3778/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0522, Series Loss: 0.0026, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3779/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0521, Series Loss: 0.0026, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3780/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0520, Series Loss: 0.0025, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [3781/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0521, Series Loss: 0.0026, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3782/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0521, Series Loss: 0.0025, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3783/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0520, Series Loss: 0.0025, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3784/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0520, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [3785/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0524, Series Loss: 0.0024, Class Loss: 0.2488, Accuracy: 0.0802\n",
      "Epoch [3786/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3787/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0523, Series Loss: 0.0025, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [3788/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0524, Series Loss: 0.0025, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3789/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0525, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3790/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0524, Series Loss: 0.0025, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3791/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3792/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3793/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0524, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3794/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0527, Series Loss: 0.0025, Class Loss: 0.2486, Accuracy: 0.0617\n",
      "Epoch [3795/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0524, Series Loss: 0.0025, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [3796/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0522, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0741\n",
      "Epoch [3797/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0522, Series Loss: 0.0025, Class Loss: 0.2486, Accuracy: 0.0679\n",
      "Epoch [3798/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0522, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3799/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0522, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3800/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0522, Series Loss: 0.0026, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3801/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0522, Series Loss: 0.0025, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [3802/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0521, Series Loss: 0.0024, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3803/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0522, Series Loss: 0.0025, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3804/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0521, Series Loss: 0.0024, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [3805/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0024, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3806/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0524, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3807/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0025, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3808/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0024, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [3809/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3810/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3811/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0523, Series Loss: 0.0025, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [3812/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0025, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3813/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0524, Series Loss: 0.0025, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3814/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0524, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3815/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0025, Class Loss: 0.2486, Accuracy: 0.0556\n",
      "Epoch [3816/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0521, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0370\n",
      "Epoch [3817/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0521, Series Loss: 0.0025, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3818/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0520, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0741\n",
      "Epoch [3819/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0522, Series Loss: 0.0025, Class Loss: 0.2488, Accuracy: 0.0741\n",
      "Epoch [3820/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3821/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0523, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3822/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0525, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0741\n",
      "Epoch [3823/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0527, Series Loss: 0.0025, Class Loss: 0.2486, Accuracy: 0.0741\n",
      "Epoch [3824/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0526, Series Loss: 0.0024, Class Loss: 0.2487, Accuracy: 0.0432\n",
      "Epoch [3825/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0525, Series Loss: 0.0024, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3826/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0024, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [3827/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0522, Series Loss: 0.0025, Class Loss: 0.2488, Accuracy: 0.0370\n",
      "Epoch [3828/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0519, Series Loss: 0.0025, Class Loss: 0.2486, Accuracy: 0.0556\n",
      "Epoch [3829/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0520, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3830/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0522, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3831/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0522, Series Loss: 0.0025, Class Loss: 0.2485, Accuracy: 0.0679\n",
      "Epoch [3832/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0522, Series Loss: 0.0025, Class Loss: 0.2486, Accuracy: 0.0556\n",
      "Epoch [3833/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0521, Series Loss: 0.0025, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [3834/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0520, Series Loss: 0.0025, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [3835/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0520, Series Loss: 0.0025, Class Loss: 0.2486, Accuracy: 0.0679\n",
      "Epoch [3836/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0519, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3837/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0520, Series Loss: 0.0024, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [3838/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0519, Series Loss: 0.0024, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3839/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0520, Series Loss: 0.0024, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3840/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0522, Series Loss: 0.0024, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3841/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0524, Series Loss: 0.0024, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3842/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0024, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3843/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0522, Series Loss: 0.0023, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [3844/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0024, Class Loss: 0.2487, Accuracy: 0.0432\n",
      "Epoch [3845/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0522, Series Loss: 0.0024, Class Loss: 0.2487, Accuracy: 0.0432\n",
      "Epoch [3846/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0519, Series Loss: 0.0024, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [3847/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0521, Series Loss: 0.0024, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3848/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0521, Series Loss: 0.0024, Class Loss: 0.2487, Accuracy: 0.0432\n",
      "Epoch [3849/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0521, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3850/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0520, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3851/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0521, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0432\n",
      "Epoch [3852/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0522, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3853/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0522, Series Loss: 0.0026, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3854/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0521, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3855/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0025, Class Loss: 0.2489, Accuracy: 0.0679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3856/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0524, Series Loss: 0.0025, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3857/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0523, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3858/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0521, Series Loss: 0.0024, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3859/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0520, Series Loss: 0.0024, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [3860/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0025, Class Loss: 0.2486, Accuracy: 0.0679\n",
      "Epoch [3861/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0524, Series Loss: 0.0024, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [3862/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0524, Series Loss: 0.0024, Class Loss: 0.2489, Accuracy: 0.0432\n",
      "Epoch [3863/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0522, Series Loss: 0.0024, Class Loss: 0.2485, Accuracy: 0.0494\n",
      "Epoch [3864/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0521, Series Loss: 0.0024, Class Loss: 0.2486, Accuracy: 0.0617\n",
      "Epoch [3865/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0521, Series Loss: 0.0024, Class Loss: 0.2486, Accuracy: 0.0802\n",
      "Epoch [3866/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0521, Series Loss: 0.0024, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3867/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0522, Series Loss: 0.0024, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3868/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0525, Series Loss: 0.0024, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3869/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0024, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3870/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0520, Series Loss: 0.0024, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3871/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0521, Series Loss: 0.0024, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [3872/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0523, Series Loss: 0.0024, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [3873/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0523, Series Loss: 0.0025, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [3874/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0521, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3875/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0520, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3876/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0518, Series Loss: 0.0024, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3877/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0520, Series Loss: 0.0024, Class Loss: 0.2489, Accuracy: 0.0679\n",
      "Epoch [3878/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0523, Series Loss: 0.0025, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3879/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0522, Series Loss: 0.0024, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [3880/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0524, Series Loss: 0.0024, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3881/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0524, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3882/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0024, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3883/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0522, Series Loss: 0.0024, Class Loss: 0.2486, Accuracy: 0.0556\n",
      "Epoch [3884/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0521, Series Loss: 0.0024, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3885/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0522, Series Loss: 0.0024, Class Loss: 0.2487, Accuracy: 0.0741\n",
      "Epoch [3886/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0522, Series Loss: 0.0024, Class Loss: 0.2487, Accuracy: 0.0741\n",
      "Epoch [3887/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0522, Series Loss: 0.0024, Class Loss: 0.2486, Accuracy: 0.0556\n",
      "Epoch [3888/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0522, Series Loss: 0.0024, Class Loss: 0.2487, Accuracy: 0.0802\n",
      "Epoch [3889/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0523, Series Loss: 0.0024, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3890/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0522, Series Loss: 0.0024, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3891/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0522, Series Loss: 0.0024, Class Loss: 0.2487, Accuracy: 0.0741\n",
      "Epoch [3892/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0522, Series Loss: 0.0024, Class Loss: 0.2487, Accuracy: 0.0741\n",
      "Epoch [3893/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0522, Series Loss: 0.0024, Class Loss: 0.2486, Accuracy: 0.0617\n",
      "Epoch [3894/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0521, Series Loss: 0.0024, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3895/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0519, Series Loss: 0.0024, Class Loss: 0.2486, Accuracy: 0.0741\n",
      "Epoch [3896/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0517, Series Loss: 0.0024, Class Loss: 0.2486, Accuracy: 0.0556\n",
      "Epoch [3897/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0515, Series Loss: 0.0024, Class Loss: 0.2487, Accuracy: 0.0432\n",
      "Epoch [3898/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0517, Series Loss: 0.0025, Class Loss: 0.2486, Accuracy: 0.0741\n",
      "Epoch [3899/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0521, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [3900/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0025, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3901/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0523, Series Loss: 0.0025, Class Loss: 0.2486, Accuracy: 0.0679\n",
      "Epoch [3902/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0521, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3903/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0521, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3904/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0521, Series Loss: 0.0025, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3905/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0522, Series Loss: 0.0024, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3906/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0024, Class Loss: 0.2487, Accuracy: 0.0432\n",
      "Epoch [3907/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0522, Series Loss: 0.0023, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [3908/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0523, Series Loss: 0.0023, Class Loss: 0.2486, Accuracy: 0.0741\n",
      "Epoch [3909/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0520, Series Loss: 0.0023, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3910/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0520, Series Loss: 0.0023, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3911/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0521, Series Loss: 0.0023, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3912/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0523, Series Loss: 0.0023, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3913/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0523, Series Loss: 0.0023, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3914/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0522, Series Loss: 0.0023, Class Loss: 0.2486, Accuracy: 0.0741\n",
      "Epoch [3915/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0524, Series Loss: 0.0023, Class Loss: 0.2488, Accuracy: 0.0556\n",
      "Epoch [3916/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0024, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3917/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0520, Series Loss: 0.0024, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3918/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0518, Series Loss: 0.0024, Class Loss: 0.2486, Accuracy: 0.0802\n",
      "Epoch [3919/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0519, Series Loss: 0.0025, Class Loss: 0.2488, Accuracy: 0.0617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3920/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0519, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3921/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0520, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3922/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0520, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3923/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0519, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3924/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0519, Series Loss: 0.0024, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3925/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0520, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3926/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0520, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3927/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0521, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3928/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0520, Series Loss: 0.0024, Class Loss: 0.2486, Accuracy: 0.0741\n",
      "Epoch [3929/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0520, Series Loss: 0.0024, Class Loss: 0.2487, Accuracy: 0.0741\n",
      "Epoch [3930/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0520, Series Loss: 0.0024, Class Loss: 0.2486, Accuracy: 0.0679\n",
      "Epoch [3931/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0520, Series Loss: 0.0023, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [3932/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0521, Series Loss: 0.0023, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3933/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0521, Series Loss: 0.0023, Class Loss: 0.2486, Accuracy: 0.0679\n",
      "Epoch [3934/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0519, Series Loss: 0.0023, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3935/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0519, Series Loss: 0.0022, Class Loss: 0.2486, Accuracy: 0.0679\n",
      "Epoch [3936/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0520, Series Loss: 0.0022, Class Loss: 0.2486, Accuracy: 0.0741\n",
      "Epoch [3937/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0520, Series Loss: 0.0022, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3938/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0520, Series Loss: 0.0022, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3939/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0519, Series Loss: 0.0023, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3940/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0519, Series Loss: 0.0023, Class Loss: 0.2486, Accuracy: 0.0679\n",
      "Epoch [3941/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0522, Series Loss: 0.0023, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3942/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0523, Series Loss: 0.0024, Class Loss: 0.2487, Accuracy: 0.0617\n",
      "Epoch [3943/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0521, Series Loss: 0.0024, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3944/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0519, Series Loss: 0.0024, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3945/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0517, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3946/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0516, Series Loss: 0.0025, Class Loss: 0.2486, Accuracy: 0.0679\n",
      "Epoch [3947/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0518, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3948/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0517, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0802\n",
      "Epoch [3949/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0518, Series Loss: 0.0025, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3950/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0519, Series Loss: 0.0025, Class Loss: 0.2486, Accuracy: 0.0679\n",
      "Epoch [3951/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0519, Series Loss: 0.0025, Class Loss: 0.2486, Accuracy: 0.0741\n",
      "Epoch [3952/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0520, Series Loss: 0.0024, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [3953/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0518, Series Loss: 0.0024, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3954/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0517, Series Loss: 0.0023, Class Loss: 0.2486, Accuracy: 0.0617\n",
      "Epoch [3955/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0516, Series Loss: 0.0022, Class Loss: 0.2487, Accuracy: 0.0370\n",
      "Epoch [3956/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0517, Series Loss: 0.0023, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3957/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0520, Series Loss: 0.0022, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [3958/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0519, Series Loss: 0.0022, Class Loss: 0.2489, Accuracy: 0.0494\n",
      "Epoch [3959/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0519, Series Loss: 0.0021, Class Loss: 0.2488, Accuracy: 0.0741\n",
      "Epoch [3960/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0519, Series Loss: 0.0021, Class Loss: 0.2487, Accuracy: 0.0741\n",
      "Epoch [3961/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0517, Series Loss: 0.0021, Class Loss: 0.2487, Accuracy: 0.0432\n",
      "Epoch [3962/4000], Discriminator Loss: 0.0939, Generator Loss: 0.0518, Series Loss: 0.0022, Class Loss: 0.2486, Accuracy: 0.0556\n",
      "Epoch [3963/4000], Discriminator Loss: 0.0939, Generator Loss: 0.0518, Series Loss: 0.0022, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [3964/4000], Discriminator Loss: 0.0939, Generator Loss: 0.0518, Series Loss: 0.0022, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [3965/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0518, Series Loss: 0.0022, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3966/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0518, Series Loss: 0.0023, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3967/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0518, Series Loss: 0.0024, Class Loss: 0.2486, Accuracy: 0.0556\n",
      "Epoch [3968/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0518, Series Loss: 0.0024, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3969/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0520, Series Loss: 0.0024, Class Loss: 0.2486, Accuracy: 0.0679\n",
      "Epoch [3970/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0519, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3971/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0520, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3972/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0521, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3973/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0520, Series Loss: 0.0026, Class Loss: 0.2486, Accuracy: 0.0679\n",
      "Epoch [3974/4000], Discriminator Loss: 0.0945, Generator Loss: 0.0520, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3975/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0521, Series Loss: 0.0026, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3976/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0520, Series Loss: 0.0026, Class Loss: 0.2488, Accuracy: 0.0432\n",
      "Epoch [3977/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0519, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3978/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0519, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [3979/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0519, Series Loss: 0.0024, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3980/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0520, Series Loss: 0.0023, Class Loss: 0.2488, Accuracy: 0.0679\n",
      "Epoch [3981/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0519, Series Loss: 0.0023, Class Loss: 0.2487, Accuracy: 0.0432\n",
      "Epoch [3982/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0519, Series Loss: 0.0022, Class Loss: 0.2489, Accuracy: 0.0556\n",
      "Epoch [3983/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0519, Series Loss: 0.0022, Class Loss: 0.2487, Accuracy: 0.0802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3984/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0519, Series Loss: 0.0022, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3985/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0518, Series Loss: 0.0021, Class Loss: 0.2487, Accuracy: 0.0864\n",
      "Epoch [3986/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0519, Series Loss: 0.0021, Class Loss: 0.2486, Accuracy: 0.0556\n",
      "Epoch [3987/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0519, Series Loss: 0.0021, Class Loss: 0.2486, Accuracy: 0.0802\n",
      "Epoch [3988/4000], Discriminator Loss: 0.0939, Generator Loss: 0.0520, Series Loss: 0.0021, Class Loss: 0.2487, Accuracy: 0.0864\n",
      "Epoch [3989/4000], Discriminator Loss: 0.0939, Generator Loss: 0.0521, Series Loss: 0.0021, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [3990/4000], Discriminator Loss: 0.0939, Generator Loss: 0.0521, Series Loss: 0.0021, Class Loss: 0.2486, Accuracy: 0.0679\n",
      "Epoch [3991/4000], Discriminator Loss: 0.0939, Generator Loss: 0.0519, Series Loss: 0.0021, Class Loss: 0.2487, Accuracy: 0.0741\n",
      "Epoch [3992/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0519, Series Loss: 0.0022, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3993/4000], Discriminator Loss: 0.0941, Generator Loss: 0.0518, Series Loss: 0.0022, Class Loss: 0.2487, Accuracy: 0.0679\n",
      "Epoch [3994/4000], Discriminator Loss: 0.0940, Generator Loss: 0.0517, Series Loss: 0.0023, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3995/4000], Discriminator Loss: 0.0942, Generator Loss: 0.0517, Series Loss: 0.0023, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3996/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0516, Series Loss: 0.0024, Class Loss: 0.2488, Accuracy: 0.0617\n",
      "Epoch [3997/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0517, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0556\n",
      "Epoch [3998/4000], Discriminator Loss: 0.0943, Generator Loss: 0.0518, Series Loss: 0.0025, Class Loss: 0.2488, Accuracy: 0.0494\n",
      "Epoch [3999/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0520, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0494\n",
      "Epoch [4000/4000], Discriminator Loss: 0.0944, Generator Loss: 0.0520, Series Loss: 0.0025, Class Loss: 0.2487, Accuracy: 0.0617\n"
     ]
    }
   ],
   "source": [
    "#训练循环\n",
    "for epoch in range(epoch_num):\n",
    "    #初始化损失值\n",
    "    D_epoch_loss = 0\n",
    "    G_epoch_loss = 0\n",
    "    C_epoch_loss = 0\n",
    "    S_epoch_loss = 0\n",
    "    acc_num = 0\n",
    "    item_num = 0\n",
    "    count = len(dataloader.dataset) #返回批次数\n",
    "    #对数据集进行迭代\n",
    "    for step,(img,label) in enumerate(dataloader):\n",
    "        img =img.to(device) #把数据放到设备上\n",
    "        label = label.to(device)\n",
    "        size = img.shape[0] #img的第一位是size,获取批次的大小\n",
    "        random_seed = torch.randn(size,100,device=device)\n",
    "        item_num += size\n",
    "        \n",
    "        #判别器训练(真实图片的损失和生成图片的损失),损失的构建和优化\n",
    "        d_optimizer.zero_grad()#梯度归零\n",
    "        #判别器对于真实图片产生的损失\n",
    "        real_output = dis(label,img) #判别器输入真实的图片，real_output对真实图片的预测结果\n",
    "        d_real_loss = loss_fn(real_output,\n",
    "                              torch.ones_like(real_output,device=device)\n",
    "                              )\n",
    "        d_real_loss.backward()#计算梯度\n",
    "        \n",
    "        #在生成器上去计算生成器的损失，优化目标是判别器上的参数\n",
    "        generated_img = gen(random_seed,label) #得到生成的图片\n",
    "        \n",
    "        #因为优化目标是判别器，所以对生成器上的优化目标进行截断\n",
    "        generated_img = torch.reshape(generated_img, (generated_img.size(0), generated_img.size(2)))\n",
    "        fake_output = dis(label,generated_img.detach()) #判别器输入生成的图片，fake_output对生成图片的预测;detach会截断梯度，梯度就不会再传递到gen模型中了\n",
    "        #判别器在生成图像上产生的损失\n",
    "        d_fake_loss = loss_fn(fake_output,\n",
    "                              torch.zeros_like(fake_output,device=device)\n",
    "                              )\n",
    "        d_fake_loss.backward()\n",
    "        #判别器损失\n",
    "        disc_loss = d_real_loss + d_fake_loss\n",
    "        #判别器优化\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        \n",
    "        #生成器上损失的构建和优化\n",
    "        g_optimizer.zero_grad() #先将生成器上的梯度置零\n",
    "        fake_output = dis(label,generated_img)\n",
    "        class_output = cls(torch.reshape(generated_img, (generated_img.size(0), 1, generated_img.size(1))))\n",
    "        cls_loss = class_loss(class_output, label)\n",
    "        series_loss = continue_loss(generated_img)\n",
    "        for i in range(size):\n",
    "            if class_output[i][torch.argmax(label[i])] >= 0.5:\n",
    "                acc_num += 1\n",
    "        gen_loss = loss_fn(fake_output,\n",
    "                              torch.ones_like(fake_output,device=device)\n",
    "                          ) + series_loss + cls_loss\n",
    "        gen_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        #累计每一个批次的loss\n",
    "        with torch.no_grad():\n",
    "            D_epoch_loss +=disc_loss\n",
    "            G_epoch_loss +=gen_loss\n",
    "            S_epoch_loss +=series_loss\n",
    "            C_epoch_loss +=cls_loss\n",
    "    #求平均损失\n",
    "    with torch.no_grad():\n",
    "        D_epoch_loss /=count\n",
    "        G_epoch_loss /=count\n",
    "        S_epoch_loss /=(count * continue_loss_weight)\n",
    "        C_epoch_loss /=(count * class_loss_weight)\n",
    "        acc = acc_num / item_num\n",
    "        D_loss.append(D_epoch_loss)\n",
    "        G_loss.append(G_epoch_loss)\n",
    "        S_loss.append(S_epoch_loss)\n",
    "        C_loss.append(C_epoch_loss)\n",
    "        accs.append(acc)\n",
    "        print(f\"Epoch [{epoch + 1}/{epoch_num}], \"\n",
    "              f\"Discriminator Loss: {D_epoch_loss:.4f}, \"\n",
    "              f\"Generator Loss: {G_epoch_loss:.4f}, \"\n",
    "              f\"Series Loss: {S_epoch_loss:.4f}, \"\n",
    "              f\"Class Loss: {C_epoch_loss:.4f}, \"\n",
    "              f\"Accuracy: {acc:.4f}\")\n",
    "        if acc > 0.8:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52ffa546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f03e42e0d00>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g_curve = [i.cpu() for i in G_loss]\n",
    "plt.plot(g_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38eb3bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f03e41faca0>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "d_curve = [i.cpu() for i in D_loss]\n",
    "plt.plot(d_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "463f9c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f03e4173a00>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "s_curve = [i.cpu() for i in S_loss]\n",
    "plt.plot(s_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9efa5b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f03e40b58b0>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "c_curve = [i.cpu() for i in C_loss]\n",
    "plt.plot(c_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cada92de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f03e0b13940>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a_curve = [i for i in accs]\n",
    "plt.plot(a_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dddb84a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = generated_img.cpu().detach()\n",
    "# output = torch.reshape(output, (output.size(1), output.size(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f3dac15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f03e0b4a2e0>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(output.numpy()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d22f52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose_list(my_list):\n",
    "    transposed_list = list(zip(*my_list))\n",
    "    for i in range(len(transposed_list)):\n",
    "        transposed_list[i] = list(transposed_list[i])\n",
    "    return transposed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d119ae78",
   "metadata": {},
   "outputs": [],
   "source": [
    "transposed_list = transpose_list(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53827e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f03e0a78f10>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(series[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee133abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = []\n",
    "for step,(img,label) in enumerate(dataloader):\n",
    "        img =img.to(device) #把数据放到设备上\n",
    "        label = label.to(device)\n",
    "        size = img.shape[0] #img的第一位是size,获取批次的大小\n",
    "        random_seed = torch.randn(size,100,device=device)\n",
    "        \n",
    "        #在生成器上去计算生成器的损失，优化目标是判别器上的参数\n",
    "        generated_img = gen(random_seed,label) #得到生成的图片\n",
    "        generated_img = torch.reshape(generated_img, (generated_img.size(0), generated_img.size(2)))\n",
    "        class_output = cls(torch.reshape(generated_img, (generated_img.size(0), 1, generated_img.size(1))))\n",
    "        auth.append(class_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "54b8f055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.4245, 0.4028, 0.4238, 0.4861, 0.3888, 0.3976, 0.3640, 0.4893, 0.3980,\n",
       "          0.4668, 0.4688, 0.5005, 0.4964, 0.4727, 0.4777, 0.4272, 0.3655, 0.5086,\n",
       "          0.2766, 0.4693, 0.4486, 0.5782, 0.5159, 0.3959, 0.3954, 0.4693, 0.4262,\n",
       "          0.3921, 0.4368, 0.4169, 0.5177, 0.3621, 0.4690, 0.4369, 0.4255, 0.4856,\n",
       "          0.3878, 0.4240, 0.4144, 0.4954, 0.4047, 0.4099, 0.4485, 0.4898, 0.4005,\n",
       "          0.4410, 0.4562, 0.4075, 0.4475, 0.4754, 0.5127, 0.4855, 0.4586, 0.3984],\n",
       "         [0.4201, 0.3827, 0.4091, 0.4876, 0.3928, 0.3769, 0.3680, 0.4878, 0.3885,\n",
       "          0.4550, 0.4701, 0.4924, 0.5003, 0.4453, 0.4892, 0.4492, 0.3651, 0.5232,\n",
       "          0.2464, 0.4674, 0.4706, 0.6004, 0.5116, 0.3958, 0.3759, 0.4926, 0.4368,\n",
       "          0.3664, 0.4481, 0.3968, 0.5129, 0.3475, 0.4648, 0.4403, 0.4254, 0.4782,\n",
       "          0.3607, 0.3985, 0.3964, 0.4898, 0.3838, 0.4268, 0.4796, 0.5092, 0.4002,\n",
       "          0.4393, 0.4626, 0.3876, 0.4345, 0.5042, 0.5274, 0.4910, 0.4585, 0.4152],\n",
       "         [0.4262, 0.4229, 0.4397, 0.4884, 0.4047, 0.4168, 0.3714, 0.4806, 0.4160,\n",
       "          0.4437, 0.4748, 0.4888, 0.4999, 0.4861, 0.4443, 0.4058, 0.3824, 0.4907,\n",
       "          0.2969, 0.4782, 0.4311, 0.5853, 0.5435, 0.3900, 0.4190, 0.4434, 0.4284,\n",
       "          0.3964, 0.4234, 0.4495, 0.5352, 0.3965, 0.4523, 0.4310, 0.4194, 0.4892,\n",
       "          0.3947, 0.4502, 0.4283, 0.5003, 0.4139, 0.4155, 0.4303, 0.4788, 0.3868,\n",
       "          0.4370, 0.4549, 0.4128, 0.4575, 0.4462, 0.5097, 0.4847, 0.4472, 0.3997],\n",
       "         [0.3898, 0.4511, 0.4589, 0.4919, 0.3554, 0.4424, 0.3715, 0.4406, 0.4318,\n",
       "          0.4068, 0.4996, 0.4858, 0.4527, 0.4650, 0.4294, 0.4261, 0.4001, 0.4641,\n",
       "          0.3039, 0.4891, 0.4279, 0.5988, 0.5654, 0.3473, 0.4775, 0.4432, 0.4653,\n",
       "          0.3554, 0.4281, 0.4603, 0.5176, 0.4171, 0.4335, 0.3911, 0.4436, 0.5041,\n",
       "          0.4132, 0.4741, 0.4636, 0.4778, 0.4232, 0.4479, 0.3984, 0.4952, 0.3348,\n",
       "          0.4431, 0.4311, 0.4173, 0.4860, 0.4251, 0.4680, 0.5052, 0.4798, 0.3980],\n",
       "         [0.4080, 0.4290, 0.4596, 0.4722, 0.3615, 0.4501, 0.3656, 0.4402, 0.4173,\n",
       "          0.4180, 0.4925, 0.4877, 0.4693, 0.4659, 0.4376, 0.4298, 0.3802, 0.4633,\n",
       "          0.3085, 0.4726, 0.4198, 0.6007, 0.5588, 0.3546, 0.4496, 0.4407, 0.4512,\n",
       "          0.3735, 0.4410, 0.4442, 0.5254, 0.4049, 0.4316, 0.3972, 0.4336, 0.4952,\n",
       "          0.4107, 0.4565, 0.4645, 0.4807, 0.4269, 0.4350, 0.4211, 0.4850, 0.3566,\n",
       "          0.4535, 0.4216, 0.4166, 0.4709, 0.4382, 0.4756, 0.5069, 0.4763, 0.4100],\n",
       "         [0.4027, 0.4241, 0.4432, 0.4823, 0.3544, 0.4465, 0.3647, 0.4644, 0.4138,\n",
       "          0.4365, 0.4926, 0.4934, 0.4661, 0.4590, 0.4556, 0.4228, 0.3511, 0.4751,\n",
       "          0.3020, 0.4766, 0.4428, 0.5909, 0.5419, 0.3539, 0.4275, 0.4600, 0.4429,\n",
       "          0.3712, 0.4504, 0.4252, 0.5415, 0.3869, 0.4487, 0.4076, 0.4179, 0.4886,\n",
       "          0.4077, 0.4453, 0.4641, 0.4966, 0.4042, 0.4295, 0.4207, 0.4823, 0.3647,\n",
       "          0.4472, 0.4157, 0.4032, 0.4832, 0.4538, 0.4722, 0.5136, 0.4823, 0.3933],\n",
       "         [0.3943, 0.4278, 0.4415, 0.4897, 0.4002, 0.4213, 0.3963, 0.4697, 0.4250,\n",
       "          0.4282, 0.4656, 0.4674, 0.4743, 0.4896, 0.4462, 0.3874, 0.4027, 0.4870,\n",
       "          0.2990, 0.4955, 0.4417, 0.5746, 0.5407, 0.3916, 0.4519, 0.4466, 0.4466,\n",
       "          0.3790, 0.4136, 0.4783, 0.5413, 0.4095, 0.4627, 0.4300, 0.4309, 0.4974,\n",
       "          0.3941, 0.4685, 0.4470, 0.4973, 0.4068, 0.4058, 0.4116, 0.4948, 0.3507,\n",
       "          0.4304, 0.4545, 0.4001, 0.4822, 0.4409, 0.4883, 0.4897, 0.4613, 0.3705],\n",
       "         [0.4165, 0.4272, 0.4269, 0.5135, 0.3882, 0.4094, 0.3742, 0.4872, 0.4154,\n",
       "          0.4495, 0.4726, 0.4927, 0.4815, 0.4751, 0.4524, 0.4054, 0.3708, 0.4976,\n",
       "          0.2917, 0.4883, 0.4489, 0.5695, 0.5319, 0.3919, 0.4212, 0.4559, 0.4284,\n",
       "          0.3937, 0.4241, 0.4515, 0.5431, 0.3797, 0.4707, 0.4294, 0.4074, 0.4875,\n",
       "          0.3949, 0.4485, 0.4281, 0.5074, 0.4006, 0.4187, 0.4242, 0.4890, 0.3766,\n",
       "          0.4231, 0.4580, 0.4022, 0.4691, 0.4550, 0.5009, 0.4759, 0.4535, 0.3863],\n",
       "         [0.3934, 0.4151, 0.4043, 0.5220, 0.3847, 0.3615, 0.3875, 0.5008, 0.4110,\n",
       "          0.4499, 0.4701, 0.4871, 0.4584, 0.4395, 0.4840, 0.4283, 0.3807, 0.5254,\n",
       "          0.2461, 0.4973, 0.4905, 0.5723, 0.5130, 0.3973, 0.4033, 0.4864, 0.4562,\n",
       "          0.3514, 0.4235, 0.4254, 0.5163, 0.3654, 0.4901, 0.4393, 0.4334, 0.4959,\n",
       "          0.3684, 0.4242, 0.4063, 0.4907, 0.3683, 0.4302, 0.4356, 0.5345, 0.3615,\n",
       "          0.4063, 0.4745, 0.3849, 0.4764, 0.4943, 0.5181, 0.4850, 0.4683, 0.3849],\n",
       "         [0.4089, 0.4475, 0.4205, 0.5352, 0.4339, 0.3710, 0.3789, 0.5201, 0.4386,\n",
       "          0.4606, 0.4600, 0.4820, 0.4887, 0.4854, 0.4508, 0.3758, 0.3960, 0.5208,\n",
       "          0.2835, 0.5109, 0.4544, 0.5469, 0.5342, 0.4170, 0.4249, 0.4329, 0.4332,\n",
       "          0.3995, 0.3805, 0.4830, 0.5474, 0.4030, 0.4915, 0.4459, 0.4273, 0.4898,\n",
       "          0.3812, 0.4671, 0.3948, 0.5155, 0.3868, 0.4017, 0.4053, 0.5079, 0.3784,\n",
       "          0.3946, 0.4951, 0.4036, 0.4811, 0.4507, 0.5183, 0.4565, 0.4272, 0.3706],\n",
       "         [0.4212, 0.4494, 0.4571, 0.4930, 0.3957, 0.4308, 0.3658, 0.4735, 0.4303,\n",
       "          0.4511, 0.4860, 0.4928, 0.4919, 0.4907, 0.4336, 0.3911, 0.3887, 0.4781,\n",
       "          0.3192, 0.4844, 0.4161, 0.5716, 0.5561, 0.3791, 0.4547, 0.4106, 0.4273,\n",
       "          0.4042, 0.4074, 0.4677, 0.5371, 0.4152, 0.4602, 0.4132, 0.4301, 0.4954,\n",
       "          0.4087, 0.4774, 0.4349, 0.4957, 0.4268, 0.4160, 0.3944, 0.4750, 0.3727,\n",
       "          0.4381, 0.4485, 0.4305, 0.4726, 0.4210, 0.4847, 0.4820, 0.4535, 0.3921],\n",
       "         [0.4342, 0.4102, 0.4420, 0.4811, 0.3546, 0.4256, 0.3527, 0.4726, 0.3930,\n",
       "          0.4726, 0.4852, 0.5168, 0.4929, 0.4621, 0.4662, 0.4294, 0.3425, 0.4775,\n",
       "          0.3068, 0.4539, 0.4277, 0.5849, 0.5350, 0.3689, 0.4024, 0.4425, 0.4045,\n",
       "          0.4057, 0.4493, 0.4139, 0.5240, 0.3590, 0.4599, 0.4081, 0.4049, 0.4785,\n",
       "          0.4214, 0.4359, 0.4363, 0.4847, 0.4239, 0.4270, 0.4327, 0.4614, 0.4037,\n",
       "          0.4593, 0.4331, 0.4257, 0.4476, 0.4503, 0.4803, 0.4880, 0.4789, 0.4060],\n",
       "         [0.4385, 0.4352, 0.4869, 0.4624, 0.3297, 0.5002, 0.3323, 0.4320, 0.4091,\n",
       "          0.4438, 0.5178, 0.5281, 0.4892, 0.4856, 0.4230, 0.4229, 0.3463, 0.4332,\n",
       "          0.3602, 0.4488, 0.3812, 0.5991, 0.5711, 0.3260, 0.4546, 0.4037, 0.4066,\n",
       "          0.4170, 0.4541, 0.4318, 0.5336, 0.3990, 0.4247, 0.3750, 0.4092, 0.4895,\n",
       "          0.4571, 0.4680, 0.4854, 0.4768, 0.4607, 0.4387, 0.4003, 0.4272, 0.3862,\n",
       "          0.4778, 0.3889, 0.4590, 0.4652, 0.3990, 0.4435, 0.5084, 0.4922, 0.4164],\n",
       "         [0.4569, 0.3942, 0.4602, 0.4594, 0.3452, 0.4554, 0.3413, 0.4612, 0.3816,\n",
       "          0.4847, 0.4933, 0.5252, 0.5118, 0.4818, 0.4629, 0.4315, 0.3332, 0.4641,\n",
       "          0.3302, 0.4317, 0.4048, 0.5874, 0.5278, 0.3607, 0.3955, 0.4354, 0.3946,\n",
       "          0.4236, 0.4612, 0.3964, 0.5175, 0.3592, 0.4517, 0.3995, 0.4004, 0.4741,\n",
       "          0.4442, 0.4268, 0.4607, 0.4783, 0.4487, 0.4143, 0.4404, 0.4334, 0.4138,\n",
       "          0.4855, 0.4105, 0.4418, 0.4346, 0.4378, 0.4765, 0.4943, 0.4864, 0.4194],\n",
       "         [0.4594, 0.3873, 0.4554, 0.4588, 0.3134, 0.4622, 0.3349, 0.4424, 0.3683,\n",
       "          0.4754, 0.5109, 0.5335, 0.5033, 0.4588, 0.4626, 0.4611, 0.3188, 0.4531,\n",
       "          0.3291, 0.4217, 0.4077, 0.6087, 0.5359, 0.3431, 0.3942, 0.4444, 0.3987,\n",
       "          0.4141, 0.4905, 0.3754, 0.5082, 0.3446, 0.4365, 0.3831, 0.3870, 0.4682,\n",
       "          0.4534, 0.4122, 0.4699, 0.4676, 0.4522, 0.4366, 0.4437, 0.4351, 0.4111,\n",
       "          0.4869, 0.3966, 0.4355, 0.4309, 0.4502, 0.4638, 0.4966, 0.5017, 0.4322],\n",
       "         [0.4215, 0.4237, 0.4558, 0.4715, 0.3310, 0.4664, 0.3522, 0.4352, 0.4019,\n",
       "          0.4375, 0.5068, 0.5079, 0.4678, 0.4623, 0.4435, 0.4454, 0.3515, 0.4483,\n",
       "          0.3251, 0.4511, 0.4200, 0.6066, 0.5523, 0.3432, 0.4426, 0.4401, 0.4291,\n",
       "          0.3870, 0.4648, 0.4219, 0.5199, 0.3799, 0.4310, 0.3847, 0.4077, 0.4791,\n",
       "          0.4461, 0.4526, 0.4823, 0.4735, 0.4429, 0.4522, 0.4208, 0.4585, 0.3733,\n",
       "          0.4623, 0.4100, 0.4312, 0.4593, 0.4367, 0.4588, 0.5007, 0.4935, 0.4133]],\n",
       "        device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>),\n",
       " tensor([[0.4316, 0.3942, 0.4255, 0.4917, 0.3865, 0.4005, 0.3718, 0.4791, 0.3916,\n",
       "          0.4569, 0.4776, 0.4960, 0.4967, 0.4712, 0.4698, 0.4343, 0.3669, 0.5019,\n",
       "          0.2746, 0.4646, 0.4539, 0.5786, 0.5185, 0.3903, 0.3959, 0.4735, 0.4252,\n",
       "          0.3935, 0.4448, 0.4101, 0.5177, 0.3645, 0.4584, 0.4268, 0.4129, 0.4838,\n",
       "          0.3877, 0.4158, 0.4221, 0.4896, 0.4082, 0.4191, 0.4626, 0.4910, 0.3951,\n",
       "          0.4461, 0.4493, 0.4023, 0.4421, 0.4716, 0.5105, 0.4814, 0.4553, 0.4071],\n",
       "         [0.4360, 0.3890, 0.4719, 0.4474, 0.3480, 0.4803, 0.3674, 0.4260, 0.3861,\n",
       "          0.4303, 0.5022, 0.4938, 0.4901, 0.4784, 0.4410, 0.4436, 0.3658, 0.4490,\n",
       "          0.3216, 0.4419, 0.4125, 0.6023, 0.5503, 0.3429, 0.4414, 0.4534, 0.4210,\n",
       "          0.3967, 0.4727, 0.4058, 0.5101, 0.3778, 0.4249, 0.3912, 0.4140, 0.4960,\n",
       "          0.4264, 0.4356, 0.4864, 0.4680, 0.4508, 0.4251, 0.4558, 0.4471, 0.3738,\n",
       "          0.4969, 0.4046, 0.4324, 0.4398, 0.4309, 0.4667, 0.5102, 0.4865, 0.4213],\n",
       "         [0.4158, 0.4117, 0.4419, 0.4939, 0.3543, 0.4240, 0.3633, 0.4679, 0.3959,\n",
       "          0.4577, 0.4922, 0.5085, 0.4726, 0.4628, 0.4705, 0.4292, 0.3638, 0.4827,\n",
       "          0.2909, 0.4710, 0.4482, 0.5815, 0.5281, 0.3683, 0.4192, 0.4573, 0.4266,\n",
       "          0.3864, 0.4460, 0.4139, 0.5212, 0.3697, 0.4596, 0.4144, 0.4125, 0.4904,\n",
       "          0.4065, 0.4397, 0.4472, 0.4797, 0.4116, 0.4275, 0.4262, 0.4828, 0.3786,\n",
       "          0.4457, 0.4377, 0.4126, 0.4628, 0.4563, 0.4824, 0.4890, 0.4773, 0.3940],\n",
       "         [0.4332, 0.3867, 0.4116, 0.5014, 0.4266, 0.3859, 0.3867, 0.5134, 0.3939,\n",
       "          0.4741, 0.4581, 0.4840, 0.5116, 0.4885, 0.4856, 0.3957, 0.3683, 0.5210,\n",
       "          0.2783, 0.4770, 0.4681, 0.5555, 0.4964, 0.4213, 0.3820, 0.4766, 0.4135,\n",
       "          0.4096, 0.4289, 0.4242, 0.5314, 0.3615, 0.4934, 0.4615, 0.4066, 0.4788,\n",
       "          0.3758, 0.4212, 0.4063, 0.5102, 0.3913, 0.3810, 0.4578, 0.4840, 0.4085,\n",
       "          0.4314, 0.4701, 0.3881, 0.4526, 0.4790, 0.5282, 0.4696, 0.4350, 0.3822],\n",
       "         [0.4141, 0.4082, 0.4241, 0.4980, 0.3785, 0.4228, 0.3773, 0.4865, 0.4079,\n",
       "          0.4580, 0.4740, 0.4924, 0.4772, 0.4609, 0.4721, 0.4076, 0.3478, 0.4931,\n",
       "          0.2950, 0.4765, 0.4635, 0.5699, 0.5189, 0.3820, 0.4000, 0.4750, 0.4279,\n",
       "          0.3819, 0.4462, 0.4224, 0.5382, 0.3707, 0.4713, 0.4326, 0.4073, 0.4797,\n",
       "          0.3954, 0.4373, 0.4420, 0.5037, 0.3947, 0.4110, 0.4345, 0.4810, 0.3853,\n",
       "          0.4325, 0.4383, 0.3952, 0.4824, 0.4632, 0.4923, 0.4971, 0.4664, 0.3835],\n",
       "         [0.4038, 0.4391, 0.4359, 0.5101, 0.3750, 0.4231, 0.3701, 0.4695, 0.4289,\n",
       "          0.4341, 0.4859, 0.4938, 0.4692, 0.4672, 0.4522, 0.4041, 0.3752, 0.4867,\n",
       "          0.2929, 0.4939, 0.4528, 0.5759, 0.5423, 0.3726, 0.4463, 0.4507, 0.4441,\n",
       "          0.3793, 0.4298, 0.4515, 0.5309, 0.3973, 0.4546, 0.4161, 0.4260, 0.4936,\n",
       "          0.3989, 0.4677, 0.4371, 0.4872, 0.4028, 0.4301, 0.4042, 0.4922, 0.3615,\n",
       "          0.4208, 0.4431, 0.4104, 0.4890, 0.4431, 0.4872, 0.4927, 0.4635, 0.3822],\n",
       "         [0.4225, 0.3929, 0.4311, 0.4737, 0.3477, 0.4269, 0.3602, 0.4633, 0.3945,\n",
       "          0.4534, 0.4829, 0.5079, 0.4799, 0.4473, 0.4800, 0.4507, 0.3383, 0.4820,\n",
       "          0.2911, 0.4545, 0.4517, 0.5927, 0.5278, 0.3650, 0.4011, 0.4810, 0.4204,\n",
       "          0.3772, 0.4683, 0.3960, 0.5149, 0.3578, 0.4520, 0.4014, 0.4121, 0.4711,\n",
       "          0.4075, 0.4197, 0.4457, 0.4759, 0.4148, 0.4335, 0.4500, 0.4820, 0.3927,\n",
       "          0.4592, 0.4268, 0.4114, 0.4565, 0.4738, 0.4775, 0.4993, 0.4864, 0.4098],\n",
       "         [0.3890, 0.4345, 0.4648, 0.4679, 0.3180, 0.4790, 0.3564, 0.4209, 0.4226,\n",
       "          0.4141, 0.5055, 0.5000, 0.4482, 0.4318, 0.4452, 0.4471, 0.3546, 0.4542,\n",
       "          0.3215, 0.4630, 0.4354, 0.6227, 0.5558, 0.3287, 0.4566, 0.4556, 0.4592,\n",
       "          0.3485, 0.4749, 0.4253, 0.5055, 0.3945, 0.4252, 0.3789, 0.4311, 0.4815,\n",
       "          0.4365, 0.4658, 0.4897, 0.4629, 0.4285, 0.4619, 0.4095, 0.4783, 0.3454,\n",
       "          0.4525, 0.4009, 0.4168, 0.4995, 0.4353, 0.4463, 0.5250, 0.4991, 0.4041],\n",
       "         [0.3960, 0.4419, 0.4488, 0.4888, 0.3710, 0.4304, 0.3689, 0.4501, 0.4318,\n",
       "          0.4201, 0.4875, 0.4915, 0.4672, 0.4548, 0.4484, 0.4312, 0.3835, 0.4797,\n",
       "          0.2974, 0.4840, 0.4341, 0.5907, 0.5586, 0.3638, 0.4528, 0.4442, 0.4532,\n",
       "          0.3657, 0.4341, 0.4469, 0.5154, 0.4106, 0.4432, 0.3974, 0.4477, 0.4937,\n",
       "          0.3963, 0.4632, 0.4433, 0.4768, 0.4134, 0.4348, 0.4148, 0.5051, 0.3587,\n",
       "          0.4337, 0.4369, 0.4174, 0.4847, 0.4422, 0.4819, 0.5001, 0.4688, 0.4026],\n",
       "         [0.3969, 0.4370, 0.4679, 0.4698, 0.3455, 0.4566, 0.3670, 0.4363, 0.4210,\n",
       "          0.4245, 0.5030, 0.4971, 0.4600, 0.4476, 0.4507, 0.4417, 0.3847, 0.4576,\n",
       "          0.3113, 0.4659, 0.4294, 0.6043, 0.5553, 0.3431, 0.4564, 0.4433, 0.4514,\n",
       "          0.3608, 0.4507, 0.4313, 0.5078, 0.4063, 0.4344, 0.3842, 0.4402, 0.4998,\n",
       "          0.4213, 0.4602, 0.4745, 0.4580, 0.4277, 0.4515, 0.4092, 0.4845, 0.3544,\n",
       "          0.4561, 0.4189, 0.4283, 0.4849, 0.4289, 0.4603, 0.5163, 0.4960, 0.4082],\n",
       "         [0.3937, 0.4225, 0.4299, 0.4984, 0.3796, 0.4019, 0.3838, 0.4654, 0.4246,\n",
       "          0.4246, 0.4761, 0.4838, 0.4649, 0.4473, 0.4642, 0.4337, 0.3926, 0.5085,\n",
       "          0.2658, 0.4872, 0.4698, 0.5876, 0.5371, 0.3785, 0.4320, 0.4820, 0.4642,\n",
       "          0.3503, 0.4309, 0.4317, 0.5103, 0.3888, 0.4522, 0.4169, 0.4464, 0.4973,\n",
       "          0.3728, 0.4402, 0.4286, 0.4842, 0.3921, 0.4413, 0.4357, 0.5182, 0.3558,\n",
       "          0.4278, 0.4557, 0.3931, 0.4793, 0.4667, 0.4972, 0.4980, 0.4620, 0.3917],\n",
       "         [0.3931, 0.4583, 0.4327, 0.5308, 0.4402, 0.3926, 0.3938, 0.4967, 0.4557,\n",
       "          0.4241, 0.4679, 0.4678, 0.4772, 0.4917, 0.4335, 0.3728, 0.4202, 0.5107,\n",
       "          0.2819, 0.5214, 0.4524, 0.5497, 0.5472, 0.4053, 0.4621, 0.4386, 0.4556,\n",
       "          0.3826, 0.3755, 0.4994, 0.5404, 0.4286, 0.4700, 0.4371, 0.4445, 0.5078,\n",
       "          0.3680, 0.4835, 0.4079, 0.5109, 0.3962, 0.4082, 0.3988, 0.5126, 0.3534,\n",
       "          0.4001, 0.4850, 0.4010, 0.4941, 0.4283, 0.5189, 0.4656, 0.4202, 0.3685],\n",
       "         [0.3894, 0.4585, 0.4329, 0.5322, 0.3726, 0.4179, 0.3781, 0.4732, 0.4442,\n",
       "          0.4222, 0.4936, 0.4961, 0.4473, 0.4625, 0.4399, 0.4026, 0.3848, 0.4845,\n",
       "          0.2899, 0.5048, 0.4571, 0.5707, 0.5541, 0.3653, 0.4600, 0.4475, 0.4533,\n",
       "          0.3743, 0.4139, 0.4689, 0.5428, 0.4032, 0.4520, 0.4092, 0.4211, 0.5000,\n",
       "          0.3937, 0.4719, 0.4405, 0.5026, 0.3961, 0.4429, 0.3883, 0.4992, 0.3440,\n",
       "          0.4048, 0.4503, 0.4035, 0.5051, 0.4371, 0.4841, 0.4811, 0.4573, 0.3714],\n",
       "         [0.4046, 0.4300, 0.4566, 0.4721, 0.3321, 0.4756, 0.3613, 0.4397, 0.4197,\n",
       "          0.4260, 0.4921, 0.4993, 0.4655, 0.4513, 0.4478, 0.4335, 0.3508, 0.4535,\n",
       "          0.3240, 0.4612, 0.4316, 0.5978, 0.5495, 0.3447, 0.4555, 0.4557, 0.4401,\n",
       "          0.3767, 0.4613, 0.4285, 0.5227, 0.3925, 0.4345, 0.3880, 0.4207, 0.4761,\n",
       "          0.4252, 0.4583, 0.4825, 0.4774, 0.4273, 0.4482, 0.4177, 0.4729, 0.3625,\n",
       "          0.4551, 0.4044, 0.4186, 0.4896, 0.4403, 0.4495, 0.5117, 0.4883, 0.3946],\n",
       "         [0.3912, 0.4641, 0.4563, 0.5028, 0.3991, 0.4530, 0.3785, 0.4557, 0.4602,\n",
       "          0.4012, 0.4810, 0.4734, 0.4698, 0.4898, 0.4125, 0.3803, 0.4021, 0.4699,\n",
       "          0.3259, 0.5050, 0.4265, 0.5746, 0.5716, 0.3696, 0.4889, 0.4267, 0.4537,\n",
       "          0.3826, 0.4068, 0.4973, 0.5484, 0.4430, 0.4361, 0.4062, 0.4415, 0.4977,\n",
       "          0.4061, 0.5025, 0.4602, 0.5020, 0.4219, 0.4295, 0.3899, 0.4840, 0.3425,\n",
       "          0.4184, 0.4431, 0.4155, 0.5104, 0.4050, 0.4790, 0.4873, 0.4419, 0.3756],\n",
       "         [0.4226, 0.4316, 0.4567, 0.4844, 0.3609, 0.4601, 0.3570, 0.4454, 0.4218,\n",
       "          0.4227, 0.4983, 0.5018, 0.4828, 0.4692, 0.4301, 0.4215, 0.3607, 0.4674,\n",
       "          0.3280, 0.4639, 0.4259, 0.5964, 0.5561, 0.3567, 0.4412, 0.4375, 0.4343,\n",
       "          0.3952, 0.4524, 0.4434, 0.5277, 0.3980, 0.4280, 0.4032, 0.4146, 0.4806,\n",
       "          0.4244, 0.4628, 0.4668, 0.4911, 0.4378, 0.4344, 0.4181, 0.4632, 0.3691,\n",
       "          0.4450, 0.4206, 0.4158, 0.4782, 0.4237, 0.4744, 0.4994, 0.4650, 0.4054]],\n",
       "        device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>),\n",
       " tensor([[0.4195, 0.4359, 0.4359, 0.5133, 0.3847, 0.3999, 0.3578, 0.4950, 0.4235,\n",
       "          0.4639, 0.4846, 0.5076, 0.4853, 0.4669, 0.4500, 0.4116, 0.3651, 0.5044,\n",
       "          0.2963, 0.4839, 0.4422, 0.5682, 0.5413, 0.3811, 0.4141, 0.4344, 0.4276,\n",
       "          0.4024, 0.4214, 0.4406, 0.5329, 0.3852, 0.4662, 0.4195, 0.4210, 0.4865,\n",
       "          0.4050, 0.4470, 0.4231, 0.5010, 0.4121, 0.4221, 0.4126, 0.4905, 0.3876,\n",
       "          0.4227, 0.4548, 0.4177, 0.4792, 0.4460, 0.4975, 0.4769, 0.4531, 0.3965],\n",
       "         [0.4125, 0.4081, 0.4279, 0.4946, 0.3767, 0.4074, 0.3848, 0.4920, 0.4027,\n",
       "          0.4596, 0.4701, 0.4908, 0.4840, 0.4767, 0.4684, 0.4015, 0.3704, 0.4990,\n",
       "          0.2893, 0.4774, 0.4524, 0.5709, 0.5152, 0.3881, 0.4089, 0.4657, 0.4240,\n",
       "          0.3947, 0.4347, 0.4289, 0.5326, 0.3662, 0.4734, 0.4299, 0.4115, 0.4904,\n",
       "          0.4044, 0.4392, 0.4421, 0.5001, 0.4067, 0.4015, 0.4289, 0.4847, 0.3753,\n",
       "          0.4421, 0.4481, 0.4032, 0.4710, 0.4571, 0.4960, 0.4832, 0.4665, 0.3807],\n",
       "         [0.4224, 0.4254, 0.4384, 0.5111, 0.4000, 0.3986, 0.3714, 0.4953, 0.4159,\n",
       "          0.4663, 0.4740, 0.5002, 0.4936, 0.4879, 0.4540, 0.3910, 0.3751, 0.5037,\n",
       "          0.2991, 0.4838, 0.4431, 0.5625, 0.5301, 0.3987, 0.4105, 0.4421, 0.4177,\n",
       "          0.4095, 0.4159, 0.4506, 0.5405, 0.3789, 0.4700, 0.4337, 0.4106, 0.4906,\n",
       "          0.4023, 0.4489, 0.4229, 0.5121, 0.4108, 0.4048, 0.4198, 0.4800, 0.3863,\n",
       "          0.4241, 0.4662, 0.4075, 0.4651, 0.4423, 0.5076, 0.4686, 0.4431, 0.3833],\n",
       "         [0.4266, 0.4075, 0.4576, 0.4776, 0.3744, 0.4266, 0.3707, 0.4514, 0.3972,\n",
       "          0.4391, 0.4882, 0.4954, 0.4925, 0.4806, 0.4462, 0.4257, 0.3835, 0.4820,\n",
       "          0.2988, 0.4651, 0.4199, 0.5941, 0.5448, 0.3704, 0.4276, 0.4409, 0.4286,\n",
       "          0.3907, 0.4447, 0.4291, 0.5152, 0.3857, 0.4411, 0.4094, 0.4242, 0.4946,\n",
       "          0.4003, 0.4386, 0.4479, 0.4775, 0.4289, 0.4275, 0.4423, 0.4787, 0.3717,\n",
       "          0.4590, 0.4366, 0.4161, 0.4481, 0.4416, 0.4946, 0.4959, 0.4659, 0.4168],\n",
       "         [0.3988, 0.4252, 0.4447, 0.5010, 0.3808, 0.4152, 0.3796, 0.4629, 0.4189,\n",
       "          0.4223, 0.4855, 0.4873, 0.4633, 0.4688, 0.4361, 0.4124, 0.3942, 0.4921,\n",
       "          0.2842, 0.4992, 0.4508, 0.5902, 0.5464, 0.3724, 0.4403, 0.4513, 0.4542,\n",
       "          0.3705, 0.4294, 0.4468, 0.5285, 0.3902, 0.4478, 0.4166, 0.4298, 0.4991,\n",
       "          0.3903, 0.4531, 0.4466, 0.4920, 0.4077, 0.4372, 0.4236, 0.4990, 0.3421,\n",
       "          0.4338, 0.4537, 0.3991, 0.4781, 0.4459, 0.4960, 0.4901, 0.4558, 0.3952],\n",
       "         [0.3997, 0.4534, 0.4751, 0.4799, 0.3833, 0.4610, 0.3777, 0.4409, 0.4372,\n",
       "          0.4027, 0.5015, 0.4792, 0.4733, 0.4911, 0.4096, 0.4097, 0.4122, 0.4496,\n",
       "          0.3230, 0.4862, 0.4006, 0.5927, 0.5787, 0.3501, 0.4883, 0.4113, 0.4530,\n",
       "          0.3859, 0.4121, 0.4723, 0.5292, 0.4406, 0.4263, 0.3906, 0.4484, 0.5073,\n",
       "          0.4088, 0.4838, 0.4703, 0.4822, 0.4434, 0.4363, 0.4029, 0.4769, 0.3432,\n",
       "          0.4546, 0.4289, 0.4349, 0.4754, 0.4019, 0.4707, 0.4933, 0.4599, 0.4067],\n",
       "         [0.4145, 0.4285, 0.4879, 0.4518, 0.3633, 0.4859, 0.3810, 0.4298, 0.4169,\n",
       "          0.4164, 0.4996, 0.4828, 0.4838, 0.5030, 0.4137, 0.4128, 0.3985, 0.4397,\n",
       "          0.3425, 0.4635, 0.3907, 0.5948, 0.5660, 0.3469, 0.4792, 0.4224, 0.4335,\n",
       "          0.3978, 0.4322, 0.4526, 0.5271, 0.4168, 0.4250, 0.3845, 0.4333, 0.5031,\n",
       "          0.4329, 0.4707, 0.5008, 0.4764, 0.4631, 0.4215, 0.4167, 0.4514, 0.3476,\n",
       "          0.4863, 0.4109, 0.4418, 0.4609, 0.3977, 0.4604, 0.4962, 0.4790, 0.4063],\n",
       "         [0.4165, 0.4185, 0.4585, 0.4721, 0.3280, 0.4665, 0.3539, 0.4388, 0.4037,\n",
       "          0.4370, 0.5036, 0.5049, 0.4673, 0.4591, 0.4471, 0.4362, 0.3438, 0.4529,\n",
       "          0.3264, 0.4540, 0.4201, 0.6052, 0.5530, 0.3381, 0.4338, 0.4454, 0.4253,\n",
       "          0.3843, 0.4724, 0.4170, 0.5304, 0.3787, 0.4308, 0.3839, 0.4070, 0.4791,\n",
       "          0.4326, 0.4456, 0.4864, 0.4827, 0.4364, 0.4430, 0.4236, 0.4590, 0.3750,\n",
       "          0.4652, 0.3981, 0.4199, 0.4750, 0.4350, 0.4490, 0.5125, 0.4944, 0.4147],\n",
       "         [0.4210, 0.4007, 0.4437, 0.4723, 0.3357, 0.4473, 0.3574, 0.4520, 0.3847,\n",
       "          0.4560, 0.5020, 0.5109, 0.4747, 0.4570, 0.4656, 0.4445, 0.3494, 0.4646,\n",
       "          0.3032, 0.4542, 0.4346, 0.5990, 0.5309, 0.3531, 0.4146, 0.4526, 0.4198,\n",
       "          0.3848, 0.4720, 0.3960, 0.5185, 0.3602, 0.4510, 0.3994, 0.4047, 0.4773,\n",
       "          0.4219, 0.4236, 0.4735, 0.4764, 0.4240, 0.4406, 0.4335, 0.4652, 0.3784,\n",
       "          0.4648, 0.4165, 0.4156, 0.4582, 0.4525, 0.4685, 0.4981, 0.4958, 0.4127],\n",
       "         [0.3946, 0.4424, 0.4472, 0.4921, 0.3405, 0.4397, 0.3554, 0.4497, 0.4194,\n",
       "          0.4248, 0.5065, 0.5093, 0.4510, 0.4440, 0.4501, 0.4408, 0.3627, 0.4733,\n",
       "          0.2917, 0.4807, 0.4439, 0.6091, 0.5523, 0.3435, 0.4414, 0.4534, 0.4525,\n",
       "          0.3604, 0.4506, 0.4203, 0.5269, 0.3861, 0.4403, 0.3915, 0.4307, 0.4871,\n",
       "          0.4028, 0.4477, 0.4619, 0.4811, 0.4045, 0.4660, 0.4108, 0.4906, 0.3532,\n",
       "          0.4368, 0.4226, 0.4144, 0.4898, 0.4501, 0.4688, 0.5093, 0.4870, 0.3993],\n",
       "         [0.4026, 0.4143, 0.4248, 0.4945, 0.3799, 0.4070, 0.3759, 0.4728, 0.4134,\n",
       "          0.4316, 0.4835, 0.4875, 0.4713, 0.4540, 0.4545, 0.4287, 0.3760, 0.4998,\n",
       "          0.2719, 0.4859, 0.4597, 0.5917, 0.5298, 0.3716, 0.4182, 0.4731, 0.4528,\n",
       "          0.3676, 0.4393, 0.4271, 0.5224, 0.3759, 0.4547, 0.4264, 0.4264, 0.4930,\n",
       "          0.3790, 0.4303, 0.4316, 0.4951, 0.3958, 0.4374, 0.4431, 0.5017, 0.3633,\n",
       "          0.4309, 0.4484, 0.3971, 0.4723, 0.4686, 0.5029, 0.4947, 0.4628, 0.3977],\n",
       "         [0.4180, 0.3895, 0.4156, 0.4854, 0.3719, 0.3974, 0.3636, 0.4849, 0.3890,\n",
       "          0.4631, 0.4702, 0.5021, 0.4907, 0.4441, 0.4880, 0.4384, 0.3509, 0.5095,\n",
       "          0.2678, 0.4645, 0.4597, 0.5915, 0.5093, 0.3872, 0.3746, 0.4848, 0.4296,\n",
       "          0.3806, 0.4658, 0.3949, 0.5208, 0.3506, 0.4717, 0.4401, 0.4085, 0.4730,\n",
       "          0.3837, 0.4008, 0.4260, 0.4959, 0.3875, 0.4198, 0.4609, 0.4931, 0.3997,\n",
       "          0.4335, 0.4514, 0.3934, 0.4578, 0.4943, 0.5087, 0.4967, 0.4675, 0.4022],\n",
       "         [0.4389, 0.3826, 0.4285, 0.4849, 0.3761, 0.3890, 0.3673, 0.4825, 0.3786,\n",
       "          0.4673, 0.4789, 0.5101, 0.5060, 0.4648, 0.4813, 0.4403, 0.3553, 0.5125,\n",
       "          0.2619, 0.4582, 0.4541, 0.5889, 0.5166, 0.3858, 0.3727, 0.4786, 0.4118,\n",
       "          0.3925, 0.4509, 0.3861, 0.5151, 0.3397, 0.4621, 0.4277, 0.4081, 0.4854,\n",
       "          0.3783, 0.3998, 0.4162, 0.4884, 0.4035, 0.4229, 0.4722, 0.4838, 0.4033,\n",
       "          0.4515, 0.4533, 0.4038, 0.4294, 0.4818, 0.5191, 0.4887, 0.4657, 0.4106],\n",
       "         [0.4183, 0.4021, 0.4160, 0.5037, 0.3812, 0.3673, 0.3672, 0.4874, 0.3972,\n",
       "          0.4563, 0.4783, 0.5068, 0.4886, 0.4511, 0.4820, 0.4425, 0.3653, 0.5257,\n",
       "          0.2496, 0.4779, 0.4699, 0.5870, 0.5213, 0.3872, 0.3859, 0.4800, 0.4349,\n",
       "          0.3679, 0.4434, 0.4053, 0.5143, 0.3525, 0.4652, 0.4271, 0.4236, 0.4845,\n",
       "          0.3667, 0.4125, 0.4012, 0.4915, 0.3802, 0.4409, 0.4576, 0.5132, 0.3879,\n",
       "          0.4234, 0.4655, 0.3924, 0.4536, 0.4895, 0.5217, 0.4914, 0.4596, 0.4032],\n",
       "         [0.4268, 0.4040, 0.4763, 0.4399, 0.3165, 0.4775, 0.3502, 0.4071, 0.3886,\n",
       "          0.4259, 0.5085, 0.5097, 0.4816, 0.4538, 0.4384, 0.4711, 0.3583, 0.4486,\n",
       "          0.3202, 0.4344, 0.3996, 0.6325, 0.5574, 0.3278, 0.4352, 0.4504, 0.4387,\n",
       "          0.3715, 0.4858, 0.3951, 0.4908, 0.3772, 0.4137, 0.3726, 0.4238, 0.4849,\n",
       "          0.4384, 0.4316, 0.4925, 0.4544, 0.4578, 0.4566, 0.4460, 0.4579, 0.3660,\n",
       "          0.4919, 0.3978, 0.4400, 0.4443, 0.4362, 0.4642, 0.5186, 0.5046, 0.4393],\n",
       "         [0.4308, 0.4219, 0.4360, 0.4949, 0.3768, 0.4239, 0.3641, 0.4833, 0.4060,\n",
       "          0.4698, 0.4785, 0.5067, 0.4949, 0.4703, 0.4568, 0.4156, 0.3599, 0.4874,\n",
       "          0.3094, 0.4683, 0.4338, 0.5761, 0.5291, 0.3854, 0.4113, 0.4469, 0.4203,\n",
       "          0.4089, 0.4356, 0.4226, 0.5221, 0.3770, 0.4665, 0.4245, 0.4128, 0.4743,\n",
       "          0.4138, 0.4447, 0.4363, 0.5000, 0.4230, 0.4173, 0.4252, 0.4723, 0.3952,\n",
       "          0.4448, 0.4562, 0.4259, 0.4593, 0.4491, 0.4974, 0.4739, 0.4618, 0.4019]],\n",
       "        device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>),\n",
       " tensor([[0.4284, 0.4267, 0.4482, 0.4695, 0.3400, 0.4613, 0.3262, 0.4521, 0.4063,\n",
       "          0.4562, 0.4960, 0.5270, 0.4860, 0.4404, 0.4600, 0.4448, 0.3309, 0.4558,\n",
       "          0.3363, 0.4501, 0.4150, 0.6013, 0.5548, 0.3508, 0.4179, 0.4288, 0.4240,\n",
       "          0.3989, 0.4659, 0.4117, 0.5175, 0.3800, 0.4429, 0.3833, 0.4172, 0.4564,\n",
       "          0.4448, 0.4417, 0.4608, 0.4734, 0.4398, 0.4471, 0.4170, 0.4576, 0.4013,\n",
       "          0.4571, 0.4138, 0.4428, 0.4708, 0.4473, 0.4633, 0.4986, 0.4861, 0.4222],\n",
       "         [0.3945, 0.4442, 0.4194, 0.5123, 0.3558, 0.4078, 0.3566, 0.4719, 0.4258,\n",
       "          0.4425, 0.4812, 0.5092, 0.4568, 0.4331, 0.4685, 0.4254, 0.3589, 0.4860,\n",
       "          0.2900, 0.4943, 0.4612, 0.5871, 0.5395, 0.3709, 0.4299, 0.4543, 0.4507,\n",
       "          0.3676, 0.4393, 0.4360, 0.5212, 0.3827, 0.4666, 0.4055, 0.4302, 0.4722,\n",
       "          0.4079, 0.4565, 0.4374, 0.4787, 0.3924, 0.4567, 0.4007, 0.5034, 0.3643,\n",
       "          0.4074, 0.4561, 0.4099, 0.5012, 0.4681, 0.4857, 0.4844, 0.4760, 0.3844],\n",
       "         [0.4185, 0.4122, 0.4071, 0.4928, 0.3856, 0.3917, 0.3599, 0.4882, 0.4095,\n",
       "          0.4552, 0.4668, 0.4954, 0.4903, 0.4426, 0.4799, 0.4324, 0.3558, 0.5048,\n",
       "          0.2875, 0.4691, 0.4601, 0.5825, 0.5240, 0.3959, 0.3963, 0.4678, 0.4373,\n",
       "          0.3800, 0.4434, 0.4257, 0.5165, 0.3718, 0.4711, 0.4243, 0.4249, 0.4611,\n",
       "          0.3939, 0.4317, 0.4187, 0.4919, 0.4034, 0.4252, 0.4391, 0.5014, 0.3965,\n",
       "          0.4244, 0.4605, 0.4017, 0.4691, 0.4844, 0.5069, 0.4823, 0.4602, 0.4036],\n",
       "         [0.4110, 0.4066, 0.4359, 0.4717, 0.3592, 0.4192, 0.3663, 0.4498, 0.3983,\n",
       "          0.4405, 0.4786, 0.5026, 0.4787, 0.4430, 0.4760, 0.4478, 0.3640, 0.4851,\n",
       "          0.2916, 0.4620, 0.4491, 0.6058, 0.5291, 0.3748, 0.4103, 0.4727, 0.4457,\n",
       "          0.3634, 0.4619, 0.4107, 0.5011, 0.3721, 0.4513, 0.4120, 0.4346, 0.4790,\n",
       "          0.4025, 0.4345, 0.4452, 0.4721, 0.4138, 0.4389, 0.4415, 0.4934, 0.3778,\n",
       "          0.4445, 0.4443, 0.4057, 0.4651, 0.4697, 0.4982, 0.4995, 0.4811, 0.4075],\n",
       "         [0.4384, 0.4032, 0.4454, 0.4679, 0.3143, 0.4392, 0.3315, 0.4508, 0.3736,\n",
       "          0.4748, 0.5038, 0.5444, 0.4904, 0.4303, 0.4848, 0.4722, 0.3236, 0.4684,\n",
       "          0.2990, 0.4317, 0.4314, 0.6116, 0.5385, 0.3468, 0.3897, 0.4553, 0.4092,\n",
       "          0.3872, 0.4878, 0.3637, 0.5033, 0.3438, 0.4460, 0.3786, 0.4072, 0.4648,\n",
       "          0.4292, 0.4060, 0.4513, 0.4552, 0.4286, 0.4598, 0.4376, 0.4668, 0.4084,\n",
       "          0.4686, 0.4079, 0.4375, 0.4492, 0.4718, 0.4740, 0.4983, 0.5063, 0.4301],\n",
       "         [0.4103, 0.4391, 0.4661, 0.4624, 0.3108, 0.4800, 0.3358, 0.4222, 0.4089,\n",
       "          0.4276, 0.5165, 0.5272, 0.4584, 0.4321, 0.4445, 0.4678, 0.3439, 0.4388,\n",
       "          0.3277, 0.4554, 0.4185, 0.6220, 0.5633, 0.3217, 0.4479, 0.4414, 0.4456,\n",
       "          0.3708, 0.4765, 0.4068, 0.5033, 0.3820, 0.4243, 0.3652, 0.4245, 0.4755,\n",
       "          0.4436, 0.4434, 0.4857, 0.4568, 0.4388, 0.4798, 0.4113, 0.4675, 0.3631,\n",
       "          0.4669, 0.3998, 0.4411, 0.4773, 0.4419, 0.4487, 0.5176, 0.5085, 0.4269],\n",
       "         [0.3986, 0.4371, 0.4156, 0.5154, 0.3637, 0.3986, 0.3585, 0.4812, 0.4216,\n",
       "          0.4494, 0.4864, 0.5133, 0.4595, 0.4233, 0.4695, 0.4351, 0.3613, 0.5010,\n",
       "          0.2719, 0.4903, 0.4718, 0.5847, 0.5304, 0.3735, 0.4128, 0.4683, 0.4516,\n",
       "          0.3647, 0.4426, 0.4213, 0.5201, 0.3715, 0.4664, 0.4170, 0.4253, 0.4777,\n",
       "          0.3919, 0.4330, 0.4229, 0.4898, 0.3853, 0.4539, 0.4197, 0.5093, 0.3704,\n",
       "          0.4102, 0.4554, 0.4015, 0.4943, 0.4796, 0.4962, 0.4874, 0.4695, 0.3915],\n",
       "         [0.4164, 0.4226, 0.4843, 0.4410, 0.3258, 0.5011, 0.3452, 0.4120, 0.4070,\n",
       "          0.4063, 0.5225, 0.5133, 0.4750, 0.4537, 0.4262, 0.4523, 0.3563, 0.4321,\n",
       "          0.3345, 0.4479, 0.3951, 0.6297, 0.5771, 0.3157, 0.4547, 0.4363, 0.4389,\n",
       "          0.3711, 0.4868, 0.4122, 0.5196, 0.3995, 0.3983, 0.3624, 0.4230, 0.4885,\n",
       "          0.4315, 0.4423, 0.5003, 0.4611, 0.4485, 0.4628, 0.4340, 0.4531, 0.3646,\n",
       "          0.4861, 0.3814, 0.4359, 0.4641, 0.4215, 0.4495, 0.5398, 0.4971, 0.4369],\n",
       "         [0.4110, 0.4179, 0.4395, 0.5031, 0.4129, 0.4074, 0.3809, 0.4834, 0.4149,\n",
       "          0.4328, 0.4810, 0.4857, 0.4885, 0.5012, 0.4502, 0.3863, 0.3920, 0.4880,\n",
       "          0.2878, 0.4949, 0.4413, 0.5694, 0.5356, 0.3894, 0.4248, 0.4449, 0.4274,\n",
       "          0.4015, 0.4228, 0.4535, 0.5520, 0.3975, 0.4566, 0.4335, 0.4180, 0.5043,\n",
       "          0.3790, 0.4451, 0.4350, 0.5059, 0.4058, 0.3999, 0.4395, 0.4805, 0.3735,\n",
       "          0.4354, 0.4485, 0.3979, 0.4649, 0.4420, 0.5073, 0.4846, 0.4410, 0.3877],\n",
       "         [0.4188, 0.4150, 0.4535, 0.4891, 0.3807, 0.4339, 0.3681, 0.4662, 0.4109,\n",
       "          0.4278, 0.4975, 0.4954, 0.4877, 0.4975, 0.4383, 0.4042, 0.3796, 0.4704,\n",
       "          0.2987, 0.4838, 0.4276, 0.5818, 0.5512, 0.3624, 0.4358, 0.4438, 0.4251,\n",
       "          0.4017, 0.4325, 0.4350, 0.5437, 0.3890, 0.4368, 0.4067, 0.4174, 0.5024,\n",
       "          0.3905, 0.4437, 0.4525, 0.4927, 0.4211, 0.4237, 0.4332, 0.4659, 0.3646,\n",
       "          0.4577, 0.4262, 0.4130, 0.4542, 0.4342, 0.4873, 0.4937, 0.4560, 0.3974],\n",
       "         [0.4000, 0.4215, 0.4356, 0.5077, 0.3972, 0.4082, 0.3928, 0.4802, 0.4203,\n",
       "          0.4305, 0.4802, 0.4768, 0.4710, 0.4925, 0.4469, 0.3906, 0.4036, 0.4891,\n",
       "          0.2814, 0.5015, 0.4534, 0.5674, 0.5362, 0.3810, 0.4397, 0.4585, 0.4440,\n",
       "          0.3814, 0.4187, 0.4515, 0.5442, 0.3971, 0.4589, 0.4235, 0.4287, 0.5118,\n",
       "          0.3801, 0.4504, 0.4418, 0.5021, 0.4018, 0.4136, 0.4249, 0.4914, 0.3495,\n",
       "          0.4362, 0.4518, 0.3977, 0.4766, 0.4407, 0.4993, 0.4864, 0.4508, 0.3765],\n",
       "         [0.4102, 0.4324, 0.4573, 0.5053, 0.4393, 0.4078, 0.3909, 0.4765, 0.4393,\n",
       "          0.4176, 0.4740, 0.4709, 0.4925, 0.5167, 0.4221, 0.3685, 0.4256, 0.4921,\n",
       "          0.2948, 0.5109, 0.4311, 0.5593, 0.5637, 0.3910, 0.4531, 0.4310, 0.4347,\n",
       "          0.4025, 0.3952, 0.4831, 0.5523, 0.4205, 0.4511, 0.4303, 0.4329, 0.5168,\n",
       "          0.3730, 0.4696, 0.4301, 0.5104, 0.4090, 0.4037, 0.4294, 0.4767, 0.3492,\n",
       "          0.4298, 0.4670, 0.4052, 0.4740, 0.4206, 0.5099, 0.4782, 0.4216, 0.3778],\n",
       "         [0.3883, 0.4383, 0.4559, 0.4917, 0.3634, 0.4343, 0.3719, 0.4480, 0.4235,\n",
       "          0.4114, 0.5001, 0.4872, 0.4607, 0.4640, 0.4395, 0.4142, 0.3968, 0.4674,\n",
       "          0.2949, 0.4945, 0.4305, 0.5914, 0.5589, 0.3530, 0.4605, 0.4368, 0.4548,\n",
       "          0.3709, 0.4308, 0.4504, 0.5292, 0.4096, 0.4411, 0.3973, 0.4380, 0.5061,\n",
       "          0.3949, 0.4567, 0.4633, 0.4719, 0.4137, 0.4422, 0.4096, 0.4943, 0.3381,\n",
       "          0.4423, 0.4325, 0.4155, 0.4836, 0.4334, 0.4768, 0.5040, 0.4724, 0.3934],\n",
       "         [0.4336, 0.4115, 0.4563, 0.4804, 0.3832, 0.4367, 0.3615, 0.4608, 0.4039,\n",
       "          0.4326, 0.4952, 0.4984, 0.4953, 0.5008, 0.4345, 0.4136, 0.3823, 0.4715,\n",
       "          0.3056, 0.4751, 0.4166, 0.5830, 0.5524, 0.3647, 0.4332, 0.4329, 0.4140,\n",
       "          0.4150, 0.4371, 0.4348, 0.5412, 0.3885, 0.4360, 0.4035, 0.4130, 0.5020,\n",
       "          0.4044, 0.4385, 0.4529, 0.4946, 0.4374, 0.4174, 0.4387, 0.4582, 0.3771,\n",
       "          0.4673, 0.4297, 0.4242, 0.4457, 0.4277, 0.4877, 0.4835, 0.4526, 0.4055],\n",
       "         [0.4087, 0.4252, 0.4661, 0.4799, 0.3980, 0.4523, 0.3813, 0.4604, 0.4215,\n",
       "          0.4204, 0.4854, 0.4746, 0.4858, 0.5103, 0.4277, 0.3847, 0.3961, 0.4635,\n",
       "          0.3208, 0.4863, 0.4157, 0.5786, 0.5561, 0.3701, 0.4528, 0.4346, 0.4361,\n",
       "          0.4008, 0.4285, 0.4584, 0.5491, 0.4194, 0.4420, 0.4136, 0.4270, 0.5056,\n",
       "          0.4006, 0.4655, 0.4695, 0.4989, 0.4298, 0.4006, 0.4261, 0.4634, 0.3592,\n",
       "          0.4567, 0.4250, 0.4147, 0.4728, 0.4165, 0.4838, 0.4952, 0.4506, 0.3924],\n",
       "         [0.4149, 0.4109, 0.4271, 0.5192, 0.4319, 0.3787, 0.3957, 0.5037, 0.4140,\n",
       "          0.4455, 0.4681, 0.4760, 0.4898, 0.5070, 0.4529, 0.3774, 0.4058, 0.5096,\n",
       "          0.2713, 0.5047, 0.4584, 0.5540, 0.5220, 0.4081, 0.4140, 0.4538, 0.4268,\n",
       "          0.4073, 0.4022, 0.4553, 0.5504, 0.3880, 0.4774, 0.4503, 0.4186, 0.5048,\n",
       "          0.3696, 0.4437, 0.4173, 0.5141, 0.4008, 0.3914, 0.4404, 0.4888, 0.3708,\n",
       "          0.4272, 0.4749, 0.3949, 0.4615, 0.4470, 0.5250, 0.4662, 0.4302, 0.3752]],\n",
       "        device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>),\n",
       " tensor([[0.3909, 0.4485, 0.4269, 0.5473, 0.3756, 0.3832, 0.3447, 0.5053, 0.4159,\n",
       "          0.4515, 0.5141, 0.5054, 0.4527, 0.4537, 0.4667, 0.4116, 0.3658, 0.4842,\n",
       "          0.2616, 0.5107, 0.4761, 0.5539, 0.5569, 0.3559, 0.4237, 0.4568, 0.4382,\n",
       "          0.3939, 0.4203, 0.4174, 0.5704, 0.3737, 0.4692, 0.4120, 0.4208, 0.5221,\n",
       "          0.3545, 0.4282, 0.4216, 0.5253, 0.3699, 0.4351, 0.3964, 0.4994, 0.3580,\n",
       "          0.4054, 0.4505, 0.3947, 0.4941, 0.4678, 0.4864, 0.4872, 0.4673, 0.3746],\n",
       "         [0.4054, 0.4302, 0.4240, 0.5383, 0.3889, 0.3701, 0.3499, 0.5145, 0.4019,\n",
       "          0.4684, 0.5024, 0.5050, 0.4741, 0.4663, 0.4748, 0.4102, 0.3646, 0.4922,\n",
       "          0.2567, 0.4983, 0.4757, 0.5443, 0.5416, 0.3726, 0.4009, 0.4610, 0.4226,\n",
       "          0.4086, 0.4226, 0.4110, 0.5664, 0.3611, 0.4790, 0.4189, 0.4171, 0.5178,\n",
       "          0.3522, 0.4140, 0.4170, 0.5190, 0.3735, 0.4207, 0.4194, 0.4954, 0.3726,\n",
       "          0.4173, 0.4572, 0.3955, 0.4750, 0.4759, 0.5022, 0.4817, 0.4606, 0.3792],\n",
       "         [0.4311, 0.4108, 0.4283, 0.5255, 0.3798, 0.3865, 0.3235, 0.5076, 0.3871,\n",
       "          0.4790, 0.5193, 0.5224, 0.4871, 0.4648, 0.4732, 0.4257, 0.3393, 0.4841,\n",
       "          0.2636, 0.4800, 0.4612, 0.5542, 0.5517, 0.3566, 0.3793, 0.4566, 0.4024,\n",
       "          0.4251, 0.4394, 0.3806, 0.5725, 0.3460, 0.4665, 0.4115, 0.4021, 0.5105,\n",
       "          0.3533, 0.3919, 0.4086, 0.5233, 0.3806, 0.4276, 0.4342, 0.4707, 0.3957,\n",
       "          0.4337, 0.4373, 0.4043, 0.4542, 0.4775, 0.4956, 0.4884, 0.4607, 0.3993],\n",
       "         [0.4448, 0.4079, 0.4484, 0.5121, 0.3915, 0.3930, 0.3285, 0.4996, 0.3795,\n",
       "          0.4761, 0.5106, 0.5194, 0.5122, 0.4909, 0.4642, 0.4214, 0.3549, 0.4753,\n",
       "          0.2796, 0.4717, 0.4338, 0.5525, 0.5562, 0.3651, 0.3864, 0.4370, 0.3938,\n",
       "          0.4415, 0.4316, 0.3921, 0.5595, 0.3567, 0.4575, 0.4085, 0.4084, 0.5177,\n",
       "          0.3629, 0.4050, 0.4186, 0.5130, 0.4064, 0.4158, 0.4418, 0.4567, 0.4055,\n",
       "          0.4527, 0.4383, 0.4182, 0.4368, 0.4570, 0.5053, 0.4804, 0.4545, 0.4082],\n",
       "         [0.4089, 0.4096, 0.4346, 0.5113, 0.3696, 0.3981, 0.3370, 0.4812, 0.3930,\n",
       "          0.4467, 0.5173, 0.5031, 0.4762, 0.4589, 0.4621, 0.4341, 0.3551, 0.4808,\n",
       "          0.2602, 0.4797, 0.4634, 0.5776, 0.5587, 0.3464, 0.4041, 0.4709, 0.4277,\n",
       "          0.3902, 0.4509, 0.3879, 0.5601, 0.3574, 0.4424, 0.4051, 0.4165, 0.5197,\n",
       "          0.3519, 0.3999, 0.4331, 0.5153, 0.3878, 0.4431, 0.4450, 0.4798, 0.3693,\n",
       "          0.4357, 0.4326, 0.3957, 0.4623, 0.4724, 0.4896, 0.5065, 0.4692, 0.3983],\n",
       "         [0.4063, 0.4350, 0.4367, 0.5267, 0.4010, 0.3938, 0.3444, 0.4915, 0.4145,\n",
       "          0.4372, 0.5078, 0.4972, 0.4756, 0.4733, 0.4445, 0.4097, 0.3726, 0.4824,\n",
       "          0.2744, 0.5020, 0.4565, 0.5590, 0.5635, 0.3622, 0.4215, 0.4472, 0.4311,\n",
       "          0.4046, 0.4162, 0.4309, 0.5662, 0.3796, 0.4516, 0.4152, 0.4238, 0.5236,\n",
       "          0.3523, 0.4316, 0.4220, 0.5256, 0.3933, 0.4263, 0.4248, 0.4839, 0.3602,\n",
       "          0.4219, 0.4518, 0.3988, 0.4693, 0.4561, 0.4998, 0.4829, 0.4478, 0.3897],\n",
       "         [0.4065, 0.4249, 0.4337, 0.5219, 0.4201, 0.3867, 0.3593, 0.5064, 0.4072,\n",
       "          0.4445, 0.4983, 0.4878, 0.4809, 0.4878, 0.4569, 0.3986, 0.3868, 0.4862,\n",
       "          0.2665, 0.5058, 0.4629, 0.5519, 0.5561, 0.3764, 0.4170, 0.4503, 0.4279,\n",
       "          0.4094, 0.4119, 0.4276, 0.5723, 0.3831, 0.4658, 0.4292, 0.4229, 0.5297,\n",
       "          0.3426, 0.4218, 0.4203, 0.5297, 0.3823, 0.4121, 0.4259, 0.4867, 0.3660,\n",
       "          0.4272, 0.4594, 0.3942, 0.4705, 0.4636, 0.5105, 0.4839, 0.4439, 0.3817],\n",
       "         [0.4170, 0.4196, 0.4257, 0.5335, 0.3829, 0.3895, 0.3260, 0.5123, 0.3980,\n",
       "          0.4744, 0.5142, 0.5207, 0.4790, 0.4565, 0.4681, 0.4183, 0.3393, 0.4885,\n",
       "          0.2727, 0.4852, 0.4702, 0.5576, 0.5446, 0.3611, 0.3856, 0.4561, 0.4106,\n",
       "          0.4222, 0.4373, 0.3969, 0.5719, 0.3464, 0.4735, 0.4241, 0.3956, 0.5032,\n",
       "          0.3650, 0.4002, 0.4156, 0.5338, 0.3801, 0.4264, 0.4236, 0.4750, 0.3903,\n",
       "          0.4195, 0.4433, 0.3967, 0.4721, 0.4768, 0.4926, 0.4861, 0.4591, 0.3887],\n",
       "         [0.4164, 0.4189, 0.4403, 0.5122, 0.3927, 0.4023, 0.3484, 0.4899, 0.3979,\n",
       "          0.4497, 0.5099, 0.4964, 0.4798, 0.4781, 0.4572, 0.4147, 0.3641, 0.4730,\n",
       "          0.2826, 0.4840, 0.4528, 0.5615, 0.5569, 0.3609, 0.4126, 0.4520, 0.4199,\n",
       "          0.4213, 0.4311, 0.4125, 0.5608, 0.3674, 0.4588, 0.4187, 0.4105, 0.5198,\n",
       "          0.3668, 0.4228, 0.4369, 0.5248, 0.4050, 0.4180, 0.4250, 0.4656, 0.3702,\n",
       "          0.4369, 0.4472, 0.4033, 0.4613, 0.4567, 0.4944, 0.4826, 0.4608, 0.3885],\n",
       "         [0.4278, 0.3893, 0.4340, 0.5009, 0.4104, 0.3881, 0.3530, 0.4938, 0.3815,\n",
       "          0.4568, 0.4953, 0.4924, 0.5012, 0.4869, 0.4686, 0.4189, 0.3700, 0.4926,\n",
       "          0.2623, 0.4807, 0.4581, 0.5606, 0.5420, 0.3763, 0.3903, 0.4669, 0.4108,\n",
       "          0.4197, 0.4398, 0.3959, 0.5623, 0.3515, 0.4607, 0.4260, 0.4124, 0.5190,\n",
       "          0.3448, 0.3952, 0.4222, 0.5223, 0.3924, 0.4033, 0.4673, 0.4714, 0.3899,\n",
       "          0.4513, 0.4488, 0.3916, 0.4393, 0.4766, 0.5113, 0.4935, 0.4495, 0.4013],\n",
       "         [0.4137, 0.4350, 0.4365, 0.5253, 0.3666, 0.4021, 0.3211, 0.4973, 0.4011,\n",
       "          0.4671, 0.5204, 0.5221, 0.4743, 0.4565, 0.4652, 0.4220, 0.3371, 0.4695,\n",
       "          0.2837, 0.4836, 0.4524, 0.5629, 0.5617, 0.3462, 0.4010, 0.4422, 0.4131,\n",
       "          0.4127, 0.4415, 0.4002, 0.5685, 0.3630, 0.4585, 0.4015, 0.4074, 0.5039,\n",
       "          0.3719, 0.4169, 0.4277, 0.5180, 0.3895, 0.4387, 0.4072, 0.4715, 0.3840,\n",
       "          0.4241, 0.4336, 0.4109, 0.4791, 0.4638, 0.4790, 0.4947, 0.4703, 0.3931],\n",
       "         [0.4248, 0.4181, 0.4414, 0.5125, 0.3534, 0.4161, 0.3214, 0.4841, 0.3901,\n",
       "          0.4632, 0.5246, 0.5188, 0.4783, 0.4671, 0.4653, 0.4316, 0.3312, 0.4589,\n",
       "          0.2862, 0.4702, 0.4470, 0.5735, 0.5575, 0.3413, 0.3964, 0.4517, 0.4098,\n",
       "          0.4181, 0.4578, 0.3907, 0.5689, 0.3555, 0.4448, 0.3963, 0.3956, 0.5068,\n",
       "          0.3877, 0.4049, 0.4464, 0.5123, 0.4018, 0.4329, 0.4251, 0.4589, 0.3902,\n",
       "          0.4447, 0.4138, 0.4108, 0.4660, 0.4648, 0.4724, 0.4995, 0.4770, 0.4012],\n",
       "         [0.4162, 0.4135, 0.4382, 0.5160, 0.3839, 0.3936, 0.3487, 0.4868, 0.3940,\n",
       "          0.4522, 0.5165, 0.5022, 0.4760, 0.4700, 0.4596, 0.4243, 0.3680, 0.4792,\n",
       "          0.2679, 0.4856, 0.4606, 0.5625, 0.5529, 0.3556, 0.4097, 0.4555, 0.4289,\n",
       "          0.4048, 0.4361, 0.4030, 0.5567, 0.3656, 0.4568, 0.4143, 0.4198, 0.5212,\n",
       "          0.3589, 0.4117, 0.4353, 0.5121, 0.3911, 0.4304, 0.4364, 0.4777, 0.3648,\n",
       "          0.4397, 0.4456, 0.3987, 0.4582, 0.4652, 0.5001, 0.4950, 0.4671, 0.3961],\n",
       "         [0.4195, 0.4035, 0.4267, 0.5110, 0.3723, 0.3935, 0.3359, 0.4920, 0.3836,\n",
       "          0.4651, 0.5175, 0.5134, 0.4787, 0.4533, 0.4786, 0.4394, 0.3368, 0.4816,\n",
       "          0.2649, 0.4708, 0.4744, 0.5705, 0.5439, 0.3550, 0.3782, 0.4736, 0.4127,\n",
       "          0.4022, 0.4601, 0.3774, 0.5593, 0.3399, 0.4598, 0.4142, 0.4014, 0.5091,\n",
       "          0.3576, 0.3909, 0.4270, 0.5187, 0.3815, 0.4352, 0.4502, 0.4725, 0.3872,\n",
       "          0.4353, 0.4308, 0.3921, 0.4617, 0.4871, 0.4943, 0.5024, 0.4741, 0.4005],\n",
       "         [0.3939, 0.4312, 0.4312, 0.5247, 0.3763, 0.3961, 0.3455, 0.4735, 0.4069,\n",
       "          0.4281, 0.5160, 0.4966, 0.4518, 0.4491, 0.4560, 0.4315, 0.3660, 0.4816,\n",
       "          0.2601, 0.4999, 0.4795, 0.5777, 0.5616, 0.3513, 0.4235, 0.4650, 0.4456,\n",
       "          0.3819, 0.4428, 0.4129, 0.5598, 0.3712, 0.4493, 0.4125, 0.4185, 0.5230,\n",
       "          0.3563, 0.4223, 0.4327, 0.5136, 0.3796, 0.4468, 0.4250, 0.4960, 0.3498,\n",
       "          0.4136, 0.4405, 0.3885, 0.4849, 0.4754, 0.4908, 0.5069, 0.4688, 0.3930],\n",
       "         [0.4028, 0.4361, 0.4258, 0.5387, 0.4101, 0.3805, 0.3503, 0.5096, 0.4170,\n",
       "          0.4479, 0.5004, 0.4906, 0.4724, 0.4697, 0.4557, 0.4018, 0.3714, 0.4929,\n",
       "          0.2633, 0.5031, 0.4739, 0.5516, 0.5605, 0.3727, 0.4109, 0.4551, 0.4344,\n",
       "          0.4072, 0.4123, 0.4264, 0.5765, 0.3819, 0.4689, 0.4298, 0.4186, 0.5183,\n",
       "          0.3442, 0.4239, 0.4094, 0.5358, 0.3754, 0.4252, 0.4192, 0.4924, 0.3674,\n",
       "          0.4059, 0.4599, 0.3916, 0.4825, 0.4691, 0.5079, 0.4819, 0.4436, 0.3802]],\n",
       "        device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>),\n",
       " tensor([[0.4356, 0.4177, 0.4675, 0.4973, 0.3772, 0.4345, 0.3289, 0.4710, 0.3814,\n",
       "          0.4707, 0.5182, 0.5107, 0.5019, 0.4945, 0.4446, 0.4147, 0.3607, 0.4491,\n",
       "          0.3110, 0.4640, 0.4161, 0.5679, 0.5665, 0.3514, 0.4182, 0.4161, 0.3946,\n",
       "          0.4485, 0.4386, 0.4078, 0.5551, 0.3737, 0.4499, 0.4043, 0.3997, 0.5166,\n",
       "          0.3928, 0.4262, 0.4505, 0.5098, 0.4366, 0.4142, 0.4195, 0.4345, 0.3898,\n",
       "          0.4649, 0.4230, 0.4349, 0.4442, 0.4326, 0.4769, 0.4832, 0.4689, 0.4075],\n",
       "         [0.4068, 0.4319, 0.4343, 0.5249, 0.3621, 0.3972, 0.3329, 0.4919, 0.3951,\n",
       "          0.4641, 0.5228, 0.5193, 0.4676, 0.4440, 0.4710, 0.4250, 0.3532, 0.4791,\n",
       "          0.2677, 0.4842, 0.4643, 0.5693, 0.5560, 0.3451, 0.4034, 0.4513, 0.4226,\n",
       "          0.3967, 0.4415, 0.3935, 0.5611, 0.3643, 0.4632, 0.4107, 0.4057, 0.5176,\n",
       "          0.3658, 0.4144, 0.4273, 0.5121, 0.3814, 0.4453, 0.4060, 0.4829, 0.3721,\n",
       "          0.4254, 0.4339, 0.4050, 0.4788, 0.4707, 0.4833, 0.5009, 0.4849, 0.3957],\n",
       "         [0.4193, 0.4002, 0.4276, 0.5166, 0.3744, 0.3831, 0.3417, 0.4960, 0.3790,\n",
       "          0.4689, 0.5055, 0.5107, 0.4816, 0.4536, 0.4855, 0.4336, 0.3530, 0.4875,\n",
       "          0.2576, 0.4755, 0.4706, 0.5682, 0.5365, 0.3621, 0.3793, 0.4736, 0.4178,\n",
       "          0.4015, 0.4514, 0.3794, 0.5521, 0.3462, 0.4702, 0.4253, 0.4043, 0.5137,\n",
       "          0.3562, 0.3908, 0.4210, 0.5125, 0.3801, 0.4308, 0.4417, 0.4804, 0.3838,\n",
       "          0.4323, 0.4420, 0.3932, 0.4605, 0.4906, 0.5000, 0.4999, 0.4760, 0.3971],\n",
       "         [0.4126, 0.4240, 0.4457, 0.5149, 0.3766, 0.4105, 0.3344, 0.4812, 0.3955,\n",
       "          0.4548, 0.5075, 0.5057, 0.4752, 0.4650, 0.4621, 0.4152, 0.3612, 0.4719,\n",
       "          0.2782, 0.4861, 0.4510, 0.5735, 0.5565, 0.3531, 0.4137, 0.4493, 0.4255,\n",
       "          0.4084, 0.4400, 0.4053, 0.5642, 0.3730, 0.4593, 0.4167, 0.4128, 0.5182,\n",
       "          0.3730, 0.4205, 0.4367, 0.5133, 0.3976, 0.4267, 0.4164, 0.4711, 0.3718,\n",
       "          0.4341, 0.4308, 0.4047, 0.4720, 0.4605, 0.4820, 0.4993, 0.4729, 0.3904],\n",
       "         [0.4532, 0.3956, 0.4522, 0.5051, 0.3844, 0.4003, 0.3242, 0.4978, 0.3695,\n",
       "          0.4926, 0.5213, 0.5260, 0.5130, 0.4854, 0.4743, 0.4261, 0.3446, 0.4724,\n",
       "          0.2869, 0.4535, 0.4363, 0.5610, 0.5443, 0.3604, 0.3706, 0.4370, 0.3824,\n",
       "          0.4519, 0.4434, 0.3784, 0.5615, 0.3449, 0.4628, 0.4143, 0.3932, 0.5173,\n",
       "          0.3777, 0.3912, 0.4217, 0.5126, 0.4171, 0.4115, 0.4418, 0.4429, 0.4147,\n",
       "          0.4606, 0.4283, 0.4242, 0.4302, 0.4598, 0.4952, 0.4888, 0.4665, 0.4143],\n",
       "         [0.4422, 0.4026, 0.4303, 0.5107, 0.3793, 0.4010, 0.3254, 0.5034, 0.3723,\n",
       "          0.4874, 0.5091, 0.5226, 0.5056, 0.4711, 0.4786, 0.4262, 0.3376, 0.4770,\n",
       "          0.2772, 0.4635, 0.4494, 0.5625, 0.5360, 0.3670, 0.3708, 0.4536, 0.3919,\n",
       "          0.4377, 0.4536, 0.3772, 0.5633, 0.3476, 0.4675, 0.4233, 0.3926, 0.5020,\n",
       "          0.3702, 0.3871, 0.4239, 0.5223, 0.3947, 0.4151, 0.4379, 0.4558, 0.4108,\n",
       "          0.4446, 0.4259, 0.4102, 0.4491, 0.4758, 0.4977, 0.4880, 0.4700, 0.4055],\n",
       "         [0.4154, 0.4371, 0.4463, 0.5251, 0.3679, 0.4033, 0.3315, 0.4909, 0.3981,\n",
       "          0.4771, 0.5226, 0.5232, 0.4764, 0.4640, 0.4679, 0.4165, 0.3603, 0.4665,\n",
       "          0.2880, 0.4824, 0.4476, 0.5623, 0.5535, 0.3550, 0.4165, 0.4296, 0.4161,\n",
       "          0.4162, 0.4336, 0.4092, 0.5549, 0.3730, 0.4729, 0.4089, 0.4160, 0.5169,\n",
       "          0.3830, 0.4249, 0.4308, 0.5082, 0.4002, 0.4334, 0.3938, 0.4690, 0.3831,\n",
       "          0.4308, 0.4368, 0.4227, 0.4743, 0.4524, 0.4804, 0.4917, 0.4812, 0.3911],\n",
       "         [0.4124, 0.4276, 0.4333, 0.5371, 0.3943, 0.3823, 0.3422, 0.5031, 0.4021,\n",
       "          0.4584, 0.5085, 0.5102, 0.4762, 0.4618, 0.4634, 0.4152, 0.3734, 0.4970,\n",
       "          0.2608, 0.4984, 0.4693, 0.5604, 0.5495, 0.3671, 0.3979, 0.4535, 0.4262,\n",
       "          0.4055, 0.4272, 0.4087, 0.5619, 0.3668, 0.4687, 0.4294, 0.4131, 0.5225,\n",
       "          0.3554, 0.4115, 0.4146, 0.5272, 0.3819, 0.4317, 0.4187, 0.4840, 0.3716,\n",
       "          0.4176, 0.4525, 0.3979, 0.4761, 0.4679, 0.5027, 0.4889, 0.4581, 0.3874],\n",
       "         [0.4306, 0.4017, 0.4277, 0.5177, 0.3914, 0.3878, 0.3324, 0.4969, 0.3823,\n",
       "          0.4646, 0.5138, 0.5131, 0.4938, 0.4724, 0.4710, 0.4245, 0.3527, 0.4851,\n",
       "          0.2645, 0.4809, 0.4608, 0.5666, 0.5484, 0.3631, 0.3839, 0.4600, 0.4059,\n",
       "          0.4204, 0.4419, 0.3893, 0.5639, 0.3502, 0.4571, 0.4247, 0.3978, 0.5149,\n",
       "          0.3593, 0.3937, 0.4150, 0.5215, 0.3937, 0.4240, 0.4427, 0.4659, 0.3941,\n",
       "          0.4339, 0.4390, 0.3983, 0.4431, 0.4744, 0.5014, 0.4865, 0.4585, 0.4025],\n",
       "         [0.4438, 0.3873, 0.4496, 0.4937, 0.3653, 0.4116, 0.3299, 0.4752, 0.3647,\n",
       "          0.4701, 0.5276, 0.5236, 0.4959, 0.4651, 0.4685, 0.4472, 0.3429, 0.4682,\n",
       "          0.2776, 0.4563, 0.4446, 0.5824, 0.5430, 0.3451, 0.3764, 0.4600, 0.4026,\n",
       "          0.4273, 0.4684, 0.3632, 0.5442, 0.3368, 0.4463, 0.4096, 0.3945, 0.5189,\n",
       "          0.3748, 0.3875, 0.4390, 0.5063, 0.4115, 0.4333, 0.4585, 0.4518, 0.3967,\n",
       "          0.4691, 0.4273, 0.4132, 0.4268, 0.4707, 0.4931, 0.5025, 0.4821, 0.4212],\n",
       "         [0.4180, 0.4314, 0.4488, 0.5119, 0.3820, 0.4091, 0.3438, 0.4803, 0.3997,\n",
       "          0.4535, 0.5114, 0.5028, 0.4883, 0.4691, 0.4490, 0.4219, 0.3734, 0.4708,\n",
       "          0.2854, 0.4806, 0.4413, 0.5725, 0.5636, 0.3550, 0.4183, 0.4403, 0.4259,\n",
       "          0.4088, 0.4302, 0.4150, 0.5494, 0.3756, 0.4541, 0.4108, 0.4169, 0.5191,\n",
       "          0.3745, 0.4222, 0.4317, 0.5112, 0.4065, 0.4356, 0.4204, 0.4727, 0.3699,\n",
       "          0.4371, 0.4421, 0.4174, 0.4596, 0.4531, 0.4902, 0.4918, 0.4659, 0.4004],\n",
       "         [0.4179, 0.4219, 0.4379, 0.5168, 0.3613, 0.4124, 0.3299, 0.4759, 0.3950,\n",
       "          0.4491, 0.5206, 0.5117, 0.4742, 0.4594, 0.4576, 0.4323, 0.3497, 0.4698,\n",
       "          0.2830, 0.4764, 0.4556, 0.5790, 0.5523, 0.3466, 0.4051, 0.4553, 0.4247,\n",
       "          0.4065, 0.4516, 0.4010, 0.5575, 0.3636, 0.4449, 0.4061, 0.4049, 0.5090,\n",
       "          0.3828, 0.4156, 0.4433, 0.5123, 0.4018, 0.4452, 0.4213, 0.4705, 0.3719,\n",
       "          0.4339, 0.4279, 0.4031, 0.4678, 0.4653, 0.4832, 0.4972, 0.4741, 0.4006],\n",
       "         [0.4131, 0.4156, 0.4310, 0.5229, 0.3643, 0.3925, 0.3333, 0.4906, 0.3906,\n",
       "          0.4610, 0.5188, 0.5189, 0.4717, 0.4464, 0.4751, 0.4366, 0.3403, 0.4847,\n",
       "          0.2560, 0.4829, 0.4745, 0.5776, 0.5470, 0.3465, 0.3890, 0.4724, 0.4188,\n",
       "          0.3909, 0.4519, 0.3815, 0.5636, 0.3469, 0.4591, 0.4149, 0.4034, 0.5118,\n",
       "          0.3578, 0.3940, 0.4236, 0.5146, 0.3742, 0.4460, 0.4322, 0.4814, 0.3771,\n",
       "          0.4229, 0.4295, 0.3922, 0.4759, 0.4843, 0.4847, 0.5087, 0.4779, 0.3937],\n",
       "         [0.4004, 0.4073, 0.4279, 0.5209, 0.3676, 0.3902, 0.3451, 0.4913, 0.3872,\n",
       "          0.4583, 0.5147, 0.5055, 0.4683, 0.4414, 0.4785, 0.4340, 0.3530, 0.4929,\n",
       "          0.2518, 0.4848, 0.4810, 0.5745, 0.5442, 0.3495, 0.3908, 0.4794, 0.4297,\n",
       "          0.3833, 0.4546, 0.3786, 0.5581, 0.3540, 0.4624, 0.4186, 0.4106, 0.5154,\n",
       "          0.3464, 0.3940, 0.4294, 0.5154, 0.3684, 0.4467, 0.4382, 0.4889, 0.3700,\n",
       "          0.4293, 0.4329, 0.3892, 0.4756, 0.4835, 0.4903, 0.5132, 0.4851, 0.3938],\n",
       "         [0.4054, 0.4045, 0.4347, 0.5042, 0.3617, 0.4035, 0.3471, 0.4830, 0.3816,\n",
       "          0.4621, 0.5171, 0.5066, 0.4700, 0.4540, 0.4843, 0.4339, 0.3555, 0.4795,\n",
       "          0.2630, 0.4740, 0.4677, 0.5697, 0.5450, 0.3493, 0.4021, 0.4688, 0.4252,\n",
       "          0.3897, 0.4543, 0.3832, 0.5512, 0.3542, 0.4659, 0.4113, 0.4131, 0.5220,\n",
       "          0.3646, 0.3979, 0.4391, 0.5058, 0.3827, 0.4303, 0.4371, 0.4802, 0.3721,\n",
       "          0.4442, 0.4239, 0.4023, 0.4648, 0.4817, 0.4806, 0.5163, 0.4946, 0.3957],\n",
       "         [0.4163, 0.4234, 0.4284, 0.5379, 0.3898, 0.3759, 0.3330, 0.5041, 0.3972,\n",
       "          0.4654, 0.5155, 0.5178, 0.4772, 0.4550, 0.4731, 0.4229, 0.3573, 0.4979,\n",
       "          0.2567, 0.4889, 0.4697, 0.5684, 0.5505, 0.3629, 0.3919, 0.4554, 0.4219,\n",
       "          0.4045, 0.4313, 0.3993, 0.5611, 0.3594, 0.4655, 0.4241, 0.4079, 0.5196,\n",
       "          0.3518, 0.4072, 0.4051, 0.5233, 0.3787, 0.4355, 0.4241, 0.4844, 0.3836,\n",
       "          0.4164, 0.4537, 0.3972, 0.4628, 0.4741, 0.5045, 0.4917, 0.4627, 0.3958]],\n",
       "        device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>),\n",
       " tensor([[0.4101, 0.4032, 0.4222, 0.5208, 0.3752, 0.3817, 0.3354, 0.5015, 0.3857,\n",
       "          0.4663, 0.5179, 0.5140, 0.4683, 0.4481, 0.4869, 0.4353, 0.3427, 0.4868,\n",
       "          0.2566, 0.4802, 0.4765, 0.5687, 0.5321, 0.3576, 0.3778, 0.4764, 0.4244,\n",
       "          0.3999, 0.4579, 0.3784, 0.5593, 0.3437, 0.4688, 0.4240, 0.4025, 0.5123,\n",
       "          0.3527, 0.3861, 0.4216, 0.5179, 0.3703, 0.4341, 0.4426, 0.4879, 0.3899,\n",
       "          0.4271, 0.4405, 0.3907, 0.4622, 0.4964, 0.4963, 0.5068, 0.4745, 0.4020],\n",
       "         [0.4113, 0.4255, 0.4284, 0.5253, 0.4090, 0.3800, 0.3489, 0.5049, 0.4073,\n",
       "          0.4562, 0.5038, 0.5007, 0.4813, 0.4694, 0.4627, 0.4101, 0.3743, 0.4931,\n",
       "          0.2684, 0.4923, 0.4657, 0.5540, 0.5542, 0.3744, 0.4059, 0.4564, 0.4285,\n",
       "          0.4096, 0.4292, 0.4182, 0.5635, 0.3726, 0.4658, 0.4298, 0.4143, 0.5203,\n",
       "          0.3499, 0.4134, 0.4151, 0.5279, 0.3812, 0.4245, 0.4275, 0.4870, 0.3767,\n",
       "          0.4165, 0.4609, 0.3944, 0.4737, 0.4781, 0.5068, 0.4905, 0.4508, 0.3866],\n",
       "         [0.4230, 0.4268, 0.4396, 0.5226, 0.3797, 0.4114, 0.3338, 0.4858, 0.3967,\n",
       "          0.4551, 0.5165, 0.5100, 0.4784, 0.4769, 0.4458, 0.4156, 0.3583, 0.4639,\n",
       "          0.2937, 0.4868, 0.4483, 0.5645, 0.5593, 0.3578, 0.4137, 0.4419, 0.4197,\n",
       "          0.4239, 0.4409, 0.4178, 0.5630, 0.3744, 0.4508, 0.4113, 0.4007, 0.5175,\n",
       "          0.3819, 0.4225, 0.4398, 0.5218, 0.4064, 0.4266, 0.4151, 0.4621, 0.3811,\n",
       "          0.4335, 0.4356, 0.4122, 0.4716, 0.4535, 0.4894, 0.4823, 0.4641, 0.3986],\n",
       "         [0.4112, 0.4352, 0.4354, 0.5329, 0.4171, 0.3849, 0.3529, 0.5031, 0.4161,\n",
       "          0.4442, 0.5040, 0.4918, 0.4781, 0.4892, 0.4474, 0.3956, 0.3852, 0.4822,\n",
       "          0.2763, 0.5049, 0.4552, 0.5518, 0.5643, 0.3714, 0.4231, 0.4435, 0.4305,\n",
       "          0.4218, 0.4089, 0.4353, 0.5764, 0.3896, 0.4614, 0.4240, 0.4198, 0.5310,\n",
       "          0.3503, 0.4303, 0.4170, 0.5365, 0.3882, 0.4148, 0.4173, 0.4823, 0.3634,\n",
       "          0.4224, 0.4594, 0.3995, 0.4722, 0.4579, 0.5044, 0.4818, 0.4441, 0.3817],\n",
       "         [0.4062, 0.4282, 0.4375, 0.5211, 0.3530, 0.4197, 0.3205, 0.4739, 0.4003,\n",
       "          0.4372, 0.5259, 0.5202, 0.4563, 0.4400, 0.4564, 0.4423, 0.3332, 0.4668,\n",
       "          0.2818, 0.4836, 0.4629, 0.5828, 0.5674, 0.3352, 0.4094, 0.4610, 0.4289,\n",
       "          0.3938, 0.4586, 0.3987, 0.5664, 0.3610, 0.4439, 0.3980, 0.4005, 0.5068,\n",
       "          0.3704, 0.4091, 0.4422, 0.5208, 0.3892, 0.4640, 0.4202, 0.4765, 0.3700,\n",
       "          0.4242, 0.4178, 0.3988, 0.4846, 0.4719, 0.4703, 0.5075, 0.4815, 0.4035],\n",
       "         [0.4325, 0.4147, 0.4475, 0.5144, 0.3839, 0.4073, 0.3317, 0.4965, 0.3860,\n",
       "          0.4722, 0.5190, 0.5197, 0.4945, 0.4853, 0.4659, 0.4117, 0.3518, 0.4649,\n",
       "          0.2882, 0.4727, 0.4429, 0.5564, 0.5549, 0.3607, 0.3986, 0.4431, 0.3994,\n",
       "          0.4365, 0.4367, 0.3943, 0.5729, 0.3617, 0.4591, 0.4115, 0.3994, 0.5179,\n",
       "          0.3700, 0.4060, 0.4343, 0.5237, 0.4055, 0.4206, 0.4266, 0.4495, 0.3988,\n",
       "          0.4447, 0.4316, 0.4161, 0.4521, 0.4595, 0.4869, 0.4869, 0.4680, 0.3968],\n",
       "         [0.4008, 0.4193, 0.4236, 0.5293, 0.4010, 0.3817, 0.3577, 0.5036, 0.3967,\n",
       "          0.4546, 0.5060, 0.4945, 0.4681, 0.4711, 0.4717, 0.4109, 0.3732, 0.4913,\n",
       "          0.2575, 0.5023, 0.4775, 0.5551, 0.5353, 0.3740, 0.4078, 0.4607, 0.4333,\n",
       "          0.4052, 0.4293, 0.4131, 0.5682, 0.3693, 0.4754, 0.4399, 0.4126, 0.5254,\n",
       "          0.3455, 0.4135, 0.4207, 0.5226, 0.3748, 0.4177, 0.4250, 0.4939, 0.3668,\n",
       "          0.4158, 0.4561, 0.3896, 0.4711, 0.4755, 0.5087, 0.4915, 0.4601, 0.3842],\n",
       "         [0.4229, 0.3955, 0.4418, 0.5049, 0.3720, 0.4031, 0.3429, 0.4795, 0.3778,\n",
       "          0.4562, 0.5237, 0.5075, 0.4826, 0.4618, 0.4651, 0.4420, 0.3581, 0.4745,\n",
       "          0.2619, 0.4726, 0.4587, 0.5751, 0.5467, 0.3515, 0.3924, 0.4659, 0.4166,\n",
       "          0.4020, 0.4572, 0.3781, 0.5444, 0.3510, 0.4547, 0.4146, 0.4058, 0.5218,\n",
       "          0.3546, 0.3918, 0.4353, 0.4995, 0.3943, 0.4404, 0.4529, 0.4682, 0.3802,\n",
       "          0.4542, 0.4344, 0.4027, 0.4466, 0.4760, 0.4981, 0.5025, 0.4747, 0.4141],\n",
       "         [0.4262, 0.4233, 0.4474, 0.5205, 0.3601, 0.4068, 0.3195, 0.4812, 0.3886,\n",
       "          0.4693, 0.5357, 0.5342, 0.4777, 0.4590, 0.4674, 0.4357, 0.3412, 0.4636,\n",
       "          0.2822, 0.4754, 0.4482, 0.5707, 0.5525, 0.3450, 0.3970, 0.4369, 0.4101,\n",
       "          0.4208, 0.4576, 0.3902, 0.5591, 0.3549, 0.4569, 0.4050, 0.4016, 0.5099,\n",
       "          0.3786, 0.4030, 0.4334, 0.5070, 0.3973, 0.4489, 0.4192, 0.4617, 0.3897,\n",
       "          0.4307, 0.4304, 0.4118, 0.4623, 0.4643, 0.4836, 0.4989, 0.4791, 0.4051],\n",
       "         [0.4196, 0.4044, 0.4299, 0.5155, 0.3778, 0.3848, 0.3389, 0.4989, 0.3817,\n",
       "          0.4723, 0.5107, 0.5138, 0.4853, 0.4555, 0.4848, 0.4311, 0.3495, 0.4856,\n",
       "          0.2591, 0.4752, 0.4674, 0.5708, 0.5375, 0.3639, 0.3832, 0.4629, 0.4155,\n",
       "          0.4067, 0.4449, 0.3823, 0.5532, 0.3476, 0.4663, 0.4229, 0.4048, 0.5138,\n",
       "          0.3541, 0.3937, 0.4185, 0.5124, 0.3808, 0.4308, 0.4365, 0.4801, 0.3900,\n",
       "          0.4315, 0.4474, 0.3996, 0.4548, 0.4828, 0.5000, 0.4988, 0.4737, 0.3994],\n",
       "         [0.4423, 0.4042, 0.4457, 0.5055, 0.3854, 0.4118, 0.3281, 0.4875, 0.3827,\n",
       "          0.4661, 0.5189, 0.5150, 0.5022, 0.4794, 0.4520, 0.4288, 0.3467, 0.4725,\n",
       "          0.2909, 0.4627, 0.4391, 0.5677, 0.5573, 0.3598, 0.3899, 0.4431, 0.3997,\n",
       "          0.4346, 0.4487, 0.3907, 0.5605, 0.3577, 0.4485, 0.4076, 0.3953, 0.5100,\n",
       "          0.3743, 0.4009, 0.4342, 0.5201, 0.4116, 0.4245, 0.4447, 0.4507, 0.4041,\n",
       "          0.4526, 0.4285, 0.4165, 0.4463, 0.4582, 0.4968, 0.4863, 0.4625, 0.4165],\n",
       "         [0.4244, 0.4078, 0.4463, 0.5106, 0.3922, 0.3977, 0.3479, 0.4949, 0.3904,\n",
       "          0.4562, 0.5167, 0.5016, 0.4919, 0.4792, 0.4623, 0.4196, 0.3688, 0.4740,\n",
       "          0.2731, 0.4751, 0.4501, 0.5629, 0.5469, 0.3620, 0.3978, 0.4519, 0.4157,\n",
       "          0.4181, 0.4321, 0.4038, 0.5582, 0.3654, 0.4626, 0.4193, 0.4073, 0.5233,\n",
       "          0.3637, 0.4058, 0.4346, 0.5108, 0.3936, 0.4204, 0.4403, 0.4693, 0.3797,\n",
       "          0.4469, 0.4414, 0.4034, 0.4504, 0.4629, 0.4988, 0.4918, 0.4655, 0.4043],\n",
       "         [0.4272, 0.4164, 0.4437, 0.5195, 0.3839, 0.3918, 0.3316, 0.4968, 0.3879,\n",
       "          0.4672, 0.5196, 0.5203, 0.4923, 0.4719, 0.4682, 0.4271, 0.3619, 0.4752,\n",
       "          0.2727, 0.4766, 0.4486, 0.5577, 0.5544, 0.3592, 0.3980, 0.4432, 0.4081,\n",
       "          0.4259, 0.4363, 0.3968, 0.5636, 0.3621, 0.4613, 0.4115, 0.4050, 0.5201,\n",
       "          0.3632, 0.3984, 0.4197, 0.5103, 0.3934, 0.4300, 0.4304, 0.4704, 0.3928,\n",
       "          0.4395, 0.4368, 0.4119, 0.4530, 0.4649, 0.4973, 0.4890, 0.4668, 0.4063],\n",
       "         [0.4285, 0.4172, 0.4319, 0.5320, 0.3836, 0.3966, 0.3310, 0.5124, 0.3874,\n",
       "          0.4879, 0.5126, 0.5176, 0.4881, 0.4806, 0.4711, 0.4044, 0.3380, 0.4735,\n",
       "          0.2849, 0.4840, 0.4559, 0.5467, 0.5363, 0.3641, 0.3869, 0.4439, 0.4008,\n",
       "          0.4390, 0.4391, 0.3997, 0.5740, 0.3533, 0.4741, 0.4275, 0.3880, 0.5096,\n",
       "          0.3757, 0.4097, 0.4228, 0.5292, 0.3914, 0.4124, 0.4224, 0.4515, 0.4038,\n",
       "          0.4299, 0.4364, 0.4088, 0.4637, 0.4644, 0.4936, 0.4784, 0.4603, 0.3886],\n",
       "         [0.4154, 0.3992, 0.4345, 0.5014, 0.3551, 0.4080, 0.3393, 0.4821, 0.3774,\n",
       "          0.4631, 0.5097, 0.5105, 0.4741, 0.4547, 0.4822, 0.4368, 0.3452, 0.4708,\n",
       "          0.2823, 0.4706, 0.4610, 0.5736, 0.5377, 0.3556, 0.3904, 0.4688, 0.4167,\n",
       "          0.4058, 0.4722, 0.3831, 0.5515, 0.3507, 0.4604, 0.4111, 0.3993, 0.5103,\n",
       "          0.3788, 0.3992, 0.4481, 0.5082, 0.3917, 0.4289, 0.4354, 0.4689, 0.3850,\n",
       "          0.4474, 0.4251, 0.4019, 0.4708, 0.4818, 0.4795, 0.5094, 0.4893, 0.3969],\n",
       "         [0.4177, 0.4200, 0.4271, 0.5289, 0.3554, 0.3868, 0.3254, 0.4907, 0.3903,\n",
       "          0.4742, 0.5283, 0.5278, 0.4689, 0.4381, 0.4850, 0.4365, 0.3360, 0.4752,\n",
       "          0.2697, 0.4791, 0.4692, 0.5700, 0.5465, 0.3497, 0.3855, 0.4601, 0.4214,\n",
       "          0.3972, 0.4625, 0.3785, 0.5593, 0.3480, 0.4658, 0.4093, 0.4034, 0.5058,\n",
       "          0.3658, 0.3967, 0.4242, 0.5082, 0.3762, 0.4524, 0.4228, 0.4815, 0.3850,\n",
       "          0.4215, 0.4326, 0.3948, 0.4740, 0.4904, 0.4862, 0.5072, 0.4824, 0.4026]],\n",
       "        device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>),\n",
       " tensor([[0.4215, 0.4099, 0.4319, 0.5146, 0.3251, 0.4121, 0.3111, 0.4898, 0.3721,\n",
       "          0.4863, 0.5317, 0.5379, 0.4660, 0.4320, 0.4934, 0.4532, 0.3111, 0.4653,\n",
       "          0.2779, 0.4587, 0.4684, 0.5704, 0.5410, 0.3361, 0.3762, 0.4641, 0.4076,\n",
       "          0.4108, 0.4814, 0.3553, 0.5553, 0.3306, 0.4648, 0.3970, 0.3896, 0.5021,\n",
       "          0.3878, 0.3831, 0.4413, 0.5027, 0.3900, 0.4477, 0.4211, 0.4675, 0.3931,\n",
       "          0.4416, 0.4103, 0.4100, 0.4712, 0.4902, 0.4679, 0.5081, 0.5040, 0.4061],\n",
       "         [0.4246, 0.4107, 0.4271, 0.5308, 0.3815, 0.3782, 0.3296, 0.5112, 0.3888,\n",
       "          0.4782, 0.5198, 0.5202, 0.4830, 0.4678, 0.4741, 0.4222, 0.3442, 0.4902,\n",
       "          0.2624, 0.4836, 0.4693, 0.5562, 0.5427, 0.3646, 0.3802, 0.4623, 0.4048,\n",
       "          0.4228, 0.4422, 0.3874, 0.5640, 0.3457, 0.4656, 0.4184, 0.3955, 0.5163,\n",
       "          0.3524, 0.3908, 0.4098, 0.5291, 0.3791, 0.4183, 0.4334, 0.4774, 0.3940,\n",
       "          0.4261, 0.4416, 0.3957, 0.4584, 0.4827, 0.4986, 0.4879, 0.4609, 0.3953],\n",
       "         [0.4161, 0.4037, 0.4290, 0.5143, 0.3883, 0.3923, 0.3398, 0.4979, 0.3893,\n",
       "          0.4558, 0.5111, 0.5044, 0.4749, 0.4662, 0.4716, 0.4247, 0.3529, 0.4869,\n",
       "          0.2659, 0.4833, 0.4692, 0.5601, 0.5479, 0.3582, 0.3937, 0.4710, 0.4197,\n",
       "          0.4095, 0.4411, 0.3916, 0.5646, 0.3484, 0.4614, 0.4194, 0.4061, 0.5267,\n",
       "          0.3513, 0.3966, 0.4213, 0.5313, 0.3845, 0.4221, 0.4441, 0.4743, 0.3813,\n",
       "          0.4381, 0.4390, 0.3957, 0.4571, 0.4789, 0.4976, 0.4978, 0.4642, 0.3935],\n",
       "         [0.4152, 0.4156, 0.4302, 0.5235, 0.3704, 0.3962, 0.3293, 0.4921, 0.3955,\n",
       "          0.4708, 0.5114, 0.5143, 0.4761, 0.4575, 0.4709, 0.4242, 0.3464, 0.4778,\n",
       "          0.2720, 0.4779, 0.4689, 0.5629, 0.5533, 0.3578, 0.3924, 0.4588, 0.4152,\n",
       "          0.4103, 0.4556, 0.3955, 0.5652, 0.3547, 0.4606, 0.4114, 0.4026, 0.5082,\n",
       "          0.3675, 0.4012, 0.4249, 0.5195, 0.3803, 0.4303, 0.4331, 0.4745, 0.3846,\n",
       "          0.4275, 0.4365, 0.3989, 0.4745, 0.4815, 0.4896, 0.4982, 0.4661, 0.3953],\n",
       "         [0.4332, 0.3953, 0.4357, 0.4999, 0.3979, 0.4018, 0.3353, 0.4849, 0.3839,\n",
       "          0.4542, 0.5088, 0.5031, 0.4990, 0.4732, 0.4594, 0.4305, 0.3530, 0.4773,\n",
       "          0.2829, 0.4629, 0.4455, 0.5713, 0.5546, 0.3631, 0.3857, 0.4578, 0.4111,\n",
       "          0.4290, 0.4531, 0.3969, 0.5569, 0.3537, 0.4519, 0.4188, 0.3998, 0.5084,\n",
       "          0.3659, 0.3944, 0.4296, 0.5246, 0.4087, 0.4174, 0.4587, 0.4603, 0.3970,\n",
       "          0.4507, 0.4392, 0.4003, 0.4413, 0.4729, 0.5040, 0.4874, 0.4540, 0.4126],\n",
       "         [0.3763, 0.4507, 0.4264, 0.5411, 0.3760, 0.3872, 0.3465, 0.4920, 0.4244,\n",
       "          0.4318, 0.5168, 0.4991, 0.4394, 0.4371, 0.4578, 0.4167, 0.3738, 0.4837,\n",
       "          0.2581, 0.5125, 0.4856, 0.5655, 0.5660, 0.3495, 0.4324, 0.4639, 0.4548,\n",
       "          0.3733, 0.4297, 0.4221, 0.5637, 0.3813, 0.4618, 0.4119, 0.4297, 0.5280,\n",
       "          0.3479, 0.4293, 0.4289, 0.5182, 0.3617, 0.4560, 0.3990, 0.5117, 0.3372,\n",
       "          0.3945, 0.4553, 0.3854, 0.5087, 0.4749, 0.4888, 0.5016, 0.4690, 0.3760],\n",
       "         [0.3895, 0.4447, 0.4176, 0.5538, 0.4151, 0.3616, 0.3609, 0.5169, 0.4215,\n",
       "          0.4491, 0.4990, 0.4894, 0.4638, 0.4651, 0.4622, 0.3902, 0.3907, 0.5045,\n",
       "          0.2564, 0.5145, 0.4866, 0.5426, 0.5535, 0.3839, 0.4219, 0.4549, 0.4445,\n",
       "          0.3978, 0.4042, 0.4428, 0.5667, 0.3819, 0.4804, 0.4365, 0.4250, 0.5307,\n",
       "          0.3429, 0.4334, 0.4033, 0.5332, 0.3657, 0.4170, 0.4002, 0.5074, 0.3505,\n",
       "          0.3887, 0.4772, 0.3871, 0.4931, 0.4711, 0.5127, 0.4750, 0.4482, 0.3650],\n",
       "         [0.4289, 0.4056, 0.4346, 0.5165, 0.4224, 0.3842, 0.3448, 0.5125, 0.3913,\n",
       "          0.4704, 0.4920, 0.4941, 0.5038, 0.4939, 0.4682, 0.3952, 0.3709, 0.4895,\n",
       "          0.2751, 0.4863, 0.4518, 0.5437, 0.5449, 0.3858, 0.3895, 0.4508, 0.4075,\n",
       "          0.4369, 0.4253, 0.4112, 0.5707, 0.3660, 0.4726, 0.4409, 0.4092, 0.5228,\n",
       "          0.3498, 0.4080, 0.4134, 0.5368, 0.3924, 0.3917, 0.4426, 0.4650, 0.3949,\n",
       "          0.4339, 0.4617, 0.3999, 0.4524, 0.4695, 0.5125, 0.4778, 0.4393, 0.3839],\n",
       "         [0.4058, 0.4497, 0.4417, 0.5419, 0.4052, 0.3949, 0.3424, 0.5033, 0.4244,\n",
       "          0.4507, 0.5086, 0.4951, 0.4724, 0.4770, 0.4401, 0.3917, 0.3740, 0.4778,\n",
       "          0.2857, 0.5033, 0.4572, 0.5493, 0.5713, 0.3623, 0.4263, 0.4307, 0.4280,\n",
       "          0.4220, 0.4060, 0.4398, 0.5739, 0.3905, 0.4640, 0.4215, 0.4140, 0.5252,\n",
       "          0.3671, 0.4430, 0.4267, 0.5343, 0.3958, 0.4212, 0.3962, 0.4678, 0.3612,\n",
       "          0.4108, 0.4511, 0.4071, 0.4967, 0.4431, 0.4948, 0.4712, 0.4481, 0.3755],\n",
       "         [0.4158, 0.4321, 0.4381, 0.5286, 0.4122, 0.3943, 0.3408, 0.5006, 0.4045,\n",
       "          0.4547, 0.5125, 0.4982, 0.4893, 0.4852, 0.4484, 0.3967, 0.3790, 0.4771,\n",
       "          0.2791, 0.4962, 0.4483, 0.5508, 0.5675, 0.3728, 0.4172, 0.4290, 0.4201,\n",
       "          0.4325, 0.4178, 0.4303, 0.5681, 0.3866, 0.4634, 0.4206, 0.4155, 0.5236,\n",
       "          0.3524, 0.4274, 0.4202, 0.5272, 0.3909, 0.4152, 0.4170, 0.4739, 0.3758,\n",
       "          0.4232, 0.4564, 0.4091, 0.4657, 0.4544, 0.5025, 0.4786, 0.4472, 0.3886],\n",
       "         [0.4122, 0.4205, 0.4425, 0.5052, 0.3612, 0.4178, 0.3346, 0.4784, 0.3907,\n",
       "          0.4514, 0.5264, 0.5122, 0.4742, 0.4641, 0.4645, 0.4332, 0.3550, 0.4557,\n",
       "          0.2797, 0.4750, 0.4435, 0.5671, 0.5682, 0.3416, 0.4200, 0.4450, 0.4222,\n",
       "          0.4126, 0.4445, 0.3963, 0.5604, 0.3705, 0.4489, 0.3928, 0.4150, 0.5176,\n",
       "          0.3657, 0.4060, 0.4455, 0.5091, 0.3976, 0.4389, 0.4234, 0.4701, 0.3724,\n",
       "          0.4489, 0.4214, 0.4149, 0.4636, 0.4658, 0.4742, 0.5044, 0.4831, 0.3986],\n",
       "         [0.4157, 0.4175, 0.4355, 0.5223, 0.3579, 0.3959, 0.3275, 0.5019, 0.3881,\n",
       "          0.4766, 0.5225, 0.5245, 0.4754, 0.4486, 0.4809, 0.4326, 0.3307, 0.4816,\n",
       "          0.2681, 0.4789, 0.4687, 0.5644, 0.5473, 0.3445, 0.3891, 0.4616, 0.4121,\n",
       "          0.4073, 0.4479, 0.3768, 0.5605, 0.3437, 0.4656, 0.4083, 0.4025, 0.5141,\n",
       "          0.3639, 0.3999, 0.4199, 0.5119, 0.3794, 0.4397, 0.4249, 0.4745, 0.3852,\n",
       "          0.4296, 0.4319, 0.4014, 0.4697, 0.4767, 0.4872, 0.5002, 0.4778, 0.3956],\n",
       "         [0.4127, 0.4117, 0.4287, 0.5221, 0.3669, 0.3942, 0.3363, 0.4940, 0.3883,\n",
       "          0.4620, 0.5178, 0.5120, 0.4725, 0.4531, 0.4775, 0.4365, 0.3439, 0.4752,\n",
       "          0.2649, 0.4804, 0.4673, 0.5684, 0.5491, 0.3509, 0.3913, 0.4681, 0.4195,\n",
       "          0.4025, 0.4541, 0.3847, 0.5618, 0.3532, 0.4579, 0.4145, 0.4039, 0.5137,\n",
       "          0.3588, 0.3928, 0.4294, 0.5175, 0.3796, 0.4358, 0.4395, 0.4804, 0.3821,\n",
       "          0.4315, 0.4290, 0.3932, 0.4645, 0.4817, 0.4875, 0.5013, 0.4749, 0.3995],\n",
       "         [0.4080, 0.4183, 0.4485, 0.5014, 0.3557, 0.4169, 0.3319, 0.4731, 0.3868,\n",
       "          0.4531, 0.5287, 0.5190, 0.4684, 0.4502, 0.4646, 0.4375, 0.3493, 0.4589,\n",
       "          0.2745, 0.4749, 0.4548, 0.5783, 0.5591, 0.3364, 0.4102, 0.4561, 0.4214,\n",
       "          0.3983, 0.4579, 0.3813, 0.5498, 0.3564, 0.4523, 0.3989, 0.4132, 0.5206,\n",
       "          0.3695, 0.4057, 0.4441, 0.4983, 0.3903, 0.4478, 0.4251, 0.4719, 0.3697,\n",
       "          0.4406, 0.4232, 0.4105, 0.4676, 0.4680, 0.4807, 0.5061, 0.4890, 0.4023],\n",
       "         [0.4107, 0.4379, 0.4405, 0.5363, 0.4001, 0.3875, 0.3368, 0.5054, 0.4102,\n",
       "          0.4614, 0.5130, 0.5049, 0.4792, 0.4750, 0.4594, 0.3991, 0.3674, 0.4805,\n",
       "          0.2775, 0.4951, 0.4560, 0.5491, 0.5662, 0.3690, 0.4149, 0.4329, 0.4207,\n",
       "          0.4204, 0.4135, 0.4269, 0.5697, 0.3808, 0.4707, 0.4164, 0.4178, 0.5222,\n",
       "          0.3572, 0.4281, 0.4157, 0.5255, 0.3890, 0.4203, 0.4024, 0.4767, 0.3743,\n",
       "          0.4167, 0.4501, 0.4080, 0.4771, 0.4560, 0.4945, 0.4772, 0.4539, 0.3843],\n",
       "         [0.4127, 0.4224, 0.4487, 0.5082, 0.3462, 0.4270, 0.3206, 0.4705, 0.3908,\n",
       "          0.4527, 0.5367, 0.5205, 0.4646, 0.4499, 0.4586, 0.4375, 0.3403, 0.4513,\n",
       "          0.2870, 0.4721, 0.4481, 0.5775, 0.5673, 0.3304, 0.4088, 0.4483, 0.4228,\n",
       "          0.4056, 0.4602, 0.3848, 0.5619, 0.3633, 0.4433, 0.3942, 0.4059, 0.5172,\n",
       "          0.3809, 0.4075, 0.4524, 0.5068, 0.4013, 0.4508, 0.4177, 0.4638, 0.3701,\n",
       "          0.4453, 0.4110, 0.4118, 0.4747, 0.4589, 0.4687, 0.5090, 0.4897, 0.4052]],\n",
       "        device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>),\n",
       " tensor([[0.4157, 0.4379, 0.4376, 0.5406, 0.3908, 0.3909, 0.3350, 0.5026, 0.4032,\n",
       "          0.4622, 0.5211, 0.5100, 0.4749, 0.4678, 0.4591, 0.4092, 0.3592, 0.4809,\n",
       "          0.2723, 0.4971, 0.4709, 0.5533, 0.5569, 0.3592, 0.4082, 0.4433, 0.4167,\n",
       "          0.4218, 0.4229, 0.4112, 0.5696, 0.3636, 0.4704, 0.4239, 0.4031, 0.5232,\n",
       "          0.3620, 0.4193, 0.4189, 0.5261, 0.3838, 0.4318, 0.4047, 0.4753, 0.3694,\n",
       "          0.4144, 0.4478, 0.4036, 0.4766, 0.4622, 0.4951, 0.4852, 0.4607, 0.3854],\n",
       "         [0.4068, 0.4108, 0.4311, 0.5118, 0.3243, 0.4094, 0.3168, 0.4825, 0.3727,\n",
       "          0.4763, 0.5395, 0.5387, 0.4553, 0.4288, 0.4902, 0.4519, 0.3234, 0.4670,\n",
       "          0.2645, 0.4714, 0.4722, 0.5779, 0.5456, 0.3303, 0.3901, 0.4673, 0.4138,\n",
       "          0.3900, 0.4734, 0.3548, 0.5541, 0.3346, 0.4631, 0.3951, 0.4001, 0.5087,\n",
       "          0.3800, 0.3863, 0.4444, 0.4954, 0.3798, 0.4578, 0.4143, 0.4785, 0.3754,\n",
       "          0.4360, 0.4080, 0.4070, 0.4742, 0.4894, 0.4620, 0.5169, 0.5101, 0.4001],\n",
       "         [0.4325, 0.4014, 0.4311, 0.5143, 0.3811, 0.3892, 0.3271, 0.5021, 0.3730,\n",
       "          0.4892, 0.5106, 0.5162, 0.4959, 0.4644, 0.4839, 0.4175, 0.3401, 0.4788,\n",
       "          0.2776, 0.4669, 0.4591, 0.5592, 0.5435, 0.3630, 0.3687, 0.4518, 0.3963,\n",
       "          0.4339, 0.4522, 0.3809, 0.5592, 0.3445, 0.4747, 0.4259, 0.3951, 0.5097,\n",
       "          0.3659, 0.3951, 0.4218, 0.5157, 0.3907, 0.4137, 0.4349, 0.4569, 0.4042,\n",
       "          0.4381, 0.4373, 0.4071, 0.4509, 0.4811, 0.4969, 0.4919, 0.4696, 0.3996],\n",
       "         [0.4115, 0.4170, 0.4274, 0.5321, 0.4078, 0.3720, 0.3549, 0.5089, 0.3958,\n",
       "          0.4606, 0.5011, 0.4947, 0.4784, 0.4738, 0.4681, 0.4110, 0.3749, 0.4965,\n",
       "          0.2510, 0.4982, 0.4715, 0.5567, 0.5418, 0.3750, 0.3994, 0.4664, 0.4250,\n",
       "          0.4068, 0.4201, 0.4105, 0.5558, 0.3645, 0.4745, 0.4327, 0.4146, 0.5303,\n",
       "          0.3431, 0.4119, 0.4086, 0.5213, 0.3762, 0.4093, 0.4311, 0.4911, 0.3716,\n",
       "          0.4198, 0.4648, 0.3939, 0.4574, 0.4795, 0.5144, 0.4838, 0.4514, 0.3870],\n",
       "         [0.4190, 0.4038, 0.4279, 0.5183, 0.4239, 0.3816, 0.3560, 0.5044, 0.3897,\n",
       "          0.4582, 0.4953, 0.4843, 0.4946, 0.4891, 0.4697, 0.3992, 0.3753, 0.4921,\n",
       "          0.2601, 0.4896, 0.4634, 0.5529, 0.5439, 0.3821, 0.3946, 0.4588, 0.4204,\n",
       "          0.4202, 0.4257, 0.4116, 0.5703, 0.3687, 0.4684, 0.4442, 0.4103, 0.5275,\n",
       "          0.3405, 0.4061, 0.4135, 0.5301, 0.3832, 0.3998, 0.4477, 0.4766, 0.3835,\n",
       "          0.4296, 0.4565, 0.3892, 0.4503, 0.4742, 0.5180, 0.4892, 0.4457, 0.3903],\n",
       "         [0.4346, 0.4100, 0.4466, 0.5087, 0.3680, 0.4210, 0.3225, 0.4788, 0.3803,\n",
       "          0.4677, 0.5224, 0.5172, 0.4888, 0.4618, 0.4556, 0.4321, 0.3419, 0.4648,\n",
       "          0.2883, 0.4664, 0.4444, 0.5718, 0.5619, 0.3471, 0.3942, 0.4442, 0.4079,\n",
       "          0.4293, 0.4622, 0.3833, 0.5586, 0.3553, 0.4512, 0.4034, 0.3972, 0.5075,\n",
       "          0.3784, 0.4010, 0.4423, 0.5155, 0.4087, 0.4293, 0.4341, 0.4515, 0.3924,\n",
       "          0.4492, 0.4220, 0.4139, 0.4563, 0.4613, 0.4847, 0.4936, 0.4706, 0.4166],\n",
       "         [0.4298, 0.4206, 0.4388, 0.5167, 0.3728, 0.3991, 0.3284, 0.4945, 0.3857,\n",
       "          0.4792, 0.5256, 0.5174, 0.4873, 0.4634, 0.4700, 0.4233, 0.3476, 0.4759,\n",
       "          0.2808, 0.4723, 0.4523, 0.5608, 0.5580, 0.3523, 0.3969, 0.4400, 0.4073,\n",
       "          0.4213, 0.4425, 0.3916, 0.5583, 0.3613, 0.4633, 0.4108, 0.4014, 0.5165,\n",
       "          0.3715, 0.4053, 0.4253, 0.5151, 0.3984, 0.4260, 0.4176, 0.4662, 0.3910,\n",
       "          0.4369, 0.4312, 0.4115, 0.4565, 0.4656, 0.4836, 0.4943, 0.4743, 0.4042],\n",
       "         [0.4274, 0.3894, 0.4323, 0.5094, 0.3636, 0.3954, 0.3302, 0.4972, 0.3668,\n",
       "          0.4803, 0.5260, 0.5212, 0.4851, 0.4573, 0.4891, 0.4388, 0.3331, 0.4848,\n",
       "          0.2563, 0.4681, 0.4688, 0.5687, 0.5388, 0.3504, 0.3703, 0.4726, 0.4019,\n",
       "          0.4117, 0.4622, 0.3582, 0.5597, 0.3337, 0.4663, 0.4192, 0.3947, 0.5199,\n",
       "          0.3527, 0.3755, 0.4254, 0.5171, 0.3791, 0.4256, 0.4415, 0.4694, 0.3906,\n",
       "          0.4380, 0.4228, 0.3959, 0.4481, 0.4868, 0.4907, 0.5097, 0.4834, 0.4020],\n",
       "         [0.3863, 0.4506, 0.4271, 0.5352, 0.3356, 0.4068, 0.3248, 0.4704, 0.4078,\n",
       "          0.4455, 0.5375, 0.5211, 0.4343, 0.4225, 0.4637, 0.4475, 0.3461, 0.4659,\n",
       "          0.2667, 0.4936, 0.4823, 0.5777, 0.5666, 0.3309, 0.4303, 0.4585, 0.4416,\n",
       "          0.3714, 0.4530, 0.3986, 0.5524, 0.3631, 0.4546, 0.3880, 0.4170, 0.5168,\n",
       "          0.3774, 0.4167, 0.4389, 0.5007, 0.3804, 0.4793, 0.3925, 0.4951, 0.3514,\n",
       "          0.4082, 0.4224, 0.4031, 0.5016, 0.4740, 0.4641, 0.5076, 0.5019, 0.3942],\n",
       "         [0.4199, 0.4129, 0.4346, 0.5230, 0.4027, 0.3795, 0.3483, 0.5017, 0.3911,\n",
       "          0.4615, 0.5049, 0.4997, 0.4895, 0.4855, 0.4634, 0.4131, 0.3755, 0.4916,\n",
       "          0.2595, 0.4927, 0.4612, 0.5555, 0.5473, 0.3697, 0.4005, 0.4565, 0.4151,\n",
       "          0.4198, 0.4202, 0.4072, 0.5615, 0.3599, 0.4681, 0.4289, 0.4110, 0.5324,\n",
       "          0.3474, 0.4086, 0.4100, 0.5251, 0.3867, 0.4149, 0.4318, 0.4799, 0.3757,\n",
       "          0.4291, 0.4574, 0.3978, 0.4497, 0.4671, 0.5083, 0.4828, 0.4502, 0.3888],\n",
       "         [0.4110, 0.4059, 0.4240, 0.5196, 0.4152, 0.3885, 0.3622, 0.5004, 0.3969,\n",
       "          0.4502, 0.4935, 0.4810, 0.4833, 0.4754, 0.4589, 0.4037, 0.3742, 0.4980,\n",
       "          0.2649, 0.4944, 0.4836, 0.5609, 0.5362, 0.3794, 0.3976, 0.4717, 0.4291,\n",
       "          0.4112, 0.4326, 0.4142, 0.5662, 0.3637, 0.4680, 0.4507, 0.4064, 0.5232,\n",
       "          0.3460, 0.4100, 0.4215, 0.5398, 0.3832, 0.4060, 0.4452, 0.4772, 0.3673,\n",
       "          0.4242, 0.4578, 0.3832, 0.4695, 0.4766, 0.5145, 0.4881, 0.4484, 0.3775],\n",
       "         [0.4186, 0.4080, 0.4312, 0.5281, 0.4016, 0.3744, 0.3498, 0.5078, 0.3839,\n",
       "          0.4707, 0.5022, 0.5018, 0.4837, 0.4741, 0.4808, 0.4075, 0.3698, 0.5017,\n",
       "          0.2585, 0.4923, 0.4737, 0.5474, 0.5386, 0.3756, 0.3858, 0.4580, 0.4162,\n",
       "          0.4178, 0.4313, 0.4001, 0.5657, 0.3578, 0.4841, 0.4387, 0.4088, 0.5283,\n",
       "          0.3468, 0.4066, 0.4101, 0.5212, 0.3777, 0.4062, 0.4267, 0.4807, 0.3787,\n",
       "          0.4254, 0.4572, 0.3922, 0.4628, 0.4747, 0.5145, 0.4903, 0.4601, 0.3869],\n",
       "         [0.4268, 0.4195, 0.4484, 0.5075, 0.3947, 0.4165, 0.3356, 0.4827, 0.3981,\n",
       "          0.4516, 0.5094, 0.4952, 0.4982, 0.4891, 0.4435, 0.4056, 0.3637, 0.4628,\n",
       "          0.2995, 0.4765, 0.4335, 0.5651, 0.5720, 0.3589, 0.4174, 0.4354, 0.4139,\n",
       "          0.4325, 0.4395, 0.4210, 0.5646, 0.3849, 0.4447, 0.4104, 0.4113, 0.5145,\n",
       "          0.3723, 0.4241, 0.4413, 0.5231, 0.4148, 0.4135, 0.4256, 0.4537, 0.3825,\n",
       "          0.4429, 0.4328, 0.4133, 0.4602, 0.4491, 0.4888, 0.4859, 0.4547, 0.3995],\n",
       "         [0.3925, 0.4565, 0.4414, 0.5289, 0.3433, 0.4272, 0.3145, 0.4660, 0.4163,\n",
       "          0.4293, 0.5404, 0.5196, 0.4421, 0.4295, 0.4432, 0.4374, 0.3444, 0.4539,\n",
       "          0.2828, 0.4939, 0.4588, 0.5845, 0.5850, 0.3239, 0.4363, 0.4463, 0.4399,\n",
       "          0.3846, 0.4508, 0.4059, 0.5650, 0.3798, 0.4398, 0.3813, 0.4155, 0.5096,\n",
       "          0.3773, 0.4273, 0.4510, 0.5110, 0.3896, 0.4791, 0.3931, 0.4841, 0.3542,\n",
       "          0.4175, 0.4186, 0.4099, 0.5000, 0.4599, 0.4588, 0.5044, 0.4873, 0.4003],\n",
       "         [0.3877, 0.4254, 0.4319, 0.5173, 0.3548, 0.3991, 0.3387, 0.4744, 0.3954,\n",
       "          0.4403, 0.5249, 0.5081, 0.4509, 0.4309, 0.4739, 0.4461, 0.3570, 0.4751,\n",
       "          0.2569, 0.4873, 0.4812, 0.5854, 0.5518, 0.3346, 0.4137, 0.4751, 0.4437,\n",
       "          0.3725, 0.4581, 0.3882, 0.5504, 0.3596, 0.4550, 0.4090, 0.4196, 0.5204,\n",
       "          0.3553, 0.4043, 0.4390, 0.5056, 0.3725, 0.4568, 0.4201, 0.4969, 0.3535,\n",
       "          0.4223, 0.4336, 0.3881, 0.4826, 0.4851, 0.4829, 0.5142, 0.4924, 0.3953],\n",
       "         [0.4040, 0.4235, 0.4365, 0.5196, 0.3657, 0.4007, 0.3399, 0.4760, 0.3915,\n",
       "          0.4473, 0.5198, 0.5066, 0.4598, 0.4582, 0.4656, 0.4232, 0.3636, 0.4715,\n",
       "          0.2603, 0.4975, 0.4690, 0.5696, 0.5576, 0.3435, 0.4172, 0.4603, 0.4280,\n",
       "          0.3929, 0.4441, 0.3997, 0.5595, 0.3637, 0.4556, 0.4133, 0.4165, 0.5275,\n",
       "          0.3554, 0.4168, 0.4342, 0.5109, 0.3798, 0.4403, 0.4151, 0.4804, 0.3553,\n",
       "          0.4257, 0.4339, 0.3960, 0.4742, 0.4694, 0.4846, 0.5048, 0.4824, 0.3884]],\n",
       "        device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>),\n",
       " tensor([[0.3925, 0.4403, 0.4321, 0.5320, 0.3789, 0.3929, 0.3524, 0.4913, 0.4192,\n",
       "          0.4427, 0.5151, 0.4947, 0.4567, 0.4670, 0.4574, 0.4043, 0.3754, 0.4759,\n",
       "          0.2716, 0.5025, 0.4710, 0.5512, 0.5625, 0.3529, 0.4335, 0.4556, 0.4365,\n",
       "          0.3917, 0.4251, 0.4290, 0.5753, 0.3765, 0.4654, 0.4103, 0.4178, 0.5264,\n",
       "          0.3602, 0.4304, 0.4353, 0.5170, 0.3753, 0.4364, 0.4046, 0.4878, 0.3474,\n",
       "          0.4138, 0.4457, 0.3961, 0.4913, 0.4649, 0.4846, 0.4938, 0.4713, 0.3766],\n",
       "         [0.4138, 0.4275, 0.4287, 0.5272, 0.3643, 0.3937, 0.3235, 0.4913, 0.4027,\n",
       "          0.4647, 0.5219, 0.5201, 0.4651, 0.4475, 0.4704, 0.4244, 0.3410, 0.4740,\n",
       "          0.2760, 0.4874, 0.4678, 0.5628, 0.5594, 0.3455, 0.3998, 0.4502, 0.4147,\n",
       "          0.4082, 0.4507, 0.3987, 0.5712, 0.3549, 0.4637, 0.4112, 0.3978, 0.5105,\n",
       "          0.3701, 0.4057, 0.4236, 0.5176, 0.3810, 0.4457, 0.4125, 0.4736, 0.3789,\n",
       "          0.4159, 0.4356, 0.4000, 0.4837, 0.4775, 0.4814, 0.4987, 0.4736, 0.3919],\n",
       "         [0.4034, 0.4029, 0.4243, 0.5063, 0.3656, 0.4012, 0.3459, 0.4810, 0.3870,\n",
       "          0.4564, 0.5121, 0.5008, 0.4659, 0.4523, 0.4774, 0.4259, 0.3495, 0.4735,\n",
       "          0.2717, 0.4769, 0.4685, 0.5721, 0.5403, 0.3539, 0.3984, 0.4686, 0.4258,\n",
       "          0.3972, 0.4664, 0.3957, 0.5595, 0.3552, 0.4604, 0.4204, 0.4023, 0.5097,\n",
       "          0.3625, 0.4012, 0.4406, 0.5108, 0.3843, 0.4280, 0.4364, 0.4763, 0.3734,\n",
       "          0.4328, 0.4330, 0.3907, 0.4713, 0.4862, 0.4884, 0.5070, 0.4812, 0.3912],\n",
       "         [0.4318, 0.4034, 0.4310, 0.5134, 0.3978, 0.3786, 0.3412, 0.5045, 0.3839,\n",
       "          0.4768, 0.4998, 0.5108, 0.4964, 0.4828, 0.4731, 0.4103, 0.3604, 0.4870,\n",
       "          0.2715, 0.4794, 0.4553, 0.5539, 0.5432, 0.3759, 0.3807, 0.4526, 0.4000,\n",
       "          0.4327, 0.4354, 0.4028, 0.5661, 0.3502, 0.4707, 0.4253, 0.3953, 0.5179,\n",
       "          0.3611, 0.3989, 0.4117, 0.5235, 0.3928, 0.4071, 0.4348, 0.4673, 0.3987,\n",
       "          0.4349, 0.4574, 0.4039, 0.4466, 0.4724, 0.5083, 0.4789, 0.4547, 0.3898],\n",
       "         [0.4036, 0.4267, 0.4364, 0.5090, 0.3920, 0.3998, 0.3530, 0.4781, 0.4032,\n",
       "          0.4453, 0.4988, 0.4905, 0.4714, 0.4730, 0.4574, 0.4121, 0.3822, 0.4736,\n",
       "          0.2823, 0.4886, 0.4563, 0.5600, 0.5564, 0.3672, 0.4253, 0.4498, 0.4309,\n",
       "          0.4056, 0.4352, 0.4304, 0.5562, 0.3818, 0.4636, 0.4228, 0.4183, 0.5217,\n",
       "          0.3679, 0.4254, 0.4366, 0.5104, 0.3989, 0.4200, 0.4177, 0.4790, 0.3640,\n",
       "          0.4275, 0.4468, 0.4029, 0.4765, 0.4629, 0.4915, 0.4889, 0.4682, 0.3869],\n",
       "         [0.4097, 0.4286, 0.4444, 0.5172, 0.3758, 0.3998, 0.3498, 0.4842, 0.3961,\n",
       "          0.4512, 0.5170, 0.5045, 0.4761, 0.4709, 0.4602, 0.4128, 0.3751, 0.4654,\n",
       "          0.2802, 0.4877, 0.4487, 0.5601, 0.5615, 0.3532, 0.4241, 0.4413, 0.4248,\n",
       "          0.4056, 0.4305, 0.4191, 0.5610, 0.3739, 0.4591, 0.4054, 0.4147, 0.5283,\n",
       "          0.3677, 0.4235, 0.4389, 0.5024, 0.3957, 0.4346, 0.4184, 0.4751, 0.3653,\n",
       "          0.4387, 0.4401, 0.4105, 0.4684, 0.4589, 0.4898, 0.4930, 0.4746, 0.3926],\n",
       "         [0.4368, 0.4172, 0.4550, 0.4948, 0.3745, 0.4135, 0.3287, 0.4799, 0.3831,\n",
       "          0.4727, 0.5247, 0.5169, 0.4973, 0.4801, 0.4647, 0.4203, 0.3586, 0.4571,\n",
       "          0.2954, 0.4624, 0.4293, 0.5626, 0.5626, 0.3537, 0.4055, 0.4254, 0.3980,\n",
       "          0.4340, 0.4449, 0.3963, 0.5534, 0.3662, 0.4546, 0.3967, 0.4071, 0.5158,\n",
       "          0.3824, 0.4131, 0.4412, 0.4975, 0.4185, 0.4229, 0.4207, 0.4478, 0.3932,\n",
       "          0.4556, 0.4259, 0.4301, 0.4466, 0.4513, 0.4872, 0.4924, 0.4788, 0.4075],\n",
       "         [0.4113, 0.4193, 0.4235, 0.5230, 0.3544, 0.3914, 0.3342, 0.4962, 0.3859,\n",
       "          0.4776, 0.5212, 0.5220, 0.4648, 0.4500, 0.4857, 0.4306, 0.3385, 0.4750,\n",
       "          0.2682, 0.4793, 0.4729, 0.5575, 0.5394, 0.3507, 0.3920, 0.4638, 0.4142,\n",
       "          0.4024, 0.4573, 0.3834, 0.5646, 0.3441, 0.4728, 0.4096, 0.3995, 0.5116,\n",
       "          0.3691, 0.3982, 0.4329, 0.5091, 0.3805, 0.4381, 0.4197, 0.4783, 0.3801,\n",
       "          0.4258, 0.4269, 0.4004, 0.4736, 0.4835, 0.4865, 0.5007, 0.4884, 0.3935],\n",
       "         [0.3926, 0.4358, 0.4258, 0.5228, 0.3725, 0.3931, 0.3481, 0.4864, 0.4058,\n",
       "          0.4536, 0.5077, 0.4982, 0.4571, 0.4548, 0.4699, 0.4162, 0.3679, 0.4743,\n",
       "          0.2756, 0.4916, 0.4707, 0.5641, 0.5503, 0.3576, 0.4196, 0.4564, 0.4321,\n",
       "          0.3903, 0.4388, 0.4224, 0.5646, 0.3763, 0.4689, 0.4172, 0.4110, 0.5150,\n",
       "          0.3667, 0.4246, 0.4342, 0.5099, 0.3823, 0.4392, 0.4002, 0.4895, 0.3615,\n",
       "          0.4130, 0.4395, 0.3990, 0.4929, 0.4701, 0.4816, 0.4963, 0.4798, 0.3780],\n",
       "         [0.4454, 0.4056, 0.4449, 0.5079, 0.3825, 0.3967, 0.3245, 0.4900, 0.3793,\n",
       "          0.4720, 0.5151, 0.5211, 0.5026, 0.4798, 0.4659, 0.4255, 0.3470, 0.4722,\n",
       "          0.2835, 0.4683, 0.4416, 0.5608, 0.5505, 0.3576, 0.3842, 0.4395, 0.3912,\n",
       "          0.4355, 0.4504, 0.3922, 0.5652, 0.3499, 0.4542, 0.4113, 0.3909, 0.5110,\n",
       "          0.3742, 0.3950, 0.4248, 0.5079, 0.4071, 0.4248, 0.4419, 0.4532, 0.4050,\n",
       "          0.4447, 0.4317, 0.4119, 0.4434, 0.4673, 0.4990, 0.4841, 0.4616, 0.4085],\n",
       "         [0.4287, 0.3907, 0.4370, 0.5087, 0.4020, 0.3881, 0.3619, 0.4967, 0.3745,\n",
       "          0.4705, 0.5020, 0.4923, 0.4971, 0.4966, 0.4789, 0.4006, 0.3734, 0.4780,\n",
       "          0.2661, 0.4816, 0.4571, 0.5487, 0.5359, 0.3762, 0.3922, 0.4573, 0.4032,\n",
       "          0.4313, 0.4328, 0.3999, 0.5687, 0.3579, 0.4754, 0.4354, 0.4016, 0.5288,\n",
       "          0.3532, 0.4003, 0.4309, 0.5116, 0.3934, 0.3945, 0.4462, 0.4611, 0.3840,\n",
       "          0.4495, 0.4438, 0.4028, 0.4421, 0.4706, 0.5048, 0.4851, 0.4663, 0.3862],\n",
       "         [0.4352, 0.4132, 0.4493, 0.5006, 0.3653, 0.4092, 0.3244, 0.4779, 0.3842,\n",
       "          0.4678, 0.5259, 0.5232, 0.4944, 0.4638, 0.4682, 0.4315, 0.3423, 0.4648,\n",
       "          0.2865, 0.4636, 0.4395, 0.5729, 0.5631, 0.3467, 0.3971, 0.4428, 0.3957,\n",
       "          0.4249, 0.4603, 0.3847, 0.5591, 0.3515, 0.4520, 0.4018, 0.3952, 0.5118,\n",
       "          0.3730, 0.4011, 0.4350, 0.5050, 0.4027, 0.4411, 0.4330, 0.4553, 0.3938,\n",
       "          0.4447, 0.4313, 0.4143, 0.4485, 0.4683, 0.4855, 0.4993, 0.4792, 0.4076],\n",
       "         [0.4034, 0.4176, 0.4427, 0.5048, 0.3393, 0.4086, 0.3311, 0.4757, 0.3826,\n",
       "          0.4660, 0.5294, 0.5238, 0.4543, 0.4508, 0.4815, 0.4404, 0.3500, 0.4611,\n",
       "          0.2754, 0.4701, 0.4590, 0.5687, 0.5504, 0.3372, 0.4091, 0.4602, 0.4187,\n",
       "          0.3969, 0.4656, 0.3821, 0.5546, 0.3554, 0.4620, 0.3954, 0.4076, 0.5211,\n",
       "          0.3815, 0.4046, 0.4508, 0.4944, 0.3917, 0.4397, 0.4061, 0.4783, 0.3704,\n",
       "          0.4378, 0.4172, 0.4103, 0.4762, 0.4751, 0.4675, 0.5103, 0.5049, 0.3930],\n",
       "         [0.4095, 0.4251, 0.4348, 0.5186, 0.3530, 0.4032, 0.3394, 0.4806, 0.3899,\n",
       "          0.4593, 0.5198, 0.5167, 0.4642, 0.4547, 0.4700, 0.4280, 0.3504, 0.4696,\n",
       "          0.2741, 0.4832, 0.4660, 0.5682, 0.5483, 0.3515, 0.4089, 0.4602, 0.4228,\n",
       "          0.4045, 0.4565, 0.3939, 0.5568, 0.3532, 0.4622, 0.4104, 0.4028, 0.5175,\n",
       "          0.3708, 0.4098, 0.4375, 0.5093, 0.3859, 0.4421, 0.4142, 0.4812, 0.3673,\n",
       "          0.4274, 0.4349, 0.3992, 0.4751, 0.4747, 0.4844, 0.4990, 0.4859, 0.3890],\n",
       "         [0.4030, 0.4287, 0.4333, 0.5230, 0.3918, 0.3894, 0.3462, 0.4928, 0.4073,\n",
       "          0.4513, 0.5125, 0.4996, 0.4720, 0.4636, 0.4658, 0.4154, 0.3724, 0.4809,\n",
       "          0.2677, 0.4918, 0.4669, 0.5552, 0.5531, 0.3607, 0.4102, 0.4547, 0.4271,\n",
       "          0.4008, 0.4300, 0.4169, 0.5640, 0.3720, 0.4668, 0.4182, 0.4157, 0.5234,\n",
       "          0.3519, 0.4146, 0.4236, 0.5185, 0.3821, 0.4280, 0.4206, 0.4823, 0.3678,\n",
       "          0.4218, 0.4470, 0.3971, 0.4762, 0.4690, 0.4973, 0.4957, 0.4653, 0.3866],\n",
       "         [0.4416, 0.4151, 0.4599, 0.5005, 0.3804, 0.4257, 0.3239, 0.4760, 0.3853,\n",
       "          0.4628, 0.5178, 0.5132, 0.5012, 0.4911, 0.4503, 0.4102, 0.3511, 0.4502,\n",
       "          0.3061, 0.4672, 0.4248, 0.5676, 0.5669, 0.3491, 0.4047, 0.4270, 0.3909,\n",
       "          0.4468, 0.4479, 0.4067, 0.5744, 0.3685, 0.4421, 0.4044, 0.3911, 0.5174,\n",
       "          0.3861, 0.4188, 0.4461, 0.5160, 0.4247, 0.4200, 0.4276, 0.4345, 0.3974,\n",
       "          0.4545, 0.4254, 0.4199, 0.4477, 0.4398, 0.4804, 0.4874, 0.4630, 0.4043]],\n",
       "        device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>),\n",
       " tensor([[0.4454, 0.3873, 0.4495, 0.4750, 0.3724, 0.4289, 0.3565, 0.4551, 0.3692,\n",
       "          0.4711, 0.4785, 0.4898, 0.5137, 0.4820, 0.4736, 0.4097, 0.3802, 0.4709,\n",
       "          0.3150, 0.4555, 0.4155, 0.5980, 0.5241, 0.3837, 0.3935, 0.4375, 0.4277,\n",
       "          0.4128, 0.4522, 0.4085, 0.5339, 0.3859, 0.4513, 0.4265, 0.4192, 0.4853,\n",
       "          0.4244, 0.4171, 0.4594, 0.4867, 0.4438, 0.4006, 0.4345, 0.4540, 0.4017,\n",
       "          0.4810, 0.4269, 0.4202, 0.4330, 0.4427, 0.4881, 0.4928, 0.4854, 0.4177],\n",
       "         [0.4471, 0.3732, 0.4611, 0.4549, 0.3745, 0.4436, 0.3569, 0.4355, 0.3647,\n",
       "          0.4471, 0.4938, 0.4889, 0.5208, 0.4843, 0.4547, 0.4280, 0.3840, 0.4659,\n",
       "          0.3084, 0.4451, 0.4044, 0.6231, 0.5290, 0.3677, 0.3906, 0.4477, 0.4309,\n",
       "          0.4015, 0.4755, 0.3997, 0.5280, 0.3833, 0.4219, 0.4266, 0.4190, 0.4958,\n",
       "          0.4130, 0.3995, 0.4696, 0.4878, 0.4500, 0.4122, 0.4694, 0.4449, 0.3939,\n",
       "          0.4965, 0.4201, 0.4103, 0.4126, 0.4446, 0.4900, 0.5068, 0.4809, 0.4308]],\n",
       "        device='cuda:0', dtype=torch.float64, grad_fn=<SigmoidBackward0>)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a6f212dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('S{}'.format(continue_loss_weight) + 'C{}'.format(class_loss_weight))\n",
    "torch.save(gen, 'S{}'.format(continue_loss_weight) + 'C{}'.format(class_loss_weight) + '/generator.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e103dde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(dis, \"discriminator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1fc12f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "code = []\n",
    "for _, (_, _) in enumerate(dataloader):\n",
    "    random_seed = torch.randn(size,100,device=device)\n",
    "    code.append(random_seed.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "01f0388c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.18405181,  0.3474403 , -0.4338672 , ..., -0.59989655,\n",
       "         -1.4840362 ,  1.4561865 ],\n",
       "        [-0.6874366 ,  1.1854961 ,  1.9425753 , ...,  0.81960946,\n",
       "         -0.80745476,  1.9644248 ]],\n",
       "\n",
       "       [[ 2.412322  ,  0.42428076,  2.2353592 , ..., -0.6080607 ,\n",
       "         -0.9325176 ,  0.19616689],\n",
       "        [-0.21482939, -1.4967655 ,  0.62355584, ...,  0.321254  ,\n",
       "          0.40731668,  1.337819  ]],\n",
       "\n",
       "       [[ 0.7632291 , -0.66426784, -1.054891  , ...,  0.33789378,\n",
       "          1.6476296 , -0.13468306],\n",
       "        [ 0.60052055, -0.47188032,  0.53224206, ...,  1.131984  ,\n",
       "         -0.16372131,  1.6330242 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.4088    , -1.2291958 , -1.3228769 , ..., -1.4907095 ,\n",
       "          2.0660143 ,  0.38935608],\n",
       "        [-1.5556674 , -0.03103677, -0.49170062, ...,  0.3761546 ,\n",
       "          0.06743082,  0.83336544]],\n",
       "\n",
       "       [[-0.8994746 , -0.6177903 ,  1.3110586 , ..., -0.48771217,\n",
       "          1.1686409 ,  0.09050365],\n",
       "        [-0.6276376 ,  0.2094867 , -2.4547002 , ..., -0.64060026,\n",
       "          0.253011  ,  2.0871704 ]],\n",
       "\n",
       "       [[ 0.33422107, -1.45899   , -0.7603723 , ..., -0.9271214 ,\n",
       "          0.57333297,  1.4669557 ],\n",
       "        [-0.53714573,  2.3421931 , -0.32427225, ...,  0.59615654,\n",
       "         -0.93161386, -0.58406323]]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dcf42e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('S{}'.format(continue_loss_weight) + 'C{}'.format(class_loss_weight) + '/code.npy', code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "30d2c6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(accs, 'S{}'.format(continue_loss_weight) + 'C{}'.format(class_loss_weight) + '/accs.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d70990",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
