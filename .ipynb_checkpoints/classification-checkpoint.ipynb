{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f3373c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用伪码表生成wave从而得到对比训练集，防止恒正运算\n",
    "# server给subject提供一个伪码表，subject利用伪码表生成对应的对照集\n",
    "# 伪码与最终的hash key或者BCH code无关\n",
    "# 判别器需要保留一定的分辨能力\n",
    "# data index range [2, 66]\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import *\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import os\n",
    "\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "from preprocess import Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a43d9db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject 13 abandoned\n",
      "subject 16 abandoned\n",
      "subject 17 abandoned\n",
      "subject 18 abandoned\n",
      "subject 20 abandoned\n",
      "subject 26 abandoned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhz/anaconda3/lib/python3.9/site-packages/scipy/interpolate/fitpack2.py:280: UserWarning: \n",
      "The maximal number of iterations maxit (set to 20 by the program)\n",
      "allowed for finding a smoothing spline with fp=s has been reached: s\n",
      "too small.\n",
      "There is an approximation returned but the corresponding weighted sum\n",
      "of squared residuals does not satisfy the condition abs(fp-s)/s < tol.\n",
      "  warnings.warn(message)\n",
      "/home/dhz/anaconda3/lib/python3.9/site-packages/numpy/ma/core.py:5244: RuntimeWarning: Mean of empty slice.\n",
      "  result = super().mean(axis=axis, dtype=dtype, **kwargs)[()]\n",
      "/home/dhz/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3723: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject 42 abandoned\n",
      "subject 47 abandoned\n",
      "subject 48 abandoned\n",
      "subject 50 abandoned\n"
     ]
    }
   ],
   "source": [
    "series = []\n",
    "items = 1\n",
    "step = 3\n",
    "subject_num = 0\n",
    "\n",
    "for num in range(2, 66):\n",
    "    try:\n",
    "        series += Process(num).prepro(1024, step, items)\n",
    "        subject_num += 1\n",
    "    except:\n",
    "        print(f'subject {num} abandoned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08d52711",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, series, items, subject_num):\n",
    "        self.series = series\n",
    "        self.codes = []\n",
    "        self.subject_num = subject_num\n",
    "        self.labels = np.zeros((len(self.series), self.subject_num), dtype='double')\n",
    "        for i in range(self.subject_num):\n",
    "            for j in range(items):\n",
    "                self.labels[i + j][i] = 1.0            \n",
    "\n",
    "    # need to overload\n",
    "    def __len__(self):\n",
    "        return len(self.series)\n",
    "\n",
    "    # need to overload\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.series[idx]), torch.tensor(self.labels[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b57bff32",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 54 is out of bounds for axis 0 with size 54",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mMyDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitems\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubject_num\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubject_num\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(dataset,batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mMyDataset.__init__\u001b[0;34m(self, series, items, subject_num)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubject_num):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(items):\n\u001b[0;32m----> 9\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 54 is out of bounds for axis 0 with size 54"
     ]
    }
   ],
   "source": [
    "dataset = MyDataset(series, items=items, subject_num=subject_num)\n",
    "dataloader = torch.utils.data.DataLoader(dataset,batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce24c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionBlock(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(ConvolutionBlock, self).__init__()\n",
    "        self.block = nn.Sequential(nn.Conv1d(input_size, hidden_size, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(hidden_size, hidden_size, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1be6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes, num_layers, num_heads, dropout, num_conv_blocks):\n",
    "        super(TransformerClassifier, self).__init__()\n",
    "        self.conv1 = ConvolutionBlock(input_size, hidden_size)\n",
    "        self.conv_blocks = nn.ModuleList([\n",
    "            ConvolutionBlock(hidden_size, hidden_size) for _ in range(num_conv_blocks)\n",
    "        ])\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(hidden_size, num_heads, dim_feedforward=hidden_size, dropout=dropout),\n",
    "            num_layers\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        for conv_block in self.conv_blocks:\n",
    "            x = conv_block(x)\n",
    "        x = x.permute(0, 2, 1)  # Reshape to (batch_size, hidden_size, seq_len)\n",
    "        x = self.transformer(x)\n",
    "        x = x.mean(dim=1)  # Average the sequence dimension\n",
    "        x = torch.sigmoid(self.fc(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6306954",
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8981c70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "input_size = 1\n",
    "hidden_size = 128\n",
    "num_classes = 54\n",
    "num_layers = 6\n",
    "num_heads = 4\n",
    "dropout = 0.2\n",
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "num_conv_blocks = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c07c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = TransformerClassifier(input_size, hidden_size, num_classes, num_layers, num_heads, dropout, num_conv_blocks).to(device)\n",
    "cls = cls.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390cc0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cls.parameters(), lr=1e-6)\n",
    "# learning 2e-5, momentum 0.1, rate=50% max = 66.7%\n",
    "# learning 2e-5, momentum 2e-3, max = 94.4%\n",
    "# lr 2e-2, momentum 2e-3, max = 67.3%\n",
    "# with sigmoid\n",
    "# SGD lr 2e-5 momentum 2e-3 max = 33.3%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513addf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_loss = []\n",
    "C_acc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6ec9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(3000):\n",
    "    epoch_iterator = tqdm(dataloader, desc=\"Training Epoch %d\" % (epoch + 1), ncols = 100)\n",
    "    #初始化损失值\n",
    "    c_epoch_loss = 0\n",
    "    acc_num = 0\n",
    "    num = 0\n",
    "    count = len(dataloader) #返回批次数\n",
    "    #对数据集进行迭代\n",
    "    for step, (subject, label) in enumerate(epoch_iterator):\n",
    "        subject = torch.reshape(subject, (subject.size(0), 1, subject.size(1)))\n",
    "        subject = subject.to(device) #把数据放到设备上\n",
    "        label = label.to(device)\n",
    "        size = subject.size(0)\n",
    "        num += size\n",
    "        \n",
    "        class_train = cls(subject)\n",
    "        c_loss = criterion(class_train, label)\n",
    "        c_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        for i in range(subject.size(0)):\n",
    "            idx1 = torch.argmax(class_train[i])\n",
    "            idx2 = torch.argmax(label[i])\n",
    "            if idx1 == idx2:\n",
    "                acc_num += 1\n",
    "        \n",
    "        #累计每一个批次的loss\n",
    "        with torch.no_grad():\n",
    "            c_epoch_loss += c_loss\n",
    "        epoch_iterator.set_postfix({\"c_loss\": '{0:1.5f}'.format(c_epoch_loss), \"accuracy\": '{0:1.3f}'.format(acc_num / num)})\n",
    "        epoch_iterator.update(1)\n",
    "            \n",
    "    #求平均损失\n",
    "    with torch.no_grad():\n",
    "        c_epoch_loss /= count\n",
    "        acc = acc_num / num\n",
    "        C_loss.append(c_epoch_loss)\n",
    "        C_acc.append(acc)\n",
    "    if acc >=0.9:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e6ca06",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_curve = [i.cpu() for i in C_loss]\n",
    "plt.plot(c_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0039dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_curve = [i for i in C_acc]\n",
    "plt.plot(a_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6404364f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('c_curve.npy', c_curve)\n",
    "np.save('a_curve.npy', a_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a82198",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(cls, \"classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853dc0b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "582.844px",
    "left": "1495px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
