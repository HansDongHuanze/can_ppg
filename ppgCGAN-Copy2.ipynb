{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9eebafaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入库\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "import torchvision #加载图片\n",
    "from torchvision import transforms #图片变换\n",
    "\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    " \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt #绘图\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "from preprocess import Process\n",
    "from transformer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f369c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 32\n",
    "def get_random_seed(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "get_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a98ad843",
   "metadata": {},
   "outputs": [],
   "source": [
    "#独热编码\n",
    "def one_hot(x,class_count=10):\n",
    "    return torch.eye(class_count)[x,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64c2d341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject 13 abandoned\n",
      "subject 16 abandoned\n",
      "subject 17 abandoned\n",
      "subject 18 abandoned\n",
      "subject 20 abandoned\n",
      "subject 26 abandoned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhz/anaconda3/lib/python3.9/site-packages/scipy/interpolate/fitpack2.py:280: UserWarning: \n",
      "The maximal number of iterations maxit (set to 20 by the program)\n",
      "allowed for finding a smoothing spline with fp=s has been reached: s\n",
      "too small.\n",
      "There is an approximation returned but the corresponding weighted sum\n",
      "of squared residuals does not satisfy the condition abs(fp-s)/s < tol.\n",
      "  warnings.warn(message)\n",
      "/home/dhz/anaconda3/lib/python3.9/site-packages/numpy/ma/core.py:5244: RuntimeWarning: Mean of empty slice.\n",
      "  result = super().mean(axis=axis, dtype=dtype, **kwargs)[()]\n",
      "/home/dhz/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3723: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject 42 abandoned\n",
      "subject 47 abandoned\n",
      "subject 48 abandoned\n",
      "subject 50 abandoned\n"
     ]
    }
   ],
   "source": [
    "series = []\n",
    "items = 3\n",
    "step = 3\n",
    "subject_num = 0\n",
    "\n",
    "for num in range(2, 66):\n",
    "    try:\n",
    "        series += Process(num).prepro(1024, step, items)\n",
    "        subject_num += 1\n",
    "    except:\n",
    "        print(f'subject {num} abandoned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c6e9e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, series, items, subject_num):\n",
    "        self.series = series\n",
    "        self.codes = []\n",
    "        self.subject_num = subject_num\n",
    "        self.labels = np.zeros((len(self.series), self.subject_num), dtype='double')\n",
    "        for i in range(self.subject_num):\n",
    "            for j in range(items):\n",
    "                self.labels[i + j][i] = 1.0            \n",
    "\n",
    "    # need to overload\n",
    "    def __len__(self):\n",
    "        return len(self.series)\n",
    "\n",
    "    # need to overload\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.series[idx]), torch.tensor(self.labels[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "463a2d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset(series, items=items, subject_num=subject_num)\n",
    "dataloader = torch.utils.data.DataLoader(dataset,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0415007e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义生成器\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, subject_num):\n",
    "        super(Generator,self).__init__()\n",
    "        self.linear1 = nn.Linear(100,512)\n",
    "        self.bn1=nn.BatchNorm1d(512)\n",
    "        self.subject_num = subject_num\n",
    "        self.linear2 = nn.Linear(subject_num,512)\n",
    "        self.bn2=nn.BatchNorm1d(512)\n",
    "        \n",
    "        self.deconv1 = nn.Conv1d(1, 3, kernel_size=2, padding='same')\n",
    "        self.bn3=nn.BatchNorm1d(3)\n",
    "        self.deconv2 = nn.Conv1d(3, 6, kernel_size=2, padding='same')\n",
    "        self.bn4=nn.BatchNorm1d(6)\n",
    "        self.deconv3 = nn.Conv1d(6, 1, kernel_size=2, padding='same')\n",
    "        \n",
    "    def forward(self,x1,x2):\n",
    "        x1=F.relu(self.linear1(x1.to(torch.float64)))\n",
    "        x1=self.bn1(x1)\n",
    "        x2=F.relu(self.linear2(x2))\n",
    "        x2=self.bn2(x2)\n",
    "        x=torch.cat([x1,x2],axis=1)\n",
    "        x=F.relu(self.deconv1(torch.reshape(x, (x.size(0), 1, x.size(1)))))\n",
    "        x=self.bn3(x)\n",
    "        x=F.relu(self.deconv2(x))\n",
    "        x=self.bn4(x)\n",
    "        x=torch.tanh(self.deconv3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c55045ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义判别器\n",
    "#输入：1，28，28图片和长度为10的condition\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, subject_num):\n",
    "        super(Discriminator,self).__init__()\n",
    "        self.subject_num = subject_num\n",
    "        self.linear = nn.Linear(self.subject_num,1024)\n",
    "        self.conv1 = nn.Conv1d(1,32,kernel_size=2,padding='same')\n",
    "        self.conv2 = nn.Conv1d(32,128,kernel_size=2,padding='same')\n",
    "        self.bn = nn.BatchNorm1d(128)\n",
    "        self.fc = nn.Linear(2048,1)\n",
    "    def forward(self,x1,x2): #x1代表label,x2代表image\n",
    "        x1=F.leaky_relu(self.linear(x1))\n",
    "        x=torch.cat([x1,x2],axis=1)            \n",
    "        x= F.dropout1d(F.leaky_relu(self.conv1(torch.reshape(x, (x.size(0), 1, x.size(1))))))\n",
    "        x= F.dropout1d(F.leaky_relu(self.conv2(x)))\n",
    "        x = self.bn(x)\n",
    "        x = torch.sigmoid(self.fc(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b06c0a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContinuityLoss(nn.Module):\n",
    "    def __init__(self, weight=1.0):\n",
    "        super(ContinuityLoss, self).__init__()\n",
    "        self.weight = weight\n",
    "        \n",
    "    def forward(self, predictions):\n",
    "        diff = predictions[:][1:] - predictions[:][:-1]\n",
    "        loss = torch.mean(torch.abs(diff))\n",
    "        return loss * self.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55bc25ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxValueLoss(nn.Module):\n",
    "    def __init__(self, weight=1.0):\n",
    "        super(MaxValueLoss, self).__init__()\n",
    "        self.weight = weight\n",
    "        self.MCE = nn.CrossEntropyLoss()\n",
    "    def forward(self, input1):\n",
    "        input2 = torch.zeros_like(input1)\n",
    "        types = torch.argmax(input1, dim = 0, keepdim=False)\n",
    "        for i in range(input1.size(0)):\n",
    "            input2[i][types[i]] = 1\n",
    "        loss = self.MCE(input1, input2)\n",
    "        return loss * self.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86bdfd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassLoss(nn.Module):\n",
    "    def __init__(self, weight=1.0):\n",
    "        super(ClassLoss, self).__init__()\n",
    "        self.weight = weight\n",
    "    def forward(self, input1, input2):\n",
    "        diff = input1 - input2\n",
    "        loss = torch.mean(torch.abs(diff))\n",
    "        return loss * self.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64a75c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassLoss(nn.Module):\n",
    "    def __init__(self, weight=1.0):\n",
    "        super(ClassLoss, self).__init__()\n",
    "        self.weight = weight\n",
    "        self.MCE = nn.CrossEntropyLoss()\n",
    "    def forward(self, input1, input2):\n",
    "        loss = self.MCE(input1, input2)\n",
    "        return loss * self.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be96d7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#设备的配置\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#初化生成器和判别器把他们放到相应的设备上\n",
    "gen = Generator(subject_num).to(device)\n",
    "gen = gen.double()\n",
    "dis = Discriminator(subject_num).to(device)\n",
    "dis = dis.double()\n",
    "cls = torch.load(\"classification\").to(device)\n",
    "cls = cls.double()\n",
    "#交叉熵损失函数\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "continue_loss_weight = 1\n",
    "continue_loss = ContinuityLoss(weight=continue_loss_weight)\n",
    "class_loss_weight = 1\n",
    "class_loss = ClassLoss(weight=class_loss_weight)\n",
    "#训练器的优化器\n",
    "discriminator_rate = 1e-5\n",
    "generator_rate = 1e-4\n",
    "d_optimizer = torch.optim.Adam(dis.parameters(),lr=discriminator_rate)\n",
    "#训练生成器的优化器\n",
    "g_optimizer = torch.optim.Adam(gen.parameters(),lr=generator_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3004abc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#设置生成绘图图片的随机张量，这里可视化16张图片\n",
    "#生成16个长度为100的随机正态分布张量\n",
    "noise_seed = torch.randn(16,100,device=device)\n",
    "label_seed = torch.randint(0,subject_num,size=(16,))\n",
    "label_seed_onehot = one_hot(label_seed, class_count=subject_num).to(device)\n",
    " \n",
    "D_loss = [] #记录训练过程中判别器的损失\n",
    "G_loss = [] #记录训练过程中生成器的损失\n",
    "S_loss = []\n",
    "C_loss = []\n",
    "accs = []\n",
    "epoch_num = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77dc5c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhz/anaconda3/lib/python3.9/site-packages/torch/nn/modules/conv.py:309: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:895.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/4000], Discriminator Loss: 0.1067, Generator Loss: 0.3282, Series Loss: 0.0261, Class Loss: 0.2496, Accuracy: 0.0741\n",
      "Epoch [2/4000], Discriminator Loss: 0.1031, Generator Loss: 0.3254, Series Loss: 0.0259, Class Loss: 0.2494, Accuracy: 0.0864\n",
      "Epoch [3/4000], Discriminator Loss: 0.1004, Generator Loss: 0.3233, Series Loss: 0.0255, Class Loss: 0.2492, Accuracy: 0.1049\n",
      "Epoch [4/4000], Discriminator Loss: 0.0986, Generator Loss: 0.3219, Series Loss: 0.0251, Class Loss: 0.2490, Accuracy: 0.0926\n",
      "Epoch [5/4000], Discriminator Loss: 0.0970, Generator Loss: 0.3210, Series Loss: 0.0248, Class Loss: 0.2491, Accuracy: 0.1049\n",
      "Epoch [6/4000], Discriminator Loss: 0.0961, Generator Loss: 0.3204, Series Loss: 0.0245, Class Loss: 0.2491, Accuracy: 0.1049\n",
      "Epoch [7/4000], Discriminator Loss: 0.0955, Generator Loss: 0.3196, Series Loss: 0.0241, Class Loss: 0.2489, Accuracy: 0.1173\n",
      "Epoch [8/4000], Discriminator Loss: 0.0957, Generator Loss: 0.3190, Series Loss: 0.0238, Class Loss: 0.2487, Accuracy: 0.1296\n",
      "Epoch [9/4000], Discriminator Loss: 0.0955, Generator Loss: 0.3187, Series Loss: 0.0234, Class Loss: 0.2487, Accuracy: 0.1173\n",
      "Epoch [10/4000], Discriminator Loss: 0.0955, Generator Loss: 0.3182, Series Loss: 0.0231, Class Loss: 0.2486, Accuracy: 0.1296\n",
      "Epoch [11/4000], Discriminator Loss: 0.0954, Generator Loss: 0.3182, Series Loss: 0.0228, Class Loss: 0.2487, Accuracy: 0.1358\n",
      "Epoch [12/4000], Discriminator Loss: 0.0954, Generator Loss: 0.3175, Series Loss: 0.0225, Class Loss: 0.2485, Accuracy: 0.1420\n",
      "Epoch [13/4000], Discriminator Loss: 0.0954, Generator Loss: 0.3172, Series Loss: 0.0221, Class Loss: 0.2485, Accuracy: 0.1667\n",
      "Epoch [14/4000], Discriminator Loss: 0.0955, Generator Loss: 0.3168, Series Loss: 0.0219, Class Loss: 0.2484, Accuracy: 0.1420\n",
      "Epoch [15/4000], Discriminator Loss: 0.0952, Generator Loss: 0.3164, Series Loss: 0.0216, Class Loss: 0.2483, Accuracy: 0.1543\n",
      "Epoch [16/4000], Discriminator Loss: 0.0952, Generator Loss: 0.3159, Series Loss: 0.0212, Class Loss: 0.2482, Accuracy: 0.1420\n",
      "Epoch [17/4000], Discriminator Loss: 0.0952, Generator Loss: 0.3157, Series Loss: 0.0210, Class Loss: 0.2480, Accuracy: 0.1790\n",
      "Epoch [18/4000], Discriminator Loss: 0.0950, Generator Loss: 0.3158, Series Loss: 0.0206, Class Loss: 0.2482, Accuracy: 0.1667\n",
      "Epoch [19/4000], Discriminator Loss: 0.0952, Generator Loss: 0.3152, Series Loss: 0.0203, Class Loss: 0.2481, Accuracy: 0.1728\n",
      "Epoch [20/4000], Discriminator Loss: 0.0953, Generator Loss: 0.3145, Series Loss: 0.0200, Class Loss: 0.2479, Accuracy: 0.1728\n",
      "Epoch [21/4000], Discriminator Loss: 0.0949, Generator Loss: 0.3147, Series Loss: 0.0198, Class Loss: 0.2480, Accuracy: 0.1667\n",
      "Epoch [22/4000], Discriminator Loss: 0.0951, Generator Loss: 0.3138, Series Loss: 0.0194, Class Loss: 0.2478, Accuracy: 0.1543\n",
      "Epoch [23/4000], Discriminator Loss: 0.0949, Generator Loss: 0.3136, Series Loss: 0.0191, Class Loss: 0.2477, Accuracy: 0.1667\n",
      "Epoch [24/4000], Discriminator Loss: 0.0949, Generator Loss: 0.3131, Series Loss: 0.0188, Class Loss: 0.2478, Accuracy: 0.1481\n",
      "Epoch [25/4000], Discriminator Loss: 0.0950, Generator Loss: 0.3131, Series Loss: 0.0186, Class Loss: 0.2478, Accuracy: 0.1667\n",
      "Epoch [26/4000], Discriminator Loss: 0.0950, Generator Loss: 0.3126, Series Loss: 0.0183, Class Loss: 0.2476, Accuracy: 0.1605\n",
      "Epoch [27/4000], Discriminator Loss: 0.0950, Generator Loss: 0.3124, Series Loss: 0.0179, Class Loss: 0.2478, Accuracy: 0.1543\n",
      "Epoch [28/4000], Discriminator Loss: 0.0951, Generator Loss: 0.3120, Series Loss: 0.0178, Class Loss: 0.2475, Accuracy: 0.1667\n",
      "Epoch [29/4000], Discriminator Loss: 0.0953, Generator Loss: 0.3114, Series Loss: 0.0175, Class Loss: 0.2473, Accuracy: 0.1728\n",
      "Epoch [30/4000], Discriminator Loss: 0.0951, Generator Loss: 0.3114, Series Loss: 0.0172, Class Loss: 0.2474, Accuracy: 0.1543\n",
      "Epoch [31/4000], Discriminator Loss: 0.0949, Generator Loss: 0.3109, Series Loss: 0.0169, Class Loss: 0.2474, Accuracy: 0.1543\n",
      "Epoch [32/4000], Discriminator Loss: 0.0947, Generator Loss: 0.3105, Series Loss: 0.0167, Class Loss: 0.2472, Accuracy: 0.1852\n",
      "Epoch [33/4000], Discriminator Loss: 0.0949, Generator Loss: 0.3103, Series Loss: 0.0164, Class Loss: 0.2474, Accuracy: 0.1481\n",
      "Epoch [34/4000], Discriminator Loss: 0.0948, Generator Loss: 0.3101, Series Loss: 0.0161, Class Loss: 0.2473, Accuracy: 0.1543\n",
      "Epoch [35/4000], Discriminator Loss: 0.0950, Generator Loss: 0.3099, Series Loss: 0.0160, Class Loss: 0.2471, Accuracy: 0.1667\n",
      "Epoch [36/4000], Discriminator Loss: 0.0948, Generator Loss: 0.3097, Series Loss: 0.0158, Class Loss: 0.2472, Accuracy: 0.1667\n",
      "Epoch [37/4000], Discriminator Loss: 0.0950, Generator Loss: 0.3093, Series Loss: 0.0155, Class Loss: 0.2472, Accuracy: 0.1605\n",
      "Epoch [38/4000], Discriminator Loss: 0.0951, Generator Loss: 0.3090, Series Loss: 0.0152, Class Loss: 0.2472, Accuracy: 0.1667\n",
      "Epoch [39/4000], Discriminator Loss: 0.0949, Generator Loss: 0.3085, Series Loss: 0.0149, Class Loss: 0.2470, Accuracy: 0.1605\n",
      "Epoch [40/4000], Discriminator Loss: 0.0948, Generator Loss: 0.3082, Series Loss: 0.0146, Class Loss: 0.2469, Accuracy: 0.1420\n",
      "Epoch [41/4000], Discriminator Loss: 0.0948, Generator Loss: 0.3081, Series Loss: 0.0145, Class Loss: 0.2470, Accuracy: 0.1543\n",
      "Epoch [42/4000], Discriminator Loss: 0.0946, Generator Loss: 0.3080, Series Loss: 0.0143, Class Loss: 0.2469, Accuracy: 0.1605\n",
      "Epoch [43/4000], Discriminator Loss: 0.0947, Generator Loss: 0.3075, Series Loss: 0.0139, Class Loss: 0.2470, Accuracy: 0.1728\n",
      "Epoch [44/4000], Discriminator Loss: 0.0948, Generator Loss: 0.3074, Series Loss: 0.0137, Class Loss: 0.2469, Accuracy: 0.1728\n",
      "Epoch [45/4000], Discriminator Loss: 0.0952, Generator Loss: 0.3070, Series Loss: 0.0135, Class Loss: 0.2469, Accuracy: 0.1667\n",
      "Epoch [46/4000], Discriminator Loss: 0.0951, Generator Loss: 0.3071, Series Loss: 0.0134, Class Loss: 0.2469, Accuracy: 0.1790\n",
      "Epoch [47/4000], Discriminator Loss: 0.0951, Generator Loss: 0.3063, Series Loss: 0.0131, Class Loss: 0.2468, Accuracy: 0.1790\n",
      "Epoch [48/4000], Discriminator Loss: 0.0950, Generator Loss: 0.3062, Series Loss: 0.0128, Class Loss: 0.2468, Accuracy: 0.1728\n",
      "Epoch [49/4000], Discriminator Loss: 0.0949, Generator Loss: 0.3059, Series Loss: 0.0126, Class Loss: 0.2468, Accuracy: 0.1728\n",
      "Epoch [50/4000], Discriminator Loss: 0.0948, Generator Loss: 0.3056, Series Loss: 0.0125, Class Loss: 0.2465, Accuracy: 0.1667\n",
      "Epoch [51/4000], Discriminator Loss: 0.0953, Generator Loss: 0.3053, Series Loss: 0.0122, Class Loss: 0.2466, Accuracy: 0.1852\n",
      "Epoch [52/4000], Discriminator Loss: 0.0951, Generator Loss: 0.3052, Series Loss: 0.0121, Class Loss: 0.2466, Accuracy: 0.1852\n",
      "Epoch [53/4000], Discriminator Loss: 0.0950, Generator Loss: 0.3049, Series Loss: 0.0118, Class Loss: 0.2465, Accuracy: 0.2037\n",
      "Epoch [54/4000], Discriminator Loss: 0.0946, Generator Loss: 0.3045, Series Loss: 0.0116, Class Loss: 0.2464, Accuracy: 0.1852\n",
      "Epoch [55/4000], Discriminator Loss: 0.0950, Generator Loss: 0.3046, Series Loss: 0.0114, Class Loss: 0.2466, Accuracy: 0.1605\n",
      "Epoch [56/4000], Discriminator Loss: 0.0950, Generator Loss: 0.3041, Series Loss: 0.0112, Class Loss: 0.2465, Accuracy: 0.1605\n",
      "Epoch [57/4000], Discriminator Loss: 0.0948, Generator Loss: 0.3039, Series Loss: 0.0110, Class Loss: 0.2465, Accuracy: 0.1667\n",
      "Epoch [58/4000], Discriminator Loss: 0.0947, Generator Loss: 0.3034, Series Loss: 0.0108, Class Loss: 0.2463, Accuracy: 0.1914\n",
      "Epoch [59/4000], Discriminator Loss: 0.0945, Generator Loss: 0.3034, Series Loss: 0.0106, Class Loss: 0.2463, Accuracy: 0.1790\n",
      "Epoch [60/4000], Discriminator Loss: 0.0949, Generator Loss: 0.3033, Series Loss: 0.0104, Class Loss: 0.2464, Accuracy: 0.1790\n",
      "Epoch [61/4000], Discriminator Loss: 0.0950, Generator Loss: 0.3032, Series Loss: 0.0102, Class Loss: 0.2464, Accuracy: 0.1852\n",
      "Epoch [62/4000], Discriminator Loss: 0.0951, Generator Loss: 0.3029, Series Loss: 0.0100, Class Loss: 0.2463, Accuracy: 0.1914\n",
      "Epoch [63/4000], Discriminator Loss: 0.0955, Generator Loss: 0.3028, Series Loss: 0.0099, Class Loss: 0.2463, Accuracy: 0.1914\n",
      "Epoch [64/4000], Discriminator Loss: 0.0948, Generator Loss: 0.3026, Series Loss: 0.0097, Class Loss: 0.2463, Accuracy: 0.2037\n",
      "Epoch [65/4000], Discriminator Loss: 0.0951, Generator Loss: 0.3019, Series Loss: 0.0094, Class Loss: 0.2462, Accuracy: 0.1790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [66/4000], Discriminator Loss: 0.0945, Generator Loss: 0.3023, Series Loss: 0.0093, Class Loss: 0.2462, Accuracy: 0.1914\n",
      "Epoch [67/4000], Discriminator Loss: 0.0948, Generator Loss: 0.3017, Series Loss: 0.0091, Class Loss: 0.2461, Accuracy: 0.2099\n",
      "Epoch [68/4000], Discriminator Loss: 0.0947, Generator Loss: 0.3015, Series Loss: 0.0090, Class Loss: 0.2460, Accuracy: 0.1914\n",
      "Epoch [69/4000], Discriminator Loss: 0.0950, Generator Loss: 0.3015, Series Loss: 0.0089, Class Loss: 0.2460, Accuracy: 0.1914\n",
      "Epoch [70/4000], Discriminator Loss: 0.0943, Generator Loss: 0.3012, Series Loss: 0.0087, Class Loss: 0.2460, Accuracy: 0.1975\n",
      "Epoch [71/4000], Discriminator Loss: 0.0945, Generator Loss: 0.3013, Series Loss: 0.0085, Class Loss: 0.2460, Accuracy: 0.1852\n",
      "Epoch [72/4000], Discriminator Loss: 0.0946, Generator Loss: 0.3011, Series Loss: 0.0084, Class Loss: 0.2460, Accuracy: 0.1790\n",
      "Epoch [73/4000], Discriminator Loss: 0.0948, Generator Loss: 0.3008, Series Loss: 0.0083, Class Loss: 0.2459, Accuracy: 0.2037\n",
      "Epoch [74/4000], Discriminator Loss: 0.0948, Generator Loss: 0.3009, Series Loss: 0.0081, Class Loss: 0.2459, Accuracy: 0.1914\n",
      "Epoch [75/4000], Discriminator Loss: 0.0945, Generator Loss: 0.3004, Series Loss: 0.0080, Class Loss: 0.2459, Accuracy: 0.2037\n",
      "Epoch [76/4000], Discriminator Loss: 0.0946, Generator Loss: 0.3006, Series Loss: 0.0080, Class Loss: 0.2460, Accuracy: 0.1914\n",
      "Epoch [77/4000], Discriminator Loss: 0.0947, Generator Loss: 0.3004, Series Loss: 0.0078, Class Loss: 0.2458, Accuracy: 0.1975\n",
      "Epoch [78/4000], Discriminator Loss: 0.0943, Generator Loss: 0.3002, Series Loss: 0.0076, Class Loss: 0.2458, Accuracy: 0.1975\n",
      "Epoch [79/4000], Discriminator Loss: 0.0941, Generator Loss: 0.3001, Series Loss: 0.0075, Class Loss: 0.2458, Accuracy: 0.2037\n",
      "Epoch [80/4000], Discriminator Loss: 0.0944, Generator Loss: 0.3000, Series Loss: 0.0074, Class Loss: 0.2458, Accuracy: 0.1914\n",
      "Epoch [81/4000], Discriminator Loss: 0.0948, Generator Loss: 0.3001, Series Loss: 0.0073, Class Loss: 0.2459, Accuracy: 0.2160\n",
      "Epoch [82/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2997, Series Loss: 0.0072, Class Loss: 0.2457, Accuracy: 0.2222\n",
      "Epoch [83/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2997, Series Loss: 0.0071, Class Loss: 0.2457, Accuracy: 0.1975\n",
      "Epoch [84/4000], Discriminator Loss: 0.0944, Generator Loss: 0.2996, Series Loss: 0.0070, Class Loss: 0.2457, Accuracy: 0.1975\n",
      "Epoch [85/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2995, Series Loss: 0.0070, Class Loss: 0.2457, Accuracy: 0.2037\n",
      "Epoch [86/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2993, Series Loss: 0.0068, Class Loss: 0.2457, Accuracy: 0.1914\n",
      "Epoch [87/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2993, Series Loss: 0.0068, Class Loss: 0.2457, Accuracy: 0.1914\n",
      "Epoch [88/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2990, Series Loss: 0.0066, Class Loss: 0.2456, Accuracy: 0.2160\n",
      "Epoch [89/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2992, Series Loss: 0.0066, Class Loss: 0.2456, Accuracy: 0.2099\n",
      "Epoch [90/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2990, Series Loss: 0.0065, Class Loss: 0.2454, Accuracy: 0.1914\n",
      "Epoch [91/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2988, Series Loss: 0.0064, Class Loss: 0.2455, Accuracy: 0.2222\n",
      "Epoch [92/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2989, Series Loss: 0.0063, Class Loss: 0.2455, Accuracy: 0.2099\n",
      "Epoch [93/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2987, Series Loss: 0.0063, Class Loss: 0.2453, Accuracy: 0.2284\n",
      "Epoch [94/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2987, Series Loss: 0.0062, Class Loss: 0.2453, Accuracy: 0.2099\n",
      "Epoch [95/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2988, Series Loss: 0.0061, Class Loss: 0.2455, Accuracy: 0.2099\n",
      "Epoch [96/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2984, Series Loss: 0.0060, Class Loss: 0.2453, Accuracy: 0.2099\n",
      "Epoch [97/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2986, Series Loss: 0.0060, Class Loss: 0.2454, Accuracy: 0.2160\n",
      "Epoch [98/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2985, Series Loss: 0.0059, Class Loss: 0.2455, Accuracy: 0.2160\n",
      "Epoch [99/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2983, Series Loss: 0.0059, Class Loss: 0.2453, Accuracy: 0.2222\n",
      "Epoch [100/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2982, Series Loss: 0.0058, Class Loss: 0.2452, Accuracy: 0.2160\n",
      "Epoch [101/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2980, Series Loss: 0.0058, Class Loss: 0.2452, Accuracy: 0.2099\n",
      "Epoch [102/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2981, Series Loss: 0.0057, Class Loss: 0.2452, Accuracy: 0.2099\n",
      "Epoch [103/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2980, Series Loss: 0.0056, Class Loss: 0.2452, Accuracy: 0.2284\n",
      "Epoch [104/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2979, Series Loss: 0.0056, Class Loss: 0.2451, Accuracy: 0.2284\n",
      "Epoch [105/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2978, Series Loss: 0.0055, Class Loss: 0.2451, Accuracy: 0.2222\n",
      "Epoch [106/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2979, Series Loss: 0.0055, Class Loss: 0.2451, Accuracy: 0.2222\n",
      "Epoch [107/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2979, Series Loss: 0.0054, Class Loss: 0.2452, Accuracy: 0.2099\n",
      "Epoch [108/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2977, Series Loss: 0.0054, Class Loss: 0.2450, Accuracy: 0.2160\n",
      "Epoch [109/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2977, Series Loss: 0.0053, Class Loss: 0.2450, Accuracy: 0.2160\n",
      "Epoch [110/4000], Discriminator Loss: 0.0927, Generator Loss: 0.2977, Series Loss: 0.0053, Class Loss: 0.2451, Accuracy: 0.2222\n",
      "Epoch [111/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2975, Series Loss: 0.0052, Class Loss: 0.2451, Accuracy: 0.2037\n",
      "Epoch [112/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2976, Series Loss: 0.0052, Class Loss: 0.2451, Accuracy: 0.2222\n",
      "Epoch [113/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2975, Series Loss: 0.0051, Class Loss: 0.2450, Accuracy: 0.2346\n",
      "Epoch [114/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2972, Series Loss: 0.0051, Class Loss: 0.2450, Accuracy: 0.2284\n",
      "Epoch [115/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2972, Series Loss: 0.0051, Class Loss: 0.2450, Accuracy: 0.2284\n",
      "Epoch [116/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2973, Series Loss: 0.0051, Class Loss: 0.2449, Accuracy: 0.2346\n",
      "Epoch [117/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2971, Series Loss: 0.0049, Class Loss: 0.2448, Accuracy: 0.2469\n",
      "Epoch [118/4000], Discriminator Loss: 0.0926, Generator Loss: 0.2971, Series Loss: 0.0049, Class Loss: 0.2449, Accuracy: 0.2222\n",
      "Epoch [119/4000], Discriminator Loss: 0.0925, Generator Loss: 0.2971, Series Loss: 0.0049, Class Loss: 0.2450, Accuracy: 0.2160\n",
      "Epoch [120/4000], Discriminator Loss: 0.0923, Generator Loss: 0.2970, Series Loss: 0.0049, Class Loss: 0.2447, Accuracy: 0.2346\n",
      "Epoch [121/4000], Discriminator Loss: 0.0923, Generator Loss: 0.2971, Series Loss: 0.0048, Class Loss: 0.2449, Accuracy: 0.2284\n",
      "Epoch [122/4000], Discriminator Loss: 0.0924, Generator Loss: 0.2970, Series Loss: 0.0048, Class Loss: 0.2448, Accuracy: 0.2407\n",
      "Epoch [123/4000], Discriminator Loss: 0.0925, Generator Loss: 0.2969, Series Loss: 0.0048, Class Loss: 0.2448, Accuracy: 0.2407\n",
      "Epoch [124/4000], Discriminator Loss: 0.0923, Generator Loss: 0.2970, Series Loss: 0.0047, Class Loss: 0.2449, Accuracy: 0.2160\n",
      "Epoch [125/4000], Discriminator Loss: 0.0923, Generator Loss: 0.2970, Series Loss: 0.0047, Class Loss: 0.2448, Accuracy: 0.2407\n",
      "Epoch [126/4000], Discriminator Loss: 0.0926, Generator Loss: 0.2967, Series Loss: 0.0046, Class Loss: 0.2448, Accuracy: 0.2407\n",
      "Epoch [127/4000], Discriminator Loss: 0.0927, Generator Loss: 0.2968, Series Loss: 0.0046, Class Loss: 0.2448, Accuracy: 0.2346\n",
      "Epoch [128/4000], Discriminator Loss: 0.0919, Generator Loss: 0.2966, Series Loss: 0.0046, Class Loss: 0.2447, Accuracy: 0.2407\n",
      "Epoch [129/4000], Discriminator Loss: 0.0925, Generator Loss: 0.2968, Series Loss: 0.0046, Class Loss: 0.2448, Accuracy: 0.2284\n",
      "Epoch [130/4000], Discriminator Loss: 0.0922, Generator Loss: 0.2968, Series Loss: 0.0045, Class Loss: 0.2448, Accuracy: 0.2284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [131/4000], Discriminator Loss: 0.0922, Generator Loss: 0.2967, Series Loss: 0.0045, Class Loss: 0.2448, Accuracy: 0.2346\n",
      "Epoch [132/4000], Discriminator Loss: 0.0921, Generator Loss: 0.2967, Series Loss: 0.0045, Class Loss: 0.2446, Accuracy: 0.2407\n",
      "Epoch [133/4000], Discriminator Loss: 0.0923, Generator Loss: 0.2966, Series Loss: 0.0045, Class Loss: 0.2446, Accuracy: 0.2346\n",
      "Epoch [134/4000], Discriminator Loss: 0.0918, Generator Loss: 0.2964, Series Loss: 0.0044, Class Loss: 0.2445, Accuracy: 0.2407\n",
      "Epoch [135/4000], Discriminator Loss: 0.0918, Generator Loss: 0.2967, Series Loss: 0.0044, Class Loss: 0.2447, Accuracy: 0.2407\n",
      "Epoch [136/4000], Discriminator Loss: 0.0919, Generator Loss: 0.2965, Series Loss: 0.0044, Class Loss: 0.2447, Accuracy: 0.2469\n",
      "Epoch [137/4000], Discriminator Loss: 0.0919, Generator Loss: 0.2963, Series Loss: 0.0043, Class Loss: 0.2446, Accuracy: 0.2407\n",
      "Epoch [138/4000], Discriminator Loss: 0.0918, Generator Loss: 0.2965, Series Loss: 0.0043, Class Loss: 0.2447, Accuracy: 0.2346\n",
      "Epoch [139/4000], Discriminator Loss: 0.0919, Generator Loss: 0.2965, Series Loss: 0.0043, Class Loss: 0.2446, Accuracy: 0.2469\n",
      "Epoch [140/4000], Discriminator Loss: 0.0919, Generator Loss: 0.2964, Series Loss: 0.0043, Class Loss: 0.2446, Accuracy: 0.2407\n",
      "Epoch [141/4000], Discriminator Loss: 0.0916, Generator Loss: 0.2963, Series Loss: 0.0042, Class Loss: 0.2446, Accuracy: 0.2346\n",
      "Epoch [142/4000], Discriminator Loss: 0.0917, Generator Loss: 0.2962, Series Loss: 0.0042, Class Loss: 0.2444, Accuracy: 0.2407\n",
      "Epoch [143/4000], Discriminator Loss: 0.0919, Generator Loss: 0.2960, Series Loss: 0.0042, Class Loss: 0.2443, Accuracy: 0.2346\n",
      "Epoch [144/4000], Discriminator Loss: 0.0918, Generator Loss: 0.2961, Series Loss: 0.0041, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [145/4000], Discriminator Loss: 0.0914, Generator Loss: 0.2962, Series Loss: 0.0041, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [146/4000], Discriminator Loss: 0.0917, Generator Loss: 0.2963, Series Loss: 0.0041, Class Loss: 0.2445, Accuracy: 0.2407\n",
      "Epoch [147/4000], Discriminator Loss: 0.0918, Generator Loss: 0.2960, Series Loss: 0.0041, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [148/4000], Discriminator Loss: 0.0914, Generator Loss: 0.2962, Series Loss: 0.0040, Class Loss: 0.2445, Accuracy: 0.2346\n",
      "Epoch [149/4000], Discriminator Loss: 0.0914, Generator Loss: 0.2961, Series Loss: 0.0040, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [150/4000], Discriminator Loss: 0.0914, Generator Loss: 0.2961, Series Loss: 0.0040, Class Loss: 0.2444, Accuracy: 0.2407\n",
      "Epoch [151/4000], Discriminator Loss: 0.0913, Generator Loss: 0.2961, Series Loss: 0.0040, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [152/4000], Discriminator Loss: 0.0913, Generator Loss: 0.2959, Series Loss: 0.0040, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [153/4000], Discriminator Loss: 0.0913, Generator Loss: 0.2960, Series Loss: 0.0039, Class Loss: 0.2445, Accuracy: 0.2901\n",
      "Epoch [154/4000], Discriminator Loss: 0.0913, Generator Loss: 0.2959, Series Loss: 0.0039, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [155/4000], Discriminator Loss: 0.0910, Generator Loss: 0.2959, Series Loss: 0.0039, Class Loss: 0.2443, Accuracy: 0.2407\n",
      "Epoch [156/4000], Discriminator Loss: 0.0911, Generator Loss: 0.2958, Series Loss: 0.0039, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [157/4000], Discriminator Loss: 0.0913, Generator Loss: 0.2959, Series Loss: 0.0038, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [158/4000], Discriminator Loss: 0.0910, Generator Loss: 0.2958, Series Loss: 0.0038, Class Loss: 0.2443, Accuracy: 0.2469\n",
      "Epoch [159/4000], Discriminator Loss: 0.0911, Generator Loss: 0.2958, Series Loss: 0.0038, Class Loss: 0.2444, Accuracy: 0.2716\n",
      "Epoch [160/4000], Discriminator Loss: 0.0911, Generator Loss: 0.2957, Series Loss: 0.0038, Class Loss: 0.2443, Accuracy: 0.2716\n",
      "Epoch [161/4000], Discriminator Loss: 0.0908, Generator Loss: 0.2958, Series Loss: 0.0037, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [162/4000], Discriminator Loss: 0.0909, Generator Loss: 0.2957, Series Loss: 0.0037, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [163/4000], Discriminator Loss: 0.0908, Generator Loss: 0.2956, Series Loss: 0.0037, Class Loss: 0.2443, Accuracy: 0.2778\n",
      "Epoch [164/4000], Discriminator Loss: 0.0909, Generator Loss: 0.2957, Series Loss: 0.0037, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [165/4000], Discriminator Loss: 0.0908, Generator Loss: 0.2957, Series Loss: 0.0037, Class Loss: 0.2442, Accuracy: 0.2778\n",
      "Epoch [166/4000], Discriminator Loss: 0.0909, Generator Loss: 0.2956, Series Loss: 0.0037, Class Loss: 0.2443, Accuracy: 0.2778\n",
      "Epoch [167/4000], Discriminator Loss: 0.0908, Generator Loss: 0.2956, Series Loss: 0.0036, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [168/4000], Discriminator Loss: 0.0907, Generator Loss: 0.2956, Series Loss: 0.0036, Class Loss: 0.2442, Accuracy: 0.2901\n",
      "Epoch [169/4000], Discriminator Loss: 0.0906, Generator Loss: 0.2957, Series Loss: 0.0036, Class Loss: 0.2443, Accuracy: 0.2963\n",
      "Epoch [170/4000], Discriminator Loss: 0.0907, Generator Loss: 0.2956, Series Loss: 0.0036, Class Loss: 0.2443, Accuracy: 0.2716\n",
      "Epoch [171/4000], Discriminator Loss: 0.0908, Generator Loss: 0.2955, Series Loss: 0.0035, Class Loss: 0.2443, Accuracy: 0.3457\n",
      "Epoch [172/4000], Discriminator Loss: 0.0903, Generator Loss: 0.2955, Series Loss: 0.0036, Class Loss: 0.2442, Accuracy: 0.2716\n",
      "Epoch [173/4000], Discriminator Loss: 0.0901, Generator Loss: 0.2954, Series Loss: 0.0035, Class Loss: 0.2442, Accuracy: 0.3210\n",
      "Epoch [174/4000], Discriminator Loss: 0.0906, Generator Loss: 0.2954, Series Loss: 0.0035, Class Loss: 0.2441, Accuracy: 0.3086\n",
      "Epoch [175/4000], Discriminator Loss: 0.0902, Generator Loss: 0.2954, Series Loss: 0.0035, Class Loss: 0.2441, Accuracy: 0.2593\n",
      "Epoch [176/4000], Discriminator Loss: 0.0902, Generator Loss: 0.2952, Series Loss: 0.0035, Class Loss: 0.2440, Accuracy: 0.3210\n",
      "Epoch [177/4000], Discriminator Loss: 0.0902, Generator Loss: 0.2955, Series Loss: 0.0035, Class Loss: 0.2443, Accuracy: 0.3086\n",
      "Epoch [178/4000], Discriminator Loss: 0.0905, Generator Loss: 0.2955, Series Loss: 0.0034, Class Loss: 0.2444, Accuracy: 0.3272\n",
      "Epoch [179/4000], Discriminator Loss: 0.0903, Generator Loss: 0.2955, Series Loss: 0.0034, Class Loss: 0.2443, Accuracy: 0.3148\n",
      "Epoch [180/4000], Discriminator Loss: 0.0901, Generator Loss: 0.2954, Series Loss: 0.0034, Class Loss: 0.2441, Accuracy: 0.3210\n",
      "Epoch [181/4000], Discriminator Loss: 0.0899, Generator Loss: 0.2953, Series Loss: 0.0034, Class Loss: 0.2441, Accuracy: 0.3395\n",
      "Epoch [182/4000], Discriminator Loss: 0.0902, Generator Loss: 0.2953, Series Loss: 0.0034, Class Loss: 0.2441, Accuracy: 0.3580\n",
      "Epoch [183/4000], Discriminator Loss: 0.0901, Generator Loss: 0.2953, Series Loss: 0.0034, Class Loss: 0.2440, Accuracy: 0.2963\n",
      "Epoch [184/4000], Discriminator Loss: 0.0900, Generator Loss: 0.2955, Series Loss: 0.0034, Class Loss: 0.2443, Accuracy: 0.3272\n",
      "Epoch [185/4000], Discriminator Loss: 0.0900, Generator Loss: 0.2955, Series Loss: 0.0033, Class Loss: 0.2442, Accuracy: 0.3086\n",
      "Epoch [186/4000], Discriminator Loss: 0.0897, Generator Loss: 0.2954, Series Loss: 0.0033, Class Loss: 0.2443, Accuracy: 0.3580\n",
      "Epoch [187/4000], Discriminator Loss: 0.0897, Generator Loss: 0.2954, Series Loss: 0.0033, Class Loss: 0.2442, Accuracy: 0.3395\n",
      "Epoch [188/4000], Discriminator Loss: 0.0897, Generator Loss: 0.2954, Series Loss: 0.0033, Class Loss: 0.2442, Accuracy: 0.3395\n",
      "Epoch [189/4000], Discriminator Loss: 0.0898, Generator Loss: 0.2953, Series Loss: 0.0033, Class Loss: 0.2442, Accuracy: 0.3519\n",
      "Epoch [190/4000], Discriminator Loss: 0.0897, Generator Loss: 0.2950, Series Loss: 0.0033, Class Loss: 0.2439, Accuracy: 0.3395\n",
      "Epoch [191/4000], Discriminator Loss: 0.0895, Generator Loss: 0.2952, Series Loss: 0.0032, Class Loss: 0.2441, Accuracy: 0.3704\n",
      "Epoch [192/4000], Discriminator Loss: 0.0896, Generator Loss: 0.2953, Series Loss: 0.0032, Class Loss: 0.2440, Accuracy: 0.3642\n",
      "Epoch [193/4000], Discriminator Loss: 0.0896, Generator Loss: 0.2952, Series Loss: 0.0032, Class Loss: 0.2440, Accuracy: 0.3580\n",
      "Epoch [194/4000], Discriminator Loss: 0.0902, Generator Loss: 0.2951, Series Loss: 0.0032, Class Loss: 0.2440, Accuracy: 0.3951\n",
      "Epoch [195/4000], Discriminator Loss: 0.0894, Generator Loss: 0.2952, Series Loss: 0.0032, Class Loss: 0.2440, Accuracy: 0.3580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [196/4000], Discriminator Loss: 0.0894, Generator Loss: 0.2954, Series Loss: 0.0032, Class Loss: 0.2440, Accuracy: 0.3951\n",
      "Epoch [197/4000], Discriminator Loss: 0.0896, Generator Loss: 0.2952, Series Loss: 0.0031, Class Loss: 0.2441, Accuracy: 0.3642\n",
      "Epoch [198/4000], Discriminator Loss: 0.0894, Generator Loss: 0.2951, Series Loss: 0.0031, Class Loss: 0.2440, Accuracy: 0.3580\n",
      "Epoch [199/4000], Discriminator Loss: 0.0894, Generator Loss: 0.2954, Series Loss: 0.0031, Class Loss: 0.2443, Accuracy: 0.3951\n",
      "Epoch [200/4000], Discriminator Loss: 0.0898, Generator Loss: 0.2953, Series Loss: 0.0031, Class Loss: 0.2441, Accuracy: 0.3642\n",
      "Epoch [201/4000], Discriminator Loss: 0.0894, Generator Loss: 0.2952, Series Loss: 0.0031, Class Loss: 0.2441, Accuracy: 0.3827\n",
      "Epoch [202/4000], Discriminator Loss: 0.0894, Generator Loss: 0.2951, Series Loss: 0.0031, Class Loss: 0.2440, Accuracy: 0.3580\n",
      "Epoch [203/4000], Discriminator Loss: 0.0893, Generator Loss: 0.2952, Series Loss: 0.0031, Class Loss: 0.2440, Accuracy: 0.3827\n",
      "Epoch [204/4000], Discriminator Loss: 0.0893, Generator Loss: 0.2951, Series Loss: 0.0031, Class Loss: 0.2440, Accuracy: 0.3704\n",
      "Epoch [205/4000], Discriminator Loss: 0.0892, Generator Loss: 0.2951, Series Loss: 0.0030, Class Loss: 0.2440, Accuracy: 0.3704\n",
      "Epoch [206/4000], Discriminator Loss: 0.0891, Generator Loss: 0.2952, Series Loss: 0.0030, Class Loss: 0.2440, Accuracy: 0.4012\n",
      "Epoch [207/4000], Discriminator Loss: 0.0890, Generator Loss: 0.2954, Series Loss: 0.0030, Class Loss: 0.2440, Accuracy: 0.4444\n",
      "Epoch [208/4000], Discriminator Loss: 0.0892, Generator Loss: 0.2950, Series Loss: 0.0030, Class Loss: 0.2440, Accuracy: 0.3951\n",
      "Epoch [209/4000], Discriminator Loss: 0.0891, Generator Loss: 0.2951, Series Loss: 0.0030, Class Loss: 0.2438, Accuracy: 0.4259\n",
      "Epoch [210/4000], Discriminator Loss: 0.0892, Generator Loss: 0.2952, Series Loss: 0.0030, Class Loss: 0.2440, Accuracy: 0.3765\n",
      "Epoch [211/4000], Discriminator Loss: 0.0889, Generator Loss: 0.2950, Series Loss: 0.0030, Class Loss: 0.2439, Accuracy: 0.4321\n",
      "Epoch [212/4000], Discriminator Loss: 0.0890, Generator Loss: 0.2950, Series Loss: 0.0030, Class Loss: 0.2439, Accuracy: 0.3827\n",
      "Epoch [213/4000], Discriminator Loss: 0.0886, Generator Loss: 0.2953, Series Loss: 0.0030, Class Loss: 0.2441, Accuracy: 0.4012\n",
      "Epoch [214/4000], Discriminator Loss: 0.0894, Generator Loss: 0.2950, Series Loss: 0.0030, Class Loss: 0.2440, Accuracy: 0.4198\n",
      "Epoch [215/4000], Discriminator Loss: 0.0888, Generator Loss: 0.2951, Series Loss: 0.0029, Class Loss: 0.2439, Accuracy: 0.4259\n",
      "Epoch [216/4000], Discriminator Loss: 0.0884, Generator Loss: 0.2950, Series Loss: 0.0029, Class Loss: 0.2438, Accuracy: 0.4383\n",
      "Epoch [217/4000], Discriminator Loss: 0.0889, Generator Loss: 0.2951, Series Loss: 0.0029, Class Loss: 0.2440, Accuracy: 0.3951\n",
      "Epoch [218/4000], Discriminator Loss: 0.0885, Generator Loss: 0.2951, Series Loss: 0.0029, Class Loss: 0.2439, Accuracy: 0.4198\n",
      "Epoch [219/4000], Discriminator Loss: 0.0885, Generator Loss: 0.2952, Series Loss: 0.0029, Class Loss: 0.2439, Accuracy: 0.3889\n",
      "Epoch [220/4000], Discriminator Loss: 0.0887, Generator Loss: 0.2952, Series Loss: 0.0029, Class Loss: 0.2438, Accuracy: 0.3765\n",
      "Epoch [221/4000], Discriminator Loss: 0.0884, Generator Loss: 0.2952, Series Loss: 0.0029, Class Loss: 0.2438, Accuracy: 0.3889\n",
      "Epoch [222/4000], Discriminator Loss: 0.0885, Generator Loss: 0.2951, Series Loss: 0.0029, Class Loss: 0.2439, Accuracy: 0.4506\n",
      "Epoch [223/4000], Discriminator Loss: 0.0881, Generator Loss: 0.2951, Series Loss: 0.0029, Class Loss: 0.2439, Accuracy: 0.3704\n",
      "Epoch [224/4000], Discriminator Loss: 0.0886, Generator Loss: 0.2950, Series Loss: 0.0028, Class Loss: 0.2438, Accuracy: 0.4383\n",
      "Epoch [225/4000], Discriminator Loss: 0.0883, Generator Loss: 0.2951, Series Loss: 0.0028, Class Loss: 0.2439, Accuracy: 0.4012\n",
      "Epoch [226/4000], Discriminator Loss: 0.0882, Generator Loss: 0.2952, Series Loss: 0.0028, Class Loss: 0.2438, Accuracy: 0.4321\n",
      "Epoch [227/4000], Discriminator Loss: 0.0882, Generator Loss: 0.2951, Series Loss: 0.0028, Class Loss: 0.2438, Accuracy: 0.4383\n",
      "Epoch [228/4000], Discriminator Loss: 0.0882, Generator Loss: 0.2952, Series Loss: 0.0028, Class Loss: 0.2437, Accuracy: 0.3827\n",
      "Epoch [229/4000], Discriminator Loss: 0.0883, Generator Loss: 0.2953, Series Loss: 0.0028, Class Loss: 0.2439, Accuracy: 0.4198\n",
      "Epoch [230/4000], Discriminator Loss: 0.0881, Generator Loss: 0.2953, Series Loss: 0.0028, Class Loss: 0.2439, Accuracy: 0.3642\n",
      "Epoch [231/4000], Discriminator Loss: 0.0882, Generator Loss: 0.2952, Series Loss: 0.0028, Class Loss: 0.2440, Accuracy: 0.4321\n",
      "Epoch [232/4000], Discriminator Loss: 0.0879, Generator Loss: 0.2953, Series Loss: 0.0028, Class Loss: 0.2439, Accuracy: 0.4444\n",
      "Epoch [233/4000], Discriminator Loss: 0.0878, Generator Loss: 0.2951, Series Loss: 0.0028, Class Loss: 0.2437, Accuracy: 0.4630\n",
      "Epoch [234/4000], Discriminator Loss: 0.0878, Generator Loss: 0.2953, Series Loss: 0.0028, Class Loss: 0.2438, Accuracy: 0.3951\n",
      "Epoch [235/4000], Discriminator Loss: 0.0876, Generator Loss: 0.2954, Series Loss: 0.0028, Class Loss: 0.2438, Accuracy: 0.3889\n",
      "Epoch [236/4000], Discriminator Loss: 0.0882, Generator Loss: 0.2952, Series Loss: 0.0027, Class Loss: 0.2438, Accuracy: 0.4136\n",
      "Epoch [237/4000], Discriminator Loss: 0.0877, Generator Loss: 0.2952, Series Loss: 0.0027, Class Loss: 0.2438, Accuracy: 0.4383\n",
      "Epoch [238/4000], Discriminator Loss: 0.0873, Generator Loss: 0.2956, Series Loss: 0.0028, Class Loss: 0.2437, Accuracy: 0.4259\n",
      "Epoch [239/4000], Discriminator Loss: 0.0876, Generator Loss: 0.2956, Series Loss: 0.0027, Class Loss: 0.2439, Accuracy: 0.4444\n",
      "Epoch [240/4000], Discriminator Loss: 0.0875, Generator Loss: 0.2953, Series Loss: 0.0027, Class Loss: 0.2438, Accuracy: 0.4321\n",
      "Epoch [241/4000], Discriminator Loss: 0.0877, Generator Loss: 0.2953, Series Loss: 0.0027, Class Loss: 0.2437, Accuracy: 0.4198\n",
      "Epoch [242/4000], Discriminator Loss: 0.0876, Generator Loss: 0.2953, Series Loss: 0.0027, Class Loss: 0.2437, Accuracy: 0.4444\n",
      "Epoch [243/4000], Discriminator Loss: 0.0877, Generator Loss: 0.2955, Series Loss: 0.0027, Class Loss: 0.2438, Accuracy: 0.4444\n",
      "Epoch [244/4000], Discriminator Loss: 0.0879, Generator Loss: 0.2954, Series Loss: 0.0027, Class Loss: 0.2438, Accuracy: 0.4568\n",
      "Epoch [245/4000], Discriminator Loss: 0.0874, Generator Loss: 0.2956, Series Loss: 0.0027, Class Loss: 0.2437, Accuracy: 0.4012\n",
      "Epoch [246/4000], Discriminator Loss: 0.0874, Generator Loss: 0.2956, Series Loss: 0.0027, Class Loss: 0.2438, Accuracy: 0.4074\n",
      "Epoch [247/4000], Discriminator Loss: 0.0870, Generator Loss: 0.2956, Series Loss: 0.0027, Class Loss: 0.2437, Accuracy: 0.3889\n",
      "Epoch [248/4000], Discriminator Loss: 0.0872, Generator Loss: 0.2956, Series Loss: 0.0027, Class Loss: 0.2437, Accuracy: 0.4630\n",
      "Epoch [249/4000], Discriminator Loss: 0.0871, Generator Loss: 0.2958, Series Loss: 0.0027, Class Loss: 0.2438, Accuracy: 0.4321\n",
      "Epoch [250/4000], Discriminator Loss: 0.0871, Generator Loss: 0.2958, Series Loss: 0.0027, Class Loss: 0.2437, Accuracy: 0.4383\n",
      "Epoch [251/4000], Discriminator Loss: 0.0871, Generator Loss: 0.2957, Series Loss: 0.0027, Class Loss: 0.2436, Accuracy: 0.4259\n",
      "Epoch [252/4000], Discriminator Loss: 0.0867, Generator Loss: 0.2959, Series Loss: 0.0027, Class Loss: 0.2437, Accuracy: 0.4383\n",
      "Epoch [253/4000], Discriminator Loss: 0.0869, Generator Loss: 0.2958, Series Loss: 0.0027, Class Loss: 0.2436, Accuracy: 0.4383\n",
      "Epoch [254/4000], Discriminator Loss: 0.0872, Generator Loss: 0.2959, Series Loss: 0.0026, Class Loss: 0.2436, Accuracy: 0.4444\n",
      "Epoch [255/4000], Discriminator Loss: 0.0863, Generator Loss: 0.2959, Series Loss: 0.0027, Class Loss: 0.2437, Accuracy: 0.4383\n",
      "Epoch [256/4000], Discriminator Loss: 0.0868, Generator Loss: 0.2961, Series Loss: 0.0026, Class Loss: 0.2437, Accuracy: 0.4383\n",
      "Epoch [257/4000], Discriminator Loss: 0.0866, Generator Loss: 0.2964, Series Loss: 0.0026, Class Loss: 0.2438, Accuracy: 0.3827\n",
      "Epoch [258/4000], Discriminator Loss: 0.0864, Generator Loss: 0.2960, Series Loss: 0.0026, Class Loss: 0.2438, Accuracy: 0.4630\n",
      "Epoch [259/4000], Discriminator Loss: 0.0866, Generator Loss: 0.2963, Series Loss: 0.0026, Class Loss: 0.2437, Accuracy: 0.4136\n",
      "Epoch [260/4000], Discriminator Loss: 0.0865, Generator Loss: 0.2959, Series Loss: 0.0026, Class Loss: 0.2436, Accuracy: 0.4877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [261/4000], Discriminator Loss: 0.0864, Generator Loss: 0.2962, Series Loss: 0.0026, Class Loss: 0.2436, Accuracy: 0.4383\n",
      "Epoch [262/4000], Discriminator Loss: 0.0862, Generator Loss: 0.2959, Series Loss: 0.0026, Class Loss: 0.2435, Accuracy: 0.4074\n",
      "Epoch [263/4000], Discriminator Loss: 0.0860, Generator Loss: 0.2961, Series Loss: 0.0026, Class Loss: 0.2437, Accuracy: 0.4321\n",
      "Epoch [264/4000], Discriminator Loss: 0.0858, Generator Loss: 0.2964, Series Loss: 0.0026, Class Loss: 0.2437, Accuracy: 0.4012\n",
      "Epoch [265/4000], Discriminator Loss: 0.0859, Generator Loss: 0.2964, Series Loss: 0.0026, Class Loss: 0.2436, Accuracy: 0.4506\n",
      "Epoch [266/4000], Discriminator Loss: 0.0863, Generator Loss: 0.2965, Series Loss: 0.0026, Class Loss: 0.2436, Accuracy: 0.4198\n",
      "Epoch [267/4000], Discriminator Loss: 0.0861, Generator Loss: 0.2963, Series Loss: 0.0026, Class Loss: 0.2436, Accuracy: 0.4198\n",
      "Epoch [268/4000], Discriminator Loss: 0.0860, Generator Loss: 0.2964, Series Loss: 0.0026, Class Loss: 0.2436, Accuracy: 0.4321\n",
      "Epoch [269/4000], Discriminator Loss: 0.0858, Generator Loss: 0.2966, Series Loss: 0.0026, Class Loss: 0.2435, Accuracy: 0.4383\n",
      "Epoch [270/4000], Discriminator Loss: 0.0860, Generator Loss: 0.2968, Series Loss: 0.0026, Class Loss: 0.2438, Accuracy: 0.3827\n",
      "Epoch [271/4000], Discriminator Loss: 0.0858, Generator Loss: 0.2972, Series Loss: 0.0026, Class Loss: 0.2437, Accuracy: 0.4012\n",
      "Epoch [272/4000], Discriminator Loss: 0.0862, Generator Loss: 0.2970, Series Loss: 0.0026, Class Loss: 0.2436, Accuracy: 0.3889\n",
      "Epoch [273/4000], Discriminator Loss: 0.0858, Generator Loss: 0.2964, Series Loss: 0.0026, Class Loss: 0.2436, Accuracy: 0.4630\n",
      "Epoch [274/4000], Discriminator Loss: 0.0857, Generator Loss: 0.2971, Series Loss: 0.0026, Class Loss: 0.2436, Accuracy: 0.4321\n",
      "Epoch [275/4000], Discriminator Loss: 0.0855, Generator Loss: 0.2966, Series Loss: 0.0026, Class Loss: 0.2436, Accuracy: 0.4506\n",
      "Epoch [276/4000], Discriminator Loss: 0.0854, Generator Loss: 0.2969, Series Loss: 0.0026, Class Loss: 0.2436, Accuracy: 0.4198\n",
      "Epoch [277/4000], Discriminator Loss: 0.0854, Generator Loss: 0.2969, Series Loss: 0.0026, Class Loss: 0.2437, Accuracy: 0.4444\n",
      "Epoch [278/4000], Discriminator Loss: 0.0857, Generator Loss: 0.2971, Series Loss: 0.0026, Class Loss: 0.2437, Accuracy: 0.4630\n",
      "Epoch [279/4000], Discriminator Loss: 0.0857, Generator Loss: 0.2967, Series Loss: 0.0026, Class Loss: 0.2436, Accuracy: 0.4691\n",
      "Epoch [280/4000], Discriminator Loss: 0.0852, Generator Loss: 0.2971, Series Loss: 0.0026, Class Loss: 0.2436, Accuracy: 0.4259\n",
      "Epoch [281/4000], Discriminator Loss: 0.0851, Generator Loss: 0.2974, Series Loss: 0.0026, Class Loss: 0.2437, Accuracy: 0.4877\n",
      "Epoch [282/4000], Discriminator Loss: 0.0855, Generator Loss: 0.2971, Series Loss: 0.0026, Class Loss: 0.2436, Accuracy: 0.4383\n",
      "Epoch [283/4000], Discriminator Loss: 0.0849, Generator Loss: 0.2975, Series Loss: 0.0026, Class Loss: 0.2436, Accuracy: 0.4383\n",
      "Epoch [284/4000], Discriminator Loss: 0.0854, Generator Loss: 0.2975, Series Loss: 0.0026, Class Loss: 0.2437, Accuracy: 0.4259\n",
      "Epoch [285/4000], Discriminator Loss: 0.0850, Generator Loss: 0.2973, Series Loss: 0.0026, Class Loss: 0.2435, Accuracy: 0.4383\n",
      "Epoch [286/4000], Discriminator Loss: 0.0854, Generator Loss: 0.2973, Series Loss: 0.0026, Class Loss: 0.2436, Accuracy: 0.4136\n",
      "Epoch [287/4000], Discriminator Loss: 0.0847, Generator Loss: 0.2977, Series Loss: 0.0026, Class Loss: 0.2437, Accuracy: 0.4321\n",
      "Epoch [288/4000], Discriminator Loss: 0.0849, Generator Loss: 0.2977, Series Loss: 0.0026, Class Loss: 0.2437, Accuracy: 0.3827\n",
      "Epoch [289/4000], Discriminator Loss: 0.0849, Generator Loss: 0.2977, Series Loss: 0.0026, Class Loss: 0.2436, Accuracy: 0.4506\n",
      "Epoch [290/4000], Discriminator Loss: 0.0852, Generator Loss: 0.2974, Series Loss: 0.0026, Class Loss: 0.2436, Accuracy: 0.4259\n",
      "Epoch [291/4000], Discriminator Loss: 0.0847, Generator Loss: 0.2977, Series Loss: 0.0026, Class Loss: 0.2435, Accuracy: 0.3765\n",
      "Epoch [292/4000], Discriminator Loss: 0.0845, Generator Loss: 0.2979, Series Loss: 0.0026, Class Loss: 0.2436, Accuracy: 0.4506\n",
      "Epoch [293/4000], Discriminator Loss: 0.0846, Generator Loss: 0.2975, Series Loss: 0.0026, Class Loss: 0.2435, Accuracy: 0.4321\n",
      "Epoch [294/4000], Discriminator Loss: 0.0847, Generator Loss: 0.2978, Series Loss: 0.0027, Class Loss: 0.2435, Accuracy: 0.4074\n",
      "Epoch [295/4000], Discriminator Loss: 0.0846, Generator Loss: 0.2981, Series Loss: 0.0026, Class Loss: 0.2437, Accuracy: 0.4074\n",
      "Epoch [296/4000], Discriminator Loss: 0.0844, Generator Loss: 0.2983, Series Loss: 0.0026, Class Loss: 0.2437, Accuracy: 0.4198\n",
      "Epoch [297/4000], Discriminator Loss: 0.0844, Generator Loss: 0.2983, Series Loss: 0.0027, Class Loss: 0.2435, Accuracy: 0.3642\n",
      "Epoch [298/4000], Discriminator Loss: 0.0845, Generator Loss: 0.2980, Series Loss: 0.0026, Class Loss: 0.2435, Accuracy: 0.4630\n",
      "Epoch [299/4000], Discriminator Loss: 0.0846, Generator Loss: 0.2983, Series Loss: 0.0027, Class Loss: 0.2437, Accuracy: 0.3642\n",
      "Epoch [300/4000], Discriminator Loss: 0.0843, Generator Loss: 0.2985, Series Loss: 0.0027, Class Loss: 0.2437, Accuracy: 0.4136\n",
      "Epoch [301/4000], Discriminator Loss: 0.0837, Generator Loss: 0.2982, Series Loss: 0.0027, Class Loss: 0.2436, Accuracy: 0.3889\n",
      "Epoch [302/4000], Discriminator Loss: 0.0844, Generator Loss: 0.2986, Series Loss: 0.0027, Class Loss: 0.2436, Accuracy: 0.4259\n",
      "Epoch [303/4000], Discriminator Loss: 0.0840, Generator Loss: 0.2982, Series Loss: 0.0027, Class Loss: 0.2436, Accuracy: 0.3704\n",
      "Epoch [304/4000], Discriminator Loss: 0.0840, Generator Loss: 0.2987, Series Loss: 0.0027, Class Loss: 0.2436, Accuracy: 0.3642\n",
      "Epoch [305/4000], Discriminator Loss: 0.0843, Generator Loss: 0.2985, Series Loss: 0.0027, Class Loss: 0.2436, Accuracy: 0.3951\n",
      "Epoch [306/4000], Discriminator Loss: 0.0839, Generator Loss: 0.2986, Series Loss: 0.0027, Class Loss: 0.2436, Accuracy: 0.4012\n",
      "Epoch [307/4000], Discriminator Loss: 0.0845, Generator Loss: 0.2988, Series Loss: 0.0027, Class Loss: 0.2435, Accuracy: 0.4259\n",
      "Epoch [308/4000], Discriminator Loss: 0.0839, Generator Loss: 0.2987, Series Loss: 0.0027, Class Loss: 0.2435, Accuracy: 0.3580\n",
      "Epoch [309/4000], Discriminator Loss: 0.0837, Generator Loss: 0.2989, Series Loss: 0.0027, Class Loss: 0.2437, Accuracy: 0.4012\n",
      "Epoch [310/4000], Discriminator Loss: 0.0842, Generator Loss: 0.2990, Series Loss: 0.0027, Class Loss: 0.2436, Accuracy: 0.4012\n",
      "Epoch [311/4000], Discriminator Loss: 0.0841, Generator Loss: 0.2990, Series Loss: 0.0027, Class Loss: 0.2435, Accuracy: 0.3580\n",
      "Epoch [312/4000], Discriminator Loss: 0.0837, Generator Loss: 0.2986, Series Loss: 0.0027, Class Loss: 0.2436, Accuracy: 0.3765\n",
      "Epoch [313/4000], Discriminator Loss: 0.0840, Generator Loss: 0.2994, Series Loss: 0.0027, Class Loss: 0.2435, Accuracy: 0.3704\n",
      "Epoch [314/4000], Discriminator Loss: 0.0839, Generator Loss: 0.2997, Series Loss: 0.0027, Class Loss: 0.2436, Accuracy: 0.3580\n",
      "Epoch [315/4000], Discriminator Loss: 0.0835, Generator Loss: 0.2992, Series Loss: 0.0027, Class Loss: 0.2438, Accuracy: 0.3704\n",
      "Epoch [316/4000], Discriminator Loss: 0.0835, Generator Loss: 0.2996, Series Loss: 0.0028, Class Loss: 0.2436, Accuracy: 0.4074\n",
      "Epoch [317/4000], Discriminator Loss: 0.0835, Generator Loss: 0.2994, Series Loss: 0.0027, Class Loss: 0.2434, Accuracy: 0.3827\n",
      "Epoch [318/4000], Discriminator Loss: 0.0837, Generator Loss: 0.2999, Series Loss: 0.0028, Class Loss: 0.2436, Accuracy: 0.3889\n",
      "Epoch [319/4000], Discriminator Loss: 0.0840, Generator Loss: 0.2992, Series Loss: 0.0028, Class Loss: 0.2436, Accuracy: 0.3457\n",
      "Epoch [320/4000], Discriminator Loss: 0.0835, Generator Loss: 0.2997, Series Loss: 0.0028, Class Loss: 0.2436, Accuracy: 0.3642\n",
      "Epoch [321/4000], Discriminator Loss: 0.0836, Generator Loss: 0.2997, Series Loss: 0.0028, Class Loss: 0.2437, Accuracy: 0.3642\n",
      "Epoch [322/4000], Discriminator Loss: 0.0837, Generator Loss: 0.2995, Series Loss: 0.0028, Class Loss: 0.2435, Accuracy: 0.3580\n",
      "Epoch [323/4000], Discriminator Loss: 0.0834, Generator Loss: 0.2998, Series Loss: 0.0028, Class Loss: 0.2436, Accuracy: 0.3765\n",
      "Epoch [324/4000], Discriminator Loss: 0.0834, Generator Loss: 0.2997, Series Loss: 0.0028, Class Loss: 0.2436, Accuracy: 0.3889\n",
      "Epoch [325/4000], Discriminator Loss: 0.0836, Generator Loss: 0.2999, Series Loss: 0.0028, Class Loss: 0.2436, Accuracy: 0.3580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [326/4000], Discriminator Loss: 0.0835, Generator Loss: 0.2991, Series Loss: 0.0028, Class Loss: 0.2435, Accuracy: 0.3395\n",
      "Epoch [327/4000], Discriminator Loss: 0.0836, Generator Loss: 0.2998, Series Loss: 0.0028, Class Loss: 0.2437, Accuracy: 0.3642\n",
      "Epoch [328/4000], Discriminator Loss: 0.0831, Generator Loss: 0.2995, Series Loss: 0.0028, Class Loss: 0.2435, Accuracy: 0.3519\n",
      "Epoch [329/4000], Discriminator Loss: 0.0831, Generator Loss: 0.3004, Series Loss: 0.0028, Class Loss: 0.2437, Accuracy: 0.3519\n",
      "Epoch [330/4000], Discriminator Loss: 0.0833, Generator Loss: 0.3001, Series Loss: 0.0028, Class Loss: 0.2435, Accuracy: 0.3704\n",
      "Epoch [331/4000], Discriminator Loss: 0.0831, Generator Loss: 0.3002, Series Loss: 0.0029, Class Loss: 0.2436, Accuracy: 0.3519\n",
      "Epoch [332/4000], Discriminator Loss: 0.0831, Generator Loss: 0.3005, Series Loss: 0.0029, Class Loss: 0.2435, Accuracy: 0.3642\n",
      "Epoch [333/4000], Discriminator Loss: 0.0833, Generator Loss: 0.3003, Series Loss: 0.0029, Class Loss: 0.2437, Accuracy: 0.3580\n",
      "Epoch [334/4000], Discriminator Loss: 0.0829, Generator Loss: 0.3005, Series Loss: 0.0029, Class Loss: 0.2435, Accuracy: 0.3642\n",
      "Epoch [335/4000], Discriminator Loss: 0.0826, Generator Loss: 0.3011, Series Loss: 0.0029, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [336/4000], Discriminator Loss: 0.0835, Generator Loss: 0.3008, Series Loss: 0.0029, Class Loss: 0.2437, Accuracy: 0.3827\n",
      "Epoch [337/4000], Discriminator Loss: 0.0827, Generator Loss: 0.3006, Series Loss: 0.0029, Class Loss: 0.2435, Accuracy: 0.3395\n",
      "Epoch [338/4000], Discriminator Loss: 0.0829, Generator Loss: 0.3005, Series Loss: 0.0029, Class Loss: 0.2435, Accuracy: 0.3519\n",
      "Epoch [339/4000], Discriminator Loss: 0.0831, Generator Loss: 0.3010, Series Loss: 0.0029, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [340/4000], Discriminator Loss: 0.0826, Generator Loss: 0.3009, Series Loss: 0.0029, Class Loss: 0.2437, Accuracy: 0.3580\n",
      "Epoch [341/4000], Discriminator Loss: 0.0831, Generator Loss: 0.3008, Series Loss: 0.0029, Class Loss: 0.2436, Accuracy: 0.3272\n",
      "Epoch [342/4000], Discriminator Loss: 0.0828, Generator Loss: 0.3010, Series Loss: 0.0029, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [343/4000], Discriminator Loss: 0.0831, Generator Loss: 0.3006, Series Loss: 0.0029, Class Loss: 0.2435, Accuracy: 0.3580\n",
      "Epoch [344/4000], Discriminator Loss: 0.0826, Generator Loss: 0.3013, Series Loss: 0.0029, Class Loss: 0.2437, Accuracy: 0.3210\n",
      "Epoch [345/4000], Discriminator Loss: 0.0828, Generator Loss: 0.3010, Series Loss: 0.0030, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [346/4000], Discriminator Loss: 0.0830, Generator Loss: 0.3006, Series Loss: 0.0029, Class Loss: 0.2435, Accuracy: 0.3272\n",
      "Epoch [347/4000], Discriminator Loss: 0.0828, Generator Loss: 0.3013, Series Loss: 0.0030, Class Loss: 0.2436, Accuracy: 0.3333\n",
      "Epoch [348/4000], Discriminator Loss: 0.0829, Generator Loss: 0.3013, Series Loss: 0.0030, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [349/4000], Discriminator Loss: 0.0831, Generator Loss: 0.3017, Series Loss: 0.0030, Class Loss: 0.2436, Accuracy: 0.3457\n",
      "Epoch [350/4000], Discriminator Loss: 0.0827, Generator Loss: 0.3014, Series Loss: 0.0030, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [351/4000], Discriminator Loss: 0.0825, Generator Loss: 0.3009, Series Loss: 0.0030, Class Loss: 0.2435, Accuracy: 0.3272\n",
      "Epoch [352/4000], Discriminator Loss: 0.0822, Generator Loss: 0.3014, Series Loss: 0.0030, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [353/4000], Discriminator Loss: 0.0824, Generator Loss: 0.3016, Series Loss: 0.0030, Class Loss: 0.2436, Accuracy: 0.3395\n",
      "Epoch [354/4000], Discriminator Loss: 0.0824, Generator Loss: 0.3025, Series Loss: 0.0030, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [355/4000], Discriminator Loss: 0.0823, Generator Loss: 0.3020, Series Loss: 0.0030, Class Loss: 0.2436, Accuracy: 0.2778\n",
      "Epoch [356/4000], Discriminator Loss: 0.0826, Generator Loss: 0.3017, Series Loss: 0.0030, Class Loss: 0.2436, Accuracy: 0.2654\n",
      "Epoch [357/4000], Discriminator Loss: 0.0823, Generator Loss: 0.3013, Series Loss: 0.0030, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [358/4000], Discriminator Loss: 0.0824, Generator Loss: 0.3016, Series Loss: 0.0031, Class Loss: 0.2436, Accuracy: 0.2778\n",
      "Epoch [359/4000], Discriminator Loss: 0.0818, Generator Loss: 0.3018, Series Loss: 0.0031, Class Loss: 0.2437, Accuracy: 0.2593\n",
      "Epoch [360/4000], Discriminator Loss: 0.0820, Generator Loss: 0.3019, Series Loss: 0.0030, Class Loss: 0.2436, Accuracy: 0.2778\n",
      "Epoch [361/4000], Discriminator Loss: 0.0826, Generator Loss: 0.3019, Series Loss: 0.0031, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [362/4000], Discriminator Loss: 0.0817, Generator Loss: 0.3024, Series Loss: 0.0031, Class Loss: 0.2435, Accuracy: 0.2778\n",
      "Epoch [363/4000], Discriminator Loss: 0.0820, Generator Loss: 0.3017, Series Loss: 0.0031, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [364/4000], Discriminator Loss: 0.0822, Generator Loss: 0.3022, Series Loss: 0.0031, Class Loss: 0.2437, Accuracy: 0.2716\n",
      "Epoch [365/4000], Discriminator Loss: 0.0823, Generator Loss: 0.3016, Series Loss: 0.0031, Class Loss: 0.2436, Accuracy: 0.2716\n",
      "Epoch [366/4000], Discriminator Loss: 0.0828, Generator Loss: 0.3021, Series Loss: 0.0031, Class Loss: 0.2435, Accuracy: 0.2716\n",
      "Epoch [367/4000], Discriminator Loss: 0.0822, Generator Loss: 0.3021, Series Loss: 0.0031, Class Loss: 0.2436, Accuracy: 0.2716\n",
      "Epoch [368/4000], Discriminator Loss: 0.0820, Generator Loss: 0.3025, Series Loss: 0.0031, Class Loss: 0.2437, Accuracy: 0.2654\n",
      "Epoch [369/4000], Discriminator Loss: 0.0821, Generator Loss: 0.3027, Series Loss: 0.0032, Class Loss: 0.2437, Accuracy: 0.2531\n",
      "Epoch [370/4000], Discriminator Loss: 0.0822, Generator Loss: 0.3021, Series Loss: 0.0032, Class Loss: 0.2437, Accuracy: 0.2654\n",
      "Epoch [371/4000], Discriminator Loss: 0.0815, Generator Loss: 0.3024, Series Loss: 0.0032, Class Loss: 0.2437, Accuracy: 0.2469\n",
      "Epoch [372/4000], Discriminator Loss: 0.0819, Generator Loss: 0.3028, Series Loss: 0.0032, Class Loss: 0.2436, Accuracy: 0.2778\n",
      "Epoch [373/4000], Discriminator Loss: 0.0822, Generator Loss: 0.3029, Series Loss: 0.0032, Class Loss: 0.2438, Accuracy: 0.2778\n",
      "Epoch [374/4000], Discriminator Loss: 0.0819, Generator Loss: 0.3029, Series Loss: 0.0032, Class Loss: 0.2436, Accuracy: 0.2716\n",
      "Epoch [375/4000], Discriminator Loss: 0.0824, Generator Loss: 0.3029, Series Loss: 0.0032, Class Loss: 0.2437, Accuracy: 0.2654\n",
      "Epoch [376/4000], Discriminator Loss: 0.0824, Generator Loss: 0.3028, Series Loss: 0.0032, Class Loss: 0.2436, Accuracy: 0.2716\n",
      "Epoch [377/4000], Discriminator Loss: 0.0814, Generator Loss: 0.3026, Series Loss: 0.0033, Class Loss: 0.2437, Accuracy: 0.2716\n",
      "Epoch [378/4000], Discriminator Loss: 0.0811, Generator Loss: 0.3028, Series Loss: 0.0033, Class Loss: 0.2437, Accuracy: 0.2407\n",
      "Epoch [379/4000], Discriminator Loss: 0.0819, Generator Loss: 0.3026, Series Loss: 0.0033, Class Loss: 0.2437, Accuracy: 0.2531\n",
      "Epoch [380/4000], Discriminator Loss: 0.0816, Generator Loss: 0.3033, Series Loss: 0.0033, Class Loss: 0.2437, Accuracy: 0.2654\n",
      "Epoch [381/4000], Discriminator Loss: 0.0823, Generator Loss: 0.3032, Series Loss: 0.0033, Class Loss: 0.2437, Accuracy: 0.2716\n",
      "Epoch [382/4000], Discriminator Loss: 0.0818, Generator Loss: 0.3025, Series Loss: 0.0033, Class Loss: 0.2436, Accuracy: 0.2716\n",
      "Epoch [383/4000], Discriminator Loss: 0.0813, Generator Loss: 0.3035, Series Loss: 0.0033, Class Loss: 0.2438, Accuracy: 0.2654\n",
      "Epoch [384/4000], Discriminator Loss: 0.0811, Generator Loss: 0.3036, Series Loss: 0.0034, Class Loss: 0.2437, Accuracy: 0.2469\n",
      "Epoch [385/4000], Discriminator Loss: 0.0815, Generator Loss: 0.3029, Series Loss: 0.0034, Class Loss: 0.2436, Accuracy: 0.2593\n",
      "Epoch [386/4000], Discriminator Loss: 0.0817, Generator Loss: 0.3027, Series Loss: 0.0033, Class Loss: 0.2435, Accuracy: 0.2593\n",
      "Epoch [387/4000], Discriminator Loss: 0.0821, Generator Loss: 0.3034, Series Loss: 0.0034, Class Loss: 0.2438, Accuracy: 0.2531\n",
      "Epoch [388/4000], Discriminator Loss: 0.0813, Generator Loss: 0.3034, Series Loss: 0.0034, Class Loss: 0.2435, Accuracy: 0.2593\n",
      "Epoch [389/4000], Discriminator Loss: 0.0813, Generator Loss: 0.3036, Series Loss: 0.0034, Class Loss: 0.2438, Accuracy: 0.2654\n",
      "Epoch [390/4000], Discriminator Loss: 0.0814, Generator Loss: 0.3037, Series Loss: 0.0034, Class Loss: 0.2437, Accuracy: 0.2531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [391/4000], Discriminator Loss: 0.0818, Generator Loss: 0.3036, Series Loss: 0.0034, Class Loss: 0.2437, Accuracy: 0.2716\n",
      "Epoch [392/4000], Discriminator Loss: 0.0807, Generator Loss: 0.3038, Series Loss: 0.0035, Class Loss: 0.2438, Accuracy: 0.2469\n",
      "Epoch [393/4000], Discriminator Loss: 0.0811, Generator Loss: 0.3038, Series Loss: 0.0035, Class Loss: 0.2438, Accuracy: 0.2593\n",
      "Epoch [394/4000], Discriminator Loss: 0.0811, Generator Loss: 0.3037, Series Loss: 0.0035, Class Loss: 0.2437, Accuracy: 0.2593\n",
      "Epoch [395/4000], Discriminator Loss: 0.0816, Generator Loss: 0.3038, Series Loss: 0.0035, Class Loss: 0.2436, Accuracy: 0.2469\n",
      "Epoch [396/4000], Discriminator Loss: 0.0815, Generator Loss: 0.3042, Series Loss: 0.0035, Class Loss: 0.2439, Accuracy: 0.2593\n",
      "Epoch [397/4000], Discriminator Loss: 0.0813, Generator Loss: 0.3039, Series Loss: 0.0036, Class Loss: 0.2438, Accuracy: 0.2469\n",
      "Epoch [398/4000], Discriminator Loss: 0.0813, Generator Loss: 0.3039, Series Loss: 0.0035, Class Loss: 0.2438, Accuracy: 0.2469\n",
      "Epoch [399/4000], Discriminator Loss: 0.0818, Generator Loss: 0.3044, Series Loss: 0.0036, Class Loss: 0.2438, Accuracy: 0.2593\n",
      "Epoch [400/4000], Discriminator Loss: 0.0820, Generator Loss: 0.3037, Series Loss: 0.0036, Class Loss: 0.2436, Accuracy: 0.2531\n",
      "Epoch [401/4000], Discriminator Loss: 0.0816, Generator Loss: 0.3037, Series Loss: 0.0036, Class Loss: 0.2437, Accuracy: 0.2531\n",
      "Epoch [402/4000], Discriminator Loss: 0.0813, Generator Loss: 0.3042, Series Loss: 0.0036, Class Loss: 0.2438, Accuracy: 0.2593\n",
      "Epoch [403/4000], Discriminator Loss: 0.0817, Generator Loss: 0.3042, Series Loss: 0.0036, Class Loss: 0.2438, Accuracy: 0.2531\n",
      "Epoch [404/4000], Discriminator Loss: 0.0815, Generator Loss: 0.3041, Series Loss: 0.0037, Class Loss: 0.2438, Accuracy: 0.2593\n",
      "Epoch [405/4000], Discriminator Loss: 0.0807, Generator Loss: 0.3044, Series Loss: 0.0037, Class Loss: 0.2438, Accuracy: 0.2531\n",
      "Epoch [406/4000], Discriminator Loss: 0.0815, Generator Loss: 0.3047, Series Loss: 0.0037, Class Loss: 0.2437, Accuracy: 0.2531\n",
      "Epoch [407/4000], Discriminator Loss: 0.0815, Generator Loss: 0.3044, Series Loss: 0.0037, Class Loss: 0.2437, Accuracy: 0.2469\n",
      "Epoch [408/4000], Discriminator Loss: 0.0814, Generator Loss: 0.3048, Series Loss: 0.0037, Class Loss: 0.2437, Accuracy: 0.2593\n",
      "Epoch [409/4000], Discriminator Loss: 0.0812, Generator Loss: 0.3048, Series Loss: 0.0038, Class Loss: 0.2438, Accuracy: 0.2469\n",
      "Epoch [410/4000], Discriminator Loss: 0.0809, Generator Loss: 0.3046, Series Loss: 0.0038, Class Loss: 0.2438, Accuracy: 0.2593\n",
      "Epoch [411/4000], Discriminator Loss: 0.0807, Generator Loss: 0.3042, Series Loss: 0.0038, Class Loss: 0.2437, Accuracy: 0.2654\n",
      "Epoch [412/4000], Discriminator Loss: 0.0806, Generator Loss: 0.3045, Series Loss: 0.0038, Class Loss: 0.2438, Accuracy: 0.2531\n",
      "Epoch [413/4000], Discriminator Loss: 0.0807, Generator Loss: 0.3047, Series Loss: 0.0039, Class Loss: 0.2438, Accuracy: 0.2531\n",
      "Epoch [414/4000], Discriminator Loss: 0.0808, Generator Loss: 0.3051, Series Loss: 0.0038, Class Loss: 0.2437, Accuracy: 0.2531\n",
      "Epoch [415/4000], Discriminator Loss: 0.0806, Generator Loss: 0.3043, Series Loss: 0.0039, Class Loss: 0.2438, Accuracy: 0.2593\n",
      "Epoch [416/4000], Discriminator Loss: 0.0807, Generator Loss: 0.3048, Series Loss: 0.0039, Class Loss: 0.2437, Accuracy: 0.2407\n",
      "Epoch [417/4000], Discriminator Loss: 0.0812, Generator Loss: 0.3048, Series Loss: 0.0039, Class Loss: 0.2437, Accuracy: 0.2531\n",
      "Epoch [418/4000], Discriminator Loss: 0.0806, Generator Loss: 0.3044, Series Loss: 0.0040, Class Loss: 0.2436, Accuracy: 0.2654\n",
      "Epoch [419/4000], Discriminator Loss: 0.0813, Generator Loss: 0.3051, Series Loss: 0.0040, Class Loss: 0.2437, Accuracy: 0.2346\n",
      "Epoch [420/4000], Discriminator Loss: 0.0811, Generator Loss: 0.3046, Series Loss: 0.0040, Class Loss: 0.2437, Accuracy: 0.2469\n",
      "Epoch [421/4000], Discriminator Loss: 0.0808, Generator Loss: 0.3054, Series Loss: 0.0041, Class Loss: 0.2439, Accuracy: 0.2469\n",
      "Epoch [422/4000], Discriminator Loss: 0.0807, Generator Loss: 0.3054, Series Loss: 0.0041, Class Loss: 0.2439, Accuracy: 0.2469\n",
      "Epoch [423/4000], Discriminator Loss: 0.0808, Generator Loss: 0.3055, Series Loss: 0.0041, Class Loss: 0.2439, Accuracy: 0.2469\n",
      "Epoch [424/4000], Discriminator Loss: 0.0813, Generator Loss: 0.3048, Series Loss: 0.0041, Class Loss: 0.2439, Accuracy: 0.2531\n",
      "Epoch [425/4000], Discriminator Loss: 0.0805, Generator Loss: 0.3056, Series Loss: 0.0042, Class Loss: 0.2438, Accuracy: 0.2531\n",
      "Epoch [426/4000], Discriminator Loss: 0.0805, Generator Loss: 0.3051, Series Loss: 0.0042, Class Loss: 0.2438, Accuracy: 0.2531\n",
      "Epoch [427/4000], Discriminator Loss: 0.0809, Generator Loss: 0.3046, Series Loss: 0.0042, Class Loss: 0.2437, Accuracy: 0.2469\n",
      "Epoch [428/4000], Discriminator Loss: 0.0804, Generator Loss: 0.3052, Series Loss: 0.0042, Class Loss: 0.2439, Accuracy: 0.2531\n",
      "Epoch [429/4000], Discriminator Loss: 0.0801, Generator Loss: 0.3054, Series Loss: 0.0042, Class Loss: 0.2439, Accuracy: 0.2469\n",
      "Epoch [430/4000], Discriminator Loss: 0.0800, Generator Loss: 0.3048, Series Loss: 0.0043, Class Loss: 0.2438, Accuracy: 0.2407\n",
      "Epoch [431/4000], Discriminator Loss: 0.0801, Generator Loss: 0.3051, Series Loss: 0.0043, Class Loss: 0.2439, Accuracy: 0.2469\n",
      "Epoch [432/4000], Discriminator Loss: 0.0809, Generator Loss: 0.3052, Series Loss: 0.0044, Class Loss: 0.2441, Accuracy: 0.2469\n",
      "Epoch [433/4000], Discriminator Loss: 0.0801, Generator Loss: 0.3052, Series Loss: 0.0044, Class Loss: 0.2439, Accuracy: 0.2531\n",
      "Epoch [434/4000], Discriminator Loss: 0.0806, Generator Loss: 0.3049, Series Loss: 0.0044, Class Loss: 0.2440, Accuracy: 0.2469\n",
      "Epoch [435/4000], Discriminator Loss: 0.0801, Generator Loss: 0.3052, Series Loss: 0.0045, Class Loss: 0.2439, Accuracy: 0.2469\n",
      "Epoch [436/4000], Discriminator Loss: 0.0805, Generator Loss: 0.3056, Series Loss: 0.0046, Class Loss: 0.2439, Accuracy: 0.2469\n",
      "Epoch [437/4000], Discriminator Loss: 0.0801, Generator Loss: 0.3057, Series Loss: 0.0046, Class Loss: 0.2438, Accuracy: 0.2469\n",
      "Epoch [438/4000], Discriminator Loss: 0.0802, Generator Loss: 0.3052, Series Loss: 0.0046, Class Loss: 0.2439, Accuracy: 0.2469\n",
      "Epoch [439/4000], Discriminator Loss: 0.0807, Generator Loss: 0.3057, Series Loss: 0.0047, Class Loss: 0.2440, Accuracy: 0.2469\n",
      "Epoch [440/4000], Discriminator Loss: 0.0806, Generator Loss: 0.3054, Series Loss: 0.0047, Class Loss: 0.2441, Accuracy: 0.2407\n",
      "Epoch [441/4000], Discriminator Loss: 0.0810, Generator Loss: 0.3056, Series Loss: 0.0048, Class Loss: 0.2440, Accuracy: 0.2407\n",
      "Epoch [442/4000], Discriminator Loss: 0.0810, Generator Loss: 0.3053, Series Loss: 0.0049, Class Loss: 0.2441, Accuracy: 0.2531\n",
      "Epoch [443/4000], Discriminator Loss: 0.0803, Generator Loss: 0.3059, Series Loss: 0.0049, Class Loss: 0.2442, Accuracy: 0.2531\n",
      "Epoch [444/4000], Discriminator Loss: 0.0804, Generator Loss: 0.3055, Series Loss: 0.0050, Class Loss: 0.2440, Accuracy: 0.2469\n",
      "Epoch [445/4000], Discriminator Loss: 0.0807, Generator Loss: 0.3054, Series Loss: 0.0051, Class Loss: 0.2442, Accuracy: 0.2531\n",
      "Epoch [446/4000], Discriminator Loss: 0.0800, Generator Loss: 0.3061, Series Loss: 0.0051, Class Loss: 0.2441, Accuracy: 0.2469\n",
      "Epoch [447/4000], Discriminator Loss: 0.0804, Generator Loss: 0.3055, Series Loss: 0.0051, Class Loss: 0.2441, Accuracy: 0.2469\n",
      "Epoch [448/4000], Discriminator Loss: 0.0806, Generator Loss: 0.3060, Series Loss: 0.0051, Class Loss: 0.2441, Accuracy: 0.2407\n",
      "Epoch [449/4000], Discriminator Loss: 0.0803, Generator Loss: 0.3053, Series Loss: 0.0052, Class Loss: 0.2440, Accuracy: 0.2469\n",
      "Epoch [450/4000], Discriminator Loss: 0.0804, Generator Loss: 0.3060, Series Loss: 0.0052, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [451/4000], Discriminator Loss: 0.0804, Generator Loss: 0.3054, Series Loss: 0.0052, Class Loss: 0.2442, Accuracy: 0.2531\n",
      "Epoch [452/4000], Discriminator Loss: 0.0808, Generator Loss: 0.3051, Series Loss: 0.0053, Class Loss: 0.2441, Accuracy: 0.2469\n",
      "Epoch [453/4000], Discriminator Loss: 0.0808, Generator Loss: 0.3056, Series Loss: 0.0054, Class Loss: 0.2443, Accuracy: 0.2469\n",
      "Epoch [454/4000], Discriminator Loss: 0.0809, Generator Loss: 0.3049, Series Loss: 0.0054, Class Loss: 0.2442, Accuracy: 0.2531\n",
      "Epoch [455/4000], Discriminator Loss: 0.0815, Generator Loss: 0.3057, Series Loss: 0.0055, Class Loss: 0.2443, Accuracy: 0.2531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [456/4000], Discriminator Loss: 0.0811, Generator Loss: 0.3055, Series Loss: 0.0056, Class Loss: 0.2441, Accuracy: 0.2469\n",
      "Epoch [457/4000], Discriminator Loss: 0.0810, Generator Loss: 0.3052, Series Loss: 0.0057, Class Loss: 0.2442, Accuracy: 0.2407\n",
      "Epoch [458/4000], Discriminator Loss: 0.0816, Generator Loss: 0.3048, Series Loss: 0.0058, Class Loss: 0.2441, Accuracy: 0.2531\n",
      "Epoch [459/4000], Discriminator Loss: 0.0814, Generator Loss: 0.3051, Series Loss: 0.0058, Class Loss: 0.2442, Accuracy: 0.2469\n",
      "Epoch [460/4000], Discriminator Loss: 0.0816, Generator Loss: 0.3049, Series Loss: 0.0059, Class Loss: 0.2442, Accuracy: 0.2531\n",
      "Epoch [461/4000], Discriminator Loss: 0.0810, Generator Loss: 0.3055, Series Loss: 0.0059, Class Loss: 0.2442, Accuracy: 0.2593\n",
      "Epoch [462/4000], Discriminator Loss: 0.0809, Generator Loss: 0.3052, Series Loss: 0.0059, Class Loss: 0.2441, Accuracy: 0.2469\n",
      "Epoch [463/4000], Discriminator Loss: 0.0812, Generator Loss: 0.3053, Series Loss: 0.0060, Class Loss: 0.2443, Accuracy: 0.2469\n",
      "Epoch [464/4000], Discriminator Loss: 0.0819, Generator Loss: 0.3053, Series Loss: 0.0061, Class Loss: 0.2442, Accuracy: 0.2593\n",
      "Epoch [465/4000], Discriminator Loss: 0.0817, Generator Loss: 0.3055, Series Loss: 0.0061, Class Loss: 0.2442, Accuracy: 0.2469\n",
      "Epoch [466/4000], Discriminator Loss: 0.0817, Generator Loss: 0.3054, Series Loss: 0.0062, Class Loss: 0.2442, Accuracy: 0.2407\n",
      "Epoch [467/4000], Discriminator Loss: 0.0818, Generator Loss: 0.3050, Series Loss: 0.0062, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [468/4000], Discriminator Loss: 0.0820, Generator Loss: 0.3045, Series Loss: 0.0063, Class Loss: 0.2441, Accuracy: 0.2469\n",
      "Epoch [469/4000], Discriminator Loss: 0.0827, Generator Loss: 0.3047, Series Loss: 0.0064, Class Loss: 0.2443, Accuracy: 0.2469\n",
      "Epoch [470/4000], Discriminator Loss: 0.0815, Generator Loss: 0.3048, Series Loss: 0.0065, Class Loss: 0.2442, Accuracy: 0.2531\n",
      "Epoch [471/4000], Discriminator Loss: 0.0826, Generator Loss: 0.3046, Series Loss: 0.0065, Class Loss: 0.2443, Accuracy: 0.2346\n",
      "Epoch [472/4000], Discriminator Loss: 0.0816, Generator Loss: 0.3050, Series Loss: 0.0066, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [473/4000], Discriminator Loss: 0.0819, Generator Loss: 0.3046, Series Loss: 0.0067, Class Loss: 0.2443, Accuracy: 0.2469\n",
      "Epoch [474/4000], Discriminator Loss: 0.0823, Generator Loss: 0.3052, Series Loss: 0.0067, Class Loss: 0.2444, Accuracy: 0.2346\n",
      "Epoch [475/4000], Discriminator Loss: 0.0823, Generator Loss: 0.3050, Series Loss: 0.0068, Class Loss: 0.2443, Accuracy: 0.2407\n",
      "Epoch [476/4000], Discriminator Loss: 0.0828, Generator Loss: 0.3047, Series Loss: 0.0069, Class Loss: 0.2441, Accuracy: 0.2407\n",
      "Epoch [477/4000], Discriminator Loss: 0.0820, Generator Loss: 0.3048, Series Loss: 0.0070, Class Loss: 0.2443, Accuracy: 0.2346\n",
      "Epoch [478/4000], Discriminator Loss: 0.0825, Generator Loss: 0.3050, Series Loss: 0.0070, Class Loss: 0.2442, Accuracy: 0.2469\n",
      "Epoch [479/4000], Discriminator Loss: 0.0828, Generator Loss: 0.3045, Series Loss: 0.0071, Class Loss: 0.2443, Accuracy: 0.2407\n",
      "Epoch [480/4000], Discriminator Loss: 0.0825, Generator Loss: 0.3045, Series Loss: 0.0071, Class Loss: 0.2443, Accuracy: 0.2469\n",
      "Epoch [481/4000], Discriminator Loss: 0.0828, Generator Loss: 0.3043, Series Loss: 0.0073, Class Loss: 0.2443, Accuracy: 0.2284\n",
      "Epoch [482/4000], Discriminator Loss: 0.0822, Generator Loss: 0.3054, Series Loss: 0.0074, Class Loss: 0.2442, Accuracy: 0.2531\n",
      "Epoch [483/4000], Discriminator Loss: 0.0834, Generator Loss: 0.3047, Series Loss: 0.0075, Class Loss: 0.2442, Accuracy: 0.2531\n",
      "Epoch [484/4000], Discriminator Loss: 0.0845, Generator Loss: 0.3037, Series Loss: 0.0075, Class Loss: 0.2443, Accuracy: 0.2407\n",
      "Epoch [485/4000], Discriminator Loss: 0.0830, Generator Loss: 0.3052, Series Loss: 0.0076, Class Loss: 0.2443, Accuracy: 0.2469\n",
      "Epoch [486/4000], Discriminator Loss: 0.0842, Generator Loss: 0.3045, Series Loss: 0.0077, Class Loss: 0.2442, Accuracy: 0.2346\n",
      "Epoch [487/4000], Discriminator Loss: 0.0835, Generator Loss: 0.3047, Series Loss: 0.0078, Class Loss: 0.2444, Accuracy: 0.2346\n",
      "Epoch [488/4000], Discriminator Loss: 0.0838, Generator Loss: 0.3045, Series Loss: 0.0079, Class Loss: 0.2443, Accuracy: 0.2407\n",
      "Epoch [489/4000], Discriminator Loss: 0.0837, Generator Loss: 0.3058, Series Loss: 0.0080, Class Loss: 0.2442, Accuracy: 0.2407\n",
      "Epoch [490/4000], Discriminator Loss: 0.0844, Generator Loss: 0.3041, Series Loss: 0.0080, Class Loss: 0.2442, Accuracy: 0.2469\n",
      "Epoch [491/4000], Discriminator Loss: 0.0841, Generator Loss: 0.3048, Series Loss: 0.0082, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [492/4000], Discriminator Loss: 0.0861, Generator Loss: 0.3036, Series Loss: 0.0083, Class Loss: 0.2443, Accuracy: 0.2407\n",
      "Epoch [493/4000], Discriminator Loss: 0.0843, Generator Loss: 0.3053, Series Loss: 0.0084, Class Loss: 0.2443, Accuracy: 0.2469\n",
      "Epoch [494/4000], Discriminator Loss: 0.0849, Generator Loss: 0.3048, Series Loss: 0.0084, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [495/4000], Discriminator Loss: 0.0841, Generator Loss: 0.3045, Series Loss: 0.0085, Class Loss: 0.2443, Accuracy: 0.2407\n",
      "Epoch [496/4000], Discriminator Loss: 0.0853, Generator Loss: 0.3045, Series Loss: 0.0085, Class Loss: 0.2442, Accuracy: 0.2407\n",
      "Epoch [497/4000], Discriminator Loss: 0.0848, Generator Loss: 0.3046, Series Loss: 0.0087, Class Loss: 0.2441, Accuracy: 0.2469\n",
      "Epoch [498/4000], Discriminator Loss: 0.0849, Generator Loss: 0.3048, Series Loss: 0.0088, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [499/4000], Discriminator Loss: 0.0858, Generator Loss: 0.3052, Series Loss: 0.0089, Class Loss: 0.2443, Accuracy: 0.2346\n",
      "Epoch [500/4000], Discriminator Loss: 0.0858, Generator Loss: 0.3049, Series Loss: 0.0090, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [501/4000], Discriminator Loss: 0.0863, Generator Loss: 0.3050, Series Loss: 0.0090, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [502/4000], Discriminator Loss: 0.0857, Generator Loss: 0.3047, Series Loss: 0.0090, Class Loss: 0.2442, Accuracy: 0.2407\n",
      "Epoch [503/4000], Discriminator Loss: 0.0862, Generator Loss: 0.3056, Series Loss: 0.0092, Class Loss: 0.2444, Accuracy: 0.2407\n",
      "Epoch [504/4000], Discriminator Loss: 0.0857, Generator Loss: 0.3054, Series Loss: 0.0092, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [505/4000], Discriminator Loss: 0.0868, Generator Loss: 0.3057, Series Loss: 0.0094, Class Loss: 0.2442, Accuracy: 0.2593\n",
      "Epoch [506/4000], Discriminator Loss: 0.0859, Generator Loss: 0.3056, Series Loss: 0.0094, Class Loss: 0.2443, Accuracy: 0.2407\n",
      "Epoch [507/4000], Discriminator Loss: 0.0877, Generator Loss: 0.3048, Series Loss: 0.0095, Class Loss: 0.2444, Accuracy: 0.2407\n",
      "Epoch [508/4000], Discriminator Loss: 0.0864, Generator Loss: 0.3050, Series Loss: 0.0095, Class Loss: 0.2442, Accuracy: 0.2469\n",
      "Epoch [509/4000], Discriminator Loss: 0.0866, Generator Loss: 0.3055, Series Loss: 0.0097, Class Loss: 0.2442, Accuracy: 0.2469\n",
      "Epoch [510/4000], Discriminator Loss: 0.0877, Generator Loss: 0.3051, Series Loss: 0.0097, Class Loss: 0.2443, Accuracy: 0.2469\n",
      "Epoch [511/4000], Discriminator Loss: 0.0873, Generator Loss: 0.3054, Series Loss: 0.0098, Class Loss: 0.2443, Accuracy: 0.2407\n",
      "Epoch [512/4000], Discriminator Loss: 0.0871, Generator Loss: 0.3054, Series Loss: 0.0099, Class Loss: 0.2442, Accuracy: 0.2531\n",
      "Epoch [513/4000], Discriminator Loss: 0.0876, Generator Loss: 0.3046, Series Loss: 0.0100, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [514/4000], Discriminator Loss: 0.0866, Generator Loss: 0.3060, Series Loss: 0.0100, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [515/4000], Discriminator Loss: 0.0873, Generator Loss: 0.3047, Series Loss: 0.0101, Class Loss: 0.2443, Accuracy: 0.2469\n",
      "Epoch [516/4000], Discriminator Loss: 0.0879, Generator Loss: 0.3051, Series Loss: 0.0101, Class Loss: 0.2443, Accuracy: 0.2469\n",
      "Epoch [517/4000], Discriminator Loss: 0.0885, Generator Loss: 0.3054, Series Loss: 0.0104, Class Loss: 0.2443, Accuracy: 0.2469\n",
      "Epoch [518/4000], Discriminator Loss: 0.0885, Generator Loss: 0.3048, Series Loss: 0.0103, Class Loss: 0.2444, Accuracy: 0.2716\n",
      "Epoch [519/4000], Discriminator Loss: 0.0881, Generator Loss: 0.3051, Series Loss: 0.0103, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [520/4000], Discriminator Loss: 0.0874, Generator Loss: 0.3056, Series Loss: 0.0105, Class Loss: 0.2443, Accuracy: 0.2407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [521/4000], Discriminator Loss: 0.0881, Generator Loss: 0.3049, Series Loss: 0.0105, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [522/4000], Discriminator Loss: 0.0887, Generator Loss: 0.3062, Series Loss: 0.0105, Class Loss: 0.2443, Accuracy: 0.2469\n",
      "Epoch [523/4000], Discriminator Loss: 0.0893, Generator Loss: 0.3057, Series Loss: 0.0106, Class Loss: 0.2442, Accuracy: 0.2654\n",
      "Epoch [524/4000], Discriminator Loss: 0.0876, Generator Loss: 0.3062, Series Loss: 0.0108, Class Loss: 0.2442, Accuracy: 0.2531\n",
      "Epoch [525/4000], Discriminator Loss: 0.0889, Generator Loss: 0.3056, Series Loss: 0.0107, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [526/4000], Discriminator Loss: 0.0891, Generator Loss: 0.3063, Series Loss: 0.0107, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [527/4000], Discriminator Loss: 0.0882, Generator Loss: 0.3056, Series Loss: 0.0107, Class Loss: 0.2443, Accuracy: 0.2346\n",
      "Epoch [528/4000], Discriminator Loss: 0.0877, Generator Loss: 0.3066, Series Loss: 0.0109, Class Loss: 0.2442, Accuracy: 0.2593\n",
      "Epoch [529/4000], Discriminator Loss: 0.0886, Generator Loss: 0.3063, Series Loss: 0.0110, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [530/4000], Discriminator Loss: 0.0891, Generator Loss: 0.3055, Series Loss: 0.0109, Class Loss: 0.2443, Accuracy: 0.2716\n",
      "Epoch [531/4000], Discriminator Loss: 0.0891, Generator Loss: 0.3055, Series Loss: 0.0110, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [532/4000], Discriminator Loss: 0.0898, Generator Loss: 0.3062, Series Loss: 0.0110, Class Loss: 0.2443, Accuracy: 0.3025\n",
      "Epoch [533/4000], Discriminator Loss: 0.0884, Generator Loss: 0.3064, Series Loss: 0.0110, Class Loss: 0.2443, Accuracy: 0.2716\n",
      "Epoch [534/4000], Discriminator Loss: 0.0899, Generator Loss: 0.3061, Series Loss: 0.0110, Class Loss: 0.2444, Accuracy: 0.2901\n",
      "Epoch [535/4000], Discriminator Loss: 0.0884, Generator Loss: 0.3065, Series Loss: 0.0111, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [536/4000], Discriminator Loss: 0.0898, Generator Loss: 0.3057, Series Loss: 0.0111, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [537/4000], Discriminator Loss: 0.0904, Generator Loss: 0.3060, Series Loss: 0.0111, Class Loss: 0.2443, Accuracy: 0.2716\n",
      "Epoch [538/4000], Discriminator Loss: 0.0899, Generator Loss: 0.3058, Series Loss: 0.0112, Class Loss: 0.2444, Accuracy: 0.2963\n",
      "Epoch [539/4000], Discriminator Loss: 0.0888, Generator Loss: 0.3062, Series Loss: 0.0111, Class Loss: 0.2444, Accuracy: 0.2901\n",
      "Epoch [540/4000], Discriminator Loss: 0.0900, Generator Loss: 0.3048, Series Loss: 0.0112, Class Loss: 0.2445, Accuracy: 0.3025\n",
      "Epoch [541/4000], Discriminator Loss: 0.0893, Generator Loss: 0.3061, Series Loss: 0.0112, Class Loss: 0.2444, Accuracy: 0.3025\n",
      "Epoch [542/4000], Discriminator Loss: 0.0885, Generator Loss: 0.3054, Series Loss: 0.0112, Class Loss: 0.2443, Accuracy: 0.2963\n",
      "Epoch [543/4000], Discriminator Loss: 0.0904, Generator Loss: 0.3053, Series Loss: 0.0113, Class Loss: 0.2444, Accuracy: 0.2963\n",
      "Epoch [544/4000], Discriminator Loss: 0.0896, Generator Loss: 0.3061, Series Loss: 0.0111, Class Loss: 0.2445, Accuracy: 0.2963\n",
      "Epoch [545/4000], Discriminator Loss: 0.0904, Generator Loss: 0.3056, Series Loss: 0.0111, Class Loss: 0.2444, Accuracy: 0.2963\n",
      "Epoch [546/4000], Discriminator Loss: 0.0899, Generator Loss: 0.3068, Series Loss: 0.0112, Class Loss: 0.2444, Accuracy: 0.2840\n",
      "Epoch [547/4000], Discriminator Loss: 0.0895, Generator Loss: 0.3062, Series Loss: 0.0112, Class Loss: 0.2445, Accuracy: 0.3086\n",
      "Epoch [548/4000], Discriminator Loss: 0.0906, Generator Loss: 0.3061, Series Loss: 0.0111, Class Loss: 0.2445, Accuracy: 0.3025\n",
      "Epoch [549/4000], Discriminator Loss: 0.0897, Generator Loss: 0.3064, Series Loss: 0.0112, Class Loss: 0.2443, Accuracy: 0.3333\n",
      "Epoch [550/4000], Discriminator Loss: 0.0912, Generator Loss: 0.3047, Series Loss: 0.0112, Class Loss: 0.2444, Accuracy: 0.3025\n",
      "Epoch [551/4000], Discriminator Loss: 0.0903, Generator Loss: 0.3052, Series Loss: 0.0110, Class Loss: 0.2443, Accuracy: 0.3025\n",
      "Epoch [552/4000], Discriminator Loss: 0.0903, Generator Loss: 0.3062, Series Loss: 0.0111, Class Loss: 0.2445, Accuracy: 0.3025\n",
      "Epoch [553/4000], Discriminator Loss: 0.0902, Generator Loss: 0.3059, Series Loss: 0.0110, Class Loss: 0.2442, Accuracy: 0.3148\n",
      "Epoch [554/4000], Discriminator Loss: 0.0895, Generator Loss: 0.3062, Series Loss: 0.0112, Class Loss: 0.2444, Accuracy: 0.3086\n",
      "Epoch [555/4000], Discriminator Loss: 0.0894, Generator Loss: 0.3059, Series Loss: 0.0111, Class Loss: 0.2444, Accuracy: 0.3148\n",
      "Epoch [556/4000], Discriminator Loss: 0.0908, Generator Loss: 0.3055, Series Loss: 0.0110, Class Loss: 0.2442, Accuracy: 0.3457\n",
      "Epoch [557/4000], Discriminator Loss: 0.0885, Generator Loss: 0.3069, Series Loss: 0.0111, Class Loss: 0.2445, Accuracy: 0.3148\n",
      "Epoch [558/4000], Discriminator Loss: 0.0887, Generator Loss: 0.3067, Series Loss: 0.0111, Class Loss: 0.2443, Accuracy: 0.3333\n",
      "Epoch [559/4000], Discriminator Loss: 0.0889, Generator Loss: 0.3066, Series Loss: 0.0110, Class Loss: 0.2444, Accuracy: 0.2901\n",
      "Epoch [560/4000], Discriminator Loss: 0.0893, Generator Loss: 0.3067, Series Loss: 0.0111, Class Loss: 0.2444, Accuracy: 0.2963\n",
      "Epoch [561/4000], Discriminator Loss: 0.0896, Generator Loss: 0.3057, Series Loss: 0.0110, Class Loss: 0.2444, Accuracy: 0.3148\n",
      "Epoch [562/4000], Discriminator Loss: 0.0899, Generator Loss: 0.3056, Series Loss: 0.0111, Class Loss: 0.2444, Accuracy: 0.3210\n",
      "Epoch [563/4000], Discriminator Loss: 0.0899, Generator Loss: 0.3055, Series Loss: 0.0110, Class Loss: 0.2443, Accuracy: 0.3333\n",
      "Epoch [564/4000], Discriminator Loss: 0.0903, Generator Loss: 0.3060, Series Loss: 0.0111, Class Loss: 0.2443, Accuracy: 0.3210\n",
      "Epoch [565/4000], Discriminator Loss: 0.0902, Generator Loss: 0.3061, Series Loss: 0.0111, Class Loss: 0.2444, Accuracy: 0.3642\n",
      "Epoch [566/4000], Discriminator Loss: 0.0896, Generator Loss: 0.3063, Series Loss: 0.0110, Class Loss: 0.2445, Accuracy: 0.3210\n",
      "Epoch [567/4000], Discriminator Loss: 0.0897, Generator Loss: 0.3066, Series Loss: 0.0111, Class Loss: 0.2443, Accuracy: 0.3210\n",
      "Epoch [568/4000], Discriminator Loss: 0.0901, Generator Loss: 0.3063, Series Loss: 0.0110, Class Loss: 0.2443, Accuracy: 0.3333\n",
      "Epoch [569/4000], Discriminator Loss: 0.0901, Generator Loss: 0.3062, Series Loss: 0.0111, Class Loss: 0.2443, Accuracy: 0.3333\n",
      "Epoch [570/4000], Discriminator Loss: 0.0896, Generator Loss: 0.3062, Series Loss: 0.0110, Class Loss: 0.2444, Accuracy: 0.3210\n",
      "Epoch [571/4000], Discriminator Loss: 0.0910, Generator Loss: 0.3059, Series Loss: 0.0109, Class Loss: 0.2443, Accuracy: 0.3519\n",
      "Epoch [572/4000], Discriminator Loss: 0.0907, Generator Loss: 0.3057, Series Loss: 0.0109, Class Loss: 0.2445, Accuracy: 0.3395\n",
      "Epoch [573/4000], Discriminator Loss: 0.0900, Generator Loss: 0.3054, Series Loss: 0.0109, Class Loss: 0.2444, Accuracy: 0.3519\n",
      "Epoch [574/4000], Discriminator Loss: 0.0902, Generator Loss: 0.3063, Series Loss: 0.0108, Class Loss: 0.2444, Accuracy: 0.3457\n",
      "Epoch [575/4000], Discriminator Loss: 0.0897, Generator Loss: 0.3070, Series Loss: 0.0109, Class Loss: 0.2445, Accuracy: 0.3457\n",
      "Epoch [576/4000], Discriminator Loss: 0.0909, Generator Loss: 0.3057, Series Loss: 0.0109, Class Loss: 0.2444, Accuracy: 0.3210\n",
      "Epoch [577/4000], Discriminator Loss: 0.0896, Generator Loss: 0.3068, Series Loss: 0.0110, Class Loss: 0.2445, Accuracy: 0.3765\n",
      "Epoch [578/4000], Discriminator Loss: 0.0914, Generator Loss: 0.3057, Series Loss: 0.0110, Class Loss: 0.2443, Accuracy: 0.3704\n",
      "Epoch [579/4000], Discriminator Loss: 0.0909, Generator Loss: 0.3057, Series Loss: 0.0109, Class Loss: 0.2445, Accuracy: 0.3333\n",
      "Epoch [580/4000], Discriminator Loss: 0.0907, Generator Loss: 0.3067, Series Loss: 0.0110, Class Loss: 0.2444, Accuracy: 0.3519\n",
      "Epoch [581/4000], Discriminator Loss: 0.0904, Generator Loss: 0.3055, Series Loss: 0.0110, Class Loss: 0.2444, Accuracy: 0.3642\n",
      "Epoch [582/4000], Discriminator Loss: 0.0900, Generator Loss: 0.3058, Series Loss: 0.0110, Class Loss: 0.2444, Accuracy: 0.3333\n",
      "Epoch [583/4000], Discriminator Loss: 0.0905, Generator Loss: 0.3066, Series Loss: 0.0109, Class Loss: 0.2444, Accuracy: 0.3457\n",
      "Epoch [584/4000], Discriminator Loss: 0.0912, Generator Loss: 0.3056, Series Loss: 0.0110, Class Loss: 0.2444, Accuracy: 0.3519\n",
      "Epoch [585/4000], Discriminator Loss: 0.0896, Generator Loss: 0.3062, Series Loss: 0.0110, Class Loss: 0.2444, Accuracy: 0.3951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [586/4000], Discriminator Loss: 0.0910, Generator Loss: 0.3056, Series Loss: 0.0110, Class Loss: 0.2443, Accuracy: 0.3889\n",
      "Epoch [587/4000], Discriminator Loss: 0.0889, Generator Loss: 0.3066, Series Loss: 0.0110, Class Loss: 0.2443, Accuracy: 0.3333\n",
      "Epoch [588/4000], Discriminator Loss: 0.0908, Generator Loss: 0.3054, Series Loss: 0.0110, Class Loss: 0.2442, Accuracy: 0.3765\n",
      "Epoch [589/4000], Discriminator Loss: 0.0914, Generator Loss: 0.3057, Series Loss: 0.0110, Class Loss: 0.2443, Accuracy: 0.3580\n",
      "Epoch [590/4000], Discriminator Loss: 0.0896, Generator Loss: 0.3063, Series Loss: 0.0110, Class Loss: 0.2442, Accuracy: 0.3395\n",
      "Epoch [591/4000], Discriminator Loss: 0.0910, Generator Loss: 0.3050, Series Loss: 0.0109, Class Loss: 0.2443, Accuracy: 0.3519\n",
      "Epoch [592/4000], Discriminator Loss: 0.0912, Generator Loss: 0.3056, Series Loss: 0.0109, Class Loss: 0.2444, Accuracy: 0.3395\n",
      "Epoch [593/4000], Discriminator Loss: 0.0908, Generator Loss: 0.3062, Series Loss: 0.0109, Class Loss: 0.2442, Accuracy: 0.3272\n",
      "Epoch [594/4000], Discriminator Loss: 0.0911, Generator Loss: 0.3061, Series Loss: 0.0109, Class Loss: 0.2443, Accuracy: 0.3210\n",
      "Epoch [595/4000], Discriminator Loss: 0.0902, Generator Loss: 0.3056, Series Loss: 0.0110, Class Loss: 0.2443, Accuracy: 0.3333\n",
      "Epoch [596/4000], Discriminator Loss: 0.0917, Generator Loss: 0.3044, Series Loss: 0.0109, Class Loss: 0.2442, Accuracy: 0.3086\n",
      "Epoch [597/4000], Discriminator Loss: 0.0898, Generator Loss: 0.3059, Series Loss: 0.0110, Class Loss: 0.2442, Accuracy: 0.2840\n",
      "Epoch [598/4000], Discriminator Loss: 0.0908, Generator Loss: 0.3055, Series Loss: 0.0110, Class Loss: 0.2443, Accuracy: 0.3025\n",
      "Epoch [599/4000], Discriminator Loss: 0.0914, Generator Loss: 0.3047, Series Loss: 0.0111, Class Loss: 0.2442, Accuracy: 0.3148\n",
      "Epoch [600/4000], Discriminator Loss: 0.0913, Generator Loss: 0.3049, Series Loss: 0.0110, Class Loss: 0.2443, Accuracy: 0.3148\n",
      "Epoch [601/4000], Discriminator Loss: 0.0912, Generator Loss: 0.3053, Series Loss: 0.0109, Class Loss: 0.2443, Accuracy: 0.2901\n",
      "Epoch [602/4000], Discriminator Loss: 0.0915, Generator Loss: 0.3051, Series Loss: 0.0110, Class Loss: 0.2441, Accuracy: 0.3086\n",
      "Epoch [603/4000], Discriminator Loss: 0.0911, Generator Loss: 0.3053, Series Loss: 0.0109, Class Loss: 0.2442, Accuracy: 0.2963\n",
      "Epoch [604/4000], Discriminator Loss: 0.0909, Generator Loss: 0.3052, Series Loss: 0.0109, Class Loss: 0.2443, Accuracy: 0.3025\n",
      "Epoch [605/4000], Discriminator Loss: 0.0909, Generator Loss: 0.3054, Series Loss: 0.0108, Class Loss: 0.2442, Accuracy: 0.3025\n",
      "Epoch [606/4000], Discriminator Loss: 0.0913, Generator Loss: 0.3049, Series Loss: 0.0108, Class Loss: 0.2441, Accuracy: 0.2901\n",
      "Epoch [607/4000], Discriminator Loss: 0.0931, Generator Loss: 0.3044, Series Loss: 0.0108, Class Loss: 0.2441, Accuracy: 0.3025\n",
      "Epoch [608/4000], Discriminator Loss: 0.0923, Generator Loss: 0.3044, Series Loss: 0.0107, Class Loss: 0.2443, Accuracy: 0.3025\n",
      "Epoch [609/4000], Discriminator Loss: 0.0921, Generator Loss: 0.3041, Series Loss: 0.0107, Class Loss: 0.2441, Accuracy: 0.2840\n",
      "Epoch [610/4000], Discriminator Loss: 0.0914, Generator Loss: 0.3054, Series Loss: 0.0107, Class Loss: 0.2442, Accuracy: 0.2901\n",
      "Epoch [611/4000], Discriminator Loss: 0.0923, Generator Loss: 0.3048, Series Loss: 0.0107, Class Loss: 0.2442, Accuracy: 0.2901\n",
      "Epoch [612/4000], Discriminator Loss: 0.0926, Generator Loss: 0.3048, Series Loss: 0.0106, Class Loss: 0.2443, Accuracy: 0.2963\n",
      "Epoch [613/4000], Discriminator Loss: 0.0908, Generator Loss: 0.3052, Series Loss: 0.0106, Class Loss: 0.2443, Accuracy: 0.2840\n",
      "Epoch [614/4000], Discriminator Loss: 0.0920, Generator Loss: 0.3053, Series Loss: 0.0106, Class Loss: 0.2442, Accuracy: 0.3086\n",
      "Epoch [615/4000], Discriminator Loss: 0.0910, Generator Loss: 0.3046, Series Loss: 0.0107, Class Loss: 0.2441, Accuracy: 0.3025\n",
      "Epoch [616/4000], Discriminator Loss: 0.0910, Generator Loss: 0.3053, Series Loss: 0.0107, Class Loss: 0.2441, Accuracy: 0.2963\n",
      "Epoch [617/4000], Discriminator Loss: 0.0910, Generator Loss: 0.3055, Series Loss: 0.0106, Class Loss: 0.2443, Accuracy: 0.2778\n",
      "Epoch [618/4000], Discriminator Loss: 0.0910, Generator Loss: 0.3054, Series Loss: 0.0106, Class Loss: 0.2442, Accuracy: 0.3025\n",
      "Epoch [619/4000], Discriminator Loss: 0.0923, Generator Loss: 0.3046, Series Loss: 0.0107, Class Loss: 0.2441, Accuracy: 0.2963\n",
      "Epoch [620/4000], Discriminator Loss: 0.0909, Generator Loss: 0.3055, Series Loss: 0.0106, Class Loss: 0.2442, Accuracy: 0.2778\n",
      "Epoch [621/4000], Discriminator Loss: 0.0906, Generator Loss: 0.3062, Series Loss: 0.0105, Class Loss: 0.2442, Accuracy: 0.2901\n",
      "Epoch [622/4000], Discriminator Loss: 0.0897, Generator Loss: 0.3057, Series Loss: 0.0107, Class Loss: 0.2442, Accuracy: 0.3086\n",
      "Epoch [623/4000], Discriminator Loss: 0.0906, Generator Loss: 0.3061, Series Loss: 0.0107, Class Loss: 0.2443, Accuracy: 0.2963\n",
      "Epoch [624/4000], Discriminator Loss: 0.0908, Generator Loss: 0.3055, Series Loss: 0.0106, Class Loss: 0.2441, Accuracy: 0.3025\n",
      "Epoch [625/4000], Discriminator Loss: 0.0905, Generator Loss: 0.3055, Series Loss: 0.0104, Class Loss: 0.2442, Accuracy: 0.3210\n",
      "Epoch [626/4000], Discriminator Loss: 0.0901, Generator Loss: 0.3058, Series Loss: 0.0106, Class Loss: 0.2441, Accuracy: 0.3210\n",
      "Epoch [627/4000], Discriminator Loss: 0.0898, Generator Loss: 0.3056, Series Loss: 0.0105, Class Loss: 0.2443, Accuracy: 0.3086\n",
      "Epoch [628/4000], Discriminator Loss: 0.0902, Generator Loss: 0.3061, Series Loss: 0.0105, Class Loss: 0.2441, Accuracy: 0.2963\n",
      "Epoch [629/4000], Discriminator Loss: 0.0907, Generator Loss: 0.3049, Series Loss: 0.0106, Class Loss: 0.2441, Accuracy: 0.2901\n",
      "Epoch [630/4000], Discriminator Loss: 0.0903, Generator Loss: 0.3058, Series Loss: 0.0105, Class Loss: 0.2442, Accuracy: 0.2963\n",
      "Epoch [631/4000], Discriminator Loss: 0.0907, Generator Loss: 0.3053, Series Loss: 0.0105, Class Loss: 0.2441, Accuracy: 0.2963\n",
      "Epoch [632/4000], Discriminator Loss: 0.0890, Generator Loss: 0.3056, Series Loss: 0.0106, Class Loss: 0.2442, Accuracy: 0.2963\n",
      "Epoch [633/4000], Discriminator Loss: 0.0899, Generator Loss: 0.3052, Series Loss: 0.0105, Class Loss: 0.2440, Accuracy: 0.3086\n",
      "Epoch [634/4000], Discriminator Loss: 0.0891, Generator Loss: 0.3053, Series Loss: 0.0104, Class Loss: 0.2442, Accuracy: 0.3086\n",
      "Epoch [635/4000], Discriminator Loss: 0.0892, Generator Loss: 0.3066, Series Loss: 0.0105, Class Loss: 0.2442, Accuracy: 0.2963\n",
      "Epoch [636/4000], Discriminator Loss: 0.0903, Generator Loss: 0.3058, Series Loss: 0.0104, Class Loss: 0.2440, Accuracy: 0.2963\n",
      "Epoch [637/4000], Discriminator Loss: 0.0896, Generator Loss: 0.3062, Series Loss: 0.0104, Class Loss: 0.2441, Accuracy: 0.3025\n",
      "Epoch [638/4000], Discriminator Loss: 0.0906, Generator Loss: 0.3057, Series Loss: 0.0103, Class Loss: 0.2440, Accuracy: 0.2963\n",
      "Epoch [639/4000], Discriminator Loss: 0.0898, Generator Loss: 0.3062, Series Loss: 0.0103, Class Loss: 0.2442, Accuracy: 0.2840\n",
      "Epoch [640/4000], Discriminator Loss: 0.0897, Generator Loss: 0.3055, Series Loss: 0.0103, Class Loss: 0.2441, Accuracy: 0.3086\n",
      "Epoch [641/4000], Discriminator Loss: 0.0890, Generator Loss: 0.3064, Series Loss: 0.0104, Class Loss: 0.2441, Accuracy: 0.2963\n",
      "Epoch [642/4000], Discriminator Loss: 0.0897, Generator Loss: 0.3062, Series Loss: 0.0103, Class Loss: 0.2441, Accuracy: 0.3025\n",
      "Epoch [643/4000], Discriminator Loss: 0.0900, Generator Loss: 0.3056, Series Loss: 0.0103, Class Loss: 0.2440, Accuracy: 0.2901\n",
      "Epoch [644/4000], Discriminator Loss: 0.0885, Generator Loss: 0.3071, Series Loss: 0.0103, Class Loss: 0.2442, Accuracy: 0.2963\n",
      "Epoch [645/4000], Discriminator Loss: 0.0898, Generator Loss: 0.3069, Series Loss: 0.0103, Class Loss: 0.2442, Accuracy: 0.2901\n",
      "Epoch [646/4000], Discriminator Loss: 0.0892, Generator Loss: 0.3069, Series Loss: 0.0103, Class Loss: 0.2442, Accuracy: 0.3086\n",
      "Epoch [647/4000], Discriminator Loss: 0.0882, Generator Loss: 0.3063, Series Loss: 0.0102, Class Loss: 0.2441, Accuracy: 0.2901\n",
      "Epoch [648/4000], Discriminator Loss: 0.0888, Generator Loss: 0.3066, Series Loss: 0.0102, Class Loss: 0.2440, Accuracy: 0.3148\n",
      "Epoch [649/4000], Discriminator Loss: 0.0900, Generator Loss: 0.3058, Series Loss: 0.0102, Class Loss: 0.2440, Accuracy: 0.2901\n",
      "Epoch [650/4000], Discriminator Loss: 0.0889, Generator Loss: 0.3069, Series Loss: 0.0103, Class Loss: 0.2440, Accuracy: 0.3210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [651/4000], Discriminator Loss: 0.0891, Generator Loss: 0.3062, Series Loss: 0.0103, Class Loss: 0.2441, Accuracy: 0.2963\n",
      "Epoch [652/4000], Discriminator Loss: 0.0885, Generator Loss: 0.3067, Series Loss: 0.0102, Class Loss: 0.2440, Accuracy: 0.3025\n",
      "Epoch [653/4000], Discriminator Loss: 0.0891, Generator Loss: 0.3063, Series Loss: 0.0103, Class Loss: 0.2441, Accuracy: 0.3148\n",
      "Epoch [654/4000], Discriminator Loss: 0.0891, Generator Loss: 0.3070, Series Loss: 0.0102, Class Loss: 0.2441, Accuracy: 0.3025\n",
      "Epoch [655/4000], Discriminator Loss: 0.0894, Generator Loss: 0.3070, Series Loss: 0.0102, Class Loss: 0.2441, Accuracy: 0.3086\n",
      "Epoch [656/4000], Discriminator Loss: 0.0889, Generator Loss: 0.3068, Series Loss: 0.0102, Class Loss: 0.2441, Accuracy: 0.3148\n",
      "Epoch [657/4000], Discriminator Loss: 0.0891, Generator Loss: 0.3070, Series Loss: 0.0102, Class Loss: 0.2441, Accuracy: 0.2963\n",
      "Epoch [658/4000], Discriminator Loss: 0.0884, Generator Loss: 0.3075, Series Loss: 0.0102, Class Loss: 0.2440, Accuracy: 0.3025\n",
      "Epoch [659/4000], Discriminator Loss: 0.0897, Generator Loss: 0.3065, Series Loss: 0.0101, Class Loss: 0.2440, Accuracy: 0.3210\n",
      "Epoch [660/4000], Discriminator Loss: 0.0890, Generator Loss: 0.3070, Series Loss: 0.0102, Class Loss: 0.2442, Accuracy: 0.3086\n",
      "Epoch [661/4000], Discriminator Loss: 0.0886, Generator Loss: 0.3066, Series Loss: 0.0101, Class Loss: 0.2441, Accuracy: 0.3086\n",
      "Epoch [662/4000], Discriminator Loss: 0.0889, Generator Loss: 0.3080, Series Loss: 0.0101, Class Loss: 0.2441, Accuracy: 0.3086\n",
      "Epoch [663/4000], Discriminator Loss: 0.0889, Generator Loss: 0.3072, Series Loss: 0.0101, Class Loss: 0.2440, Accuracy: 0.2840\n",
      "Epoch [664/4000], Discriminator Loss: 0.0887, Generator Loss: 0.3071, Series Loss: 0.0101, Class Loss: 0.2441, Accuracy: 0.3086\n",
      "Epoch [665/4000], Discriminator Loss: 0.0886, Generator Loss: 0.3072, Series Loss: 0.0102, Class Loss: 0.2440, Accuracy: 0.3086\n",
      "Epoch [666/4000], Discriminator Loss: 0.0888, Generator Loss: 0.3064, Series Loss: 0.0100, Class Loss: 0.2441, Accuracy: 0.3025\n",
      "Epoch [667/4000], Discriminator Loss: 0.0884, Generator Loss: 0.3074, Series Loss: 0.0101, Class Loss: 0.2441, Accuracy: 0.3086\n",
      "Epoch [668/4000], Discriminator Loss: 0.0896, Generator Loss: 0.3073, Series Loss: 0.0101, Class Loss: 0.2440, Accuracy: 0.2963\n",
      "Epoch [669/4000], Discriminator Loss: 0.0886, Generator Loss: 0.3068, Series Loss: 0.0101, Class Loss: 0.2440, Accuracy: 0.3148\n",
      "Epoch [670/4000], Discriminator Loss: 0.0893, Generator Loss: 0.3070, Series Loss: 0.0101, Class Loss: 0.2440, Accuracy: 0.2963\n",
      "Epoch [671/4000], Discriminator Loss: 0.0894, Generator Loss: 0.3066, Series Loss: 0.0101, Class Loss: 0.2440, Accuracy: 0.3086\n",
      "Epoch [672/4000], Discriminator Loss: 0.0886, Generator Loss: 0.3067, Series Loss: 0.0101, Class Loss: 0.2441, Accuracy: 0.2963\n",
      "Epoch [673/4000], Discriminator Loss: 0.0893, Generator Loss: 0.3068, Series Loss: 0.0100, Class Loss: 0.2441, Accuracy: 0.3086\n",
      "Epoch [674/4000], Discriminator Loss: 0.0883, Generator Loss: 0.3075, Series Loss: 0.0100, Class Loss: 0.2441, Accuracy: 0.2901\n",
      "Epoch [675/4000], Discriminator Loss: 0.0899, Generator Loss: 0.3071, Series Loss: 0.0101, Class Loss: 0.2441, Accuracy: 0.2963\n",
      "Epoch [676/4000], Discriminator Loss: 0.0882, Generator Loss: 0.3074, Series Loss: 0.0100, Class Loss: 0.2440, Accuracy: 0.2840\n",
      "Epoch [677/4000], Discriminator Loss: 0.0890, Generator Loss: 0.3074, Series Loss: 0.0100, Class Loss: 0.2441, Accuracy: 0.2963\n",
      "Epoch [678/4000], Discriminator Loss: 0.0880, Generator Loss: 0.3069, Series Loss: 0.0100, Class Loss: 0.2440, Accuracy: 0.2840\n",
      "Epoch [679/4000], Discriminator Loss: 0.0889, Generator Loss: 0.3070, Series Loss: 0.0099, Class Loss: 0.2440, Accuracy: 0.3086\n",
      "Epoch [680/4000], Discriminator Loss: 0.0896, Generator Loss: 0.3072, Series Loss: 0.0100, Class Loss: 0.2440, Accuracy: 0.2778\n",
      "Epoch [681/4000], Discriminator Loss: 0.0901, Generator Loss: 0.3068, Series Loss: 0.0099, Class Loss: 0.2442, Accuracy: 0.2901\n",
      "Epoch [682/4000], Discriminator Loss: 0.0889, Generator Loss: 0.3069, Series Loss: 0.0099, Class Loss: 0.2440, Accuracy: 0.2963\n",
      "Epoch [683/4000], Discriminator Loss: 0.0896, Generator Loss: 0.3078, Series Loss: 0.0100, Class Loss: 0.2441, Accuracy: 0.3148\n",
      "Epoch [684/4000], Discriminator Loss: 0.0892, Generator Loss: 0.3065, Series Loss: 0.0100, Class Loss: 0.2441, Accuracy: 0.2963\n",
      "Epoch [685/4000], Discriminator Loss: 0.0895, Generator Loss: 0.3071, Series Loss: 0.0100, Class Loss: 0.2440, Accuracy: 0.2840\n",
      "Epoch [686/4000], Discriminator Loss: 0.0892, Generator Loss: 0.3073, Series Loss: 0.0099, Class Loss: 0.2440, Accuracy: 0.2901\n",
      "Epoch [687/4000], Discriminator Loss: 0.0897, Generator Loss: 0.3076, Series Loss: 0.0100, Class Loss: 0.2442, Accuracy: 0.2654\n",
      "Epoch [688/4000], Discriminator Loss: 0.0884, Generator Loss: 0.3070, Series Loss: 0.0099, Class Loss: 0.2440, Accuracy: 0.2963\n",
      "Epoch [689/4000], Discriminator Loss: 0.0891, Generator Loss: 0.3070, Series Loss: 0.0099, Class Loss: 0.2441, Accuracy: 0.2963\n",
      "Epoch [690/4000], Discriminator Loss: 0.0894, Generator Loss: 0.3074, Series Loss: 0.0099, Class Loss: 0.2442, Accuracy: 0.2778\n",
      "Epoch [691/4000], Discriminator Loss: 0.0896, Generator Loss: 0.3065, Series Loss: 0.0099, Class Loss: 0.2440, Accuracy: 0.2963\n",
      "Epoch [692/4000], Discriminator Loss: 0.0891, Generator Loss: 0.3068, Series Loss: 0.0099, Class Loss: 0.2441, Accuracy: 0.2963\n",
      "Epoch [693/4000], Discriminator Loss: 0.0899, Generator Loss: 0.3066, Series Loss: 0.0099, Class Loss: 0.2440, Accuracy: 0.2654\n",
      "Epoch [694/4000], Discriminator Loss: 0.0894, Generator Loss: 0.3069, Series Loss: 0.0099, Class Loss: 0.2441, Accuracy: 0.2840\n",
      "Epoch [695/4000], Discriminator Loss: 0.0885, Generator Loss: 0.3071, Series Loss: 0.0100, Class Loss: 0.2441, Accuracy: 0.2901\n",
      "Epoch [696/4000], Discriminator Loss: 0.0891, Generator Loss: 0.3069, Series Loss: 0.0099, Class Loss: 0.2441, Accuracy: 0.2778\n",
      "Epoch [697/4000], Discriminator Loss: 0.0896, Generator Loss: 0.3076, Series Loss: 0.0099, Class Loss: 0.2442, Accuracy: 0.2778\n",
      "Epoch [698/4000], Discriminator Loss: 0.0896, Generator Loss: 0.3068, Series Loss: 0.0099, Class Loss: 0.2441, Accuracy: 0.2840\n",
      "Epoch [699/4000], Discriminator Loss: 0.0895, Generator Loss: 0.3070, Series Loss: 0.0100, Class Loss: 0.2440, Accuracy: 0.2901\n",
      "Epoch [700/4000], Discriminator Loss: 0.0901, Generator Loss: 0.3063, Series Loss: 0.0100, Class Loss: 0.2439, Accuracy: 0.2963\n",
      "Epoch [701/4000], Discriminator Loss: 0.0887, Generator Loss: 0.3070, Series Loss: 0.0100, Class Loss: 0.2441, Accuracy: 0.2654\n",
      "Epoch [702/4000], Discriminator Loss: 0.0900, Generator Loss: 0.3066, Series Loss: 0.0100, Class Loss: 0.2441, Accuracy: 0.2963\n",
      "Epoch [703/4000], Discriminator Loss: 0.0891, Generator Loss: 0.3065, Series Loss: 0.0100, Class Loss: 0.2440, Accuracy: 0.2716\n",
      "Epoch [704/4000], Discriminator Loss: 0.0890, Generator Loss: 0.3062, Series Loss: 0.0100, Class Loss: 0.2442, Accuracy: 0.2716\n",
      "Epoch [705/4000], Discriminator Loss: 0.0895, Generator Loss: 0.3070, Series Loss: 0.0100, Class Loss: 0.2441, Accuracy: 0.2963\n",
      "Epoch [706/4000], Discriminator Loss: 0.0891, Generator Loss: 0.3070, Series Loss: 0.0100, Class Loss: 0.2441, Accuracy: 0.2840\n",
      "Epoch [707/4000], Discriminator Loss: 0.0899, Generator Loss: 0.3071, Series Loss: 0.0100, Class Loss: 0.2441, Accuracy: 0.2716\n",
      "Epoch [708/4000], Discriminator Loss: 0.0897, Generator Loss: 0.3066, Series Loss: 0.0100, Class Loss: 0.2441, Accuracy: 0.2716\n",
      "Epoch [709/4000], Discriminator Loss: 0.0902, Generator Loss: 0.3063, Series Loss: 0.0101, Class Loss: 0.2441, Accuracy: 0.2901\n",
      "Epoch [710/4000], Discriminator Loss: 0.0899, Generator Loss: 0.3068, Series Loss: 0.0100, Class Loss: 0.2440, Accuracy: 0.2778\n",
      "Epoch [711/4000], Discriminator Loss: 0.0892, Generator Loss: 0.3075, Series Loss: 0.0101, Class Loss: 0.2441, Accuracy: 0.2654\n",
      "Epoch [712/4000], Discriminator Loss: 0.0894, Generator Loss: 0.3067, Series Loss: 0.0100, Class Loss: 0.2440, Accuracy: 0.2778\n",
      "Epoch [713/4000], Discriminator Loss: 0.0888, Generator Loss: 0.3061, Series Loss: 0.0100, Class Loss: 0.2441, Accuracy: 0.2654\n",
      "Epoch [714/4000], Discriminator Loss: 0.0899, Generator Loss: 0.3063, Series Loss: 0.0100, Class Loss: 0.2440, Accuracy: 0.2654\n",
      "Epoch [715/4000], Discriminator Loss: 0.0898, Generator Loss: 0.3063, Series Loss: 0.0100, Class Loss: 0.2440, Accuracy: 0.2593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [716/4000], Discriminator Loss: 0.0898, Generator Loss: 0.3053, Series Loss: 0.0101, Class Loss: 0.2439, Accuracy: 0.2654\n",
      "Epoch [717/4000], Discriminator Loss: 0.0899, Generator Loss: 0.3061, Series Loss: 0.0100, Class Loss: 0.2442, Accuracy: 0.2593\n",
      "Epoch [718/4000], Discriminator Loss: 0.0898, Generator Loss: 0.3056, Series Loss: 0.0100, Class Loss: 0.2440, Accuracy: 0.2531\n",
      "Epoch [719/4000], Discriminator Loss: 0.0897, Generator Loss: 0.3061, Series Loss: 0.0101, Class Loss: 0.2440, Accuracy: 0.2531\n",
      "Epoch [720/4000], Discriminator Loss: 0.0902, Generator Loss: 0.3058, Series Loss: 0.0100, Class Loss: 0.2441, Accuracy: 0.2778\n",
      "Epoch [721/4000], Discriminator Loss: 0.0902, Generator Loss: 0.3063, Series Loss: 0.0101, Class Loss: 0.2441, Accuracy: 0.2716\n",
      "Epoch [722/4000], Discriminator Loss: 0.0903, Generator Loss: 0.3060, Series Loss: 0.0101, Class Loss: 0.2440, Accuracy: 0.2778\n",
      "Epoch [723/4000], Discriminator Loss: 0.0896, Generator Loss: 0.3061, Series Loss: 0.0102, Class Loss: 0.2441, Accuracy: 0.2469\n",
      "Epoch [724/4000], Discriminator Loss: 0.0900, Generator Loss: 0.3059, Series Loss: 0.0102, Class Loss: 0.2440, Accuracy: 0.2778\n",
      "Epoch [725/4000], Discriminator Loss: 0.0895, Generator Loss: 0.3057, Series Loss: 0.0101, Class Loss: 0.2441, Accuracy: 0.2716\n",
      "Epoch [726/4000], Discriminator Loss: 0.0896, Generator Loss: 0.3059, Series Loss: 0.0102, Class Loss: 0.2440, Accuracy: 0.2654\n",
      "Epoch [727/4000], Discriminator Loss: 0.0905, Generator Loss: 0.3055, Series Loss: 0.0101, Class Loss: 0.2441, Accuracy: 0.2593\n",
      "Epoch [728/4000], Discriminator Loss: 0.0897, Generator Loss: 0.3058, Series Loss: 0.0102, Class Loss: 0.2440, Accuracy: 0.2840\n",
      "Epoch [729/4000], Discriminator Loss: 0.0903, Generator Loss: 0.3059, Series Loss: 0.0102, Class Loss: 0.2441, Accuracy: 0.2593\n",
      "Epoch [730/4000], Discriminator Loss: 0.0899, Generator Loss: 0.3068, Series Loss: 0.0101, Class Loss: 0.2440, Accuracy: 0.2593\n",
      "Epoch [731/4000], Discriminator Loss: 0.0899, Generator Loss: 0.3065, Series Loss: 0.0102, Class Loss: 0.2438, Accuracy: 0.2778\n",
      "Epoch [732/4000], Discriminator Loss: 0.0903, Generator Loss: 0.3062, Series Loss: 0.0101, Class Loss: 0.2441, Accuracy: 0.2654\n",
      "Epoch [733/4000], Discriminator Loss: 0.0907, Generator Loss: 0.3058, Series Loss: 0.0102, Class Loss: 0.2440, Accuracy: 0.2840\n",
      "Epoch [734/4000], Discriminator Loss: 0.0907, Generator Loss: 0.3056, Series Loss: 0.0103, Class Loss: 0.2440, Accuracy: 0.2840\n",
      "Epoch [735/4000], Discriminator Loss: 0.0910, Generator Loss: 0.3064, Series Loss: 0.0101, Class Loss: 0.2441, Accuracy: 0.2778\n",
      "Epoch [736/4000], Discriminator Loss: 0.0903, Generator Loss: 0.3063, Series Loss: 0.0102, Class Loss: 0.2442, Accuracy: 0.2654\n",
      "Epoch [737/4000], Discriminator Loss: 0.0909, Generator Loss: 0.3064, Series Loss: 0.0102, Class Loss: 0.2439, Accuracy: 0.2901\n",
      "Epoch [738/4000], Discriminator Loss: 0.0906, Generator Loss: 0.3064, Series Loss: 0.0103, Class Loss: 0.2440, Accuracy: 0.2716\n",
      "Epoch [739/4000], Discriminator Loss: 0.0912, Generator Loss: 0.3059, Series Loss: 0.0103, Class Loss: 0.2440, Accuracy: 0.2840\n",
      "Epoch [740/4000], Discriminator Loss: 0.0901, Generator Loss: 0.3055, Series Loss: 0.0103, Class Loss: 0.2440, Accuracy: 0.2840\n",
      "Epoch [741/4000], Discriminator Loss: 0.0907, Generator Loss: 0.3064, Series Loss: 0.0103, Class Loss: 0.2440, Accuracy: 0.2716\n",
      "Epoch [742/4000], Discriminator Loss: 0.0904, Generator Loss: 0.3067, Series Loss: 0.0104, Class Loss: 0.2441, Accuracy: 0.2778\n",
      "Epoch [743/4000], Discriminator Loss: 0.0896, Generator Loss: 0.3062, Series Loss: 0.0104, Class Loss: 0.2441, Accuracy: 0.2901\n",
      "Epoch [744/4000], Discriminator Loss: 0.0912, Generator Loss: 0.3060, Series Loss: 0.0104, Class Loss: 0.2440, Accuracy: 0.2840\n",
      "Epoch [745/4000], Discriminator Loss: 0.0907, Generator Loss: 0.3063, Series Loss: 0.0103, Class Loss: 0.2440, Accuracy: 0.2840\n",
      "Epoch [746/4000], Discriminator Loss: 0.0909, Generator Loss: 0.3057, Series Loss: 0.0104, Class Loss: 0.2441, Accuracy: 0.2716\n",
      "Epoch [747/4000], Discriminator Loss: 0.0904, Generator Loss: 0.3064, Series Loss: 0.0105, Class Loss: 0.2440, Accuracy: 0.2840\n",
      "Epoch [748/4000], Discriminator Loss: 0.0904, Generator Loss: 0.3062, Series Loss: 0.0105, Class Loss: 0.2439, Accuracy: 0.2840\n",
      "Epoch [749/4000], Discriminator Loss: 0.0904, Generator Loss: 0.3058, Series Loss: 0.0105, Class Loss: 0.2441, Accuracy: 0.2901\n",
      "Epoch [750/4000], Discriminator Loss: 0.0913, Generator Loss: 0.3053, Series Loss: 0.0104, Class Loss: 0.2440, Accuracy: 0.2901\n",
      "Epoch [751/4000], Discriminator Loss: 0.0897, Generator Loss: 0.3062, Series Loss: 0.0106, Class Loss: 0.2440, Accuracy: 0.2901\n",
      "Epoch [752/4000], Discriminator Loss: 0.0904, Generator Loss: 0.3068, Series Loss: 0.0106, Class Loss: 0.2441, Accuracy: 0.2840\n",
      "Epoch [753/4000], Discriminator Loss: 0.0907, Generator Loss: 0.3056, Series Loss: 0.0106, Class Loss: 0.2440, Accuracy: 0.2963\n",
      "Epoch [754/4000], Discriminator Loss: 0.0906, Generator Loss: 0.3057, Series Loss: 0.0105, Class Loss: 0.2441, Accuracy: 0.2963\n",
      "Epoch [755/4000], Discriminator Loss: 0.0901, Generator Loss: 0.3070, Series Loss: 0.0106, Class Loss: 0.2441, Accuracy: 0.2840\n",
      "Epoch [756/4000], Discriminator Loss: 0.0906, Generator Loss: 0.3060, Series Loss: 0.0106, Class Loss: 0.2440, Accuracy: 0.2840\n",
      "Epoch [757/4000], Discriminator Loss: 0.0907, Generator Loss: 0.3054, Series Loss: 0.0106, Class Loss: 0.2441, Accuracy: 0.2963\n",
      "Epoch [758/4000], Discriminator Loss: 0.0906, Generator Loss: 0.3067, Series Loss: 0.0107, Class Loss: 0.2440, Accuracy: 0.2963\n",
      "Epoch [759/4000], Discriminator Loss: 0.0906, Generator Loss: 0.3057, Series Loss: 0.0107, Class Loss: 0.2441, Accuracy: 0.2901\n",
      "Epoch [760/4000], Discriminator Loss: 0.0900, Generator Loss: 0.3064, Series Loss: 0.0107, Class Loss: 0.2441, Accuracy: 0.2963\n",
      "Epoch [761/4000], Discriminator Loss: 0.0902, Generator Loss: 0.3063, Series Loss: 0.0105, Class Loss: 0.2439, Accuracy: 0.2716\n",
      "Epoch [762/4000], Discriminator Loss: 0.0902, Generator Loss: 0.3057, Series Loss: 0.0107, Class Loss: 0.2441, Accuracy: 0.3086\n",
      "Epoch [763/4000], Discriminator Loss: 0.0912, Generator Loss: 0.3061, Series Loss: 0.0106, Class Loss: 0.2441, Accuracy: 0.2778\n",
      "Epoch [764/4000], Discriminator Loss: 0.0898, Generator Loss: 0.3067, Series Loss: 0.0107, Class Loss: 0.2439, Accuracy: 0.2963\n",
      "Epoch [765/4000], Discriminator Loss: 0.0901, Generator Loss: 0.3066, Series Loss: 0.0106, Class Loss: 0.2441, Accuracy: 0.2840\n",
      "Epoch [766/4000], Discriminator Loss: 0.0910, Generator Loss: 0.3058, Series Loss: 0.0106, Class Loss: 0.2441, Accuracy: 0.2901\n",
      "Epoch [767/4000], Discriminator Loss: 0.0907, Generator Loss: 0.3055, Series Loss: 0.0106, Class Loss: 0.2441, Accuracy: 0.2963\n",
      "Epoch [768/4000], Discriminator Loss: 0.0898, Generator Loss: 0.3056, Series Loss: 0.0107, Class Loss: 0.2439, Accuracy: 0.2963\n",
      "Epoch [769/4000], Discriminator Loss: 0.0898, Generator Loss: 0.3057, Series Loss: 0.0107, Class Loss: 0.2440, Accuracy: 0.2901\n",
      "Epoch [770/4000], Discriminator Loss: 0.0906, Generator Loss: 0.3060, Series Loss: 0.0107, Class Loss: 0.2440, Accuracy: 0.2963\n",
      "Epoch [771/4000], Discriminator Loss: 0.0900, Generator Loss: 0.3059, Series Loss: 0.0106, Class Loss: 0.2440, Accuracy: 0.2963\n",
      "Epoch [772/4000], Discriminator Loss: 0.0906, Generator Loss: 0.3065, Series Loss: 0.0106, Class Loss: 0.2440, Accuracy: 0.2901\n",
      "Epoch [773/4000], Discriminator Loss: 0.0902, Generator Loss: 0.3066, Series Loss: 0.0107, Class Loss: 0.2440, Accuracy: 0.3025\n",
      "Epoch [774/4000], Discriminator Loss: 0.0904, Generator Loss: 0.3056, Series Loss: 0.0107, Class Loss: 0.2441, Accuracy: 0.2901\n",
      "Epoch [775/4000], Discriminator Loss: 0.0900, Generator Loss: 0.3058, Series Loss: 0.0107, Class Loss: 0.2441, Accuracy: 0.2963\n",
      "Epoch [776/4000], Discriminator Loss: 0.0901, Generator Loss: 0.3059, Series Loss: 0.0107, Class Loss: 0.2440, Accuracy: 0.2963\n",
      "Epoch [777/4000], Discriminator Loss: 0.0904, Generator Loss: 0.3064, Series Loss: 0.0107, Class Loss: 0.2441, Accuracy: 0.3086\n",
      "Epoch [778/4000], Discriminator Loss: 0.0903, Generator Loss: 0.3056, Series Loss: 0.0106, Class Loss: 0.2440, Accuracy: 0.3025\n",
      "Epoch [779/4000], Discriminator Loss: 0.0900, Generator Loss: 0.3065, Series Loss: 0.0107, Class Loss: 0.2440, Accuracy: 0.2901\n",
      "Epoch [780/4000], Discriminator Loss: 0.0908, Generator Loss: 0.3059, Series Loss: 0.0106, Class Loss: 0.2440, Accuracy: 0.3025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [781/4000], Discriminator Loss: 0.0917, Generator Loss: 0.3053, Series Loss: 0.0106, Class Loss: 0.2440, Accuracy: 0.2963\n",
      "Epoch [782/4000], Discriminator Loss: 0.0909, Generator Loss: 0.3060, Series Loss: 0.0107, Class Loss: 0.2441, Accuracy: 0.2963\n",
      "Epoch [783/4000], Discriminator Loss: 0.0904, Generator Loss: 0.3060, Series Loss: 0.0106, Class Loss: 0.2441, Accuracy: 0.2963\n",
      "Epoch [784/4000], Discriminator Loss: 0.0901, Generator Loss: 0.3059, Series Loss: 0.0108, Class Loss: 0.2441, Accuracy: 0.2963\n",
      "Epoch [785/4000], Discriminator Loss: 0.0913, Generator Loss: 0.3054, Series Loss: 0.0107, Class Loss: 0.2439, Accuracy: 0.2963\n",
      "Epoch [786/4000], Discriminator Loss: 0.0899, Generator Loss: 0.3060, Series Loss: 0.0107, Class Loss: 0.2440, Accuracy: 0.3148\n",
      "Epoch [787/4000], Discriminator Loss: 0.0897, Generator Loss: 0.3069, Series Loss: 0.0106, Class Loss: 0.2441, Accuracy: 0.2963\n",
      "Epoch [788/4000], Discriminator Loss: 0.0905, Generator Loss: 0.3059, Series Loss: 0.0107, Class Loss: 0.2440, Accuracy: 0.2963\n",
      "Epoch [789/4000], Discriminator Loss: 0.0907, Generator Loss: 0.3057, Series Loss: 0.0107, Class Loss: 0.2441, Accuracy: 0.2963\n",
      "Epoch [790/4000], Discriminator Loss: 0.0905, Generator Loss: 0.3061, Series Loss: 0.0107, Class Loss: 0.2440, Accuracy: 0.2963\n",
      "Epoch [791/4000], Discriminator Loss: 0.0910, Generator Loss: 0.3055, Series Loss: 0.0107, Class Loss: 0.2440, Accuracy: 0.3086\n",
      "Epoch [792/4000], Discriminator Loss: 0.0900, Generator Loss: 0.3063, Series Loss: 0.0107, Class Loss: 0.2440, Accuracy: 0.3025\n",
      "Epoch [793/4000], Discriminator Loss: 0.0906, Generator Loss: 0.3061, Series Loss: 0.0107, Class Loss: 0.2441, Accuracy: 0.2840\n",
      "Epoch [794/4000], Discriminator Loss: 0.0908, Generator Loss: 0.3052, Series Loss: 0.0108, Class Loss: 0.2440, Accuracy: 0.2840\n",
      "Epoch [795/4000], Discriminator Loss: 0.0909, Generator Loss: 0.3054, Series Loss: 0.0107, Class Loss: 0.2441, Accuracy: 0.2963\n",
      "Epoch [796/4000], Discriminator Loss: 0.0904, Generator Loss: 0.3058, Series Loss: 0.0108, Class Loss: 0.2440, Accuracy: 0.3086\n",
      "Epoch [797/4000], Discriminator Loss: 0.0906, Generator Loss: 0.3059, Series Loss: 0.0108, Class Loss: 0.2441, Accuracy: 0.3086\n",
      "Epoch [798/4000], Discriminator Loss: 0.0907, Generator Loss: 0.3063, Series Loss: 0.0108, Class Loss: 0.2440, Accuracy: 0.3025\n",
      "Epoch [799/4000], Discriminator Loss: 0.0898, Generator Loss: 0.3067, Series Loss: 0.0109, Class Loss: 0.2440, Accuracy: 0.3025\n",
      "Epoch [800/4000], Discriminator Loss: 0.0908, Generator Loss: 0.3063, Series Loss: 0.0108, Class Loss: 0.2440, Accuracy: 0.2840\n",
      "Epoch [801/4000], Discriminator Loss: 0.0907, Generator Loss: 0.3065, Series Loss: 0.0107, Class Loss: 0.2440, Accuracy: 0.3025\n",
      "Epoch [802/4000], Discriminator Loss: 0.0910, Generator Loss: 0.3061, Series Loss: 0.0108, Class Loss: 0.2441, Accuracy: 0.3025\n",
      "Epoch [803/4000], Discriminator Loss: 0.0897, Generator Loss: 0.3067, Series Loss: 0.0109, Class Loss: 0.2441, Accuracy: 0.2963\n",
      "Epoch [804/4000], Discriminator Loss: 0.0907, Generator Loss: 0.3064, Series Loss: 0.0109, Class Loss: 0.2440, Accuracy: 0.3025\n",
      "Epoch [805/4000], Discriminator Loss: 0.0910, Generator Loss: 0.3056, Series Loss: 0.0108, Class Loss: 0.2440, Accuracy: 0.2901\n",
      "Epoch [806/4000], Discriminator Loss: 0.0904, Generator Loss: 0.3062, Series Loss: 0.0108, Class Loss: 0.2441, Accuracy: 0.3025\n",
      "Epoch [807/4000], Discriminator Loss: 0.0907, Generator Loss: 0.3061, Series Loss: 0.0108, Class Loss: 0.2441, Accuracy: 0.3025\n",
      "Epoch [808/4000], Discriminator Loss: 0.0904, Generator Loss: 0.3060, Series Loss: 0.0108, Class Loss: 0.2441, Accuracy: 0.2901\n",
      "Epoch [809/4000], Discriminator Loss: 0.0908, Generator Loss: 0.3062, Series Loss: 0.0108, Class Loss: 0.2441, Accuracy: 0.2963\n",
      "Epoch [810/4000], Discriminator Loss: 0.0906, Generator Loss: 0.3054, Series Loss: 0.0109, Class Loss: 0.2441, Accuracy: 0.2963\n",
      "Epoch [811/4000], Discriminator Loss: 0.0906, Generator Loss: 0.3056, Series Loss: 0.0108, Class Loss: 0.2440, Accuracy: 0.3086\n",
      "Epoch [812/4000], Discriminator Loss: 0.0895, Generator Loss: 0.3070, Series Loss: 0.0109, Class Loss: 0.2442, Accuracy: 0.2963\n",
      "Epoch [813/4000], Discriminator Loss: 0.0907, Generator Loss: 0.3059, Series Loss: 0.0109, Class Loss: 0.2441, Accuracy: 0.2901\n",
      "Epoch [814/4000], Discriminator Loss: 0.0910, Generator Loss: 0.3058, Series Loss: 0.0108, Class Loss: 0.2443, Accuracy: 0.2963\n",
      "Epoch [815/4000], Discriminator Loss: 0.0910, Generator Loss: 0.3064, Series Loss: 0.0109, Class Loss: 0.2441, Accuracy: 0.2901\n",
      "Epoch [816/4000], Discriminator Loss: 0.0902, Generator Loss: 0.3067, Series Loss: 0.0109, Class Loss: 0.2441, Accuracy: 0.2901\n",
      "Epoch [817/4000], Discriminator Loss: 0.0901, Generator Loss: 0.3068, Series Loss: 0.0109, Class Loss: 0.2440, Accuracy: 0.3086\n",
      "Epoch [818/4000], Discriminator Loss: 0.0909, Generator Loss: 0.3057, Series Loss: 0.0109, Class Loss: 0.2441, Accuracy: 0.3025\n",
      "Epoch [819/4000], Discriminator Loss: 0.0899, Generator Loss: 0.3062, Series Loss: 0.0109, Class Loss: 0.2441, Accuracy: 0.3025\n",
      "Epoch [820/4000], Discriminator Loss: 0.0903, Generator Loss: 0.3066, Series Loss: 0.0110, Class Loss: 0.2441, Accuracy: 0.2901\n",
      "Epoch [821/4000], Discriminator Loss: 0.0909, Generator Loss: 0.3067, Series Loss: 0.0110, Class Loss: 0.2441, Accuracy: 0.2901\n",
      "Epoch [822/4000], Discriminator Loss: 0.0899, Generator Loss: 0.3068, Series Loss: 0.0111, Class Loss: 0.2441, Accuracy: 0.3025\n",
      "Epoch [823/4000], Discriminator Loss: 0.0905, Generator Loss: 0.3059, Series Loss: 0.0111, Class Loss: 0.2440, Accuracy: 0.2901\n",
      "Epoch [824/4000], Discriminator Loss: 0.0910, Generator Loss: 0.3063, Series Loss: 0.0110, Class Loss: 0.2441, Accuracy: 0.2963\n",
      "Epoch [825/4000], Discriminator Loss: 0.0906, Generator Loss: 0.3067, Series Loss: 0.0110, Class Loss: 0.2442, Accuracy: 0.3025\n",
      "Epoch [826/4000], Discriminator Loss: 0.0910, Generator Loss: 0.3060, Series Loss: 0.0111, Class Loss: 0.2441, Accuracy: 0.2963\n",
      "Epoch [827/4000], Discriminator Loss: 0.0902, Generator Loss: 0.3061, Series Loss: 0.0111, Class Loss: 0.2442, Accuracy: 0.3025\n",
      "Epoch [828/4000], Discriminator Loss: 0.0918, Generator Loss: 0.3062, Series Loss: 0.0111, Class Loss: 0.2441, Accuracy: 0.2963\n",
      "Epoch [829/4000], Discriminator Loss: 0.0906, Generator Loss: 0.3062, Series Loss: 0.0110, Class Loss: 0.2441, Accuracy: 0.3025\n",
      "Epoch [830/4000], Discriminator Loss: 0.0914, Generator Loss: 0.3061, Series Loss: 0.0111, Class Loss: 0.2441, Accuracy: 0.2963\n",
      "Epoch [831/4000], Discriminator Loss: 0.0905, Generator Loss: 0.3061, Series Loss: 0.0112, Class Loss: 0.2441, Accuracy: 0.2901\n",
      "Epoch [832/4000], Discriminator Loss: 0.0906, Generator Loss: 0.3054, Series Loss: 0.0111, Class Loss: 0.2441, Accuracy: 0.2963\n",
      "Epoch [833/4000], Discriminator Loss: 0.0917, Generator Loss: 0.3056, Series Loss: 0.0112, Class Loss: 0.2442, Accuracy: 0.3086\n",
      "Epoch [834/4000], Discriminator Loss: 0.0910, Generator Loss: 0.3063, Series Loss: 0.0110, Class Loss: 0.2441, Accuracy: 0.3025\n",
      "Epoch [835/4000], Discriminator Loss: 0.0906, Generator Loss: 0.3064, Series Loss: 0.0111, Class Loss: 0.2441, Accuracy: 0.2963\n",
      "Epoch [836/4000], Discriminator Loss: 0.0904, Generator Loss: 0.3067, Series Loss: 0.0111, Class Loss: 0.2441, Accuracy: 0.3025\n",
      "Epoch [837/4000], Discriminator Loss: 0.0913, Generator Loss: 0.3056, Series Loss: 0.0112, Class Loss: 0.2440, Accuracy: 0.3025\n",
      "Epoch [838/4000], Discriminator Loss: 0.0914, Generator Loss: 0.3059, Series Loss: 0.0111, Class Loss: 0.2442, Accuracy: 0.2901\n",
      "Epoch [839/4000], Discriminator Loss: 0.0906, Generator Loss: 0.3071, Series Loss: 0.0112, Class Loss: 0.2442, Accuracy: 0.2901\n",
      "Epoch [840/4000], Discriminator Loss: 0.0912, Generator Loss: 0.3062, Series Loss: 0.0112, Class Loss: 0.2441, Accuracy: 0.2963\n",
      "Epoch [841/4000], Discriminator Loss: 0.0912, Generator Loss: 0.3059, Series Loss: 0.0112, Class Loss: 0.2442, Accuracy: 0.2901\n",
      "Epoch [842/4000], Discriminator Loss: 0.0908, Generator Loss: 0.3062, Series Loss: 0.0112, Class Loss: 0.2441, Accuracy: 0.3025\n",
      "Epoch [843/4000], Discriminator Loss: 0.0914, Generator Loss: 0.3062, Series Loss: 0.0112, Class Loss: 0.2441, Accuracy: 0.2963\n",
      "Epoch [844/4000], Discriminator Loss: 0.0910, Generator Loss: 0.3063, Series Loss: 0.0112, Class Loss: 0.2442, Accuracy: 0.2963\n",
      "Epoch [845/4000], Discriminator Loss: 0.0912, Generator Loss: 0.3064, Series Loss: 0.0112, Class Loss: 0.2441, Accuracy: 0.3025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [846/4000], Discriminator Loss: 0.0906, Generator Loss: 0.3056, Series Loss: 0.0111, Class Loss: 0.2440, Accuracy: 0.3025\n",
      "Epoch [847/4000], Discriminator Loss: 0.0912, Generator Loss: 0.3066, Series Loss: 0.0113, Class Loss: 0.2441, Accuracy: 0.3025\n",
      "Epoch [848/4000], Discriminator Loss: 0.0917, Generator Loss: 0.3062, Series Loss: 0.0111, Class Loss: 0.2441, Accuracy: 0.3025\n",
      "Epoch [849/4000], Discriminator Loss: 0.0915, Generator Loss: 0.3065, Series Loss: 0.0111, Class Loss: 0.2442, Accuracy: 0.3025\n",
      "Epoch [850/4000], Discriminator Loss: 0.0905, Generator Loss: 0.3068, Series Loss: 0.0112, Class Loss: 0.2441, Accuracy: 0.3025\n",
      "Epoch [851/4000], Discriminator Loss: 0.0911, Generator Loss: 0.3059, Series Loss: 0.0111, Class Loss: 0.2439, Accuracy: 0.3025\n",
      "Epoch [852/4000], Discriminator Loss: 0.0909, Generator Loss: 0.3063, Series Loss: 0.0111, Class Loss: 0.2440, Accuracy: 0.3025\n",
      "Epoch [853/4000], Discriminator Loss: 0.0908, Generator Loss: 0.3066, Series Loss: 0.0112, Class Loss: 0.2440, Accuracy: 0.2963\n",
      "Epoch [854/4000], Discriminator Loss: 0.0916, Generator Loss: 0.3061, Series Loss: 0.0111, Class Loss: 0.2441, Accuracy: 0.3148\n",
      "Epoch [855/4000], Discriminator Loss: 0.0913, Generator Loss: 0.3060, Series Loss: 0.0111, Class Loss: 0.2441, Accuracy: 0.3025\n",
      "Epoch [856/4000], Discriminator Loss: 0.0911, Generator Loss: 0.3057, Series Loss: 0.0111, Class Loss: 0.2440, Accuracy: 0.3025\n",
      "Epoch [857/4000], Discriminator Loss: 0.0913, Generator Loss: 0.3051, Series Loss: 0.0111, Class Loss: 0.2441, Accuracy: 0.3086\n",
      "Epoch [858/4000], Discriminator Loss: 0.0918, Generator Loss: 0.3056, Series Loss: 0.0111, Class Loss: 0.2441, Accuracy: 0.3086\n",
      "Epoch [859/4000], Discriminator Loss: 0.0918, Generator Loss: 0.3056, Series Loss: 0.0111, Class Loss: 0.2440, Accuracy: 0.3025\n",
      "Epoch [860/4000], Discriminator Loss: 0.0920, Generator Loss: 0.3060, Series Loss: 0.0111, Class Loss: 0.2440, Accuracy: 0.3025\n",
      "Epoch [861/4000], Discriminator Loss: 0.0919, Generator Loss: 0.3059, Series Loss: 0.0110, Class Loss: 0.2441, Accuracy: 0.3025\n",
      "Epoch [862/4000], Discriminator Loss: 0.0910, Generator Loss: 0.3062, Series Loss: 0.0111, Class Loss: 0.2440, Accuracy: 0.2963\n",
      "Epoch [863/4000], Discriminator Loss: 0.0910, Generator Loss: 0.3061, Series Loss: 0.0111, Class Loss: 0.2441, Accuracy: 0.3025\n",
      "Epoch [864/4000], Discriminator Loss: 0.0905, Generator Loss: 0.3061, Series Loss: 0.0110, Class Loss: 0.2440, Accuracy: 0.3025\n",
      "Epoch [865/4000], Discriminator Loss: 0.0917, Generator Loss: 0.3054, Series Loss: 0.0110, Class Loss: 0.2441, Accuracy: 0.2901\n",
      "Epoch [866/4000], Discriminator Loss: 0.0912, Generator Loss: 0.3061, Series Loss: 0.0110, Class Loss: 0.2440, Accuracy: 0.3025\n",
      "Epoch [867/4000], Discriminator Loss: 0.0915, Generator Loss: 0.3063, Series Loss: 0.0110, Class Loss: 0.2440, Accuracy: 0.2963\n",
      "Epoch [868/4000], Discriminator Loss: 0.0909, Generator Loss: 0.3061, Series Loss: 0.0110, Class Loss: 0.2440, Accuracy: 0.3025\n",
      "Epoch [869/4000], Discriminator Loss: 0.0912, Generator Loss: 0.3060, Series Loss: 0.0111, Class Loss: 0.2441, Accuracy: 0.3086\n",
      "Epoch [870/4000], Discriminator Loss: 0.0913, Generator Loss: 0.3058, Series Loss: 0.0110, Class Loss: 0.2441, Accuracy: 0.3025\n",
      "Epoch [871/4000], Discriminator Loss: 0.0912, Generator Loss: 0.3060, Series Loss: 0.0110, Class Loss: 0.2441, Accuracy: 0.2963\n",
      "Epoch [872/4000], Discriminator Loss: 0.0919, Generator Loss: 0.3062, Series Loss: 0.0110, Class Loss: 0.2442, Accuracy: 0.3148\n",
      "Epoch [873/4000], Discriminator Loss: 0.0911, Generator Loss: 0.3059, Series Loss: 0.0109, Class Loss: 0.2442, Accuracy: 0.3086\n",
      "Epoch [874/4000], Discriminator Loss: 0.0905, Generator Loss: 0.3061, Series Loss: 0.0109, Class Loss: 0.2440, Accuracy: 0.2901\n",
      "Epoch [875/4000], Discriminator Loss: 0.0902, Generator Loss: 0.3057, Series Loss: 0.0110, Class Loss: 0.2440, Accuracy: 0.3086\n",
      "Epoch [876/4000], Discriminator Loss: 0.0924, Generator Loss: 0.3055, Series Loss: 0.0109, Class Loss: 0.2440, Accuracy: 0.2901\n",
      "Epoch [877/4000], Discriminator Loss: 0.0909, Generator Loss: 0.3054, Series Loss: 0.0107, Class Loss: 0.2439, Accuracy: 0.3025\n",
      "Epoch [878/4000], Discriminator Loss: 0.0913, Generator Loss: 0.3060, Series Loss: 0.0109, Class Loss: 0.2441, Accuracy: 0.2963\n",
      "Epoch [879/4000], Discriminator Loss: 0.0911, Generator Loss: 0.3056, Series Loss: 0.0109, Class Loss: 0.2441, Accuracy: 0.2901\n",
      "Epoch [880/4000], Discriminator Loss: 0.0907, Generator Loss: 0.3057, Series Loss: 0.0109, Class Loss: 0.2441, Accuracy: 0.2963\n",
      "Epoch [881/4000], Discriminator Loss: 0.0908, Generator Loss: 0.3056, Series Loss: 0.0109, Class Loss: 0.2440, Accuracy: 0.2963\n",
      "Epoch [882/4000], Discriminator Loss: 0.0914, Generator Loss: 0.3059, Series Loss: 0.0109, Class Loss: 0.2441, Accuracy: 0.3086\n",
      "Epoch [883/4000], Discriminator Loss: 0.0913, Generator Loss: 0.3058, Series Loss: 0.0109, Class Loss: 0.2440, Accuracy: 0.3272\n",
      "Epoch [884/4000], Discriminator Loss: 0.0908, Generator Loss: 0.3064, Series Loss: 0.0108, Class Loss: 0.2440, Accuracy: 0.3148\n",
      "Epoch [885/4000], Discriminator Loss: 0.0907, Generator Loss: 0.3059, Series Loss: 0.0109, Class Loss: 0.2440, Accuracy: 0.3086\n",
      "Epoch [886/4000], Discriminator Loss: 0.0911, Generator Loss: 0.3051, Series Loss: 0.0108, Class Loss: 0.2439, Accuracy: 0.3025\n",
      "Epoch [887/4000], Discriminator Loss: 0.0916, Generator Loss: 0.3049, Series Loss: 0.0108, Class Loss: 0.2440, Accuracy: 0.3086\n",
      "Epoch [888/4000], Discriminator Loss: 0.0909, Generator Loss: 0.3052, Series Loss: 0.0109, Class Loss: 0.2440, Accuracy: 0.3086\n",
      "Epoch [889/4000], Discriminator Loss: 0.0910, Generator Loss: 0.3055, Series Loss: 0.0108, Class Loss: 0.2440, Accuracy: 0.3086\n",
      "Epoch [890/4000], Discriminator Loss: 0.0924, Generator Loss: 0.3053, Series Loss: 0.0108, Class Loss: 0.2441, Accuracy: 0.3086\n",
      "Epoch [891/4000], Discriminator Loss: 0.0914, Generator Loss: 0.3064, Series Loss: 0.0108, Class Loss: 0.2440, Accuracy: 0.3086\n",
      "Epoch [892/4000], Discriminator Loss: 0.0910, Generator Loss: 0.3060, Series Loss: 0.0109, Class Loss: 0.2440, Accuracy: 0.3148\n",
      "Epoch [893/4000], Discriminator Loss: 0.0903, Generator Loss: 0.3067, Series Loss: 0.0109, Class Loss: 0.2441, Accuracy: 0.2963\n",
      "Epoch [894/4000], Discriminator Loss: 0.0907, Generator Loss: 0.3051, Series Loss: 0.0109, Class Loss: 0.2440, Accuracy: 0.2963\n",
      "Epoch [895/4000], Discriminator Loss: 0.0913, Generator Loss: 0.3060, Series Loss: 0.0108, Class Loss: 0.2442, Accuracy: 0.2963\n",
      "Epoch [896/4000], Discriminator Loss: 0.0911, Generator Loss: 0.3055, Series Loss: 0.0108, Class Loss: 0.2441, Accuracy: 0.2901\n",
      "Epoch [897/4000], Discriminator Loss: 0.0910, Generator Loss: 0.3053, Series Loss: 0.0107, Class Loss: 0.2441, Accuracy: 0.2963\n",
      "Epoch [898/4000], Discriminator Loss: 0.0916, Generator Loss: 0.3058, Series Loss: 0.0107, Class Loss: 0.2440, Accuracy: 0.3086\n",
      "Epoch [899/4000], Discriminator Loss: 0.0919, Generator Loss: 0.3062, Series Loss: 0.0107, Class Loss: 0.2441, Accuracy: 0.3025\n",
      "Epoch [900/4000], Discriminator Loss: 0.0908, Generator Loss: 0.3053, Series Loss: 0.0107, Class Loss: 0.2440, Accuracy: 0.3148\n",
      "Epoch [901/4000], Discriminator Loss: 0.0914, Generator Loss: 0.3053, Series Loss: 0.0107, Class Loss: 0.2441, Accuracy: 0.3025\n",
      "Epoch [902/4000], Discriminator Loss: 0.0912, Generator Loss: 0.3057, Series Loss: 0.0107, Class Loss: 0.2441, Accuracy: 0.3086\n",
      "Epoch [903/4000], Discriminator Loss: 0.0912, Generator Loss: 0.3058, Series Loss: 0.0107, Class Loss: 0.2441, Accuracy: 0.3086\n",
      "Epoch [904/4000], Discriminator Loss: 0.0914, Generator Loss: 0.3050, Series Loss: 0.0107, Class Loss: 0.2441, Accuracy: 0.2963\n",
      "Epoch [905/4000], Discriminator Loss: 0.0912, Generator Loss: 0.3049, Series Loss: 0.0107, Class Loss: 0.2440, Accuracy: 0.3025\n",
      "Epoch [906/4000], Discriminator Loss: 0.0904, Generator Loss: 0.3059, Series Loss: 0.0108, Class Loss: 0.2441, Accuracy: 0.3025\n",
      "Epoch [907/4000], Discriminator Loss: 0.0916, Generator Loss: 0.3049, Series Loss: 0.0107, Class Loss: 0.2440, Accuracy: 0.2963\n",
      "Epoch [908/4000], Discriminator Loss: 0.0907, Generator Loss: 0.3056, Series Loss: 0.0107, Class Loss: 0.2441, Accuracy: 0.3148\n",
      "Epoch [909/4000], Discriminator Loss: 0.0908, Generator Loss: 0.3046, Series Loss: 0.0107, Class Loss: 0.2440, Accuracy: 0.2963\n",
      "Epoch [910/4000], Discriminator Loss: 0.0909, Generator Loss: 0.3055, Series Loss: 0.0108, Class Loss: 0.2441, Accuracy: 0.3025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [911/4000], Discriminator Loss: 0.0914, Generator Loss: 0.3051, Series Loss: 0.0107, Class Loss: 0.2440, Accuracy: 0.3086\n",
      "Epoch [912/4000], Discriminator Loss: 0.0909, Generator Loss: 0.3063, Series Loss: 0.0108, Class Loss: 0.2440, Accuracy: 0.3025\n",
      "Epoch [913/4000], Discriminator Loss: 0.0908, Generator Loss: 0.3056, Series Loss: 0.0107, Class Loss: 0.2441, Accuracy: 0.2963\n",
      "Epoch [914/4000], Discriminator Loss: 0.0908, Generator Loss: 0.3060, Series Loss: 0.0108, Class Loss: 0.2440, Accuracy: 0.3025\n",
      "Epoch [915/4000], Discriminator Loss: 0.0920, Generator Loss: 0.3049, Series Loss: 0.0108, Class Loss: 0.2440, Accuracy: 0.2963\n",
      "Epoch [916/4000], Discriminator Loss: 0.0918, Generator Loss: 0.3053, Series Loss: 0.0108, Class Loss: 0.2439, Accuracy: 0.2963\n",
      "Epoch [917/4000], Discriminator Loss: 0.0918, Generator Loss: 0.3056, Series Loss: 0.0107, Class Loss: 0.2441, Accuracy: 0.3025\n",
      "Epoch [918/4000], Discriminator Loss: 0.0917, Generator Loss: 0.3056, Series Loss: 0.0108, Class Loss: 0.2439, Accuracy: 0.3086\n",
      "Epoch [919/4000], Discriminator Loss: 0.0914, Generator Loss: 0.3057, Series Loss: 0.0107, Class Loss: 0.2441, Accuracy: 0.3086\n",
      "Epoch [920/4000], Discriminator Loss: 0.0914, Generator Loss: 0.3052, Series Loss: 0.0107, Class Loss: 0.2440, Accuracy: 0.3148\n",
      "Epoch [921/4000], Discriminator Loss: 0.0912, Generator Loss: 0.3056, Series Loss: 0.0107, Class Loss: 0.2441, Accuracy: 0.3025\n",
      "Epoch [922/4000], Discriminator Loss: 0.0907, Generator Loss: 0.3054, Series Loss: 0.0107, Class Loss: 0.2442, Accuracy: 0.3025\n",
      "Epoch [923/4000], Discriminator Loss: 0.0918, Generator Loss: 0.3048, Series Loss: 0.0106, Class Loss: 0.2440, Accuracy: 0.2901\n",
      "Epoch [924/4000], Discriminator Loss: 0.0912, Generator Loss: 0.3056, Series Loss: 0.0108, Class Loss: 0.2441, Accuracy: 0.3148\n",
      "Epoch [925/4000], Discriminator Loss: 0.0910, Generator Loss: 0.3051, Series Loss: 0.0106, Class Loss: 0.2440, Accuracy: 0.3086\n",
      "Epoch [926/4000], Discriminator Loss: 0.0916, Generator Loss: 0.3047, Series Loss: 0.0107, Class Loss: 0.2441, Accuracy: 0.2963\n",
      "Epoch [927/4000], Discriminator Loss: 0.0921, Generator Loss: 0.3049, Series Loss: 0.0106, Class Loss: 0.2440, Accuracy: 0.3148\n",
      "Epoch [928/4000], Discriminator Loss: 0.0920, Generator Loss: 0.3047, Series Loss: 0.0106, Class Loss: 0.2439, Accuracy: 0.3148\n",
      "Epoch [929/4000], Discriminator Loss: 0.0911, Generator Loss: 0.3054, Series Loss: 0.0106, Class Loss: 0.2440, Accuracy: 0.3148\n",
      "Epoch [930/4000], Discriminator Loss: 0.0913, Generator Loss: 0.3056, Series Loss: 0.0106, Class Loss: 0.2441, Accuracy: 0.3086\n",
      "Epoch [931/4000], Discriminator Loss: 0.0909, Generator Loss: 0.3055, Series Loss: 0.0106, Class Loss: 0.2439, Accuracy: 0.3086\n",
      "Epoch [932/4000], Discriminator Loss: 0.0911, Generator Loss: 0.3057, Series Loss: 0.0107, Class Loss: 0.2441, Accuracy: 0.3025\n",
      "Epoch [933/4000], Discriminator Loss: 0.0911, Generator Loss: 0.3055, Series Loss: 0.0106, Class Loss: 0.2440, Accuracy: 0.3086\n",
      "Epoch [934/4000], Discriminator Loss: 0.0912, Generator Loss: 0.3051, Series Loss: 0.0107, Class Loss: 0.2440, Accuracy: 0.3025\n",
      "Epoch [935/4000], Discriminator Loss: 0.0914, Generator Loss: 0.3047, Series Loss: 0.0107, Class Loss: 0.2440, Accuracy: 0.3148\n",
      "Epoch [936/4000], Discriminator Loss: 0.0916, Generator Loss: 0.3047, Series Loss: 0.0105, Class Loss: 0.2441, Accuracy: 0.3086\n",
      "Epoch [937/4000], Discriminator Loss: 0.0905, Generator Loss: 0.3049, Series Loss: 0.0105, Class Loss: 0.2441, Accuracy: 0.3025\n",
      "Epoch [938/4000], Discriminator Loss: 0.0914, Generator Loss: 0.3057, Series Loss: 0.0105, Class Loss: 0.2440, Accuracy: 0.3086\n",
      "Epoch [939/4000], Discriminator Loss: 0.0914, Generator Loss: 0.3052, Series Loss: 0.0105, Class Loss: 0.2440, Accuracy: 0.3025\n",
      "Epoch [940/4000], Discriminator Loss: 0.0908, Generator Loss: 0.3057, Series Loss: 0.0106, Class Loss: 0.2440, Accuracy: 0.3086\n",
      "Epoch [941/4000], Discriminator Loss: 0.0910, Generator Loss: 0.3056, Series Loss: 0.0106, Class Loss: 0.2440, Accuracy: 0.3025\n",
      "Epoch [942/4000], Discriminator Loss: 0.0917, Generator Loss: 0.3051, Series Loss: 0.0105, Class Loss: 0.2439, Accuracy: 0.3086\n",
      "Epoch [943/4000], Discriminator Loss: 0.0907, Generator Loss: 0.3046, Series Loss: 0.0105, Class Loss: 0.2439, Accuracy: 0.3086\n",
      "Epoch [944/4000], Discriminator Loss: 0.0916, Generator Loss: 0.3050, Series Loss: 0.0105, Class Loss: 0.2440, Accuracy: 0.3148\n",
      "Epoch [945/4000], Discriminator Loss: 0.0913, Generator Loss: 0.3051, Series Loss: 0.0105, Class Loss: 0.2440, Accuracy: 0.3086\n",
      "Epoch [946/4000], Discriminator Loss: 0.0913, Generator Loss: 0.3044, Series Loss: 0.0106, Class Loss: 0.2440, Accuracy: 0.3086\n",
      "Epoch [947/4000], Discriminator Loss: 0.0908, Generator Loss: 0.3050, Series Loss: 0.0104, Class Loss: 0.2440, Accuracy: 0.3086\n",
      "Epoch [948/4000], Discriminator Loss: 0.0905, Generator Loss: 0.3046, Series Loss: 0.0104, Class Loss: 0.2439, Accuracy: 0.3086\n",
      "Epoch [949/4000], Discriminator Loss: 0.0916, Generator Loss: 0.3045, Series Loss: 0.0104, Class Loss: 0.2440, Accuracy: 0.3025\n",
      "Epoch [950/4000], Discriminator Loss: 0.0915, Generator Loss: 0.3055, Series Loss: 0.0105, Class Loss: 0.2440, Accuracy: 0.3148\n",
      "Epoch [951/4000], Discriminator Loss: 0.0905, Generator Loss: 0.3045, Series Loss: 0.0105, Class Loss: 0.2439, Accuracy: 0.3086\n",
      "Epoch [952/4000], Discriminator Loss: 0.0914, Generator Loss: 0.3042, Series Loss: 0.0104, Class Loss: 0.2440, Accuracy: 0.3025\n",
      "Epoch [953/4000], Discriminator Loss: 0.0912, Generator Loss: 0.3046, Series Loss: 0.0104, Class Loss: 0.2441, Accuracy: 0.3148\n",
      "Epoch [954/4000], Discriminator Loss: 0.0921, Generator Loss: 0.3044, Series Loss: 0.0104, Class Loss: 0.2439, Accuracy: 0.3025\n",
      "Epoch [955/4000], Discriminator Loss: 0.0914, Generator Loss: 0.3052, Series Loss: 0.0103, Class Loss: 0.2439, Accuracy: 0.3086\n",
      "Epoch [956/4000], Discriminator Loss: 0.0911, Generator Loss: 0.3052, Series Loss: 0.0104, Class Loss: 0.2439, Accuracy: 0.3025\n",
      "Epoch [957/4000], Discriminator Loss: 0.0913, Generator Loss: 0.3048, Series Loss: 0.0104, Class Loss: 0.2440, Accuracy: 0.2963\n",
      "Epoch [958/4000], Discriminator Loss: 0.0914, Generator Loss: 0.3047, Series Loss: 0.0104, Class Loss: 0.2441, Accuracy: 0.2963\n",
      "Epoch [959/4000], Discriminator Loss: 0.0909, Generator Loss: 0.3047, Series Loss: 0.0104, Class Loss: 0.2439, Accuracy: 0.3086\n",
      "Epoch [960/4000], Discriminator Loss: 0.0906, Generator Loss: 0.3046, Series Loss: 0.0104, Class Loss: 0.2439, Accuracy: 0.3025\n",
      "Epoch [961/4000], Discriminator Loss: 0.0908, Generator Loss: 0.3047, Series Loss: 0.0104, Class Loss: 0.2440, Accuracy: 0.3086\n",
      "Epoch [962/4000], Discriminator Loss: 0.0919, Generator Loss: 0.3039, Series Loss: 0.0103, Class Loss: 0.2439, Accuracy: 0.3148\n",
      "Epoch [963/4000], Discriminator Loss: 0.0910, Generator Loss: 0.3045, Series Loss: 0.0103, Class Loss: 0.2439, Accuracy: 0.3025\n",
      "Epoch [964/4000], Discriminator Loss: 0.0914, Generator Loss: 0.3050, Series Loss: 0.0104, Class Loss: 0.2440, Accuracy: 0.3086\n",
      "Epoch [965/4000], Discriminator Loss: 0.0914, Generator Loss: 0.3056, Series Loss: 0.0103, Class Loss: 0.2440, Accuracy: 0.3086\n",
      "Epoch [966/4000], Discriminator Loss: 0.0920, Generator Loss: 0.3043, Series Loss: 0.0102, Class Loss: 0.2440, Accuracy: 0.3148\n",
      "Epoch [967/4000], Discriminator Loss: 0.0922, Generator Loss: 0.3042, Series Loss: 0.0102, Class Loss: 0.2440, Accuracy: 0.3086\n",
      "Epoch [968/4000], Discriminator Loss: 0.0914, Generator Loss: 0.3051, Series Loss: 0.0103, Class Loss: 0.2439, Accuracy: 0.3148\n",
      "Epoch [969/4000], Discriminator Loss: 0.0911, Generator Loss: 0.3053, Series Loss: 0.0102, Class Loss: 0.2439, Accuracy: 0.3086\n",
      "Epoch [970/4000], Discriminator Loss: 0.0920, Generator Loss: 0.3050, Series Loss: 0.0104, Class Loss: 0.2440, Accuracy: 0.3025\n",
      "Epoch [971/4000], Discriminator Loss: 0.0913, Generator Loss: 0.3051, Series Loss: 0.0103, Class Loss: 0.2439, Accuracy: 0.3086\n",
      "Epoch [972/4000], Discriminator Loss: 0.0917, Generator Loss: 0.3043, Series Loss: 0.0103, Class Loss: 0.2441, Accuracy: 0.2963\n",
      "Epoch [973/4000], Discriminator Loss: 0.0919, Generator Loss: 0.3042, Series Loss: 0.0103, Class Loss: 0.2440, Accuracy: 0.2963\n",
      "Epoch [974/4000], Discriminator Loss: 0.0914, Generator Loss: 0.3045, Series Loss: 0.0102, Class Loss: 0.2439, Accuracy: 0.3025\n",
      "Epoch [975/4000], Discriminator Loss: 0.0917, Generator Loss: 0.3044, Series Loss: 0.0103, Class Loss: 0.2440, Accuracy: 0.3086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [976/4000], Discriminator Loss: 0.0921, Generator Loss: 0.3045, Series Loss: 0.0103, Class Loss: 0.2440, Accuracy: 0.2963\n",
      "Epoch [977/4000], Discriminator Loss: 0.0919, Generator Loss: 0.3047, Series Loss: 0.0102, Class Loss: 0.2439, Accuracy: 0.3025\n",
      "Epoch [978/4000], Discriminator Loss: 0.0913, Generator Loss: 0.3046, Series Loss: 0.0103, Class Loss: 0.2439, Accuracy: 0.3025\n",
      "Epoch [979/4000], Discriminator Loss: 0.0920, Generator Loss: 0.3048, Series Loss: 0.0103, Class Loss: 0.2440, Accuracy: 0.2963\n",
      "Epoch [980/4000], Discriminator Loss: 0.0919, Generator Loss: 0.3043, Series Loss: 0.0102, Class Loss: 0.2440, Accuracy: 0.3025\n",
      "Epoch [981/4000], Discriminator Loss: 0.0912, Generator Loss: 0.3044, Series Loss: 0.0103, Class Loss: 0.2439, Accuracy: 0.2963\n",
      "Epoch [982/4000], Discriminator Loss: 0.0917, Generator Loss: 0.3042, Series Loss: 0.0102, Class Loss: 0.2440, Accuracy: 0.3086\n",
      "Epoch [983/4000], Discriminator Loss: 0.0918, Generator Loss: 0.3049, Series Loss: 0.0102, Class Loss: 0.2439, Accuracy: 0.3025\n",
      "Epoch [984/4000], Discriminator Loss: 0.0916, Generator Loss: 0.3048, Series Loss: 0.0103, Class Loss: 0.2439, Accuracy: 0.3025\n",
      "Epoch [985/4000], Discriminator Loss: 0.0913, Generator Loss: 0.3044, Series Loss: 0.0103, Class Loss: 0.2439, Accuracy: 0.3086\n",
      "Epoch [986/4000], Discriminator Loss: 0.0918, Generator Loss: 0.3045, Series Loss: 0.0103, Class Loss: 0.2439, Accuracy: 0.3086\n",
      "Epoch [987/4000], Discriminator Loss: 0.0913, Generator Loss: 0.3042, Series Loss: 0.0102, Class Loss: 0.2440, Accuracy: 0.3025\n",
      "Epoch [988/4000], Discriminator Loss: 0.0914, Generator Loss: 0.3039, Series Loss: 0.0102, Class Loss: 0.2440, Accuracy: 0.3025\n",
      "Epoch [989/4000], Discriminator Loss: 0.0920, Generator Loss: 0.3040, Series Loss: 0.0102, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [990/4000], Discriminator Loss: 0.0913, Generator Loss: 0.3044, Series Loss: 0.0102, Class Loss: 0.2439, Accuracy: 0.3086\n",
      "Epoch [991/4000], Discriminator Loss: 0.0916, Generator Loss: 0.3040, Series Loss: 0.0102, Class Loss: 0.2439, Accuracy: 0.3025\n",
      "Epoch [992/4000], Discriminator Loss: 0.0910, Generator Loss: 0.3052, Series Loss: 0.0103, Class Loss: 0.2439, Accuracy: 0.2901\n",
      "Epoch [993/4000], Discriminator Loss: 0.0913, Generator Loss: 0.3039, Series Loss: 0.0102, Class Loss: 0.2439, Accuracy: 0.3025\n",
      "Epoch [994/4000], Discriminator Loss: 0.0918, Generator Loss: 0.3041, Series Loss: 0.0102, Class Loss: 0.2439, Accuracy: 0.3025\n",
      "Epoch [995/4000], Discriminator Loss: 0.0918, Generator Loss: 0.3044, Series Loss: 0.0102, Class Loss: 0.2439, Accuracy: 0.2963\n",
      "Epoch [996/4000], Discriminator Loss: 0.0916, Generator Loss: 0.3044, Series Loss: 0.0101, Class Loss: 0.2439, Accuracy: 0.2840\n",
      "Epoch [997/4000], Discriminator Loss: 0.0910, Generator Loss: 0.3040, Series Loss: 0.0102, Class Loss: 0.2439, Accuracy: 0.3025\n",
      "Epoch [998/4000], Discriminator Loss: 0.0922, Generator Loss: 0.3034, Series Loss: 0.0101, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [999/4000], Discriminator Loss: 0.0914, Generator Loss: 0.3046, Series Loss: 0.0102, Class Loss: 0.2439, Accuracy: 0.3025\n",
      "Epoch [1000/4000], Discriminator Loss: 0.0920, Generator Loss: 0.3041, Series Loss: 0.0101, Class Loss: 0.2439, Accuracy: 0.3025\n",
      "Epoch [1001/4000], Discriminator Loss: 0.0924, Generator Loss: 0.3038, Series Loss: 0.0100, Class Loss: 0.2439, Accuracy: 0.3086\n",
      "Epoch [1002/4000], Discriminator Loss: 0.0925, Generator Loss: 0.3037, Series Loss: 0.0102, Class Loss: 0.2440, Accuracy: 0.3148\n",
      "Epoch [1003/4000], Discriminator Loss: 0.0913, Generator Loss: 0.3046, Series Loss: 0.0101, Class Loss: 0.2440, Accuracy: 0.3086\n",
      "Epoch [1004/4000], Discriminator Loss: 0.0917, Generator Loss: 0.3037, Series Loss: 0.0100, Class Loss: 0.2440, Accuracy: 0.3148\n",
      "Epoch [1005/4000], Discriminator Loss: 0.0918, Generator Loss: 0.3037, Series Loss: 0.0100, Class Loss: 0.2439, Accuracy: 0.3086\n",
      "Epoch [1006/4000], Discriminator Loss: 0.0916, Generator Loss: 0.3042, Series Loss: 0.0100, Class Loss: 0.2439, Accuracy: 0.3086\n",
      "Epoch [1007/4000], Discriminator Loss: 0.0915, Generator Loss: 0.3040, Series Loss: 0.0100, Class Loss: 0.2440, Accuracy: 0.3025\n",
      "Epoch [1008/4000], Discriminator Loss: 0.0920, Generator Loss: 0.3047, Series Loss: 0.0100, Class Loss: 0.2440, Accuracy: 0.3148\n",
      "Epoch [1009/4000], Discriminator Loss: 0.0919, Generator Loss: 0.3044, Series Loss: 0.0100, Class Loss: 0.2441, Accuracy: 0.2963\n",
      "Epoch [1010/4000], Discriminator Loss: 0.0919, Generator Loss: 0.3043, Series Loss: 0.0100, Class Loss: 0.2440, Accuracy: 0.3025\n",
      "Epoch [1011/4000], Discriminator Loss: 0.0919, Generator Loss: 0.3040, Series Loss: 0.0100, Class Loss: 0.2439, Accuracy: 0.3025\n",
      "Epoch [1012/4000], Discriminator Loss: 0.0919, Generator Loss: 0.3041, Series Loss: 0.0100, Class Loss: 0.2441, Accuracy: 0.3086\n",
      "Epoch [1013/4000], Discriminator Loss: 0.0929, Generator Loss: 0.3032, Series Loss: 0.0100, Class Loss: 0.2439, Accuracy: 0.3148\n",
      "Epoch [1014/4000], Discriminator Loss: 0.0918, Generator Loss: 0.3040, Series Loss: 0.0100, Class Loss: 0.2440, Accuracy: 0.3025\n",
      "Epoch [1015/4000], Discriminator Loss: 0.0920, Generator Loss: 0.3038, Series Loss: 0.0100, Class Loss: 0.2440, Accuracy: 0.3086\n",
      "Epoch [1016/4000], Discriminator Loss: 0.0921, Generator Loss: 0.3038, Series Loss: 0.0100, Class Loss: 0.2440, Accuracy: 0.2963\n",
      "Epoch [1017/4000], Discriminator Loss: 0.0924, Generator Loss: 0.3043, Series Loss: 0.0100, Class Loss: 0.2440, Accuracy: 0.3148\n",
      "Epoch [1018/4000], Discriminator Loss: 0.0919, Generator Loss: 0.3042, Series Loss: 0.0100, Class Loss: 0.2439, Accuracy: 0.3025\n",
      "Epoch [1019/4000], Discriminator Loss: 0.0916, Generator Loss: 0.3037, Series Loss: 0.0100, Class Loss: 0.2439, Accuracy: 0.2963\n",
      "Epoch [1020/4000], Discriminator Loss: 0.0922, Generator Loss: 0.3041, Series Loss: 0.0100, Class Loss: 0.2439, Accuracy: 0.3148\n",
      "Epoch [1021/4000], Discriminator Loss: 0.0918, Generator Loss: 0.3039, Series Loss: 0.0100, Class Loss: 0.2440, Accuracy: 0.3086\n",
      "Epoch [1022/4000], Discriminator Loss: 0.0925, Generator Loss: 0.3036, Series Loss: 0.0100, Class Loss: 0.2439, Accuracy: 0.3025\n",
      "Epoch [1023/4000], Discriminator Loss: 0.0919, Generator Loss: 0.3044, Series Loss: 0.0100, Class Loss: 0.2439, Accuracy: 0.3025\n",
      "Epoch [1024/4000], Discriminator Loss: 0.0923, Generator Loss: 0.3041, Series Loss: 0.0100, Class Loss: 0.2440, Accuracy: 0.3025\n",
      "Epoch [1025/4000], Discriminator Loss: 0.0922, Generator Loss: 0.3046, Series Loss: 0.0100, Class Loss: 0.2439, Accuracy: 0.3025\n",
      "Epoch [1026/4000], Discriminator Loss: 0.0927, Generator Loss: 0.3038, Series Loss: 0.0101, Class Loss: 0.2440, Accuracy: 0.3025\n",
      "Epoch [1027/4000], Discriminator Loss: 0.0920, Generator Loss: 0.3049, Series Loss: 0.0100, Class Loss: 0.2440, Accuracy: 0.3086\n",
      "Epoch [1028/4000], Discriminator Loss: 0.0920, Generator Loss: 0.3035, Series Loss: 0.0099, Class Loss: 0.2439, Accuracy: 0.3025\n",
      "Epoch [1029/4000], Discriminator Loss: 0.0913, Generator Loss: 0.3038, Series Loss: 0.0100, Class Loss: 0.2439, Accuracy: 0.3086\n",
      "Epoch [1030/4000], Discriminator Loss: 0.0921, Generator Loss: 0.3034, Series Loss: 0.0101, Class Loss: 0.2440, Accuracy: 0.3148\n",
      "Epoch [1031/4000], Discriminator Loss: 0.0920, Generator Loss: 0.3035, Series Loss: 0.0100, Class Loss: 0.2439, Accuracy: 0.3086\n",
      "Epoch [1032/4000], Discriminator Loss: 0.0926, Generator Loss: 0.3040, Series Loss: 0.0100, Class Loss: 0.2440, Accuracy: 0.3025\n",
      "Epoch [1033/4000], Discriminator Loss: 0.0928, Generator Loss: 0.3039, Series Loss: 0.0100, Class Loss: 0.2440, Accuracy: 0.3148\n",
      "Epoch [1034/4000], Discriminator Loss: 0.0918, Generator Loss: 0.3040, Series Loss: 0.0101, Class Loss: 0.2440, Accuracy: 0.3148\n",
      "Epoch [1035/4000], Discriminator Loss: 0.0927, Generator Loss: 0.3034, Series Loss: 0.0101, Class Loss: 0.2440, Accuracy: 0.3025\n",
      "Epoch [1036/4000], Discriminator Loss: 0.0922, Generator Loss: 0.3041, Series Loss: 0.0100, Class Loss: 0.2439, Accuracy: 0.2963\n",
      "Epoch [1037/4000], Discriminator Loss: 0.0923, Generator Loss: 0.3037, Series Loss: 0.0101, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1038/4000], Discriminator Loss: 0.0921, Generator Loss: 0.3035, Series Loss: 0.0100, Class Loss: 0.2440, Accuracy: 0.3086\n",
      "Epoch [1039/4000], Discriminator Loss: 0.0924, Generator Loss: 0.3040, Series Loss: 0.0100, Class Loss: 0.2439, Accuracy: 0.3025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1040/4000], Discriminator Loss: 0.0917, Generator Loss: 0.3038, Series Loss: 0.0100, Class Loss: 0.2440, Accuracy: 0.3025\n",
      "Epoch [1041/4000], Discriminator Loss: 0.0927, Generator Loss: 0.3035, Series Loss: 0.0099, Class Loss: 0.2439, Accuracy: 0.3025\n",
      "Epoch [1042/4000], Discriminator Loss: 0.0918, Generator Loss: 0.3042, Series Loss: 0.0099, Class Loss: 0.2439, Accuracy: 0.3025\n",
      "Epoch [1043/4000], Discriminator Loss: 0.0927, Generator Loss: 0.3033, Series Loss: 0.0099, Class Loss: 0.2440, Accuracy: 0.3025\n",
      "Epoch [1044/4000], Discriminator Loss: 0.0917, Generator Loss: 0.3039, Series Loss: 0.0099, Class Loss: 0.2439, Accuracy: 0.2963\n",
      "Epoch [1045/4000], Discriminator Loss: 0.0928, Generator Loss: 0.3038, Series Loss: 0.0101, Class Loss: 0.2440, Accuracy: 0.2963\n",
      "Epoch [1046/4000], Discriminator Loss: 0.0929, Generator Loss: 0.3036, Series Loss: 0.0100, Class Loss: 0.2439, Accuracy: 0.3025\n",
      "Epoch [1047/4000], Discriminator Loss: 0.0922, Generator Loss: 0.3039, Series Loss: 0.0100, Class Loss: 0.2439, Accuracy: 0.3025\n",
      "Epoch [1048/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3038, Series Loss: 0.0100, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1049/4000], Discriminator Loss: 0.0920, Generator Loss: 0.3043, Series Loss: 0.0100, Class Loss: 0.2441, Accuracy: 0.3025\n",
      "Epoch [1050/4000], Discriminator Loss: 0.0923, Generator Loss: 0.3038, Series Loss: 0.0100, Class Loss: 0.2439, Accuracy: 0.2963\n",
      "Epoch [1051/4000], Discriminator Loss: 0.0924, Generator Loss: 0.3035, Series Loss: 0.0100, Class Loss: 0.2440, Accuracy: 0.3025\n",
      "Epoch [1052/4000], Discriminator Loss: 0.0926, Generator Loss: 0.3032, Series Loss: 0.0100, Class Loss: 0.2439, Accuracy: 0.3086\n",
      "Epoch [1053/4000], Discriminator Loss: 0.0925, Generator Loss: 0.3039, Series Loss: 0.0100, Class Loss: 0.2440, Accuracy: 0.2963\n",
      "Epoch [1054/4000], Discriminator Loss: 0.0918, Generator Loss: 0.3038, Series Loss: 0.0100, Class Loss: 0.2440, Accuracy: 0.3086\n",
      "Epoch [1055/4000], Discriminator Loss: 0.0921, Generator Loss: 0.3039, Series Loss: 0.0100, Class Loss: 0.2440, Accuracy: 0.2963\n",
      "Epoch [1056/4000], Discriminator Loss: 0.0919, Generator Loss: 0.3041, Series Loss: 0.0100, Class Loss: 0.2440, Accuracy: 0.3086\n",
      "Epoch [1057/4000], Discriminator Loss: 0.0924, Generator Loss: 0.3041, Series Loss: 0.0100, Class Loss: 0.2439, Accuracy: 0.2963\n",
      "Epoch [1058/4000], Discriminator Loss: 0.0922, Generator Loss: 0.3034, Series Loss: 0.0100, Class Loss: 0.2439, Accuracy: 0.3148\n",
      "Epoch [1059/4000], Discriminator Loss: 0.0923, Generator Loss: 0.3033, Series Loss: 0.0099, Class Loss: 0.2439, Accuracy: 0.3025\n",
      "Epoch [1060/4000], Discriminator Loss: 0.0921, Generator Loss: 0.3033, Series Loss: 0.0099, Class Loss: 0.2439, Accuracy: 0.3025\n",
      "Epoch [1061/4000], Discriminator Loss: 0.0926, Generator Loss: 0.3032, Series Loss: 0.0098, Class Loss: 0.2439, Accuracy: 0.2963\n",
      "Epoch [1062/4000], Discriminator Loss: 0.0922, Generator Loss: 0.3036, Series Loss: 0.0099, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1063/4000], Discriminator Loss: 0.0926, Generator Loss: 0.3037, Series Loss: 0.0100, Class Loss: 0.2440, Accuracy: 0.3086\n",
      "Epoch [1064/4000], Discriminator Loss: 0.0924, Generator Loss: 0.3037, Series Loss: 0.0098, Class Loss: 0.2440, Accuracy: 0.2963\n",
      "Epoch [1065/4000], Discriminator Loss: 0.0925, Generator Loss: 0.3035, Series Loss: 0.0099, Class Loss: 0.2440, Accuracy: 0.2963\n",
      "Epoch [1066/4000], Discriminator Loss: 0.0928, Generator Loss: 0.3030, Series Loss: 0.0098, Class Loss: 0.2439, Accuracy: 0.2963\n",
      "Epoch [1067/4000], Discriminator Loss: 0.0929, Generator Loss: 0.3030, Series Loss: 0.0098, Class Loss: 0.2439, Accuracy: 0.3025\n",
      "Epoch [1068/4000], Discriminator Loss: 0.0921, Generator Loss: 0.3036, Series Loss: 0.0099, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1069/4000], Discriminator Loss: 0.0918, Generator Loss: 0.3036, Series Loss: 0.0098, Class Loss: 0.2439, Accuracy: 0.3086\n",
      "Epoch [1070/4000], Discriminator Loss: 0.0923, Generator Loss: 0.3035, Series Loss: 0.0097, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [1071/4000], Discriminator Loss: 0.0928, Generator Loss: 0.3038, Series Loss: 0.0098, Class Loss: 0.2439, Accuracy: 0.3086\n",
      "Epoch [1072/4000], Discriminator Loss: 0.0927, Generator Loss: 0.3038, Series Loss: 0.0097, Class Loss: 0.2439, Accuracy: 0.2901\n",
      "Epoch [1073/4000], Discriminator Loss: 0.0925, Generator Loss: 0.3034, Series Loss: 0.0097, Class Loss: 0.2439, Accuracy: 0.2963\n",
      "Epoch [1074/4000], Discriminator Loss: 0.0917, Generator Loss: 0.3039, Series Loss: 0.0098, Class Loss: 0.2440, Accuracy: 0.2963\n",
      "Epoch [1075/4000], Discriminator Loss: 0.0914, Generator Loss: 0.3037, Series Loss: 0.0098, Class Loss: 0.2438, Accuracy: 0.2963\n",
      "Epoch [1076/4000], Discriminator Loss: 0.0917, Generator Loss: 0.3040, Series Loss: 0.0098, Class Loss: 0.2440, Accuracy: 0.3086\n",
      "Epoch [1077/4000], Discriminator Loss: 0.0935, Generator Loss: 0.3031, Series Loss: 0.0097, Class Loss: 0.2439, Accuracy: 0.3086\n",
      "Epoch [1078/4000], Discriminator Loss: 0.0921, Generator Loss: 0.3037, Series Loss: 0.0098, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1079/4000], Discriminator Loss: 0.0926, Generator Loss: 0.3039, Series Loss: 0.0098, Class Loss: 0.2440, Accuracy: 0.2963\n",
      "Epoch [1080/4000], Discriminator Loss: 0.0918, Generator Loss: 0.3032, Series Loss: 0.0098, Class Loss: 0.2439, Accuracy: 0.3086\n",
      "Epoch [1081/4000], Discriminator Loss: 0.0928, Generator Loss: 0.3033, Series Loss: 0.0097, Class Loss: 0.2439, Accuracy: 0.3025\n",
      "Epoch [1082/4000], Discriminator Loss: 0.0926, Generator Loss: 0.3030, Series Loss: 0.0098, Class Loss: 0.2440, Accuracy: 0.3025\n",
      "Epoch [1083/4000], Discriminator Loss: 0.0924, Generator Loss: 0.3035, Series Loss: 0.0097, Class Loss: 0.2440, Accuracy: 0.3025\n",
      "Epoch [1084/4000], Discriminator Loss: 0.0927, Generator Loss: 0.3028, Series Loss: 0.0097, Class Loss: 0.2438, Accuracy: 0.3148\n",
      "Epoch [1085/4000], Discriminator Loss: 0.0922, Generator Loss: 0.3034, Series Loss: 0.0097, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1086/4000], Discriminator Loss: 0.0921, Generator Loss: 0.3030, Series Loss: 0.0097, Class Loss: 0.2438, Accuracy: 0.2963\n",
      "Epoch [1087/4000], Discriminator Loss: 0.0921, Generator Loss: 0.3031, Series Loss: 0.0097, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [1088/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3028, Series Loss: 0.0096, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [1089/4000], Discriminator Loss: 0.0921, Generator Loss: 0.3040, Series Loss: 0.0098, Class Loss: 0.2440, Accuracy: 0.3025\n",
      "Epoch [1090/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3041, Series Loss: 0.0098, Class Loss: 0.2439, Accuracy: 0.3086\n",
      "Epoch [1091/4000], Discriminator Loss: 0.0921, Generator Loss: 0.3037, Series Loss: 0.0097, Class Loss: 0.2440, Accuracy: 0.3025\n",
      "Epoch [1092/4000], Discriminator Loss: 0.0916, Generator Loss: 0.3044, Series Loss: 0.0097, Class Loss: 0.2440, Accuracy: 0.2901\n",
      "Epoch [1093/4000], Discriminator Loss: 0.0925, Generator Loss: 0.3032, Series Loss: 0.0097, Class Loss: 0.2439, Accuracy: 0.3086\n",
      "Epoch [1094/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3025, Series Loss: 0.0096, Class Loss: 0.2439, Accuracy: 0.3025\n",
      "Epoch [1095/4000], Discriminator Loss: 0.0917, Generator Loss: 0.3036, Series Loss: 0.0096, Class Loss: 0.2439, Accuracy: 0.2963\n",
      "Epoch [1096/4000], Discriminator Loss: 0.0928, Generator Loss: 0.3028, Series Loss: 0.0095, Class Loss: 0.2439, Accuracy: 0.3148\n",
      "Epoch [1097/4000], Discriminator Loss: 0.0926, Generator Loss: 0.3030, Series Loss: 0.0096, Class Loss: 0.2439, Accuracy: 0.3025\n",
      "Epoch [1098/4000], Discriminator Loss: 0.0928, Generator Loss: 0.3030, Series Loss: 0.0096, Class Loss: 0.2439, Accuracy: 0.2963\n",
      "Epoch [1099/4000], Discriminator Loss: 0.0923, Generator Loss: 0.3039, Series Loss: 0.0098, Class Loss: 0.2439, Accuracy: 0.3086\n",
      "Epoch [1100/4000], Discriminator Loss: 0.0922, Generator Loss: 0.3031, Series Loss: 0.0096, Class Loss: 0.2439, Accuracy: 0.3025\n",
      "Epoch [1101/4000], Discriminator Loss: 0.0920, Generator Loss: 0.3037, Series Loss: 0.0096, Class Loss: 0.2439, Accuracy: 0.3086\n",
      "Epoch [1102/4000], Discriminator Loss: 0.0925, Generator Loss: 0.3033, Series Loss: 0.0097, Class Loss: 0.2439, Accuracy: 0.3025\n",
      "Epoch [1103/4000], Discriminator Loss: 0.0926, Generator Loss: 0.3034, Series Loss: 0.0096, Class Loss: 0.2439, Accuracy: 0.3025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1104/4000], Discriminator Loss: 0.0931, Generator Loss: 0.3029, Series Loss: 0.0096, Class Loss: 0.2438, Accuracy: 0.2963\n",
      "Epoch [1105/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3034, Series Loss: 0.0097, Class Loss: 0.2439, Accuracy: 0.2963\n",
      "Epoch [1106/4000], Discriminator Loss: 0.0923, Generator Loss: 0.3037, Series Loss: 0.0097, Class Loss: 0.2440, Accuracy: 0.2901\n",
      "Epoch [1107/4000], Discriminator Loss: 0.0928, Generator Loss: 0.3028, Series Loss: 0.0096, Class Loss: 0.2440, Accuracy: 0.3025\n",
      "Epoch [1108/4000], Discriminator Loss: 0.0928, Generator Loss: 0.3030, Series Loss: 0.0096, Class Loss: 0.2440, Accuracy: 0.3086\n",
      "Epoch [1109/4000], Discriminator Loss: 0.0922, Generator Loss: 0.3027, Series Loss: 0.0096, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [1110/4000], Discriminator Loss: 0.0921, Generator Loss: 0.3037, Series Loss: 0.0097, Class Loss: 0.2439, Accuracy: 0.2963\n",
      "Epoch [1111/4000], Discriminator Loss: 0.0923, Generator Loss: 0.3031, Series Loss: 0.0097, Class Loss: 0.2440, Accuracy: 0.3025\n",
      "Epoch [1112/4000], Discriminator Loss: 0.0918, Generator Loss: 0.3042, Series Loss: 0.0096, Class Loss: 0.2440, Accuracy: 0.3025\n",
      "Epoch [1113/4000], Discriminator Loss: 0.0922, Generator Loss: 0.3039, Series Loss: 0.0096, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1114/4000], Discriminator Loss: 0.0926, Generator Loss: 0.3033, Series Loss: 0.0096, Class Loss: 0.2438, Accuracy: 0.2963\n",
      "Epoch [1115/4000], Discriminator Loss: 0.0916, Generator Loss: 0.3037, Series Loss: 0.0096, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1116/4000], Discriminator Loss: 0.0923, Generator Loss: 0.3029, Series Loss: 0.0097, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1117/4000], Discriminator Loss: 0.0916, Generator Loss: 0.3031, Series Loss: 0.0096, Class Loss: 0.2438, Accuracy: 0.2963\n",
      "Epoch [1118/4000], Discriminator Loss: 0.0920, Generator Loss: 0.3024, Series Loss: 0.0095, Class Loss: 0.2438, Accuracy: 0.2963\n",
      "Epoch [1119/4000], Discriminator Loss: 0.0925, Generator Loss: 0.3037, Series Loss: 0.0096, Class Loss: 0.2439, Accuracy: 0.3025\n",
      "Epoch [1120/4000], Discriminator Loss: 0.0926, Generator Loss: 0.3032, Series Loss: 0.0096, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1121/4000], Discriminator Loss: 0.0921, Generator Loss: 0.3031, Series Loss: 0.0096, Class Loss: 0.2439, Accuracy: 0.3148\n",
      "Epoch [1122/4000], Discriminator Loss: 0.0923, Generator Loss: 0.3033, Series Loss: 0.0096, Class Loss: 0.2439, Accuracy: 0.3086\n",
      "Epoch [1123/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3030, Series Loss: 0.0096, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1124/4000], Discriminator Loss: 0.0918, Generator Loss: 0.3030, Series Loss: 0.0096, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [1125/4000], Discriminator Loss: 0.0922, Generator Loss: 0.3034, Series Loss: 0.0096, Class Loss: 0.2439, Accuracy: 0.2901\n",
      "Epoch [1126/4000], Discriminator Loss: 0.0922, Generator Loss: 0.3031, Series Loss: 0.0096, Class Loss: 0.2438, Accuracy: 0.2901\n",
      "Epoch [1127/4000], Discriminator Loss: 0.0921, Generator Loss: 0.3035, Series Loss: 0.0096, Class Loss: 0.2439, Accuracy: 0.3148\n",
      "Epoch [1128/4000], Discriminator Loss: 0.0931, Generator Loss: 0.3028, Series Loss: 0.0096, Class Loss: 0.2439, Accuracy: 0.3025\n",
      "Epoch [1129/4000], Discriminator Loss: 0.0931, Generator Loss: 0.3030, Series Loss: 0.0095, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1130/4000], Discriminator Loss: 0.0929, Generator Loss: 0.3039, Series Loss: 0.0095, Class Loss: 0.2439, Accuracy: 0.3148\n",
      "Epoch [1131/4000], Discriminator Loss: 0.0921, Generator Loss: 0.3032, Series Loss: 0.0096, Class Loss: 0.2439, Accuracy: 0.3086\n",
      "Epoch [1132/4000], Discriminator Loss: 0.0926, Generator Loss: 0.3026, Series Loss: 0.0096, Class Loss: 0.2438, Accuracy: 0.3148\n",
      "Epoch [1133/4000], Discriminator Loss: 0.0926, Generator Loss: 0.3032, Series Loss: 0.0097, Class Loss: 0.2439, Accuracy: 0.3025\n",
      "Epoch [1134/4000], Discriminator Loss: 0.0922, Generator Loss: 0.3028, Series Loss: 0.0097, Class Loss: 0.2440, Accuracy: 0.2901\n",
      "Epoch [1135/4000], Discriminator Loss: 0.0929, Generator Loss: 0.3031, Series Loss: 0.0097, Class Loss: 0.2439, Accuracy: 0.3086\n",
      "Epoch [1136/4000], Discriminator Loss: 0.0928, Generator Loss: 0.3036, Series Loss: 0.0097, Class Loss: 0.2440, Accuracy: 0.3148\n",
      "Epoch [1137/4000], Discriminator Loss: 0.0928, Generator Loss: 0.3036, Series Loss: 0.0096, Class Loss: 0.2438, Accuracy: 0.2963\n",
      "Epoch [1138/4000], Discriminator Loss: 0.0924, Generator Loss: 0.3024, Series Loss: 0.0095, Class Loss: 0.2439, Accuracy: 0.3086\n",
      "Epoch [1139/4000], Discriminator Loss: 0.0925, Generator Loss: 0.3029, Series Loss: 0.0096, Class Loss: 0.2439, Accuracy: 0.2963\n",
      "Epoch [1140/4000], Discriminator Loss: 0.0925, Generator Loss: 0.3034, Series Loss: 0.0096, Class Loss: 0.2439, Accuracy: 0.3025\n",
      "Epoch [1141/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3029, Series Loss: 0.0096, Class Loss: 0.2438, Accuracy: 0.3148\n",
      "Epoch [1142/4000], Discriminator Loss: 0.0920, Generator Loss: 0.3039, Series Loss: 0.0098, Class Loss: 0.2439, Accuracy: 0.3086\n",
      "Epoch [1143/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3028, Series Loss: 0.0097, Class Loss: 0.2438, Accuracy: 0.2901\n",
      "Epoch [1144/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3033, Series Loss: 0.0097, Class Loss: 0.2439, Accuracy: 0.3025\n",
      "Epoch [1145/4000], Discriminator Loss: 0.0927, Generator Loss: 0.3033, Series Loss: 0.0096, Class Loss: 0.2438, Accuracy: 0.2963\n",
      "Epoch [1146/4000], Discriminator Loss: 0.0927, Generator Loss: 0.3032, Series Loss: 0.0097, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [1147/4000], Discriminator Loss: 0.0923, Generator Loss: 0.3035, Series Loss: 0.0096, Class Loss: 0.2439, Accuracy: 0.3148\n",
      "Epoch [1148/4000], Discriminator Loss: 0.0931, Generator Loss: 0.3027, Series Loss: 0.0096, Class Loss: 0.2439, Accuracy: 0.3148\n",
      "Epoch [1149/4000], Discriminator Loss: 0.0923, Generator Loss: 0.3033, Series Loss: 0.0096, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1150/4000], Discriminator Loss: 0.0924, Generator Loss: 0.3033, Series Loss: 0.0096, Class Loss: 0.2438, Accuracy: 0.2963\n",
      "Epoch [1151/4000], Discriminator Loss: 0.0925, Generator Loss: 0.3033, Series Loss: 0.0097, Class Loss: 0.2438, Accuracy: 0.2963\n",
      "Epoch [1152/4000], Discriminator Loss: 0.0922, Generator Loss: 0.3028, Series Loss: 0.0096, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1153/4000], Discriminator Loss: 0.0927, Generator Loss: 0.3024, Series Loss: 0.0096, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1154/4000], Discriminator Loss: 0.0927, Generator Loss: 0.3033, Series Loss: 0.0095, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [1155/4000], Discriminator Loss: 0.0928, Generator Loss: 0.3028, Series Loss: 0.0096, Class Loss: 0.2438, Accuracy: 0.2963\n",
      "Epoch [1156/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3030, Series Loss: 0.0096, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [1157/4000], Discriminator Loss: 0.0926, Generator Loss: 0.3028, Series Loss: 0.0096, Class Loss: 0.2439, Accuracy: 0.3025\n",
      "Epoch [1158/4000], Discriminator Loss: 0.0921, Generator Loss: 0.3031, Series Loss: 0.0097, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1159/4000], Discriminator Loss: 0.0928, Generator Loss: 0.3035, Series Loss: 0.0095, Class Loss: 0.2439, Accuracy: 0.2901\n",
      "Epoch [1160/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3034, Series Loss: 0.0095, Class Loss: 0.2439, Accuracy: 0.3025\n",
      "Epoch [1161/4000], Discriminator Loss: 0.0926, Generator Loss: 0.3031, Series Loss: 0.0095, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [1162/4000], Discriminator Loss: 0.0922, Generator Loss: 0.3030, Series Loss: 0.0096, Class Loss: 0.2439, Accuracy: 0.2901\n",
      "Epoch [1163/4000], Discriminator Loss: 0.0927, Generator Loss: 0.3038, Series Loss: 0.0095, Class Loss: 0.2440, Accuracy: 0.2963\n",
      "Epoch [1164/4000], Discriminator Loss: 0.0917, Generator Loss: 0.3035, Series Loss: 0.0094, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1165/4000], Discriminator Loss: 0.0927, Generator Loss: 0.3026, Series Loss: 0.0096, Class Loss: 0.2438, Accuracy: 0.2963\n",
      "Epoch [1166/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3030, Series Loss: 0.0095, Class Loss: 0.2439, Accuracy: 0.2963\n",
      "Epoch [1167/4000], Discriminator Loss: 0.0929, Generator Loss: 0.3030, Series Loss: 0.0094, Class Loss: 0.2438, Accuracy: 0.3025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1168/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3026, Series Loss: 0.0094, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1169/4000], Discriminator Loss: 0.0929, Generator Loss: 0.3028, Series Loss: 0.0094, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [1170/4000], Discriminator Loss: 0.0925, Generator Loss: 0.3037, Series Loss: 0.0094, Class Loss: 0.2438, Accuracy: 0.2963\n",
      "Epoch [1171/4000], Discriminator Loss: 0.0926, Generator Loss: 0.3034, Series Loss: 0.0094, Class Loss: 0.2439, Accuracy: 0.2963\n",
      "Epoch [1172/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3030, Series Loss: 0.0092, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1173/4000], Discriminator Loss: 0.0928, Generator Loss: 0.3033, Series Loss: 0.0093, Class Loss: 0.2439, Accuracy: 0.3025\n",
      "Epoch [1174/4000], Discriminator Loss: 0.0929, Generator Loss: 0.3030, Series Loss: 0.0093, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [1175/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3034, Series Loss: 0.0094, Class Loss: 0.2439, Accuracy: 0.2963\n",
      "Epoch [1176/4000], Discriminator Loss: 0.0927, Generator Loss: 0.3029, Series Loss: 0.0094, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1177/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3032, Series Loss: 0.0094, Class Loss: 0.2439, Accuracy: 0.2963\n",
      "Epoch [1178/4000], Discriminator Loss: 0.0937, Generator Loss: 0.3028, Series Loss: 0.0094, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1179/4000], Discriminator Loss: 0.0922, Generator Loss: 0.3033, Series Loss: 0.0095, Class Loss: 0.2439, Accuracy: 0.2963\n",
      "Epoch [1180/4000], Discriminator Loss: 0.0926, Generator Loss: 0.3025, Series Loss: 0.0094, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1181/4000], Discriminator Loss: 0.0920, Generator Loss: 0.3024, Series Loss: 0.0093, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1182/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3028, Series Loss: 0.0094, Class Loss: 0.2438, Accuracy: 0.2963\n",
      "Epoch [1183/4000], Discriminator Loss: 0.0926, Generator Loss: 0.3034, Series Loss: 0.0095, Class Loss: 0.2439, Accuracy: 0.3025\n",
      "Epoch [1184/4000], Discriminator Loss: 0.0926, Generator Loss: 0.3028, Series Loss: 0.0094, Class Loss: 0.2438, Accuracy: 0.2963\n",
      "Epoch [1185/4000], Discriminator Loss: 0.0926, Generator Loss: 0.3030, Series Loss: 0.0093, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1186/4000], Discriminator Loss: 0.0927, Generator Loss: 0.3033, Series Loss: 0.0095, Class Loss: 0.2439, Accuracy: 0.3086\n",
      "Epoch [1187/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3028, Series Loss: 0.0094, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1188/4000], Discriminator Loss: 0.0931, Generator Loss: 0.3028, Series Loss: 0.0094, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1189/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3027, Series Loss: 0.0094, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1190/4000], Discriminator Loss: 0.0926, Generator Loss: 0.3035, Series Loss: 0.0094, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [1191/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3027, Series Loss: 0.0094, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [1192/4000], Discriminator Loss: 0.0926, Generator Loss: 0.3035, Series Loss: 0.0094, Class Loss: 0.2439, Accuracy: 0.2901\n",
      "Epoch [1193/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3030, Series Loss: 0.0094, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1194/4000], Discriminator Loss: 0.0925, Generator Loss: 0.3030, Series Loss: 0.0094, Class Loss: 0.2438, Accuracy: 0.2963\n",
      "Epoch [1195/4000], Discriminator Loss: 0.0921, Generator Loss: 0.3027, Series Loss: 0.0093, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [1196/4000], Discriminator Loss: 0.0929, Generator Loss: 0.3031, Series Loss: 0.0093, Class Loss: 0.2439, Accuracy: 0.3148\n",
      "Epoch [1197/4000], Discriminator Loss: 0.0923, Generator Loss: 0.3027, Series Loss: 0.0093, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [1198/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3029, Series Loss: 0.0094, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1199/4000], Discriminator Loss: 0.0929, Generator Loss: 0.3026, Series Loss: 0.0092, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1200/4000], Discriminator Loss: 0.0931, Generator Loss: 0.3026, Series Loss: 0.0093, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1201/4000], Discriminator Loss: 0.0928, Generator Loss: 0.3027, Series Loss: 0.0093, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1202/4000], Discriminator Loss: 0.0928, Generator Loss: 0.3024, Series Loss: 0.0093, Class Loss: 0.2439, Accuracy: 0.3025\n",
      "Epoch [1203/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3023, Series Loss: 0.0092, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1204/4000], Discriminator Loss: 0.0925, Generator Loss: 0.3030, Series Loss: 0.0094, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [1205/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3032, Series Loss: 0.0094, Class Loss: 0.2439, Accuracy: 0.2963\n",
      "Epoch [1206/4000], Discriminator Loss: 0.0925, Generator Loss: 0.3022, Series Loss: 0.0092, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [1207/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3029, Series Loss: 0.0092, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1208/4000], Discriminator Loss: 0.0927, Generator Loss: 0.3022, Series Loss: 0.0092, Class Loss: 0.2438, Accuracy: 0.3148\n",
      "Epoch [1209/4000], Discriminator Loss: 0.0927, Generator Loss: 0.3028, Series Loss: 0.0093, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1210/4000], Discriminator Loss: 0.0924, Generator Loss: 0.3024, Series Loss: 0.0093, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1211/4000], Discriminator Loss: 0.0927, Generator Loss: 0.3024, Series Loss: 0.0093, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [1212/4000], Discriminator Loss: 0.0927, Generator Loss: 0.3023, Series Loss: 0.0092, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1213/4000], Discriminator Loss: 0.0935, Generator Loss: 0.3023, Series Loss: 0.0093, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [1214/4000], Discriminator Loss: 0.0931, Generator Loss: 0.3022, Series Loss: 0.0093, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1215/4000], Discriminator Loss: 0.0929, Generator Loss: 0.3025, Series Loss: 0.0093, Class Loss: 0.2438, Accuracy: 0.2963\n",
      "Epoch [1216/4000], Discriminator Loss: 0.0933, Generator Loss: 0.3022, Series Loss: 0.0091, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [1217/4000], Discriminator Loss: 0.0926, Generator Loss: 0.3031, Series Loss: 0.0093, Class Loss: 0.2437, Accuracy: 0.3210\n",
      "Epoch [1218/4000], Discriminator Loss: 0.0937, Generator Loss: 0.3026, Series Loss: 0.0091, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1219/4000], Discriminator Loss: 0.0938, Generator Loss: 0.3025, Series Loss: 0.0092, Class Loss: 0.2438, Accuracy: 0.3148\n",
      "Epoch [1220/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3025, Series Loss: 0.0093, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1221/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3024, Series Loss: 0.0093, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1222/4000], Discriminator Loss: 0.0933, Generator Loss: 0.3028, Series Loss: 0.0093, Class Loss: 0.2438, Accuracy: 0.2963\n",
      "Epoch [1223/4000], Discriminator Loss: 0.0938, Generator Loss: 0.3028, Series Loss: 0.0093, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [1224/4000], Discriminator Loss: 0.0927, Generator Loss: 0.3029, Series Loss: 0.0093, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [1225/4000], Discriminator Loss: 0.0931, Generator Loss: 0.3022, Series Loss: 0.0093, Class Loss: 0.2438, Accuracy: 0.2901\n",
      "Epoch [1226/4000], Discriminator Loss: 0.0935, Generator Loss: 0.3019, Series Loss: 0.0092, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1227/4000], Discriminator Loss: 0.0929, Generator Loss: 0.3024, Series Loss: 0.0092, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1228/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3021, Series Loss: 0.0091, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1229/4000], Discriminator Loss: 0.0938, Generator Loss: 0.3019, Series Loss: 0.0092, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [1230/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3024, Series Loss: 0.0092, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1231/4000], Discriminator Loss: 0.0942, Generator Loss: 0.3022, Series Loss: 0.0092, Class Loss: 0.2438, Accuracy: 0.2963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1232/4000], Discriminator Loss: 0.0931, Generator Loss: 0.3025, Series Loss: 0.0092, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1233/4000], Discriminator Loss: 0.0935, Generator Loss: 0.3023, Series Loss: 0.0092, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1234/4000], Discriminator Loss: 0.0937, Generator Loss: 0.3017, Series Loss: 0.0091, Class Loss: 0.2438, Accuracy: 0.3148\n",
      "Epoch [1235/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3023, Series Loss: 0.0092, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [1236/4000], Discriminator Loss: 0.0942, Generator Loss: 0.3017, Series Loss: 0.0092, Class Loss: 0.2438, Accuracy: 0.2963\n",
      "Epoch [1237/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3025, Series Loss: 0.0091, Class Loss: 0.2438, Accuracy: 0.3148\n",
      "Epoch [1238/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3023, Series Loss: 0.0093, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1239/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3023, Series Loss: 0.0091, Class Loss: 0.2438, Accuracy: 0.2963\n",
      "Epoch [1240/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3023, Series Loss: 0.0091, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [1241/4000], Discriminator Loss: 0.0928, Generator Loss: 0.3022, Series Loss: 0.0092, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1242/4000], Discriminator Loss: 0.0933, Generator Loss: 0.3022, Series Loss: 0.0090, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1243/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3020, Series Loss: 0.0091, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1244/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3022, Series Loss: 0.0092, Class Loss: 0.2438, Accuracy: 0.3210\n",
      "Epoch [1245/4000], Discriminator Loss: 0.0935, Generator Loss: 0.3024, Series Loss: 0.0091, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [1246/4000], Discriminator Loss: 0.0937, Generator Loss: 0.3024, Series Loss: 0.0092, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1247/4000], Discriminator Loss: 0.0928, Generator Loss: 0.3028, Series Loss: 0.0092, Class Loss: 0.2439, Accuracy: 0.2901\n",
      "Epoch [1248/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3022, Series Loss: 0.0092, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1249/4000], Discriminator Loss: 0.0927, Generator Loss: 0.3029, Series Loss: 0.0092, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1250/4000], Discriminator Loss: 0.0928, Generator Loss: 0.3026, Series Loss: 0.0093, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1251/4000], Discriminator Loss: 0.0929, Generator Loss: 0.3027, Series Loss: 0.0093, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1252/4000], Discriminator Loss: 0.0928, Generator Loss: 0.3024, Series Loss: 0.0092, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [1253/4000], Discriminator Loss: 0.0937, Generator Loss: 0.3020, Series Loss: 0.0092, Class Loss: 0.2438, Accuracy: 0.2963\n",
      "Epoch [1254/4000], Discriminator Loss: 0.0931, Generator Loss: 0.3026, Series Loss: 0.0092, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [1255/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3021, Series Loss: 0.0093, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1256/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3019, Series Loss: 0.0092, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [1257/4000], Discriminator Loss: 0.0929, Generator Loss: 0.3020, Series Loss: 0.0092, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1258/4000], Discriminator Loss: 0.0933, Generator Loss: 0.3018, Series Loss: 0.0092, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1259/4000], Discriminator Loss: 0.0935, Generator Loss: 0.3023, Series Loss: 0.0092, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [1260/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3023, Series Loss: 0.0093, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1261/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3026, Series Loss: 0.0092, Class Loss: 0.2438, Accuracy: 0.3148\n",
      "Epoch [1262/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3022, Series Loss: 0.0092, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [1263/4000], Discriminator Loss: 0.0933, Generator Loss: 0.3022, Series Loss: 0.0092, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1264/4000], Discriminator Loss: 0.0937, Generator Loss: 0.3020, Series Loss: 0.0092, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [1265/4000], Discriminator Loss: 0.0946, Generator Loss: 0.3020, Series Loss: 0.0092, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1266/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3024, Series Loss: 0.0093, Class Loss: 0.2439, Accuracy: 0.3025\n",
      "Epoch [1267/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3024, Series Loss: 0.0092, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1268/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3022, Series Loss: 0.0093, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1269/4000], Discriminator Loss: 0.0941, Generator Loss: 0.3022, Series Loss: 0.0092, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1270/4000], Discriminator Loss: 0.0937, Generator Loss: 0.3022, Series Loss: 0.0092, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1271/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3017, Series Loss: 0.0092, Class Loss: 0.2438, Accuracy: 0.3210\n",
      "Epoch [1272/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3024, Series Loss: 0.0092, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [1273/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3023, Series Loss: 0.0092, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [1274/4000], Discriminator Loss: 0.0935, Generator Loss: 0.3019, Series Loss: 0.0092, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [1275/4000], Discriminator Loss: 0.0940, Generator Loss: 0.3013, Series Loss: 0.0091, Class Loss: 0.2437, Accuracy: 0.3210\n",
      "Epoch [1276/4000], Discriminator Loss: 0.0931, Generator Loss: 0.3022, Series Loss: 0.0092, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1277/4000], Discriminator Loss: 0.0942, Generator Loss: 0.3021, Series Loss: 0.0093, Class Loss: 0.2437, Accuracy: 0.3210\n",
      "Epoch [1278/4000], Discriminator Loss: 0.0935, Generator Loss: 0.3022, Series Loss: 0.0093, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1279/4000], Discriminator Loss: 0.0935, Generator Loss: 0.3020, Series Loss: 0.0092, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1280/4000], Discriminator Loss: 0.0928, Generator Loss: 0.3024, Series Loss: 0.0092, Class Loss: 0.2437, Accuracy: 0.2840\n",
      "Epoch [1281/4000], Discriminator Loss: 0.0941, Generator Loss: 0.3022, Series Loss: 0.0091, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [1282/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3023, Series Loss: 0.0092, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [1283/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3029, Series Loss: 0.0091, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1284/4000], Discriminator Loss: 0.0933, Generator Loss: 0.3023, Series Loss: 0.0091, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1285/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3021, Series Loss: 0.0091, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1286/4000], Discriminator Loss: 0.0938, Generator Loss: 0.3018, Series Loss: 0.0091, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [1287/4000], Discriminator Loss: 0.0933, Generator Loss: 0.3019, Series Loss: 0.0092, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1288/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3027, Series Loss: 0.0091, Class Loss: 0.2439, Accuracy: 0.3086\n",
      "Epoch [1289/4000], Discriminator Loss: 0.0940, Generator Loss: 0.3020, Series Loss: 0.0091, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [1290/4000], Discriminator Loss: 0.0935, Generator Loss: 0.3022, Series Loss: 0.0091, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1291/4000], Discriminator Loss: 0.0939, Generator Loss: 0.3016, Series Loss: 0.0092, Class Loss: 0.2438, Accuracy: 0.2963\n",
      "Epoch [1292/4000], Discriminator Loss: 0.0938, Generator Loss: 0.3019, Series Loss: 0.0092, Class Loss: 0.2439, Accuracy: 0.3025\n",
      "Epoch [1293/4000], Discriminator Loss: 0.0935, Generator Loss: 0.3019, Series Loss: 0.0092, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1294/4000], Discriminator Loss: 0.0940, Generator Loss: 0.3021, Series Loss: 0.0091, Class Loss: 0.2439, Accuracy: 0.3086\n",
      "Epoch [1295/4000], Discriminator Loss: 0.0929, Generator Loss: 0.3019, Series Loss: 0.0091, Class Loss: 0.2437, Accuracy: 0.3025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1296/4000], Discriminator Loss: 0.0938, Generator Loss: 0.3022, Series Loss: 0.0091, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [1297/4000], Discriminator Loss: 0.0940, Generator Loss: 0.3018, Series Loss: 0.0091, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1298/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3027, Series Loss: 0.0091, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1299/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3026, Series Loss: 0.0092, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [1300/4000], Discriminator Loss: 0.0926, Generator Loss: 0.3022, Series Loss: 0.0091, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1301/4000], Discriminator Loss: 0.0944, Generator Loss: 0.3019, Series Loss: 0.0092, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [1302/4000], Discriminator Loss: 0.0933, Generator Loss: 0.3019, Series Loss: 0.0091, Class Loss: 0.2438, Accuracy: 0.2963\n",
      "Epoch [1303/4000], Discriminator Loss: 0.0943, Generator Loss: 0.3020, Series Loss: 0.0091, Class Loss: 0.2438, Accuracy: 0.2963\n",
      "Epoch [1304/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3022, Series Loss: 0.0092, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [1305/4000], Discriminator Loss: 0.0940, Generator Loss: 0.3017, Series Loss: 0.0091, Class Loss: 0.2437, Accuracy: 0.2840\n",
      "Epoch [1306/4000], Discriminator Loss: 0.0944, Generator Loss: 0.3014, Series Loss: 0.0091, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1307/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3016, Series Loss: 0.0090, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1308/4000], Discriminator Loss: 0.0933, Generator Loss: 0.3023, Series Loss: 0.0091, Class Loss: 0.2436, Accuracy: 0.3210\n",
      "Epoch [1309/4000], Discriminator Loss: 0.0933, Generator Loss: 0.3021, Series Loss: 0.0090, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1310/4000], Discriminator Loss: 0.0944, Generator Loss: 0.3016, Series Loss: 0.0090, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1311/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3017, Series Loss: 0.0090, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1312/4000], Discriminator Loss: 0.0937, Generator Loss: 0.3021, Series Loss: 0.0090, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1313/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3021, Series Loss: 0.0090, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [1314/4000], Discriminator Loss: 0.0935, Generator Loss: 0.3018, Series Loss: 0.0089, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1315/4000], Discriminator Loss: 0.0938, Generator Loss: 0.3020, Series Loss: 0.0090, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1316/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3016, Series Loss: 0.0090, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [1317/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3023, Series Loss: 0.0091, Class Loss: 0.2438, Accuracy: 0.3148\n",
      "Epoch [1318/4000], Discriminator Loss: 0.0938, Generator Loss: 0.3021, Series Loss: 0.0090, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [1319/4000], Discriminator Loss: 0.0938, Generator Loss: 0.3016, Series Loss: 0.0090, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [1320/4000], Discriminator Loss: 0.0937, Generator Loss: 0.3014, Series Loss: 0.0089, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1321/4000], Discriminator Loss: 0.0941, Generator Loss: 0.3017, Series Loss: 0.0090, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [1322/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3014, Series Loss: 0.0090, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1323/4000], Discriminator Loss: 0.0940, Generator Loss: 0.3019, Series Loss: 0.0090, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1324/4000], Discriminator Loss: 0.0940, Generator Loss: 0.3020, Series Loss: 0.0090, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1325/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3021, Series Loss: 0.0090, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1326/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3017, Series Loss: 0.0091, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [1327/4000], Discriminator Loss: 0.0937, Generator Loss: 0.3017, Series Loss: 0.0089, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [1328/4000], Discriminator Loss: 0.0937, Generator Loss: 0.3018, Series Loss: 0.0090, Class Loss: 0.2439, Accuracy: 0.2963\n",
      "Epoch [1329/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3019, Series Loss: 0.0091, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1330/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3011, Series Loss: 0.0090, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [1331/4000], Discriminator Loss: 0.0933, Generator Loss: 0.3017, Series Loss: 0.0090, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [1332/4000], Discriminator Loss: 0.0941, Generator Loss: 0.3019, Series Loss: 0.0090, Class Loss: 0.2439, Accuracy: 0.2963\n",
      "Epoch [1333/4000], Discriminator Loss: 0.0940, Generator Loss: 0.3021, Series Loss: 0.0090, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [1334/4000], Discriminator Loss: 0.0929, Generator Loss: 0.3020, Series Loss: 0.0090, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1335/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3023, Series Loss: 0.0090, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1336/4000], Discriminator Loss: 0.0940, Generator Loss: 0.3019, Series Loss: 0.0090, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1337/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3024, Series Loss: 0.0090, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [1338/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3020, Series Loss: 0.0089, Class Loss: 0.2438, Accuracy: 0.2963\n",
      "Epoch [1339/4000], Discriminator Loss: 0.0927, Generator Loss: 0.3021, Series Loss: 0.0089, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1340/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3022, Series Loss: 0.0091, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1341/4000], Discriminator Loss: 0.0933, Generator Loss: 0.3017, Series Loss: 0.0090, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1342/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3015, Series Loss: 0.0090, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1343/4000], Discriminator Loss: 0.0939, Generator Loss: 0.3018, Series Loss: 0.0090, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1344/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3021, Series Loss: 0.0089, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1345/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3016, Series Loss: 0.0091, Class Loss: 0.2437, Accuracy: 0.3210\n",
      "Epoch [1346/4000], Discriminator Loss: 0.0931, Generator Loss: 0.3026, Series Loss: 0.0089, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [1347/4000], Discriminator Loss: 0.0938, Generator Loss: 0.3019, Series Loss: 0.0089, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [1348/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3022, Series Loss: 0.0090, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1349/4000], Discriminator Loss: 0.0931, Generator Loss: 0.3019, Series Loss: 0.0089, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1350/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3019, Series Loss: 0.0091, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [1351/4000], Discriminator Loss: 0.0935, Generator Loss: 0.3014, Series Loss: 0.0089, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1352/4000], Discriminator Loss: 0.0943, Generator Loss: 0.3020, Series Loss: 0.0090, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [1353/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3018, Series Loss: 0.0089, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [1354/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3015, Series Loss: 0.0090, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1355/4000], Discriminator Loss: 0.0938, Generator Loss: 0.3018, Series Loss: 0.0089, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1356/4000], Discriminator Loss: 0.0935, Generator Loss: 0.3017, Series Loss: 0.0089, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [1357/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3020, Series Loss: 0.0089, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [1358/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3021, Series Loss: 0.0091, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1359/4000], Discriminator Loss: 0.0933, Generator Loss: 0.3014, Series Loss: 0.0089, Class Loss: 0.2437, Accuracy: 0.2963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1360/4000], Discriminator Loss: 0.0929, Generator Loss: 0.3014, Series Loss: 0.0088, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [1361/4000], Discriminator Loss: 0.0935, Generator Loss: 0.3020, Series Loss: 0.0090, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1362/4000], Discriminator Loss: 0.0942, Generator Loss: 0.3016, Series Loss: 0.0090, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [1363/4000], Discriminator Loss: 0.0929, Generator Loss: 0.3016, Series Loss: 0.0089, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1364/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3015, Series Loss: 0.0089, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1365/4000], Discriminator Loss: 0.0931, Generator Loss: 0.3018, Series Loss: 0.0088, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1366/4000], Discriminator Loss: 0.0933, Generator Loss: 0.3023, Series Loss: 0.0089, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1367/4000], Discriminator Loss: 0.0933, Generator Loss: 0.3021, Series Loss: 0.0089, Class Loss: 0.2437, Accuracy: 0.3210\n",
      "Epoch [1368/4000], Discriminator Loss: 0.0931, Generator Loss: 0.3015, Series Loss: 0.0089, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1369/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3017, Series Loss: 0.0090, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1370/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3013, Series Loss: 0.0089, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1371/4000], Discriminator Loss: 0.0938, Generator Loss: 0.3020, Series Loss: 0.0090, Class Loss: 0.2436, Accuracy: 0.3210\n",
      "Epoch [1372/4000], Discriminator Loss: 0.0931, Generator Loss: 0.3016, Series Loss: 0.0088, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1373/4000], Discriminator Loss: 0.0937, Generator Loss: 0.3019, Series Loss: 0.0089, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1374/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3021, Series Loss: 0.0088, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1375/4000], Discriminator Loss: 0.0931, Generator Loss: 0.3023, Series Loss: 0.0087, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1376/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3014, Series Loss: 0.0088, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [1377/4000], Discriminator Loss: 0.0939, Generator Loss: 0.3018, Series Loss: 0.0088, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1378/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3011, Series Loss: 0.0088, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1379/4000], Discriminator Loss: 0.0938, Generator Loss: 0.3018, Series Loss: 0.0089, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1380/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3019, Series Loss: 0.0088, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1381/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3017, Series Loss: 0.0088, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [1382/4000], Discriminator Loss: 0.0942, Generator Loss: 0.3015, Series Loss: 0.0088, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1383/4000], Discriminator Loss: 0.0935, Generator Loss: 0.3015, Series Loss: 0.0088, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1384/4000], Discriminator Loss: 0.0939, Generator Loss: 0.3014, Series Loss: 0.0089, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1385/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3017, Series Loss: 0.0089, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1386/4000], Discriminator Loss: 0.0937, Generator Loss: 0.3015, Series Loss: 0.0088, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1387/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3016, Series Loss: 0.0087, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [1388/4000], Discriminator Loss: 0.0931, Generator Loss: 0.3012, Series Loss: 0.0088, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1389/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3019, Series Loss: 0.0088, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1390/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3011, Series Loss: 0.0088, Class Loss: 0.2438, Accuracy: 0.3148\n",
      "Epoch [1391/4000], Discriminator Loss: 0.0940, Generator Loss: 0.3012, Series Loss: 0.0088, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [1392/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3009, Series Loss: 0.0088, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1393/4000], Discriminator Loss: 0.0939, Generator Loss: 0.3009, Series Loss: 0.0088, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [1394/4000], Discriminator Loss: 0.0935, Generator Loss: 0.3008, Series Loss: 0.0089, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1395/4000], Discriminator Loss: 0.0943, Generator Loss: 0.3007, Series Loss: 0.0087, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [1396/4000], Discriminator Loss: 0.0941, Generator Loss: 0.3013, Series Loss: 0.0088, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1397/4000], Discriminator Loss: 0.0940, Generator Loss: 0.3012, Series Loss: 0.0087, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1398/4000], Discriminator Loss: 0.0931, Generator Loss: 0.3014, Series Loss: 0.0087, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1399/4000], Discriminator Loss: 0.0933, Generator Loss: 0.3014, Series Loss: 0.0088, Class Loss: 0.2437, Accuracy: 0.3272\n",
      "Epoch [1400/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3016, Series Loss: 0.0088, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1401/4000], Discriminator Loss: 0.0938, Generator Loss: 0.3016, Series Loss: 0.0087, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1402/4000], Discriminator Loss: 0.0939, Generator Loss: 0.3015, Series Loss: 0.0087, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1403/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3012, Series Loss: 0.0087, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1404/4000], Discriminator Loss: 0.0944, Generator Loss: 0.3009, Series Loss: 0.0086, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1405/4000], Discriminator Loss: 0.0941, Generator Loss: 0.3013, Series Loss: 0.0087, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [1406/4000], Discriminator Loss: 0.0935, Generator Loss: 0.3012, Series Loss: 0.0088, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [1407/4000], Discriminator Loss: 0.0941, Generator Loss: 0.3008, Series Loss: 0.0087, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1408/4000], Discriminator Loss: 0.0939, Generator Loss: 0.3012, Series Loss: 0.0087, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [1409/4000], Discriminator Loss: 0.0942, Generator Loss: 0.3015, Series Loss: 0.0086, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1410/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3017, Series Loss: 0.0087, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1411/4000], Discriminator Loss: 0.0943, Generator Loss: 0.3018, Series Loss: 0.0087, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1412/4000], Discriminator Loss: 0.0943, Generator Loss: 0.3019, Series Loss: 0.0087, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1413/4000], Discriminator Loss: 0.0944, Generator Loss: 0.3013, Series Loss: 0.0087, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1414/4000], Discriminator Loss: 0.0944, Generator Loss: 0.3016, Series Loss: 0.0087, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1415/4000], Discriminator Loss: 0.0939, Generator Loss: 0.3014, Series Loss: 0.0087, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1416/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3019, Series Loss: 0.0087, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [1417/4000], Discriminator Loss: 0.0933, Generator Loss: 0.3013, Series Loss: 0.0087, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [1418/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3015, Series Loss: 0.0087, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [1419/4000], Discriminator Loss: 0.0937, Generator Loss: 0.3008, Series Loss: 0.0085, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [1420/4000], Discriminator Loss: 0.0939, Generator Loss: 0.3016, Series Loss: 0.0087, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1421/4000], Discriminator Loss: 0.0933, Generator Loss: 0.3016, Series Loss: 0.0087, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1422/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3018, Series Loss: 0.0086, Class Loss: 0.2438, Accuracy: 0.3148\n",
      "Epoch [1423/4000], Discriminator Loss: 0.0940, Generator Loss: 0.3010, Series Loss: 0.0086, Class Loss: 0.2437, Accuracy: 0.3025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1424/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3017, Series Loss: 0.0086, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1425/4000], Discriminator Loss: 0.0944, Generator Loss: 0.3012, Series Loss: 0.0086, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1426/4000], Discriminator Loss: 0.0931, Generator Loss: 0.3015, Series Loss: 0.0086, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1427/4000], Discriminator Loss: 0.0940, Generator Loss: 0.3017, Series Loss: 0.0087, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [1428/4000], Discriminator Loss: 0.0940, Generator Loss: 0.3015, Series Loss: 0.0087, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1429/4000], Discriminator Loss: 0.0939, Generator Loss: 0.3017, Series Loss: 0.0087, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [1430/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3018, Series Loss: 0.0086, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1431/4000], Discriminator Loss: 0.0941, Generator Loss: 0.3015, Series Loss: 0.0086, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1432/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3014, Series Loss: 0.0087, Class Loss: 0.2438, Accuracy: 0.2963\n",
      "Epoch [1433/4000], Discriminator Loss: 0.0931, Generator Loss: 0.3019, Series Loss: 0.0087, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1434/4000], Discriminator Loss: 0.0942, Generator Loss: 0.3017, Series Loss: 0.0087, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [1435/4000], Discriminator Loss: 0.0938, Generator Loss: 0.3009, Series Loss: 0.0086, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1436/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3016, Series Loss: 0.0086, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1437/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3015, Series Loss: 0.0086, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [1438/4000], Discriminator Loss: 0.0935, Generator Loss: 0.3012, Series Loss: 0.0086, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1439/4000], Discriminator Loss: 0.0938, Generator Loss: 0.3013, Series Loss: 0.0086, Class Loss: 0.2439, Accuracy: 0.3025\n",
      "Epoch [1440/4000], Discriminator Loss: 0.0929, Generator Loss: 0.3019, Series Loss: 0.0086, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [1441/4000], Discriminator Loss: 0.0933, Generator Loss: 0.3017, Series Loss: 0.0086, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1442/4000], Discriminator Loss: 0.0933, Generator Loss: 0.3017, Series Loss: 0.0087, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [1443/4000], Discriminator Loss: 0.0931, Generator Loss: 0.3017, Series Loss: 0.0086, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1444/4000], Discriminator Loss: 0.0937, Generator Loss: 0.3013, Series Loss: 0.0086, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [1445/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3016, Series Loss: 0.0087, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1446/4000], Discriminator Loss: 0.0940, Generator Loss: 0.3016, Series Loss: 0.0086, Class Loss: 0.2437, Accuracy: 0.3210\n",
      "Epoch [1447/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3017, Series Loss: 0.0086, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [1448/4000], Discriminator Loss: 0.0925, Generator Loss: 0.3013, Series Loss: 0.0086, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1449/4000], Discriminator Loss: 0.0937, Generator Loss: 0.3011, Series Loss: 0.0086, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1450/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3010, Series Loss: 0.0086, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1451/4000], Discriminator Loss: 0.0938, Generator Loss: 0.3010, Series Loss: 0.0086, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1452/4000], Discriminator Loss: 0.0935, Generator Loss: 0.3016, Series Loss: 0.0087, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1453/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3018, Series Loss: 0.0085, Class Loss: 0.2438, Accuracy: 0.2963\n",
      "Epoch [1454/4000], Discriminator Loss: 0.0937, Generator Loss: 0.3018, Series Loss: 0.0087, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1455/4000], Discriminator Loss: 0.0935, Generator Loss: 0.3013, Series Loss: 0.0086, Class Loss: 0.2438, Accuracy: 0.3148\n",
      "Epoch [1456/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3015, Series Loss: 0.0085, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1457/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3015, Series Loss: 0.0085, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [1458/4000], Discriminator Loss: 0.0935, Generator Loss: 0.3015, Series Loss: 0.0085, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1459/4000], Discriminator Loss: 0.0937, Generator Loss: 0.3016, Series Loss: 0.0085, Class Loss: 0.2438, Accuracy: 0.2963\n",
      "Epoch [1460/4000], Discriminator Loss: 0.0931, Generator Loss: 0.3017, Series Loss: 0.0085, Class Loss: 0.2437, Accuracy: 0.3210\n",
      "Epoch [1461/4000], Discriminator Loss: 0.0937, Generator Loss: 0.3012, Series Loss: 0.0085, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [1462/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3016, Series Loss: 0.0085, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1463/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3015, Series Loss: 0.0084, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [1464/4000], Discriminator Loss: 0.0937, Generator Loss: 0.3016, Series Loss: 0.0085, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1465/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3017, Series Loss: 0.0085, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1466/4000], Discriminator Loss: 0.0931, Generator Loss: 0.3017, Series Loss: 0.0084, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1467/4000], Discriminator Loss: 0.0938, Generator Loss: 0.3018, Series Loss: 0.0085, Class Loss: 0.2439, Accuracy: 0.3148\n",
      "Epoch [1468/4000], Discriminator Loss: 0.0937, Generator Loss: 0.3010, Series Loss: 0.0085, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1469/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3010, Series Loss: 0.0085, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1470/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3010, Series Loss: 0.0084, Class Loss: 0.2438, Accuracy: 0.2963\n",
      "Epoch [1471/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3015, Series Loss: 0.0085, Class Loss: 0.2438, Accuracy: 0.3148\n",
      "Epoch [1472/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3012, Series Loss: 0.0085, Class Loss: 0.2439, Accuracy: 0.3086\n",
      "Epoch [1473/4000], Discriminator Loss: 0.0938, Generator Loss: 0.3012, Series Loss: 0.0084, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1474/4000], Discriminator Loss: 0.0941, Generator Loss: 0.3011, Series Loss: 0.0084, Class Loss: 0.2438, Accuracy: 0.2901\n",
      "Epoch [1475/4000], Discriminator Loss: 0.0935, Generator Loss: 0.3012, Series Loss: 0.0084, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [1476/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3008, Series Loss: 0.0084, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1477/4000], Discriminator Loss: 0.0938, Generator Loss: 0.3010, Series Loss: 0.0085, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1478/4000], Discriminator Loss: 0.0935, Generator Loss: 0.3012, Series Loss: 0.0083, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1479/4000], Discriminator Loss: 0.0931, Generator Loss: 0.3011, Series Loss: 0.0084, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1480/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3009, Series Loss: 0.0084, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [1481/4000], Discriminator Loss: 0.0931, Generator Loss: 0.3009, Series Loss: 0.0084, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [1482/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3015, Series Loss: 0.0084, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [1483/4000], Discriminator Loss: 0.0929, Generator Loss: 0.3015, Series Loss: 0.0084, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1484/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3008, Series Loss: 0.0084, Class Loss: 0.2436, Accuracy: 0.3272\n",
      "Epoch [1485/4000], Discriminator Loss: 0.0928, Generator Loss: 0.3009, Series Loss: 0.0083, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [1486/4000], Discriminator Loss: 0.0933, Generator Loss: 0.3010, Series Loss: 0.0084, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1487/4000], Discriminator Loss: 0.0929, Generator Loss: 0.3009, Series Loss: 0.0083, Class Loss: 0.2437, Accuracy: 0.3086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1488/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3010, Series Loss: 0.0084, Class Loss: 0.2438, Accuracy: 0.2963\n",
      "Epoch [1489/4000], Discriminator Loss: 0.0937, Generator Loss: 0.3009, Series Loss: 0.0084, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1490/4000], Discriminator Loss: 0.0935, Generator Loss: 0.3013, Series Loss: 0.0084, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1491/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3013, Series Loss: 0.0085, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [1492/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3012, Series Loss: 0.0084, Class Loss: 0.2438, Accuracy: 0.2963\n",
      "Epoch [1493/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3010, Series Loss: 0.0083, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [1494/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3016, Series Loss: 0.0085, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [1495/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3009, Series Loss: 0.0084, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [1496/4000], Discriminator Loss: 0.0929, Generator Loss: 0.3012, Series Loss: 0.0084, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1497/4000], Discriminator Loss: 0.0940, Generator Loss: 0.3012, Series Loss: 0.0084, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1498/4000], Discriminator Loss: 0.0933, Generator Loss: 0.3010, Series Loss: 0.0084, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1499/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3008, Series Loss: 0.0084, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1500/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3010, Series Loss: 0.0084, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1501/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3015, Series Loss: 0.0084, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [1502/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3010, Series Loss: 0.0084, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [1503/4000], Discriminator Loss: 0.0935, Generator Loss: 0.3009, Series Loss: 0.0083, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1504/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3011, Series Loss: 0.0085, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1505/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3013, Series Loss: 0.0084, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1506/4000], Discriminator Loss: 0.0937, Generator Loss: 0.3011, Series Loss: 0.0084, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [1507/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3012, Series Loss: 0.0083, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1508/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3015, Series Loss: 0.0083, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [1509/4000], Discriminator Loss: 0.0935, Generator Loss: 0.3015, Series Loss: 0.0084, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1510/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3012, Series Loss: 0.0083, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [1511/4000], Discriminator Loss: 0.0938, Generator Loss: 0.3014, Series Loss: 0.0083, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1512/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3009, Series Loss: 0.0083, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1513/4000], Discriminator Loss: 0.0931, Generator Loss: 0.3018, Series Loss: 0.0085, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1514/4000], Discriminator Loss: 0.0933, Generator Loss: 0.3013, Series Loss: 0.0083, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1515/4000], Discriminator Loss: 0.0933, Generator Loss: 0.3013, Series Loss: 0.0083, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [1516/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3012, Series Loss: 0.0084, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [1517/4000], Discriminator Loss: 0.0937, Generator Loss: 0.3006, Series Loss: 0.0083, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1518/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3008, Series Loss: 0.0084, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1519/4000], Discriminator Loss: 0.0928, Generator Loss: 0.3013, Series Loss: 0.0084, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [1520/4000], Discriminator Loss: 0.0935, Generator Loss: 0.3014, Series Loss: 0.0084, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [1521/4000], Discriminator Loss: 0.0928, Generator Loss: 0.3015, Series Loss: 0.0083, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1522/4000], Discriminator Loss: 0.0935, Generator Loss: 0.3012, Series Loss: 0.0083, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1523/4000], Discriminator Loss: 0.0931, Generator Loss: 0.3011, Series Loss: 0.0083, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [1524/4000], Discriminator Loss: 0.0935, Generator Loss: 0.3009, Series Loss: 0.0083, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [1525/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3004, Series Loss: 0.0083, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [1526/4000], Discriminator Loss: 0.0938, Generator Loss: 0.3007, Series Loss: 0.0084, Class Loss: 0.2438, Accuracy: 0.3148\n",
      "Epoch [1527/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3005, Series Loss: 0.0082, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [1528/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3005, Series Loss: 0.0082, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1529/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3010, Series Loss: 0.0082, Class Loss: 0.2437, Accuracy: 0.3272\n",
      "Epoch [1530/4000], Discriminator Loss: 0.0926, Generator Loss: 0.3014, Series Loss: 0.0083, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [1531/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3013, Series Loss: 0.0083, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1532/4000], Discriminator Loss: 0.0933, Generator Loss: 0.3012, Series Loss: 0.0082, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [1533/4000], Discriminator Loss: 0.0939, Generator Loss: 0.3008, Series Loss: 0.0081, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1534/4000], Discriminator Loss: 0.0939, Generator Loss: 0.3008, Series Loss: 0.0082, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [1535/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3015, Series Loss: 0.0082, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [1536/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3012, Series Loss: 0.0083, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1537/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3010, Series Loss: 0.0082, Class Loss: 0.2438, Accuracy: 0.3148\n",
      "Epoch [1538/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3012, Series Loss: 0.0083, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [1539/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3007, Series Loss: 0.0082, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1540/4000], Discriminator Loss: 0.0937, Generator Loss: 0.3009, Series Loss: 0.0083, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1541/4000], Discriminator Loss: 0.0931, Generator Loss: 0.3008, Series Loss: 0.0082, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1542/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3004, Series Loss: 0.0081, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1543/4000], Discriminator Loss: 0.0931, Generator Loss: 0.3007, Series Loss: 0.0082, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1544/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3006, Series Loss: 0.0082, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [1545/4000], Discriminator Loss: 0.0938, Generator Loss: 0.3008, Series Loss: 0.0083, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [1546/4000], Discriminator Loss: 0.0935, Generator Loss: 0.3004, Series Loss: 0.0081, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [1547/4000], Discriminator Loss: 0.0933, Generator Loss: 0.3007, Series Loss: 0.0081, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1548/4000], Discriminator Loss: 0.0931, Generator Loss: 0.3006, Series Loss: 0.0082, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1549/4000], Discriminator Loss: 0.0939, Generator Loss: 0.3005, Series Loss: 0.0081, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1550/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3006, Series Loss: 0.0081, Class Loss: 0.2436, Accuracy: 0.3210\n",
      "Epoch [1551/4000], Discriminator Loss: 0.0940, Generator Loss: 0.3011, Series Loss: 0.0082, Class Loss: 0.2437, Accuracy: 0.3086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1552/4000], Discriminator Loss: 0.0935, Generator Loss: 0.3007, Series Loss: 0.0081, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [1553/4000], Discriminator Loss: 0.0935, Generator Loss: 0.3005, Series Loss: 0.0081, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1554/4000], Discriminator Loss: 0.0938, Generator Loss: 0.3003, Series Loss: 0.0081, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1555/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3009, Series Loss: 0.0082, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1556/4000], Discriminator Loss: 0.0935, Generator Loss: 0.3004, Series Loss: 0.0082, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1557/4000], Discriminator Loss: 0.0935, Generator Loss: 0.3004, Series Loss: 0.0081, Class Loss: 0.2439, Accuracy: 0.3025\n",
      "Epoch [1558/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3002, Series Loss: 0.0082, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1559/4000], Discriminator Loss: 0.0933, Generator Loss: 0.3007, Series Loss: 0.0081, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [1560/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3007, Series Loss: 0.0081, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [1561/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3010, Series Loss: 0.0081, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1562/4000], Discriminator Loss: 0.0935, Generator Loss: 0.3008, Series Loss: 0.0081, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1563/4000], Discriminator Loss: 0.0931, Generator Loss: 0.3007, Series Loss: 0.0081, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1564/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3012, Series Loss: 0.0082, Class Loss: 0.2436, Accuracy: 0.3210\n",
      "Epoch [1565/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3001, Series Loss: 0.0081, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1566/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3005, Series Loss: 0.0080, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1567/4000], Discriminator Loss: 0.0929, Generator Loss: 0.3009, Series Loss: 0.0080, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [1568/4000], Discriminator Loss: 0.0938, Generator Loss: 0.3007, Series Loss: 0.0080, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1569/4000], Discriminator Loss: 0.0935, Generator Loss: 0.3003, Series Loss: 0.0079, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [1570/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3005, Series Loss: 0.0080, Class Loss: 0.2436, Accuracy: 0.3210\n",
      "Epoch [1571/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3004, Series Loss: 0.0081, Class Loss: 0.2436, Accuracy: 0.3210\n",
      "Epoch [1572/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3007, Series Loss: 0.0081, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1573/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3005, Series Loss: 0.0082, Class Loss: 0.2436, Accuracy: 0.3210\n",
      "Epoch [1574/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3007, Series Loss: 0.0081, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1575/4000], Discriminator Loss: 0.0933, Generator Loss: 0.3003, Series Loss: 0.0080, Class Loss: 0.2437, Accuracy: 0.3210\n",
      "Epoch [1576/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3003, Series Loss: 0.0080, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [1577/4000], Discriminator Loss: 0.0937, Generator Loss: 0.3003, Series Loss: 0.0081, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1578/4000], Discriminator Loss: 0.0928, Generator Loss: 0.3005, Series Loss: 0.0080, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1579/4000], Discriminator Loss: 0.0938, Generator Loss: 0.3000, Series Loss: 0.0080, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1580/4000], Discriminator Loss: 0.0933, Generator Loss: 0.3008, Series Loss: 0.0080, Class Loss: 0.2438, Accuracy: 0.2963\n",
      "Epoch [1581/4000], Discriminator Loss: 0.0933, Generator Loss: 0.3002, Series Loss: 0.0080, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [1582/4000], Discriminator Loss: 0.0935, Generator Loss: 0.3000, Series Loss: 0.0080, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1583/4000], Discriminator Loss: 0.0939, Generator Loss: 0.3000, Series Loss: 0.0080, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1584/4000], Discriminator Loss: 0.0937, Generator Loss: 0.3000, Series Loss: 0.0080, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1585/4000], Discriminator Loss: 0.0933, Generator Loss: 0.3004, Series Loss: 0.0079, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1586/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3004, Series Loss: 0.0081, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1587/4000], Discriminator Loss: 0.0939, Generator Loss: 0.3000, Series Loss: 0.0080, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1588/4000], Discriminator Loss: 0.0938, Generator Loss: 0.3005, Series Loss: 0.0080, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1589/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3003, Series Loss: 0.0079, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [1590/4000], Discriminator Loss: 0.0939, Generator Loss: 0.3006, Series Loss: 0.0079, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [1591/4000], Discriminator Loss: 0.0938, Generator Loss: 0.3005, Series Loss: 0.0080, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1592/4000], Discriminator Loss: 0.0938, Generator Loss: 0.3001, Series Loss: 0.0079, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1593/4000], Discriminator Loss: 0.0937, Generator Loss: 0.3003, Series Loss: 0.0079, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [1594/4000], Discriminator Loss: 0.0941, Generator Loss: 0.3001, Series Loss: 0.0079, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1595/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3007, Series Loss: 0.0080, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1596/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3006, Series Loss: 0.0080, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1597/4000], Discriminator Loss: 0.0939, Generator Loss: 0.3002, Series Loss: 0.0080, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1598/4000], Discriminator Loss: 0.0938, Generator Loss: 0.3003, Series Loss: 0.0081, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [1599/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2999, Series Loss: 0.0078, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [1600/4000], Discriminator Loss: 0.0938, Generator Loss: 0.3003, Series Loss: 0.0080, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [1601/4000], Discriminator Loss: 0.0946, Generator Loss: 0.3002, Series Loss: 0.0080, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1602/4000], Discriminator Loss: 0.0940, Generator Loss: 0.3004, Series Loss: 0.0079, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1603/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3004, Series Loss: 0.0079, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1604/4000], Discriminator Loss: 0.0933, Generator Loss: 0.3001, Series Loss: 0.0079, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1605/4000], Discriminator Loss: 0.0933, Generator Loss: 0.3003, Series Loss: 0.0080, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1606/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3003, Series Loss: 0.0079, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [1607/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3003, Series Loss: 0.0079, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1608/4000], Discriminator Loss: 0.0935, Generator Loss: 0.3005, Series Loss: 0.0080, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [1609/4000], Discriminator Loss: 0.0933, Generator Loss: 0.3007, Series Loss: 0.0080, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1610/4000], Discriminator Loss: 0.0939, Generator Loss: 0.3005, Series Loss: 0.0079, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [1611/4000], Discriminator Loss: 0.0941, Generator Loss: 0.3003, Series Loss: 0.0080, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1612/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3006, Series Loss: 0.0079, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1613/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3004, Series Loss: 0.0080, Class Loss: 0.2438, Accuracy: 0.3148\n",
      "Epoch [1614/4000], Discriminator Loss: 0.0939, Generator Loss: 0.3005, Series Loss: 0.0080, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1615/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3008, Series Loss: 0.0079, Class Loss: 0.2437, Accuracy: 0.3086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1616/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3008, Series Loss: 0.0080, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1617/4000], Discriminator Loss: 0.0938, Generator Loss: 0.3002, Series Loss: 0.0079, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [1618/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3001, Series Loss: 0.0079, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1619/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3006, Series Loss: 0.0080, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1620/4000], Discriminator Loss: 0.0931, Generator Loss: 0.3006, Series Loss: 0.0080, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1621/4000], Discriminator Loss: 0.0933, Generator Loss: 0.3002, Series Loss: 0.0079, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1622/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2999, Series Loss: 0.0080, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1623/4000], Discriminator Loss: 0.0935, Generator Loss: 0.3003, Series Loss: 0.0081, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1624/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3001, Series Loss: 0.0079, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1625/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3003, Series Loss: 0.0080, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [1626/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3004, Series Loss: 0.0079, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1627/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3000, Series Loss: 0.0079, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1628/4000], Discriminator Loss: 0.0933, Generator Loss: 0.3002, Series Loss: 0.0079, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [1629/4000], Discriminator Loss: 0.0935, Generator Loss: 0.3002, Series Loss: 0.0079, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [1630/4000], Discriminator Loss: 0.0931, Generator Loss: 0.3001, Series Loss: 0.0080, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1631/4000], Discriminator Loss: 0.0933, Generator Loss: 0.3001, Series Loss: 0.0079, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [1632/4000], Discriminator Loss: 0.0929, Generator Loss: 0.3001, Series Loss: 0.0080, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1633/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2999, Series Loss: 0.0078, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1634/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2998, Series Loss: 0.0079, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1635/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3001, Series Loss: 0.0079, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1636/4000], Discriminator Loss: 0.0935, Generator Loss: 0.3000, Series Loss: 0.0079, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [1637/4000], Discriminator Loss: 0.0929, Generator Loss: 0.3000, Series Loss: 0.0078, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1638/4000], Discriminator Loss: 0.0927, Generator Loss: 0.2999, Series Loss: 0.0078, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [1639/4000], Discriminator Loss: 0.0933, Generator Loss: 0.3003, Series Loss: 0.0079, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1640/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2998, Series Loss: 0.0079, Class Loss: 0.2436, Accuracy: 0.3210\n",
      "Epoch [1641/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2997, Series Loss: 0.0078, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1642/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2999, Series Loss: 0.0077, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1643/4000], Discriminator Loss: 0.0935, Generator Loss: 0.3002, Series Loss: 0.0078, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1644/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3000, Series Loss: 0.0078, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1645/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2997, Series Loss: 0.0077, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1646/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2992, Series Loss: 0.0077, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [1647/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3001, Series Loss: 0.0078, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [1648/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2997, Series Loss: 0.0078, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1649/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2999, Series Loss: 0.0078, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [1650/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2999, Series Loss: 0.0078, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [1651/4000], Discriminator Loss: 0.0931, Generator Loss: 0.3002, Series Loss: 0.0079, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [1652/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2999, Series Loss: 0.0078, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1653/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3003, Series Loss: 0.0078, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1654/4000], Discriminator Loss: 0.0931, Generator Loss: 0.3006, Series Loss: 0.0078, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [1655/4000], Discriminator Loss: 0.0931, Generator Loss: 0.3006, Series Loss: 0.0078, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1656/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2997, Series Loss: 0.0078, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1657/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2999, Series Loss: 0.0077, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [1658/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3004, Series Loss: 0.0078, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1659/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3000, Series Loss: 0.0077, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [1660/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2998, Series Loss: 0.0078, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1661/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3000, Series Loss: 0.0078, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1662/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3004, Series Loss: 0.0078, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1663/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3003, Series Loss: 0.0078, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1664/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3005, Series Loss: 0.0079, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [1665/4000], Discriminator Loss: 0.0938, Generator Loss: 0.3003, Series Loss: 0.0079, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [1666/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2997, Series Loss: 0.0078, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1667/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3001, Series Loss: 0.0078, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1668/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3000, Series Loss: 0.0076, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [1669/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2999, Series Loss: 0.0077, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1670/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3002, Series Loss: 0.0077, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1671/4000], Discriminator Loss: 0.0933, Generator Loss: 0.3002, Series Loss: 0.0077, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1672/4000], Discriminator Loss: 0.0935, Generator Loss: 0.3003, Series Loss: 0.0077, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1673/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3002, Series Loss: 0.0077, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1674/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3001, Series Loss: 0.0077, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1675/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3004, Series Loss: 0.0077, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [1676/4000], Discriminator Loss: 0.0931, Generator Loss: 0.3002, Series Loss: 0.0077, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1677/4000], Discriminator Loss: 0.0940, Generator Loss: 0.3000, Series Loss: 0.0077, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1678/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3003, Series Loss: 0.0077, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1679/4000], Discriminator Loss: 0.0933, Generator Loss: 0.3003, Series Loss: 0.0078, Class Loss: 0.2437, Accuracy: 0.3086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1680/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3000, Series Loss: 0.0077, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1681/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2998, Series Loss: 0.0078, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1682/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2997, Series Loss: 0.0077, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1683/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2997, Series Loss: 0.0078, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1684/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2996, Series Loss: 0.0077, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1685/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3000, Series Loss: 0.0077, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1686/4000], Discriminator Loss: 0.0937, Generator Loss: 0.3000, Series Loss: 0.0076, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [1687/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3005, Series Loss: 0.0078, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1688/4000], Discriminator Loss: 0.0933, Generator Loss: 0.3004, Series Loss: 0.0077, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [1689/4000], Discriminator Loss: 0.0933, Generator Loss: 0.3000, Series Loss: 0.0078, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [1690/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2999, Series Loss: 0.0077, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [1691/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3002, Series Loss: 0.0078, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [1692/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3007, Series Loss: 0.0078, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1693/4000], Discriminator Loss: 0.0935, Generator Loss: 0.3004, Series Loss: 0.0077, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [1694/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3007, Series Loss: 0.0078, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1695/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3004, Series Loss: 0.0077, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1696/4000], Discriminator Loss: 0.0939, Generator Loss: 0.3000, Series Loss: 0.0077, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1697/4000], Discriminator Loss: 0.0931, Generator Loss: 0.3003, Series Loss: 0.0078, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1698/4000], Discriminator Loss: 0.0931, Generator Loss: 0.3002, Series Loss: 0.0077, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1699/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3003, Series Loss: 0.0078, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1700/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2998, Series Loss: 0.0077, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1701/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2999, Series Loss: 0.0077, Class Loss: 0.2437, Accuracy: 0.3210\n",
      "Epoch [1702/4000], Discriminator Loss: 0.0929, Generator Loss: 0.3004, Series Loss: 0.0077, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [1703/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2998, Series Loss: 0.0077, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [1704/4000], Discriminator Loss: 0.0933, Generator Loss: 0.3000, Series Loss: 0.0077, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [1705/4000], Discriminator Loss: 0.0935, Generator Loss: 0.3000, Series Loss: 0.0077, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1706/4000], Discriminator Loss: 0.0933, Generator Loss: 0.3001, Series Loss: 0.0078, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1707/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2999, Series Loss: 0.0077, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [1708/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3002, Series Loss: 0.0077, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [1709/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3000, Series Loss: 0.0076, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [1710/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2999, Series Loss: 0.0077, Class Loss: 0.2437, Accuracy: 0.2840\n",
      "Epoch [1711/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2998, Series Loss: 0.0076, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1712/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3000, Series Loss: 0.0076, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [1713/4000], Discriminator Loss: 0.0931, Generator Loss: 0.3000, Series Loss: 0.0077, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1714/4000], Discriminator Loss: 0.0929, Generator Loss: 0.3000, Series Loss: 0.0078, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [1715/4000], Discriminator Loss: 0.0933, Generator Loss: 0.3001, Series Loss: 0.0076, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [1716/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2996, Series Loss: 0.0076, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1717/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2999, Series Loss: 0.0077, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1718/4000], Discriminator Loss: 0.0927, Generator Loss: 0.3000, Series Loss: 0.0076, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [1719/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2999, Series Loss: 0.0077, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1720/4000], Discriminator Loss: 0.0933, Generator Loss: 0.3001, Series Loss: 0.0076, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1721/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3002, Series Loss: 0.0076, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [1722/4000], Discriminator Loss: 0.0928, Generator Loss: 0.3001, Series Loss: 0.0076, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [1723/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2996, Series Loss: 0.0076, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1724/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2999, Series Loss: 0.0077, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1725/4000], Discriminator Loss: 0.0925, Generator Loss: 0.2999, Series Loss: 0.0076, Class Loss: 0.2438, Accuracy: 0.2901\n",
      "Epoch [1726/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3003, Series Loss: 0.0077, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1727/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3002, Series Loss: 0.0076, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1728/4000], Discriminator Loss: 0.0928, Generator Loss: 0.3002, Series Loss: 0.0076, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1729/4000], Discriminator Loss: 0.0936, Generator Loss: 0.3001, Series Loss: 0.0077, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [1730/4000], Discriminator Loss: 0.0929, Generator Loss: 0.3002, Series Loss: 0.0077, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [1731/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3004, Series Loss: 0.0077, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [1732/4000], Discriminator Loss: 0.0935, Generator Loss: 0.3001, Series Loss: 0.0077, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [1733/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2999, Series Loss: 0.0077, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1734/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2998, Series Loss: 0.0077, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1735/4000], Discriminator Loss: 0.0926, Generator Loss: 0.3003, Series Loss: 0.0077, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1736/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2998, Series Loss: 0.0076, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1737/4000], Discriminator Loss: 0.0927, Generator Loss: 0.3003, Series Loss: 0.0077, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1738/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2999, Series Loss: 0.0077, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [1739/4000], Discriminator Loss: 0.0931, Generator Loss: 0.3000, Series Loss: 0.0076, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1740/4000], Discriminator Loss: 0.0928, Generator Loss: 0.3004, Series Loss: 0.0076, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [1741/4000], Discriminator Loss: 0.0927, Generator Loss: 0.3003, Series Loss: 0.0076, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [1742/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3002, Series Loss: 0.0076, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1743/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3001, Series Loss: 0.0076, Class Loss: 0.2436, Accuracy: 0.3025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1744/4000], Discriminator Loss: 0.0929, Generator Loss: 0.3005, Series Loss: 0.0076, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1745/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2997, Series Loss: 0.0076, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1746/4000], Discriminator Loss: 0.0926, Generator Loss: 0.3002, Series Loss: 0.0077, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [1747/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3001, Series Loss: 0.0077, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1748/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2999, Series Loss: 0.0077, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1749/4000], Discriminator Loss: 0.0928, Generator Loss: 0.3002, Series Loss: 0.0077, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1750/4000], Discriminator Loss: 0.0927, Generator Loss: 0.3000, Series Loss: 0.0076, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [1751/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2998, Series Loss: 0.0077, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1752/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2995, Series Loss: 0.0075, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1753/4000], Discriminator Loss: 0.0927, Generator Loss: 0.2996, Series Loss: 0.0075, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [1754/4000], Discriminator Loss: 0.0927, Generator Loss: 0.3000, Series Loss: 0.0076, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [1755/4000], Discriminator Loss: 0.0927, Generator Loss: 0.2995, Series Loss: 0.0075, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1756/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2996, Series Loss: 0.0076, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [1757/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2999, Series Loss: 0.0075, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1758/4000], Discriminator Loss: 0.0924, Generator Loss: 0.3000, Series Loss: 0.0076, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1759/4000], Discriminator Loss: 0.0927, Generator Loss: 0.3003, Series Loss: 0.0076, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1760/4000], Discriminator Loss: 0.0929, Generator Loss: 0.3003, Series Loss: 0.0077, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1761/4000], Discriminator Loss: 0.0926, Generator Loss: 0.3000, Series Loss: 0.0076, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [1762/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2997, Series Loss: 0.0075, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1763/4000], Discriminator Loss: 0.0929, Generator Loss: 0.3001, Series Loss: 0.0077, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [1764/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2999, Series Loss: 0.0076, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1765/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2999, Series Loss: 0.0076, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [1766/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2998, Series Loss: 0.0077, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [1767/4000], Discriminator Loss: 0.0926, Generator Loss: 0.2995, Series Loss: 0.0076, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [1768/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2999, Series Loss: 0.0076, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [1769/4000], Discriminator Loss: 0.0929, Generator Loss: 0.3000, Series Loss: 0.0076, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1770/4000], Discriminator Loss: 0.0925, Generator Loss: 0.2999, Series Loss: 0.0076, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1771/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3002, Series Loss: 0.0076, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1772/4000], Discriminator Loss: 0.0929, Generator Loss: 0.3000, Series Loss: 0.0077, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [1773/4000], Discriminator Loss: 0.0926, Generator Loss: 0.3001, Series Loss: 0.0076, Class Loss: 0.2435, Accuracy: 0.3148\n",
      "Epoch [1774/4000], Discriminator Loss: 0.0928, Generator Loss: 0.3001, Series Loss: 0.0076, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [1775/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3001, Series Loss: 0.0077, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1776/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2999, Series Loss: 0.0076, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [1777/4000], Discriminator Loss: 0.0926, Generator Loss: 0.3003, Series Loss: 0.0076, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [1778/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3000, Series Loss: 0.0075, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [1779/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2997, Series Loss: 0.0075, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1780/4000], Discriminator Loss: 0.0925, Generator Loss: 0.2998, Series Loss: 0.0077, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1781/4000], Discriminator Loss: 0.0926, Generator Loss: 0.2996, Series Loss: 0.0076, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1782/4000], Discriminator Loss: 0.0929, Generator Loss: 0.3000, Series Loss: 0.0076, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [1783/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2997, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1784/4000], Discriminator Loss: 0.0931, Generator Loss: 0.3000, Series Loss: 0.0075, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1785/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3001, Series Loss: 0.0076, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [1786/4000], Discriminator Loss: 0.0926, Generator Loss: 0.3005, Series Loss: 0.0076, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1787/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3003, Series Loss: 0.0076, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [1788/4000], Discriminator Loss: 0.0927, Generator Loss: 0.3001, Series Loss: 0.0076, Class Loss: 0.2435, Accuracy: 0.3148\n",
      "Epoch [1789/4000], Discriminator Loss: 0.0928, Generator Loss: 0.3000, Series Loss: 0.0076, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [1790/4000], Discriminator Loss: 0.0928, Generator Loss: 0.3002, Series Loss: 0.0076, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [1791/4000], Discriminator Loss: 0.0928, Generator Loss: 0.3001, Series Loss: 0.0076, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1792/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3001, Series Loss: 0.0075, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [1793/4000], Discriminator Loss: 0.0929, Generator Loss: 0.3006, Series Loss: 0.0077, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1794/4000], Discriminator Loss: 0.0927, Generator Loss: 0.2997, Series Loss: 0.0075, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [1795/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2997, Series Loss: 0.0075, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [1796/4000], Discriminator Loss: 0.0924, Generator Loss: 0.2998, Series Loss: 0.0075, Class Loss: 0.2434, Accuracy: 0.3025\n",
      "Epoch [1797/4000], Discriminator Loss: 0.0929, Generator Loss: 0.3000, Series Loss: 0.0076, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1798/4000], Discriminator Loss: 0.0925, Generator Loss: 0.2998, Series Loss: 0.0075, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1799/4000], Discriminator Loss: 0.0926, Generator Loss: 0.2998, Series Loss: 0.0075, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [1800/4000], Discriminator Loss: 0.0927, Generator Loss: 0.2996, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [1801/4000], Discriminator Loss: 0.0928, Generator Loss: 0.3002, Series Loss: 0.0075, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [1802/4000], Discriminator Loss: 0.0925, Generator Loss: 0.2999, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1803/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2996, Series Loss: 0.0075, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [1804/4000], Discriminator Loss: 0.0928, Generator Loss: 0.3002, Series Loss: 0.0075, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [1805/4000], Discriminator Loss: 0.0926, Generator Loss: 0.2999, Series Loss: 0.0075, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [1806/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2999, Series Loss: 0.0075, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [1807/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3000, Series Loss: 0.0075, Class Loss: 0.2435, Accuracy: 0.3086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1808/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2999, Series Loss: 0.0075, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [1809/4000], Discriminator Loss: 0.0925, Generator Loss: 0.2999, Series Loss: 0.0076, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [1810/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2999, Series Loss: 0.0075, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1811/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2997, Series Loss: 0.0076, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1812/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2996, Series Loss: 0.0075, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [1813/4000], Discriminator Loss: 0.0928, Generator Loss: 0.3000, Series Loss: 0.0076, Class Loss: 0.2434, Accuracy: 0.2963\n",
      "Epoch [1814/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2996, Series Loss: 0.0075, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [1815/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2997, Series Loss: 0.0075, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1816/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2996, Series Loss: 0.0075, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [1817/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2994, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [1818/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2994, Series Loss: 0.0076, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [1819/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2995, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.3272\n",
      "Epoch [1820/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2998, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1821/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2998, Series Loss: 0.0075, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1822/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2994, Series Loss: 0.0075, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [1823/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2996, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [1824/4000], Discriminator Loss: 0.0929, Generator Loss: 0.3000, Series Loss: 0.0076, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1825/4000], Discriminator Loss: 0.0929, Generator Loss: 0.3000, Series Loss: 0.0075, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1826/4000], Discriminator Loss: 0.0927, Generator Loss: 0.2999, Series Loss: 0.0075, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [1827/4000], Discriminator Loss: 0.0927, Generator Loss: 0.3005, Series Loss: 0.0075, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1828/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2999, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [1829/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2996, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [1830/4000], Discriminator Loss: 0.0923, Generator Loss: 0.3001, Series Loss: 0.0075, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [1831/4000], Discriminator Loss: 0.0934, Generator Loss: 0.3003, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [1832/4000], Discriminator Loss: 0.0927, Generator Loss: 0.3001, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [1833/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2994, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.3148\n",
      "Epoch [1834/4000], Discriminator Loss: 0.0924, Generator Loss: 0.3001, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1835/4000], Discriminator Loss: 0.0926, Generator Loss: 0.3002, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [1836/4000], Discriminator Loss: 0.0926, Generator Loss: 0.3003, Series Loss: 0.0075, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1837/4000], Discriminator Loss: 0.0927, Generator Loss: 0.2999, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1838/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3001, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [1839/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3000, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [1840/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2998, Series Loss: 0.0073, Class Loss: 0.2435, Accuracy: 0.3148\n",
      "Epoch [1841/4000], Discriminator Loss: 0.0929, Generator Loss: 0.3006, Series Loss: 0.0075, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [1842/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3001, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1843/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2999, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1844/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2994, Series Loss: 0.0075, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [1845/4000], Discriminator Loss: 0.0927, Generator Loss: 0.3001, Series Loss: 0.0075, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1846/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2995, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.3148\n",
      "Epoch [1847/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2997, Series Loss: 0.0075, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [1848/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2996, Series Loss: 0.0076, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [1849/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3003, Series Loss: 0.0075, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1850/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2999, Series Loss: 0.0073, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1851/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2996, Series Loss: 0.0075, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1852/4000], Discriminator Loss: 0.0926, Generator Loss: 0.2999, Series Loss: 0.0075, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1853/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2997, Series Loss: 0.0075, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [1854/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2997, Series Loss: 0.0075, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [1855/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2997, Series Loss: 0.0075, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1856/4000], Discriminator Loss: 0.0928, Generator Loss: 0.3001, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1857/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3004, Series Loss: 0.0075, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [1858/4000], Discriminator Loss: 0.0929, Generator Loss: 0.3002, Series Loss: 0.0076, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1859/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2998, Series Loss: 0.0075, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1860/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2999, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [1861/4000], Discriminator Loss: 0.0926, Generator Loss: 0.3002, Series Loss: 0.0075, Class Loss: 0.2437, Accuracy: 0.2840\n",
      "Epoch [1862/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2998, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [1863/4000], Discriminator Loss: 0.0927, Generator Loss: 0.2999, Series Loss: 0.0075, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [1864/4000], Discriminator Loss: 0.0927, Generator Loss: 0.3000, Series Loss: 0.0075, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [1865/4000], Discriminator Loss: 0.0924, Generator Loss: 0.3000, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1866/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2998, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1867/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2994, Series Loss: 0.0075, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [1868/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2996, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [1869/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2994, Series Loss: 0.0075, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1870/4000], Discriminator Loss: 0.0926, Generator Loss: 0.2998, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1871/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2998, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.2963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1872/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2998, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [1873/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2996, Series Loss: 0.0075, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1874/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2995, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [1875/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2998, Series Loss: 0.0075, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [1876/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3000, Series Loss: 0.0075, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [1877/4000], Discriminator Loss: 0.0932, Generator Loss: 0.3004, Series Loss: 0.0075, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [1878/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2997, Series Loss: 0.0073, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [1879/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2997, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [1880/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2995, Series Loss: 0.0074, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1881/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2995, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1882/4000], Discriminator Loss: 0.0929, Generator Loss: 0.3000, Series Loss: 0.0075, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [1883/4000], Discriminator Loss: 0.0927, Generator Loss: 0.3002, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1884/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2997, Series Loss: 0.0075, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [1885/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2998, Series Loss: 0.0075, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [1886/4000], Discriminator Loss: 0.0927, Generator Loss: 0.2996, Series Loss: 0.0075, Class Loss: 0.2434, Accuracy: 0.3025\n",
      "Epoch [1887/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2996, Series Loss: 0.0075, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [1888/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2995, Series Loss: 0.0075, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [1889/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2996, Series Loss: 0.0075, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1890/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2995, Series Loss: 0.0074, Class Loss: 0.2434, Accuracy: 0.3025\n",
      "Epoch [1891/4000], Discriminator Loss: 0.0927, Generator Loss: 0.2998, Series Loss: 0.0075, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [1892/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2998, Series Loss: 0.0075, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [1893/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2999, Series Loss: 0.0075, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1894/4000], Discriminator Loss: 0.0926, Generator Loss: 0.2998, Series Loss: 0.0075, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1895/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2999, Series Loss: 0.0075, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [1896/4000], Discriminator Loss: 0.0926, Generator Loss: 0.2995, Series Loss: 0.0075, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [1897/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2993, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [1898/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2993, Series Loss: 0.0075, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1899/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2992, Series Loss: 0.0074, Class Loss: 0.2434, Accuracy: 0.3148\n",
      "Epoch [1900/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2999, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [1901/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2999, Series Loss: 0.0074, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1902/4000], Discriminator Loss: 0.0929, Generator Loss: 0.3002, Series Loss: 0.0074, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [1903/4000], Discriminator Loss: 0.0933, Generator Loss: 0.3000, Series Loss: 0.0075, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [1904/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2996, Series Loss: 0.0074, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [1905/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2994, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1906/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2993, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [1907/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2994, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1908/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2996, Series Loss: 0.0075, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1909/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2994, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [1910/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2997, Series Loss: 0.0076, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1911/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2996, Series Loss: 0.0075, Class Loss: 0.2435, Accuracy: 0.3148\n",
      "Epoch [1912/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2994, Series Loss: 0.0075, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1913/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2993, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [1914/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2993, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [1915/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2992, Series Loss: 0.0075, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [1916/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2996, Series Loss: 0.0075, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [1917/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2996, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1918/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2994, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [1919/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2995, Series Loss: 0.0075, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [1920/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2997, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [1921/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2998, Series Loss: 0.0075, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1922/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2994, Series Loss: 0.0075, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [1923/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2993, Series Loss: 0.0075, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [1924/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2995, Series Loss: 0.0075, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1925/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2996, Series Loss: 0.0075, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1926/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2991, Series Loss: 0.0075, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1927/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2991, Series Loss: 0.0075, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [1928/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2994, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1929/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2991, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [1930/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2993, Series Loss: 0.0074, Class Loss: 0.2434, Accuracy: 0.3148\n",
      "Epoch [1931/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2996, Series Loss: 0.0075, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1932/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2992, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [1933/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2995, Series Loss: 0.0075, Class Loss: 0.2434, Accuracy: 0.3148\n",
      "Epoch [1934/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2994, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1935/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2992, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.2963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1936/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2995, Series Loss: 0.0073, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [1937/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2995, Series Loss: 0.0075, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1938/4000], Discriminator Loss: 0.0925, Generator Loss: 0.2996, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [1939/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2997, Series Loss: 0.0074, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1940/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2993, Series Loss: 0.0073, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1941/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2991, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [1942/4000], Discriminator Loss: 0.0933, Generator Loss: 0.3000, Series Loss: 0.0075, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [1943/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2994, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [1944/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2996, Series Loss: 0.0073, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [1945/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2996, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [1946/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2995, Series Loss: 0.0073, Class Loss: 0.2435, Accuracy: 0.3148\n",
      "Epoch [1947/4000], Discriminator Loss: 0.0926, Generator Loss: 0.2997, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [1948/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2994, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [1949/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2995, Series Loss: 0.0075, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [1950/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2995, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [1951/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2999, Series Loss: 0.0075, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [1952/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2997, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [1953/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2998, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [1954/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2993, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1955/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2993, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [1956/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2994, Series Loss: 0.0075, Class Loss: 0.2434, Accuracy: 0.3086\n",
      "Epoch [1957/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2996, Series Loss: 0.0075, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [1958/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2996, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [1959/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2997, Series Loss: 0.0075, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1960/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2995, Series Loss: 0.0075, Class Loss: 0.2434, Accuracy: 0.3148\n",
      "Epoch [1961/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2993, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.3148\n",
      "Epoch [1962/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2987, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [1963/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2989, Series Loss: 0.0074, Class Loss: 0.2434, Accuracy: 0.3086\n",
      "Epoch [1964/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2996, Series Loss: 0.0075, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [1965/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2994, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [1966/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2994, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.3148\n",
      "Epoch [1967/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2993, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [1968/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2995, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1969/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2994, Series Loss: 0.0075, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [1970/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2992, Series Loss: 0.0075, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [1971/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2990, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1972/4000], Discriminator Loss: 0.0927, Generator Loss: 0.2996, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [1973/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2990, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [1974/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2993, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [1975/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2995, Series Loss: 0.0075, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1976/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2997, Series Loss: 0.0073, Class Loss: 0.2435, Accuracy: 0.2840\n",
      "Epoch [1977/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2995, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1978/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2992, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1979/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2996, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [1980/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2998, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [1981/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2994, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [1982/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2992, Series Loss: 0.0073, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1983/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2998, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [1984/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2997, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [1985/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2997, Series Loss: 0.0073, Class Loss: 0.2434, Accuracy: 0.2840\n",
      "Epoch [1986/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2998, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [1987/4000], Discriminator Loss: 0.0927, Generator Loss: 0.3000, Series Loss: 0.0075, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1988/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2991, Series Loss: 0.0075, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [1989/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2990, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [1990/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2992, Series Loss: 0.0075, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [1991/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2993, Series Loss: 0.0075, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [1992/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2994, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [1993/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2992, Series Loss: 0.0075, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [1994/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2993, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [1995/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2991, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [1996/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2995, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [1997/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2997, Series Loss: 0.0074, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [1998/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2998, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [1999/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2992, Series Loss: 0.0074, Class Loss: 0.2437, Accuracy: 0.3025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2000/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2990, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2001/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2996, Series Loss: 0.0075, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2002/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2994, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.3148\n",
      "Epoch [2003/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2994, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [2004/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2998, Series Loss: 0.0074, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [2005/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2994, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2006/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2999, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2007/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2996, Series Loss: 0.0073, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2008/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2995, Series Loss: 0.0073, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2009/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2995, Series Loss: 0.0073, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2010/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2991, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2011/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2991, Series Loss: 0.0073, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2012/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2995, Series Loss: 0.0074, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2013/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2988, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [2014/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2995, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2015/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2992, Series Loss: 0.0073, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2016/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2997, Series Loss: 0.0074, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [2017/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2993, Series Loss: 0.0074, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2018/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2993, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2019/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2993, Series Loss: 0.0073, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2020/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2997, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2021/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2994, Series Loss: 0.0073, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2022/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2995, Series Loss: 0.0073, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [2023/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2993, Series Loss: 0.0073, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2024/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2993, Series Loss: 0.0073, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2025/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2994, Series Loss: 0.0073, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2026/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2998, Series Loss: 0.0073, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2027/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2999, Series Loss: 0.0073, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2028/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2997, Series Loss: 0.0073, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2029/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2994, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [2030/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2994, Series Loss: 0.0073, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2031/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2994, Series Loss: 0.0073, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2032/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2998, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2033/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2993, Series Loss: 0.0072, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2034/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2989, Series Loss: 0.0073, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2035/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2992, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2036/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2987, Series Loss: 0.0073, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2037/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2990, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2038/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2989, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [2039/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2989, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2040/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2995, Series Loss: 0.0073, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2041/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2992, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2042/4000], Discriminator Loss: 0.0929, Generator Loss: 0.3000, Series Loss: 0.0074, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2043/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2993, Series Loss: 0.0073, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2044/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2993, Series Loss: 0.0073, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [2045/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2988, Series Loss: 0.0072, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2046/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2992, Series Loss: 0.0073, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2047/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2995, Series Loss: 0.0073, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2048/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2997, Series Loss: 0.0074, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2049/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2995, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2050/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2995, Series Loss: 0.0073, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2051/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2995, Series Loss: 0.0073, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2052/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2997, Series Loss: 0.0073, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2053/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2994, Series Loss: 0.0075, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2054/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2993, Series Loss: 0.0073, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2055/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2997, Series Loss: 0.0073, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2056/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2998, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2057/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2994, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2058/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2996, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2059/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2996, Series Loss: 0.0073, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2060/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2995, Series Loss: 0.0073, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2061/4000], Discriminator Loss: 0.0927, Generator Loss: 0.2998, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2062/4000], Discriminator Loss: 0.0925, Generator Loss: 0.2996, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2063/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2993, Series Loss: 0.0073, Class Loss: 0.2437, Accuracy: 0.3025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2064/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2994, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2065/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2995, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2066/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2993, Series Loss: 0.0072, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2067/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2995, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2068/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2992, Series Loss: 0.0073, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2069/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2993, Series Loss: 0.0073, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [2070/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2994, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2071/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2993, Series Loss: 0.0073, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2072/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2995, Series Loss: 0.0073, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2073/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2994, Series Loss: 0.0073, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2074/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2991, Series Loss: 0.0073, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2075/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2990, Series Loss: 0.0073, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2076/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2992, Series Loss: 0.0073, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2077/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2992, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2078/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2993, Series Loss: 0.0073, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [2079/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2992, Series Loss: 0.0073, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2080/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2994, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [2081/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2994, Series Loss: 0.0074, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2082/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2994, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [2083/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2989, Series Loss: 0.0073, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2084/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2989, Series Loss: 0.0072, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2085/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2992, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2086/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2993, Series Loss: 0.0073, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2087/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2994, Series Loss: 0.0073, Class Loss: 0.2435, Accuracy: 0.3148\n",
      "Epoch [2088/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2995, Series Loss: 0.0073, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2089/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2993, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2090/4000], Discriminator Loss: 0.0927, Generator Loss: 0.2995, Series Loss: 0.0073, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [2091/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2995, Series Loss: 0.0073, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2092/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2995, Series Loss: 0.0073, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2093/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2993, Series Loss: 0.0073, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2094/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2994, Series Loss: 0.0073, Class Loss: 0.2434, Accuracy: 0.3025\n",
      "Epoch [2095/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3003, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2096/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2996, Series Loss: 0.0074, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2097/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2994, Series Loss: 0.0073, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2098/4000], Discriminator Loss: 0.0929, Generator Loss: 0.3000, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2099/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2993, Series Loss: 0.0074, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [2100/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2993, Series Loss: 0.0073, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2101/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2991, Series Loss: 0.0074, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [2102/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2994, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2103/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2990, Series Loss: 0.0074, Class Loss: 0.2434, Accuracy: 0.3086\n",
      "Epoch [2104/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2995, Series Loss: 0.0072, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [2105/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2990, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [2106/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2996, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2107/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2997, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2108/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2991, Series Loss: 0.0073, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2109/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2992, Series Loss: 0.0072, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2110/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2999, Series Loss: 0.0073, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2111/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2994, Series Loss: 0.0073, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2112/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2987, Series Loss: 0.0072, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2113/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2994, Series Loss: 0.0073, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2114/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2994, Series Loss: 0.0073, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2115/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2993, Series Loss: 0.0073, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2116/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2990, Series Loss: 0.0072, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2117/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2991, Series Loss: 0.0072, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [2118/4000], Discriminator Loss: 0.0927, Generator Loss: 0.2995, Series Loss: 0.0073, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [2119/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2997, Series Loss: 0.0073, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [2120/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2996, Series Loss: 0.0073, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [2121/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2992, Series Loss: 0.0073, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2122/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2996, Series Loss: 0.0073, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [2123/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2993, Series Loss: 0.0073, Class Loss: 0.2437, Accuracy: 0.2840\n",
      "Epoch [2124/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2993, Series Loss: 0.0074, Class Loss: 0.2434, Accuracy: 0.3025\n",
      "Epoch [2125/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2990, Series Loss: 0.0073, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2126/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2991, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2127/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2992, Series Loss: 0.0072, Class Loss: 0.2436, Accuracy: 0.2963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2128/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2996, Series Loss: 0.0073, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2129/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2994, Series Loss: 0.0074, Class Loss: 0.2438, Accuracy: 0.2901\n",
      "Epoch [2130/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2996, Series Loss: 0.0074, Class Loss: 0.2438, Accuracy: 0.2963\n",
      "Epoch [2131/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2990, Series Loss: 0.0073, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2132/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2991, Series Loss: 0.0074, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2133/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2989, Series Loss: 0.0073, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [2134/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2991, Series Loss: 0.0073, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2135/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2993, Series Loss: 0.0074, Class Loss: 0.2438, Accuracy: 0.2901\n",
      "Epoch [2136/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2992, Series Loss: 0.0073, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2137/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2994, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2138/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2994, Series Loss: 0.0073, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [2139/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2994, Series Loss: 0.0073, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2140/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2994, Series Loss: 0.0074, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [2141/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2989, Series Loss: 0.0073, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [2142/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2988, Series Loss: 0.0072, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2143/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2987, Series Loss: 0.0073, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2144/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2993, Series Loss: 0.0073, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [2145/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2994, Series Loss: 0.0072, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [2146/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2990, Series Loss: 0.0072, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [2147/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2998, Series Loss: 0.0074, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2148/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2999, Series Loss: 0.0072, Class Loss: 0.2438, Accuracy: 0.2901\n",
      "Epoch [2149/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2993, Series Loss: 0.0072, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2150/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2992, Series Loss: 0.0073, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [2151/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2994, Series Loss: 0.0073, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [2152/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2988, Series Loss: 0.0072, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2153/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2990, Series Loss: 0.0073, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [2154/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2990, Series Loss: 0.0073, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [2155/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2990, Series Loss: 0.0072, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [2156/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2990, Series Loss: 0.0072, Class Loss: 0.2438, Accuracy: 0.2840\n",
      "Epoch [2157/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2993, Series Loss: 0.0073, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2158/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2992, Series Loss: 0.0073, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2159/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2987, Series Loss: 0.0072, Class Loss: 0.2438, Accuracy: 0.2963\n",
      "Epoch [2160/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2988, Series Loss: 0.0071, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [2161/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2987, Series Loss: 0.0071, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2162/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2989, Series Loss: 0.0072, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2163/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2988, Series Loss: 0.0072, Class Loss: 0.2438, Accuracy: 0.2963\n",
      "Epoch [2164/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2986, Series Loss: 0.0071, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [2165/4000], Discriminator Loss: 0.0946, Generator Loss: 0.2986, Series Loss: 0.0072, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2166/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2988, Series Loss: 0.0072, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2167/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2985, Series Loss: 0.0072, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2168/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2987, Series Loss: 0.0073, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2169/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2985, Series Loss: 0.0071, Class Loss: 0.2437, Accuracy: 0.2840\n",
      "Epoch [2170/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2990, Series Loss: 0.0072, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2171/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2988, Series Loss: 0.0071, Class Loss: 0.2438, Accuracy: 0.2901\n",
      "Epoch [2172/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2992, Series Loss: 0.0071, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [2173/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2991, Series Loss: 0.0072, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2174/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2989, Series Loss: 0.0073, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2175/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2990, Series Loss: 0.0073, Class Loss: 0.2438, Accuracy: 0.2963\n",
      "Epoch [2176/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2989, Series Loss: 0.0071, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [2177/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2990, Series Loss: 0.0073, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2178/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2992, Series Loss: 0.0072, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2179/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2991, Series Loss: 0.0072, Class Loss: 0.2438, Accuracy: 0.2963\n",
      "Epoch [2180/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2989, Series Loss: 0.0072, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2181/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2992, Series Loss: 0.0072, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2182/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2994, Series Loss: 0.0071, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2183/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2993, Series Loss: 0.0072, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2184/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2989, Series Loss: 0.0071, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2185/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2990, Series Loss: 0.0073, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [2186/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2992, Series Loss: 0.0071, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2187/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2992, Series Loss: 0.0072, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2188/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2987, Series Loss: 0.0072, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2189/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2988, Series Loss: 0.0072, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [2190/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2988, Series Loss: 0.0072, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [2191/4000], Discriminator Loss: 0.0945, Generator Loss: 0.2986, Series Loss: 0.0073, Class Loss: 0.2436, Accuracy: 0.2963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2192/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2989, Series Loss: 0.0072, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2193/4000], Discriminator Loss: 0.0944, Generator Loss: 0.2991, Series Loss: 0.0072, Class Loss: 0.2438, Accuracy: 0.2963\n",
      "Epoch [2194/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2990, Series Loss: 0.0072, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2195/4000], Discriminator Loss: 0.0944, Generator Loss: 0.2991, Series Loss: 0.0073, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [2196/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2988, Series Loss: 0.0071, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2197/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2990, Series Loss: 0.0072, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2198/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2993, Series Loss: 0.0072, Class Loss: 0.2438, Accuracy: 0.2963\n",
      "Epoch [2199/4000], Discriminator Loss: 0.0946, Generator Loss: 0.2985, Series Loss: 0.0071, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2200/4000], Discriminator Loss: 0.0945, Generator Loss: 0.2986, Series Loss: 0.0072, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [2201/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2986, Series Loss: 0.0072, Class Loss: 0.2438, Accuracy: 0.2901\n",
      "Epoch [2202/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2984, Series Loss: 0.0071, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [2203/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2987, Series Loss: 0.0072, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2204/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2987, Series Loss: 0.0072, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2205/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2990, Series Loss: 0.0071, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2206/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2988, Series Loss: 0.0071, Class Loss: 0.2438, Accuracy: 0.2901\n",
      "Epoch [2207/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2989, Series Loss: 0.0072, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2208/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2986, Series Loss: 0.0072, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2209/4000], Discriminator Loss: 0.0944, Generator Loss: 0.2986, Series Loss: 0.0072, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [2210/4000], Discriminator Loss: 0.0946, Generator Loss: 0.2990, Series Loss: 0.0072, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2211/4000], Discriminator Loss: 0.0945, Generator Loss: 0.2983, Series Loss: 0.0071, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [2212/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2990, Series Loss: 0.0071, Class Loss: 0.2439, Accuracy: 0.2901\n",
      "Epoch [2213/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2987, Series Loss: 0.0072, Class Loss: 0.2438, Accuracy: 0.2963\n",
      "Epoch [2214/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2990, Series Loss: 0.0072, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [2215/4000], Discriminator Loss: 0.0946, Generator Loss: 0.2982, Series Loss: 0.0071, Class Loss: 0.2438, Accuracy: 0.2963\n",
      "Epoch [2216/4000], Discriminator Loss: 0.0944, Generator Loss: 0.2982, Series Loss: 0.0072, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2217/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2985, Series Loss: 0.0072, Class Loss: 0.2438, Accuracy: 0.2963\n",
      "Epoch [2218/4000], Discriminator Loss: 0.0944, Generator Loss: 0.2983, Series Loss: 0.0070, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2219/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2984, Series Loss: 0.0070, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [2220/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2987, Series Loss: 0.0071, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2221/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2991, Series Loss: 0.0070, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [2222/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2989, Series Loss: 0.0070, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [2223/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2991, Series Loss: 0.0071, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2224/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2992, Series Loss: 0.0071, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [2225/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2993, Series Loss: 0.0070, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2226/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2993, Series Loss: 0.0071, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [2227/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2994, Series Loss: 0.0071, Class Loss: 0.2437, Accuracy: 0.3210\n",
      "Epoch [2228/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2990, Series Loss: 0.0070, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2229/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2992, Series Loss: 0.0071, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2230/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2989, Series Loss: 0.0071, Class Loss: 0.2438, Accuracy: 0.2901\n",
      "Epoch [2231/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2982, Series Loss: 0.0070, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2232/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2984, Series Loss: 0.0071, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2233/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2985, Series Loss: 0.0070, Class Loss: 0.2438, Accuracy: 0.2963\n",
      "Epoch [2234/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2988, Series Loss: 0.0070, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [2235/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2986, Series Loss: 0.0070, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [2236/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2990, Series Loss: 0.0071, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2237/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2991, Series Loss: 0.0071, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2238/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2990, Series Loss: 0.0071, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2239/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2993, Series Loss: 0.0070, Class Loss: 0.2438, Accuracy: 0.2963\n",
      "Epoch [2240/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2992, Series Loss: 0.0069, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2241/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2992, Series Loss: 0.0069, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2242/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2992, Series Loss: 0.0071, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2243/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2987, Series Loss: 0.0070, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2244/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2988, Series Loss: 0.0070, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [2245/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2989, Series Loss: 0.0070, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2246/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2984, Series Loss: 0.0072, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2247/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2986, Series Loss: 0.0071, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2248/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2983, Series Loss: 0.0070, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2249/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2986, Series Loss: 0.0070, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2250/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2988, Series Loss: 0.0070, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2251/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2987, Series Loss: 0.0070, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [2252/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2985, Series Loss: 0.0071, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [2253/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2987, Series Loss: 0.0070, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [2254/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2986, Series Loss: 0.0070, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2255/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2988, Series Loss: 0.0071, Class Loss: 0.2436, Accuracy: 0.2963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2256/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2987, Series Loss: 0.0070, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2257/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2990, Series Loss: 0.0070, Class Loss: 0.2437, Accuracy: 0.2840\n",
      "Epoch [2258/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2993, Series Loss: 0.0070, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [2259/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2988, Series Loss: 0.0070, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2260/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2989, Series Loss: 0.0071, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2261/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2983, Series Loss: 0.0070, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2262/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2988, Series Loss: 0.0070, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [2263/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2987, Series Loss: 0.0070, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2264/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2988, Series Loss: 0.0069, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [2265/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2993, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [2266/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2994, Series Loss: 0.0071, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2267/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2992, Series Loss: 0.0069, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2268/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2992, Series Loss: 0.0069, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [2269/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2991, Series Loss: 0.0070, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2270/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2996, Series Loss: 0.0070, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [2271/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2989, Series Loss: 0.0070, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [2272/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2991, Series Loss: 0.0071, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2273/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2990, Series Loss: 0.0070, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2274/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2990, Series Loss: 0.0070, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2275/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2990, Series Loss: 0.0070, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [2276/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2987, Series Loss: 0.0071, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2277/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2990, Series Loss: 0.0071, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2278/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2991, Series Loss: 0.0071, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2279/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2989, Series Loss: 0.0070, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [2280/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2989, Series Loss: 0.0070, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [2281/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2997, Series Loss: 0.0070, Class Loss: 0.2438, Accuracy: 0.2840\n",
      "Epoch [2282/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2990, Series Loss: 0.0069, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2283/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2994, Series Loss: 0.0071, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2284/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2992, Series Loss: 0.0070, Class Loss: 0.2438, Accuracy: 0.2901\n",
      "Epoch [2285/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2990, Series Loss: 0.0070, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2286/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2989, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2287/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2995, Series Loss: 0.0070, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2288/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2987, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2289/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2988, Series Loss: 0.0069, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2290/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2989, Series Loss: 0.0070, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2291/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2997, Series Loss: 0.0071, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2292/4000], Discriminator Loss: 0.0930, Generator Loss: 0.3000, Series Loss: 0.0070, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2293/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2993, Series Loss: 0.0070, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2294/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2990, Series Loss: 0.0070, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2295/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2987, Series Loss: 0.0070, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2296/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2991, Series Loss: 0.0070, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [2297/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2990, Series Loss: 0.0070, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2298/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2990, Series Loss: 0.0070, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2299/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2987, Series Loss: 0.0070, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2300/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2985, Series Loss: 0.0070, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2301/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2985, Series Loss: 0.0070, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2302/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2985, Series Loss: 0.0069, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2303/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2986, Series Loss: 0.0070, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [2304/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2988, Series Loss: 0.0070, Class Loss: 0.2439, Accuracy: 0.2901\n",
      "Epoch [2305/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2986, Series Loss: 0.0070, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2306/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2986, Series Loss: 0.0070, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2307/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2987, Series Loss: 0.0070, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2308/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2989, Series Loss: 0.0070, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2309/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2984, Series Loss: 0.0070, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2310/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2983, Series Loss: 0.0070, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2311/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2979, Series Loss: 0.0071, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [2312/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2986, Series Loss: 0.0070, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [2313/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2989, Series Loss: 0.0070, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2314/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2989, Series Loss: 0.0069, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [2315/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2986, Series Loss: 0.0070, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [2316/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2986, Series Loss: 0.0070, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2317/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2987, Series Loss: 0.0070, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [2318/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2985, Series Loss: 0.0070, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [2319/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2985, Series Loss: 0.0070, Class Loss: 0.2437, Accuracy: 0.2901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2320/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2986, Series Loss: 0.0070, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2321/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2986, Series Loss: 0.0071, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2322/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2988, Series Loss: 0.0070, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [2323/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2985, Series Loss: 0.0069, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2324/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2982, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2325/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2987, Series Loss: 0.0070, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2326/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2983, Series Loss: 0.0071, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2327/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2988, Series Loss: 0.0070, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [2328/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2981, Series Loss: 0.0069, Class Loss: 0.2435, Accuracy: 0.3148\n",
      "Epoch [2329/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2985, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2330/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2988, Series Loss: 0.0070, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2331/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2984, Series Loss: 0.0071, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2332/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2985, Series Loss: 0.0069, Class Loss: 0.2438, Accuracy: 0.3086\n",
      "Epoch [2333/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2985, Series Loss: 0.0070, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [2334/4000], Discriminator Loss: 0.0944, Generator Loss: 0.2985, Series Loss: 0.0069, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [2335/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2990, Series Loss: 0.0069, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2336/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2984, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2337/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2988, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2338/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2985, Series Loss: 0.0069, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [2339/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2986, Series Loss: 0.0069, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2340/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2986, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2341/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2985, Series Loss: 0.0069, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2342/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2986, Series Loss: 0.0069, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2343/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2989, Series Loss: 0.0070, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [2344/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2988, Series Loss: 0.0070, Class Loss: 0.2437, Accuracy: 0.3210\n",
      "Epoch [2345/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2991, Series Loss: 0.0069, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2346/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2988, Series Loss: 0.0071, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2347/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2987, Series Loss: 0.0070, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2348/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2986, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2349/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2988, Series Loss: 0.0071, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2350/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2988, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2351/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2988, Series Loss: 0.0070, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2352/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2987, Series Loss: 0.0069, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2353/4000], Discriminator Loss: 0.0944, Generator Loss: 0.2985, Series Loss: 0.0069, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2354/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2984, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [2355/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2986, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [2356/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2986, Series Loss: 0.0070, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [2357/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2984, Series Loss: 0.0071, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2358/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2984, Series Loss: 0.0069, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2359/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2983, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2360/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2984, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2361/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2987, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2362/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2988, Series Loss: 0.0069, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2363/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2988, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.2778\n",
      "Epoch [2364/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2986, Series Loss: 0.0070, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2365/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2987, Series Loss: 0.0070, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [2366/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2985, Series Loss: 0.0069, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2367/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2989, Series Loss: 0.0070, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [2368/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2984, Series Loss: 0.0070, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2369/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2985, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [2370/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2985, Series Loss: 0.0069, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2371/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2986, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2372/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2987, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2373/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2984, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2374/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2985, Series Loss: 0.0068, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [2375/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2985, Series Loss: 0.0070, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2376/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2987, Series Loss: 0.0070, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2377/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2987, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2378/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2986, Series Loss: 0.0070, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2379/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2986, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2380/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2988, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2381/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2982, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [2382/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2985, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2383/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2987, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.3148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2384/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2988, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2385/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2988, Series Loss: 0.0070, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2386/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2990, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [2387/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2986, Series Loss: 0.0069, Class Loss: 0.2438, Accuracy: 0.2901\n",
      "Epoch [2388/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2983, Series Loss: 0.0070, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2389/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2984, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [2390/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2980, Series Loss: 0.0070, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [2391/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2983, Series Loss: 0.0070, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2392/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2983, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2393/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2983, Series Loss: 0.0068, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2394/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2987, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [2395/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2987, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2396/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2988, Series Loss: 0.0068, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2397/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2987, Series Loss: 0.0069, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2398/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2989, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2399/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2987, Series Loss: 0.0069, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2400/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2992, Series Loss: 0.0069, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [2401/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2987, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2402/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2984, Series Loss: 0.0069, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2403/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2990, Series Loss: 0.0068, Class Loss: 0.2435, Accuracy: 0.3148\n",
      "Epoch [2404/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2988, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2405/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2986, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2406/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2989, Series Loss: 0.0070, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [2407/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2985, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2408/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2983, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2409/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2987, Series Loss: 0.0069, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [2410/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2988, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2411/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2987, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2412/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2988, Series Loss: 0.0069, Class Loss: 0.2435, Accuracy: 0.3210\n",
      "Epoch [2413/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2988, Series Loss: 0.0068, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [2414/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2988, Series Loss: 0.0068, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [2415/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2989, Series Loss: 0.0068, Class Loss: 0.2438, Accuracy: 0.2901\n",
      "Epoch [2416/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2984, Series Loss: 0.0069, Class Loss: 0.2437, Accuracy: 0.2840\n",
      "Epoch [2417/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2986, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2418/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2988, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2419/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2987, Series Loss: 0.0069, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [2420/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2983, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2421/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2986, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2422/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2980, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2423/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2982, Series Loss: 0.0068, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [2424/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2984, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [2425/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2981, Series Loss: 0.0069, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2426/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2983, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2427/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2983, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [2428/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2989, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2429/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2983, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2430/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2985, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2431/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2983, Series Loss: 0.0069, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2432/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2985, Series Loss: 0.0068, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [2433/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2986, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2434/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2983, Series Loss: 0.0069, Class Loss: 0.2435, Accuracy: 0.2778\n",
      "Epoch [2435/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2986, Series Loss: 0.0068, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2436/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2984, Series Loss: 0.0069, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2437/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2985, Series Loss: 0.0067, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2438/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2984, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2439/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2986, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2440/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2981, Series Loss: 0.0070, Class Loss: 0.2435, Accuracy: 0.3148\n",
      "Epoch [2441/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2986, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [2442/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2981, Series Loss: 0.0068, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [2443/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2979, Series Loss: 0.0068, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2444/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2981, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [2445/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2980, Series Loss: 0.0069, Class Loss: 0.2435, Accuracy: 0.3148\n",
      "Epoch [2446/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2984, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [2447/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2985, Series Loss: 0.0069, Class Loss: 0.2434, Accuracy: 0.3025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2448/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2986, Series Loss: 0.0069, Class Loss: 0.2437, Accuracy: 0.2716\n",
      "Epoch [2449/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2985, Series Loss: 0.0069, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [2450/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2985, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [2451/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2986, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2452/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2981, Series Loss: 0.0069, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2453/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2987, Series Loss: 0.0070, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2454/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2985, Series Loss: 0.0068, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2455/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2987, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.3210\n",
      "Epoch [2456/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2984, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2457/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2983, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2458/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2985, Series Loss: 0.0069, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2459/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2982, Series Loss: 0.0069, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2460/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2990, Series Loss: 0.0069, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [2461/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2984, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2462/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2985, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [2463/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2983, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2464/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2982, Series Loss: 0.0068, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [2465/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2987, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2466/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2988, Series Loss: 0.0069, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2467/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2985, Series Loss: 0.0069, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2468/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2983, Series Loss: 0.0068, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2469/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2985, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2470/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2988, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2471/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2987, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.3210\n",
      "Epoch [2472/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2988, Series Loss: 0.0068, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2473/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2983, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2474/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2984, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2475/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2988, Series Loss: 0.0067, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2476/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2986, Series Loss: 0.0068, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2477/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2990, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2478/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2986, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2479/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2986, Series Loss: 0.0067, Class Loss: 0.2435, Accuracy: 0.3148\n",
      "Epoch [2480/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2986, Series Loss: 0.0069, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2481/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2987, Series Loss: 0.0067, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [2482/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2988, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2483/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2984, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2484/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2986, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2485/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2986, Series Loss: 0.0068, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2486/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2986, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2487/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2989, Series Loss: 0.0068, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2488/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2986, Series Loss: 0.0068, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2489/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2985, Series Loss: 0.0067, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2490/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2987, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2491/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2988, Series Loss: 0.0068, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2492/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2989, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2493/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2987, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2494/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2985, Series Loss: 0.0068, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2495/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2983, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [2496/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2981, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2497/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2984, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [2498/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2986, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2499/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2982, Series Loss: 0.0068, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2500/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2988, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [2501/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2984, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2502/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2983, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [2503/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2980, Series Loss: 0.0068, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2504/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2978, Series Loss: 0.0067, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2505/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2978, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2506/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2982, Series Loss: 0.0068, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2507/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2986, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2508/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2984, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2509/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2986, Series Loss: 0.0068, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2510/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2983, Series Loss: 0.0068, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2511/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2985, Series Loss: 0.0067, Class Loss: 0.2436, Accuracy: 0.2963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2512/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2987, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2513/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2988, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2514/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2985, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2515/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2987, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2516/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2987, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2517/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2985, Series Loss: 0.0070, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2518/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2990, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2519/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2985, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2520/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2984, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [2521/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2984, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.3210\n",
      "Epoch [2522/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2982, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2523/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2979, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.3210\n",
      "Epoch [2524/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2983, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [2525/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2986, Series Loss: 0.0069, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2526/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2983, Series Loss: 0.0068, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2527/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2981, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2528/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2982, Series Loss: 0.0068, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [2529/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2981, Series Loss: 0.0068, Class Loss: 0.2435, Accuracy: 0.3148\n",
      "Epoch [2530/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2985, Series Loss: 0.0067, Class Loss: 0.2435, Accuracy: 0.3272\n",
      "Epoch [2531/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2986, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2532/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2985, Series Loss: 0.0069, Class Loss: 0.2435, Accuracy: 0.2840\n",
      "Epoch [2533/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2985, Series Loss: 0.0067, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2534/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2988, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2535/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2987, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [2536/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2987, Series Loss: 0.0068, Class Loss: 0.2435, Accuracy: 0.3148\n",
      "Epoch [2537/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2987, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2538/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2989, Series Loss: 0.0069, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [2539/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2986, Series Loss: 0.0068, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2540/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2987, Series Loss: 0.0068, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2541/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2982, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2542/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2981, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2543/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2983, Series Loss: 0.0068, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2544/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2988, Series Loss: 0.0068, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2545/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2985, Series Loss: 0.0067, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [2546/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2988, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2547/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2987, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2548/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2984, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [2549/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2983, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [2550/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2982, Series Loss: 0.0068, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2551/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2985, Series Loss: 0.0069, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [2552/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2981, Series Loss: 0.0068, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2553/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2983, Series Loss: 0.0067, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [2554/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2983, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2555/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2985, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [2556/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2982, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2557/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2982, Series Loss: 0.0068, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2558/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2982, Series Loss: 0.0067, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2559/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2985, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2560/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2984, Series Loss: 0.0067, Class Loss: 0.2435, Accuracy: 0.2840\n",
      "Epoch [2561/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2989, Series Loss: 0.0067, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2562/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2985, Series Loss: 0.0066, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [2563/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2976, Series Loss: 0.0067, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2564/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2979, Series Loss: 0.0067, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [2565/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2979, Series Loss: 0.0067, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2566/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2979, Series Loss: 0.0067, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2567/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2982, Series Loss: 0.0068, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2568/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2976, Series Loss: 0.0067, Class Loss: 0.2434, Accuracy: 0.3148\n",
      "Epoch [2569/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2979, Series Loss: 0.0067, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [2570/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2981, Series Loss: 0.0066, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [2571/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2977, Series Loss: 0.0066, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2572/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2982, Series Loss: 0.0067, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2573/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2982, Series Loss: 0.0067, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2574/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2985, Series Loss: 0.0067, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2575/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2980, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.3210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2576/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2983, Series Loss: 0.0067, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [2577/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2983, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2578/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2979, Series Loss: 0.0066, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [2579/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2985, Series Loss: 0.0067, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2580/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2980, Series Loss: 0.0067, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2581/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2986, Series Loss: 0.0067, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2582/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2988, Series Loss: 0.0067, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2583/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2985, Series Loss: 0.0067, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2584/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2984, Series Loss: 0.0067, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2585/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2982, Series Loss: 0.0067, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2586/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2982, Series Loss: 0.0067, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2587/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2982, Series Loss: 0.0067, Class Loss: 0.2435, Accuracy: 0.3148\n",
      "Epoch [2588/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2985, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [2589/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2981, Series Loss: 0.0068, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2590/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2982, Series Loss: 0.0067, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2591/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2985, Series Loss: 0.0067, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2592/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2985, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2593/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2987, Series Loss: 0.0067, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [2594/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2984, Series Loss: 0.0067, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2595/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2985, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2596/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2988, Series Loss: 0.0067, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [2597/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2988, Series Loss: 0.0067, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [2598/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2988, Series Loss: 0.0067, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2599/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2986, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2600/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2985, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2601/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2985, Series Loss: 0.0067, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2602/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2986, Series Loss: 0.0068, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [2603/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2980, Series Loss: 0.0067, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [2604/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2981, Series Loss: 0.0067, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2605/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2981, Series Loss: 0.0067, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2606/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2980, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [2607/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2977, Series Loss: 0.0067, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2608/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2978, Series Loss: 0.0067, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [2609/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2975, Series Loss: 0.0067, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2610/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2978, Series Loss: 0.0067, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [2611/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2983, Series Loss: 0.0067, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2612/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2979, Series Loss: 0.0067, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [2613/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2983, Series Loss: 0.0067, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [2614/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2980, Series Loss: 0.0067, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2615/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2978, Series Loss: 0.0066, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2616/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2975, Series Loss: 0.0065, Class Loss: 0.2435, Accuracy: 0.2840\n",
      "Epoch [2617/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2976, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2618/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2976, Series Loss: 0.0066, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [2619/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2979, Series Loss: 0.0066, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2620/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2981, Series Loss: 0.0066, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2621/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2982, Series Loss: 0.0066, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [2622/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2982, Series Loss: 0.0065, Class Loss: 0.2436, Accuracy: 0.3210\n",
      "Epoch [2623/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2983, Series Loss: 0.0066, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2624/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2979, Series Loss: 0.0067, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2625/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2981, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2626/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2982, Series Loss: 0.0066, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [2627/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2980, Series Loss: 0.0067, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2628/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2985, Series Loss: 0.0066, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [2629/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2981, Series Loss: 0.0066, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2630/4000], Discriminator Loss: 0.0946, Generator Loss: 0.2980, Series Loss: 0.0067, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2631/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2983, Series Loss: 0.0066, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2632/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2976, Series Loss: 0.0065, Class Loss: 0.2434, Accuracy: 0.3086\n",
      "Epoch [2633/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2984, Series Loss: 0.0067, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2634/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2981, Series Loss: 0.0067, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2635/4000], Discriminator Loss: 0.0944, Generator Loss: 0.2980, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2636/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2981, Series Loss: 0.0067, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2637/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2981, Series Loss: 0.0067, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2638/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2980, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2639/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2981, Series Loss: 0.0067, Class Loss: 0.2436, Accuracy: 0.3025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2640/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2980, Series Loss: 0.0066, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [2641/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2984, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2642/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2982, Series Loss: 0.0066, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2643/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2982, Series Loss: 0.0067, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2644/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2983, Series Loss: 0.0067, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2645/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2985, Series Loss: 0.0067, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2646/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2984, Series Loss: 0.0067, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2647/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2980, Series Loss: 0.0068, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2648/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2982, Series Loss: 0.0068, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2649/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2980, Series Loss: 0.0067, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2650/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2980, Series Loss: 0.0067, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2651/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2981, Series Loss: 0.0067, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2652/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2981, Series Loss: 0.0067, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [2653/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2980, Series Loss: 0.0067, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2654/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2979, Series Loss: 0.0067, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2655/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2979, Series Loss: 0.0068, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [2656/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2982, Series Loss: 0.0067, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [2657/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2983, Series Loss: 0.0066, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [2658/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2980, Series Loss: 0.0067, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2659/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2979, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [2660/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2980, Series Loss: 0.0067, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [2661/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2985, Series Loss: 0.0066, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [2662/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2983, Series Loss: 0.0066, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2663/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2983, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2664/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2982, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2665/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2982, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2666/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2981, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2667/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2979, Series Loss: 0.0066, Class Loss: 0.2434, Accuracy: 0.3086\n",
      "Epoch [2668/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2979, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.3210\n",
      "Epoch [2669/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2980, Series Loss: 0.0067, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2670/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2979, Series Loss: 0.0066, Class Loss: 0.2434, Accuracy: 0.2963\n",
      "Epoch [2671/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2979, Series Loss: 0.0067, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2672/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2981, Series Loss: 0.0067, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2673/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2981, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2674/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2980, Series Loss: 0.0067, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2675/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2979, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.3148\n",
      "Epoch [2676/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2979, Series Loss: 0.0065, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2677/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2977, Series Loss: 0.0065, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2678/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2979, Series Loss: 0.0066, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2679/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2980, Series Loss: 0.0065, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2680/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2981, Series Loss: 0.0066, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2681/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2981, Series Loss: 0.0065, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2682/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2982, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2683/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2985, Series Loss: 0.0065, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2684/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2982, Series Loss: 0.0065, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2685/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2981, Series Loss: 0.0066, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2686/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2985, Series Loss: 0.0066, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2687/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2984, Series Loss: 0.0066, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2688/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2980, Series Loss: 0.0066, Class Loss: 0.2434, Accuracy: 0.3086\n",
      "Epoch [2689/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2982, Series Loss: 0.0066, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [2690/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2982, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [2691/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2983, Series Loss: 0.0066, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2692/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2980, Series Loss: 0.0065, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2693/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2980, Series Loss: 0.0066, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2694/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2980, Series Loss: 0.0067, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [2695/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2981, Series Loss: 0.0065, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [2696/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2982, Series Loss: 0.0065, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2697/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2980, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.3148\n",
      "Epoch [2698/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2982, Series Loss: 0.0066, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2699/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2982, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2700/4000], Discriminator Loss: 0.0945, Generator Loss: 0.2980, Series Loss: 0.0066, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [2701/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2980, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2702/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2980, Series Loss: 0.0066, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [2703/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2981, Series Loss: 0.0066, Class Loss: 0.2437, Accuracy: 0.2963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2704/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2983, Series Loss: 0.0066, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [2705/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2981, Series Loss: 0.0065, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2706/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2982, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2707/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2979, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2708/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2982, Series Loss: 0.0067, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2709/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2980, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2710/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2981, Series Loss: 0.0067, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2711/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2981, Series Loss: 0.0066, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2712/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2979, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2713/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2980, Series Loss: 0.0066, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [2714/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2984, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2715/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2978, Series Loss: 0.0067, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2716/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2979, Series Loss: 0.0065, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [2717/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2978, Series Loss: 0.0066, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2718/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2977, Series Loss: 0.0066, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2719/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2980, Series Loss: 0.0066, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2720/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2980, Series Loss: 0.0066, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2721/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2981, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.3148\n",
      "Epoch [2722/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2977, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2723/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2982, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2724/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2980, Series Loss: 0.0065, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2725/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2981, Series Loss: 0.0066, Class Loss: 0.2434, Accuracy: 0.3148\n",
      "Epoch [2726/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2981, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2727/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2981, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2728/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2979, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.3148\n",
      "Epoch [2729/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2984, Series Loss: 0.0066, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2730/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2982, Series Loss: 0.0066, Class Loss: 0.2434, Accuracy: 0.2963\n",
      "Epoch [2731/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2983, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [2732/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2982, Series Loss: 0.0067, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2733/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2979, Series Loss: 0.0067, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [2734/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2982, Series Loss: 0.0066, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2735/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2979, Series Loss: 0.0066, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [2736/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2979, Series Loss: 0.0065, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [2737/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2980, Series Loss: 0.0067, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2738/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2978, Series Loss: 0.0066, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2739/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2978, Series Loss: 0.0066, Class Loss: 0.2434, Accuracy: 0.3025\n",
      "Epoch [2740/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2982, Series Loss: 0.0066, Class Loss: 0.2434, Accuracy: 0.3025\n",
      "Epoch [2741/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2979, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2742/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2978, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.3148\n",
      "Epoch [2743/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2978, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2744/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2978, Series Loss: 0.0066, Class Loss: 0.2434, Accuracy: 0.3086\n",
      "Epoch [2745/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2978, Series Loss: 0.0067, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2746/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2978, Series Loss: 0.0067, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2747/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2976, Series Loss: 0.0066, Class Loss: 0.2434, Accuracy: 0.3025\n",
      "Epoch [2748/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2976, Series Loss: 0.0067, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [2749/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2978, Series Loss: 0.0067, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2750/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2981, Series Loss: 0.0066, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [2751/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2980, Series Loss: 0.0065, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2752/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2984, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2753/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2981, Series Loss: 0.0065, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [2754/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2986, Series Loss: 0.0066, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2755/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2981, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2756/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2985, Series Loss: 0.0066, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2757/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2978, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [2758/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2980, Series Loss: 0.0065, Class Loss: 0.2435, Accuracy: 0.3148\n",
      "Epoch [2759/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2980, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.3148\n",
      "Epoch [2760/4000], Discriminator Loss: 0.0944, Generator Loss: 0.2976, Series Loss: 0.0066, Class Loss: 0.2434, Accuracy: 0.3086\n",
      "Epoch [2761/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2976, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2762/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2982, Series Loss: 0.0067, Class Loss: 0.2435, Accuracy: 0.3148\n",
      "Epoch [2763/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2982, Series Loss: 0.0067, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2764/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2979, Series Loss: 0.0066, Class Loss: 0.2437, Accuracy: 0.2840\n",
      "Epoch [2765/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2980, Series Loss: 0.0066, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2766/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2979, Series Loss: 0.0066, Class Loss: 0.2438, Accuracy: 0.2901\n",
      "Epoch [2767/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2981, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.3025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2768/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2983, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2769/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2982, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.3148\n",
      "Epoch [2770/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2978, Series Loss: 0.0066, Class Loss: 0.2434, Accuracy: 0.3025\n",
      "Epoch [2771/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2979, Series Loss: 0.0065, Class Loss: 0.2433, Accuracy: 0.3025\n",
      "Epoch [2772/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2978, Series Loss: 0.0065, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2773/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2975, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2774/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2978, Series Loss: 0.0065, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2775/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2977, Series Loss: 0.0065, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2776/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2978, Series Loss: 0.0065, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2777/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2979, Series Loss: 0.0065, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2778/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2983, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2779/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2977, Series Loss: 0.0065, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2780/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2979, Series Loss: 0.0066, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2781/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2977, Series Loss: 0.0065, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2782/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2975, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2783/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2979, Series Loss: 0.0065, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2784/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2980, Series Loss: 0.0066, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2785/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2980, Series Loss: 0.0065, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2786/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2981, Series Loss: 0.0065, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [2787/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2982, Series Loss: 0.0066, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2788/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2980, Series Loss: 0.0066, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2789/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2978, Series Loss: 0.0065, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2790/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2977, Series Loss: 0.0065, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2791/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2981, Series Loss: 0.0065, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2792/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2979, Series Loss: 0.0066, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [2793/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2981, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2794/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2981, Series Loss: 0.0066, Class Loss: 0.2434, Accuracy: 0.3025\n",
      "Epoch [2795/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2983, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2796/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2986, Series Loss: 0.0067, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2797/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2987, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2798/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2983, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2799/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2983, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2800/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2986, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2801/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2981, Series Loss: 0.0066, Class Loss: 0.2434, Accuracy: 0.2901\n",
      "Epoch [2802/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2981, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.3148\n",
      "Epoch [2803/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2980, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.3148\n",
      "Epoch [2804/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2980, Series Loss: 0.0065, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2805/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2981, Series Loss: 0.0065, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2806/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2982, Series Loss: 0.0067, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2807/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2983, Series Loss: 0.0066, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [2808/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2982, Series Loss: 0.0067, Class Loss: 0.2435, Accuracy: 0.3210\n",
      "Epoch [2809/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2979, Series Loss: 0.0066, Class Loss: 0.2434, Accuracy: 0.3272\n",
      "Epoch [2810/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2982, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2811/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2979, Series Loss: 0.0066, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2812/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2982, Series Loss: 0.0066, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2813/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2980, Series Loss: 0.0066, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2814/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2980, Series Loss: 0.0066, Class Loss: 0.2436, Accuracy: 0.3272\n",
      "Epoch [2815/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2981, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2816/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2978, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.3148\n",
      "Epoch [2817/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2977, Series Loss: 0.0065, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2818/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2984, Series Loss: 0.0066, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2819/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2981, Series Loss: 0.0065, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [2820/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2980, Series Loss: 0.0066, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2821/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2978, Series Loss: 0.0066, Class Loss: 0.2434, Accuracy: 0.3086\n",
      "Epoch [2822/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2978, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2823/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2977, Series Loss: 0.0065, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2824/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2981, Series Loss: 0.0065, Class Loss: 0.2434, Accuracy: 0.2963\n",
      "Epoch [2825/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2977, Series Loss: 0.0065, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2826/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2977, Series Loss: 0.0065, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [2827/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2978, Series Loss: 0.0065, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2828/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2978, Series Loss: 0.0066, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2829/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2980, Series Loss: 0.0066, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2830/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2978, Series Loss: 0.0065, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [2831/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2981, Series Loss: 0.0066, Class Loss: 0.2437, Accuracy: 0.3025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2832/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2977, Series Loss: 0.0065, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2833/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2982, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2834/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2978, Series Loss: 0.0065, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2835/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2977, Series Loss: 0.0065, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2836/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2979, Series Loss: 0.0066, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2837/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2977, Series Loss: 0.0065, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2838/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2975, Series Loss: 0.0065, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [2839/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2975, Series Loss: 0.0066, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2840/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2976, Series Loss: 0.0065, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2841/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2977, Series Loss: 0.0065, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2842/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2975, Series Loss: 0.0065, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [2843/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2975, Series Loss: 0.0064, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2844/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2978, Series Loss: 0.0064, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [2845/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2980, Series Loss: 0.0064, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2846/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2979, Series Loss: 0.0064, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2847/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2977, Series Loss: 0.0065, Class Loss: 0.2435, Accuracy: 0.3210\n",
      "Epoch [2848/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2975, Series Loss: 0.0064, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2849/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2976, Series Loss: 0.0065, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2850/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2976, Series Loss: 0.0065, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2851/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2977, Series Loss: 0.0064, Class Loss: 0.2434, Accuracy: 0.3025\n",
      "Epoch [2852/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2976, Series Loss: 0.0064, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2853/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2977, Series Loss: 0.0064, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [2854/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2979, Series Loss: 0.0065, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2855/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2976, Series Loss: 0.0064, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2856/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2976, Series Loss: 0.0064, Class Loss: 0.2435, Accuracy: 0.3148\n",
      "Epoch [2857/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2976, Series Loss: 0.0064, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2858/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2976, Series Loss: 0.0065, Class Loss: 0.2434, Accuracy: 0.2840\n",
      "Epoch [2859/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2981, Series Loss: 0.0065, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2860/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2977, Series Loss: 0.0065, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2861/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2977, Series Loss: 0.0065, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2862/4000], Discriminator Loss: 0.0944, Generator Loss: 0.2971, Series Loss: 0.0065, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [2863/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2976, Series Loss: 0.0064, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2864/4000], Discriminator Loss: 0.0945, Generator Loss: 0.2974, Series Loss: 0.0064, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2865/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2976, Series Loss: 0.0064, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2866/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2976, Series Loss: 0.0064, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2867/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2973, Series Loss: 0.0064, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2868/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2974, Series Loss: 0.0064, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2869/4000], Discriminator Loss: 0.0947, Generator Loss: 0.2974, Series Loss: 0.0064, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2870/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2972, Series Loss: 0.0064, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2871/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2972, Series Loss: 0.0065, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2872/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2973, Series Loss: 0.0064, Class Loss: 0.2435, Accuracy: 0.3148\n",
      "Epoch [2873/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2972, Series Loss: 0.0065, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2874/4000], Discriminator Loss: 0.0946, Generator Loss: 0.2969, Series Loss: 0.0065, Class Loss: 0.2434, Accuracy: 0.2963\n",
      "Epoch [2875/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2973, Series Loss: 0.0064, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2876/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2973, Series Loss: 0.0063, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2877/4000], Discriminator Loss: 0.0944, Generator Loss: 0.2972, Series Loss: 0.0064, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2878/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2974, Series Loss: 0.0064, Class Loss: 0.2436, Accuracy: 0.3210\n",
      "Epoch [2879/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2973, Series Loss: 0.0065, Class Loss: 0.2435, Accuracy: 0.3148\n",
      "Epoch [2880/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2974, Series Loss: 0.0065, Class Loss: 0.2435, Accuracy: 0.3210\n",
      "Epoch [2881/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2975, Series Loss: 0.0064, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2882/4000], Discriminator Loss: 0.0944, Generator Loss: 0.2974, Series Loss: 0.0065, Class Loss: 0.2434, Accuracy: 0.3025\n",
      "Epoch [2883/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2975, Series Loss: 0.0065, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2884/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2975, Series Loss: 0.0065, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2885/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2976, Series Loss: 0.0065, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2886/4000], Discriminator Loss: 0.0946, Generator Loss: 0.2974, Series Loss: 0.0064, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [2887/4000], Discriminator Loss: 0.0945, Generator Loss: 0.2973, Series Loss: 0.0064, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2888/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2976, Series Loss: 0.0065, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2889/4000], Discriminator Loss: 0.0944, Generator Loss: 0.2975, Series Loss: 0.0065, Class Loss: 0.2434, Accuracy: 0.3086\n",
      "Epoch [2890/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2978, Series Loss: 0.0065, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [2891/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2978, Series Loss: 0.0066, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2892/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2973, Series Loss: 0.0065, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2893/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2973, Series Loss: 0.0065, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2894/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2976, Series Loss: 0.0066, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2895/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2972, Series Loss: 0.0064, Class Loss: 0.2435, Accuracy: 0.2840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2896/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2975, Series Loss: 0.0064, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2897/4000], Discriminator Loss: 0.0944, Generator Loss: 0.2974, Series Loss: 0.0065, Class Loss: 0.2435, Accuracy: 0.2778\n",
      "Epoch [2898/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2976, Series Loss: 0.0064, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [2899/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2973, Series Loss: 0.0064, Class Loss: 0.2434, Accuracy: 0.3148\n",
      "Epoch [2900/4000], Discriminator Loss: 0.0944, Generator Loss: 0.2978, Series Loss: 0.0064, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [2901/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2975, Series Loss: 0.0064, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2902/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2975, Series Loss: 0.0064, Class Loss: 0.2435, Accuracy: 0.2840\n",
      "Epoch [2903/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2979, Series Loss: 0.0063, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2904/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2971, Series Loss: 0.0063, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2905/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2973, Series Loss: 0.0063, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2906/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2973, Series Loss: 0.0063, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [2907/4000], Discriminator Loss: 0.0944, Generator Loss: 0.2976, Series Loss: 0.0064, Class Loss: 0.2434, Accuracy: 0.3025\n",
      "Epoch [2908/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2975, Series Loss: 0.0064, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2909/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2976, Series Loss: 0.0064, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2910/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2973, Series Loss: 0.0064, Class Loss: 0.2435, Accuracy: 0.2840\n",
      "Epoch [2911/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2972, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2912/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2974, Series Loss: 0.0065, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2913/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2971, Series Loss: 0.0064, Class Loss: 0.2434, Accuracy: 0.3025\n",
      "Epoch [2914/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2972, Series Loss: 0.0063, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2915/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2975, Series Loss: 0.0064, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2916/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2976, Series Loss: 0.0063, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2917/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2975, Series Loss: 0.0064, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [2918/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2973, Series Loss: 0.0063, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2919/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2975, Series Loss: 0.0063, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [2920/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2976, Series Loss: 0.0063, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [2921/4000], Discriminator Loss: 0.0945, Generator Loss: 0.2975, Series Loss: 0.0064, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2922/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2976, Series Loss: 0.0064, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2923/4000], Discriminator Loss: 0.0945, Generator Loss: 0.2971, Series Loss: 0.0063, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2924/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2975, Series Loss: 0.0063, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2925/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2977, Series Loss: 0.0063, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [2926/4000], Discriminator Loss: 0.0944, Generator Loss: 0.2975, Series Loss: 0.0063, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [2927/4000], Discriminator Loss: 0.0944, Generator Loss: 0.2975, Series Loss: 0.0065, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2928/4000], Discriminator Loss: 0.0945, Generator Loss: 0.2974, Series Loss: 0.0064, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2929/4000], Discriminator Loss: 0.0944, Generator Loss: 0.2973, Series Loss: 0.0063, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [2930/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2971, Series Loss: 0.0063, Class Loss: 0.2433, Accuracy: 0.3086\n",
      "Epoch [2931/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2972, Series Loss: 0.0064, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [2932/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2972, Series Loss: 0.0063, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [2933/4000], Discriminator Loss: 0.0944, Generator Loss: 0.2972, Series Loss: 0.0063, Class Loss: 0.2434, Accuracy: 0.3025\n",
      "Epoch [2934/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2974, Series Loss: 0.0064, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2935/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2974, Series Loss: 0.0063, Class Loss: 0.2434, Accuracy: 0.3148\n",
      "Epoch [2936/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2976, Series Loss: 0.0063, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2937/4000], Discriminator Loss: 0.0944, Generator Loss: 0.2975, Series Loss: 0.0063, Class Loss: 0.2435, Accuracy: 0.3148\n",
      "Epoch [2938/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2972, Series Loss: 0.0063, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2939/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2974, Series Loss: 0.0063, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2940/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2970, Series Loss: 0.0064, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [2941/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2974, Series Loss: 0.0063, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2942/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2972, Series Loss: 0.0063, Class Loss: 0.2434, Accuracy: 0.3025\n",
      "Epoch [2943/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2970, Series Loss: 0.0063, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2944/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2972, Series Loss: 0.0063, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2945/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2973, Series Loss: 0.0064, Class Loss: 0.2434, Accuracy: 0.3086\n",
      "Epoch [2946/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2970, Series Loss: 0.0063, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2947/4000], Discriminator Loss: 0.0945, Generator Loss: 0.2969, Series Loss: 0.0062, Class Loss: 0.2434, Accuracy: 0.3148\n",
      "Epoch [2948/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2971, Series Loss: 0.0063, Class Loss: 0.2435, Accuracy: 0.3148\n",
      "Epoch [2949/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2972, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [2950/4000], Discriminator Loss: 0.0944, Generator Loss: 0.2969, Series Loss: 0.0062, Class Loss: 0.2434, Accuracy: 0.2963\n",
      "Epoch [2951/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2970, Series Loss: 0.0063, Class Loss: 0.2434, Accuracy: 0.3086\n",
      "Epoch [2952/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2970, Series Loss: 0.0063, Class Loss: 0.2435, Accuracy: 0.2840\n",
      "Epoch [2953/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2967, Series Loss: 0.0063, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2954/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2971, Series Loss: 0.0062, Class Loss: 0.2434, Accuracy: 0.3148\n",
      "Epoch [2955/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2972, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.3272\n",
      "Epoch [2956/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2972, Series Loss: 0.0062, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [2957/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2969, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2958/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2972, Series Loss: 0.0063, Class Loss: 0.2435, Accuracy: 0.3210\n",
      "Epoch [2959/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2970, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.2963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2960/4000], Discriminator Loss: 0.0944, Generator Loss: 0.2973, Series Loss: 0.0062, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [2961/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2969, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.3086\n",
      "Epoch [2962/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2969, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2963/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2971, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.3210\n",
      "Epoch [2964/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2975, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2965/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2973, Series Loss: 0.0063, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2966/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2974, Series Loss: 0.0063, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2967/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2975, Series Loss: 0.0063, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2968/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2973, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [2969/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2975, Series Loss: 0.0063, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2970/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2976, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2971/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2979, Series Loss: 0.0063, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2972/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2974, Series Loss: 0.0064, Class Loss: 0.2435, Accuracy: 0.2654\n",
      "Epoch [2973/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2971, Series Loss: 0.0063, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [2974/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2973, Series Loss: 0.0063, Class Loss: 0.2434, Accuracy: 0.3148\n",
      "Epoch [2975/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2973, Series Loss: 0.0063, Class Loss: 0.2434, Accuracy: 0.2963\n",
      "Epoch [2976/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2972, Series Loss: 0.0062, Class Loss: 0.2434, Accuracy: 0.3025\n",
      "Epoch [2977/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2972, Series Loss: 0.0062, Class Loss: 0.2434, Accuracy: 0.2963\n",
      "Epoch [2978/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2975, Series Loss: 0.0063, Class Loss: 0.2435, Accuracy: 0.2778\n",
      "Epoch [2979/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2974, Series Loss: 0.0063, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [2980/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2973, Series Loss: 0.0062, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [2981/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2973, Series Loss: 0.0063, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [2982/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2975, Series Loss: 0.0063, Class Loss: 0.2436, Accuracy: 0.2778\n",
      "Epoch [2983/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2972, Series Loss: 0.0063, Class Loss: 0.2435, Accuracy: 0.2716\n",
      "Epoch [2984/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2976, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [2985/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2978, Series Loss: 0.0062, Class Loss: 0.2436, Accuracy: 0.2778\n",
      "Epoch [2986/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2973, Series Loss: 0.0062, Class Loss: 0.2434, Accuracy: 0.2840\n",
      "Epoch [2987/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2974, Series Loss: 0.0063, Class Loss: 0.2434, Accuracy: 0.2901\n",
      "Epoch [2988/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2974, Series Loss: 0.0063, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [2989/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2969, Series Loss: 0.0063, Class Loss: 0.2434, Accuracy: 0.2901\n",
      "Epoch [2990/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2972, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [2991/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2970, Series Loss: 0.0062, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [2992/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2973, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.3148\n",
      "Epoch [2993/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2972, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2778\n",
      "Epoch [2994/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2975, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [2995/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2973, Series Loss: 0.0062, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [2996/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2973, Series Loss: 0.0062, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [2997/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2971, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.2963\n",
      "Epoch [2998/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2971, Series Loss: 0.0062, Class Loss: 0.2434, Accuracy: 0.2963\n",
      "Epoch [2999/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2971, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.2840\n",
      "Epoch [3000/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2970, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3001/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2972, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2778\n",
      "Epoch [3002/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2974, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.2963\n",
      "Epoch [3003/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2973, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.3148\n",
      "Epoch [3004/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2974, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.2840\n",
      "Epoch [3005/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2972, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3006/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2973, Series Loss: 0.0062, Class Loss: 0.2434, Accuracy: 0.2778\n",
      "Epoch [3007/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2977, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3008/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2972, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3009/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2973, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3010/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2973, Series Loss: 0.0062, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3011/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2972, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3012/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2974, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3013/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2975, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [3014/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2974, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3015/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2970, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [3016/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2968, Series Loss: 0.0060, Class Loss: 0.2435, Accuracy: 0.2840\n",
      "Epoch [3017/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2969, Series Loss: 0.0063, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3018/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2969, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3019/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2972, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2840\n",
      "Epoch [3020/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2970, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3021/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2972, Series Loss: 0.0062, Class Loss: 0.2434, Accuracy: 0.3086\n",
      "Epoch [3022/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2971, Series Loss: 0.0060, Class Loss: 0.2434, Accuracy: 0.2963\n",
      "Epoch [3023/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2968, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3024/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2972, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3210\n",
      "Epoch [3025/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2973, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3026/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2970, Series Loss: 0.0061, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [3027/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2978, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3028/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2977, Series Loss: 0.0060, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [3029/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2975, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3030/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2975, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3031/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2971, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.2840\n",
      "Epoch [3032/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2975, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.2840\n",
      "Epoch [3033/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2972, Series Loss: 0.0062, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [3034/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2971, Series Loss: 0.0062, Class Loss: 0.2434, Accuracy: 0.2963\n",
      "Epoch [3035/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2969, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.2778\n",
      "Epoch [3036/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2973, Series Loss: 0.0061, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3037/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2971, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.2963\n",
      "Epoch [3038/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2970, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2840\n",
      "Epoch [3039/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2971, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3040/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2975, Series Loss: 0.0062, Class Loss: 0.2436, Accuracy: 0.2716\n",
      "Epoch [3041/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2974, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3042/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2972, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2840\n",
      "Epoch [3043/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2971, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.3086\n",
      "Epoch [3044/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2970, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3045/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2971, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.2963\n",
      "Epoch [3046/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2974, Series Loss: 0.0062, Class Loss: 0.2434, Accuracy: 0.2901\n",
      "Epoch [3047/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2975, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3048/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2975, Series Loss: 0.0062, Class Loss: 0.2434, Accuracy: 0.2778\n",
      "Epoch [3049/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2972, Series Loss: 0.0061, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [3050/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2976, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.2901\n",
      "Epoch [3051/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2976, Series Loss: 0.0061, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [3052/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2972, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2778\n",
      "Epoch [3053/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2978, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.3086\n",
      "Epoch [3054/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2982, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [3055/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2978, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2716\n",
      "Epoch [3056/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2977, Series Loss: 0.0062, Class Loss: 0.2434, Accuracy: 0.2963\n",
      "Epoch [3057/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2975, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3058/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2974, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.3086\n",
      "Epoch [3059/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2975, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [3060/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2973, Series Loss: 0.0062, Class Loss: 0.2433, Accuracy: 0.3086\n",
      "Epoch [3061/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2974, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3062/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2973, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.2901\n",
      "Epoch [3063/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2975, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.3148\n",
      "Epoch [3064/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2972, Series Loss: 0.0061, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3065/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2973, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.2840\n",
      "Epoch [3066/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2971, Series Loss: 0.0061, Class Loss: 0.2433, Accuracy: 0.3148\n",
      "Epoch [3067/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2971, Series Loss: 0.0060, Class Loss: 0.2434, Accuracy: 0.3148\n",
      "Epoch [3068/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2969, Series Loss: 0.0060, Class Loss: 0.2434, Accuracy: 0.2901\n",
      "Epoch [3069/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2972, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3070/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2969, Series Loss: 0.0062, Class Loss: 0.2434, Accuracy: 0.2963\n",
      "Epoch [3071/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2973, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.3086\n",
      "Epoch [3072/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2973, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3073/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2972, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3074/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2972, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3148\n",
      "Epoch [3075/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2975, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2716\n",
      "Epoch [3076/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2975, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3077/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2973, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3078/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2976, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3210\n",
      "Epoch [3079/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2977, Series Loss: 0.0061, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [3080/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2973, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3081/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2971, Series Loss: 0.0062, Class Loss: 0.2436, Accuracy: 0.2716\n",
      "Epoch [3082/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2972, Series Loss: 0.0061, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [3083/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2970, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3084/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2972, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3210\n",
      "Epoch [3085/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2973, Series Loss: 0.0062, Class Loss: 0.2434, Accuracy: 0.3086\n",
      "Epoch [3086/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2971, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.3025\n",
      "Epoch [3087/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2974, Series Loss: 0.0062, Class Loss: 0.2434, Accuracy: 0.2963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3088/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2976, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3089/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2976, Series Loss: 0.0063, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [3090/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2977, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3091/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2979, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3092/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2977, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2778\n",
      "Epoch [3093/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2976, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3094/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2976, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.2654\n",
      "Epoch [3095/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2976, Series Loss: 0.0061, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3096/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2977, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3097/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2979, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3098/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2977, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3099/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2976, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3100/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2980, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [3101/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2977, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3102/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2978, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3103/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2974, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2840\n",
      "Epoch [3104/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2974, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [3105/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2974, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3106/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2976, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3107/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2974, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2840\n",
      "Epoch [3108/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2975, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3109/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2975, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.2840\n",
      "Epoch [3110/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2975, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.2963\n",
      "Epoch [3111/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2976, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.3086\n",
      "Epoch [3112/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2979, Series Loss: 0.0060, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3113/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2978, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3114/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2976, Series Loss: 0.0060, Class Loss: 0.2434, Accuracy: 0.3025\n",
      "Epoch [3115/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2973, Series Loss: 0.0060, Class Loss: 0.2434, Accuracy: 0.3025\n",
      "Epoch [3116/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2976, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3117/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2977, Series Loss: 0.0060, Class Loss: 0.2434, Accuracy: 0.3086\n",
      "Epoch [3118/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2976, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.2901\n",
      "Epoch [3119/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2974, Series Loss: 0.0060, Class Loss: 0.2435, Accuracy: 0.2840\n",
      "Epoch [3120/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2976, Series Loss: 0.0060, Class Loss: 0.2434, Accuracy: 0.2901\n",
      "Epoch [3121/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2978, Series Loss: 0.0060, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3122/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2975, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.2901\n",
      "Epoch [3123/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2973, Series Loss: 0.0060, Class Loss: 0.2435, Accuracy: 0.2840\n",
      "Epoch [3124/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2970, Series Loss: 0.0060, Class Loss: 0.2434, Accuracy: 0.3086\n",
      "Epoch [3125/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2973, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3126/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2971, Series Loss: 0.0060, Class Loss: 0.2434, Accuracy: 0.2963\n",
      "Epoch [3127/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2972, Series Loss: 0.0060, Class Loss: 0.2434, Accuracy: 0.3086\n",
      "Epoch [3128/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2975, Series Loss: 0.0060, Class Loss: 0.2434, Accuracy: 0.2840\n",
      "Epoch [3129/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2977, Series Loss: 0.0059, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3130/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2971, Series Loss: 0.0060, Class Loss: 0.2433, Accuracy: 0.3086\n",
      "Epoch [3131/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2975, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.2963\n",
      "Epoch [3132/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2973, Series Loss: 0.0060, Class Loss: 0.2434, Accuracy: 0.3086\n",
      "Epoch [3133/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2972, Series Loss: 0.0060, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3134/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2975, Series Loss: 0.0060, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3135/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2975, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.2901\n",
      "Epoch [3136/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2974, Series Loss: 0.0060, Class Loss: 0.2434, Accuracy: 0.3086\n",
      "Epoch [3137/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2976, Series Loss: 0.0060, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3138/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2980, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2840\n",
      "Epoch [3139/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2979, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.2901\n",
      "Epoch [3140/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2978, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3141/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2979, Series Loss: 0.0062, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3142/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2977, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [3143/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2974, Series Loss: 0.0062, Class Loss: 0.2434, Accuracy: 0.3086\n",
      "Epoch [3144/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2975, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3145/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2974, Series Loss: 0.0062, Class Loss: 0.2432, Accuracy: 0.3025\n",
      "Epoch [3146/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2978, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.2840\n",
      "Epoch [3147/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2975, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [3148/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2976, Series Loss: 0.0061, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [3149/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2973, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3150/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2973, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.2963\n",
      "Epoch [3151/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2975, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3152/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2974, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3153/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2971, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.2840\n",
      "Epoch [3154/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2973, Series Loss: 0.0060, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [3155/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2974, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3156/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2969, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [3157/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2971, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [3158/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2975, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3159/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2976, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.2901\n",
      "Epoch [3160/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2974, Series Loss: 0.0060, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3161/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2974, Series Loss: 0.0061, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [3162/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2975, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.2901\n",
      "Epoch [3163/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2976, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.3025\n",
      "Epoch [3164/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2973, Series Loss: 0.0060, Class Loss: 0.2434, Accuracy: 0.2963\n",
      "Epoch [3165/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2974, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.2901\n",
      "Epoch [3166/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2974, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3167/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2971, Series Loss: 0.0062, Class Loss: 0.2434, Accuracy: 0.2840\n",
      "Epoch [3168/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2976, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3169/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2974, Series Loss: 0.0061, Class Loss: 0.2436, Accuracy: 0.2778\n",
      "Epoch [3170/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2974, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3171/4000], Discriminator Loss: 0.0927, Generator Loss: 0.2976, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.3025\n",
      "Epoch [3172/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2975, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3173/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2972, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3174/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2973, Series Loss: 0.0060, Class Loss: 0.2434, Accuracy: 0.2963\n",
      "Epoch [3175/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2973, Series Loss: 0.0062, Class Loss: 0.2434, Accuracy: 0.3025\n",
      "Epoch [3176/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2974, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.2840\n",
      "Epoch [3177/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2978, Series Loss: 0.0061, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [3178/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2976, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3179/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2971, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.3025\n",
      "Epoch [3180/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2973, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.2778\n",
      "Epoch [3181/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2974, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3182/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2975, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2778\n",
      "Epoch [3183/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2974, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.2963\n",
      "Epoch [3184/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2974, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [3185/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2979, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [3186/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2977, Series Loss: 0.0062, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [3187/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2978, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [3188/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2976, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3189/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2975, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.3025\n",
      "Epoch [3190/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2974, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2840\n",
      "Epoch [3191/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2977, Series Loss: 0.0061, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [3192/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2976, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.2840\n",
      "Epoch [3193/4000], Discriminator Loss: 0.0926, Generator Loss: 0.2981, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3194/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2977, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.3025\n",
      "Epoch [3195/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2975, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2840\n",
      "Epoch [3196/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2985, Series Loss: 0.0061, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [3197/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2977, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.3210\n",
      "Epoch [3198/4000], Discriminator Loss: 0.0927, Generator Loss: 0.2975, Series Loss: 0.0060, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3199/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2976, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.3210\n",
      "Epoch [3200/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2978, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3201/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2979, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3202/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2978, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3203/4000], Discriminator Loss: 0.0927, Generator Loss: 0.2977, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.2963\n",
      "Epoch [3204/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2978, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.3148\n",
      "Epoch [3205/4000], Discriminator Loss: 0.0925, Generator Loss: 0.2978, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3206/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2976, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3207/4000], Discriminator Loss: 0.0927, Generator Loss: 0.2980, Series Loss: 0.0061, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [3208/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2976, Series Loss: 0.0060, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3209/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2979, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3210/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2977, Series Loss: 0.0061, Class Loss: 0.2433, Accuracy: 0.2963\n",
      "Epoch [3211/4000], Discriminator Loss: 0.0927, Generator Loss: 0.2981, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [3212/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2978, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3213/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2978, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [3214/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2977, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.3148\n",
      "Epoch [3215/4000], Discriminator Loss: 0.0927, Generator Loss: 0.2983, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3216/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2976, Series Loss: 0.0062, Class Loss: 0.2434, Accuracy: 0.3148\n",
      "Epoch [3217/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2980, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3218/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2977, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3219/4000], Discriminator Loss: 0.0926, Generator Loss: 0.2976, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.3148\n",
      "Epoch [3220/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2979, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.2901\n",
      "Epoch [3221/4000], Discriminator Loss: 0.0926, Generator Loss: 0.2980, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3222/4000], Discriminator Loss: 0.0927, Generator Loss: 0.2977, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3223/4000], Discriminator Loss: 0.0926, Generator Loss: 0.2981, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.3025\n",
      "Epoch [3224/4000], Discriminator Loss: 0.0927, Generator Loss: 0.2979, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3225/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2979, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2840\n",
      "Epoch [3226/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2980, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.2840\n",
      "Epoch [3227/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2979, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.3025\n",
      "Epoch [3228/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2979, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.3025\n",
      "Epoch [3229/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2980, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.3025\n",
      "Epoch [3230/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2976, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.2963\n",
      "Epoch [3231/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2980, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3232/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2980, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3233/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2979, Series Loss: 0.0060, Class Loss: 0.2434, Accuracy: 0.2840\n",
      "Epoch [3234/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2982, Series Loss: 0.0061, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [3235/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2979, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.2778\n",
      "Epoch [3236/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2981, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3148\n",
      "Epoch [3237/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2980, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3238/4000], Discriminator Loss: 0.0925, Generator Loss: 0.2977, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.3210\n",
      "Epoch [3239/4000], Discriminator Loss: 0.0926, Generator Loss: 0.2978, Series Loss: 0.0062, Class Loss: 0.2434, Accuracy: 0.3025\n",
      "Epoch [3240/4000], Discriminator Loss: 0.0925, Generator Loss: 0.2976, Series Loss: 0.0061, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [3241/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2975, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3210\n",
      "Epoch [3242/4000], Discriminator Loss: 0.0927, Generator Loss: 0.2973, Series Loss: 0.0060, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [3243/4000], Discriminator Loss: 0.0927, Generator Loss: 0.2975, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3244/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2977, Series Loss: 0.0061, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [3245/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2974, Series Loss: 0.0061, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [3246/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2977, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [3247/4000], Discriminator Loss: 0.0925, Generator Loss: 0.2979, Series Loss: 0.0060, Class Loss: 0.2435, Accuracy: 0.2840\n",
      "Epoch [3248/4000], Discriminator Loss: 0.0922, Generator Loss: 0.2981, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3210\n",
      "Epoch [3249/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2978, Series Loss: 0.0060, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [3250/4000], Discriminator Loss: 0.0923, Generator Loss: 0.2978, Series Loss: 0.0060, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3251/4000], Discriminator Loss: 0.0924, Generator Loss: 0.2978, Series Loss: 0.0060, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [3252/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2977, Series Loss: 0.0060, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3253/4000], Discriminator Loss: 0.0926, Generator Loss: 0.2976, Series Loss: 0.0060, Class Loss: 0.2434, Accuracy: 0.2963\n",
      "Epoch [3254/4000], Discriminator Loss: 0.0926, Generator Loss: 0.2979, Series Loss: 0.0060, Class Loss: 0.2434, Accuracy: 0.2901\n",
      "Epoch [3255/4000], Discriminator Loss: 0.0927, Generator Loss: 0.2976, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.2901\n",
      "Epoch [3256/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2976, Series Loss: 0.0060, Class Loss: 0.2434, Accuracy: 0.3086\n",
      "Epoch [3257/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2974, Series Loss: 0.0060, Class Loss: 0.2435, Accuracy: 0.2840\n",
      "Epoch [3258/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2978, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3259/4000], Discriminator Loss: 0.0927, Generator Loss: 0.2979, Series Loss: 0.0061, Class Loss: 0.2436, Accuracy: 0.2778\n",
      "Epoch [3260/4000], Discriminator Loss: 0.0927, Generator Loss: 0.2975, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2716\n",
      "Epoch [3261/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2976, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3262/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2974, Series Loss: 0.0060, Class Loss: 0.2435, Accuracy: 0.2840\n",
      "Epoch [3263/4000], Discriminator Loss: 0.0926, Generator Loss: 0.2975, Series Loss: 0.0060, Class Loss: 0.2434, Accuracy: 0.2901\n",
      "Epoch [3264/4000], Discriminator Loss: 0.0925, Generator Loss: 0.2977, Series Loss: 0.0060, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3265/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2980, Series Loss: 0.0060, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [3266/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2978, Series Loss: 0.0060, Class Loss: 0.2436, Accuracy: 0.2716\n",
      "Epoch [3267/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2976, Series Loss: 0.0061, Class Loss: 0.2433, Accuracy: 0.3025\n",
      "Epoch [3268/4000], Discriminator Loss: 0.0927, Generator Loss: 0.2977, Series Loss: 0.0060, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3269/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2976, Series Loss: 0.0060, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [3270/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2974, Series Loss: 0.0060, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3271/4000], Discriminator Loss: 0.0925, Generator Loss: 0.2977, Series Loss: 0.0061, Class Loss: 0.2436, Accuracy: 0.2778\n",
      "Epoch [3272/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2976, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2654\n",
      "Epoch [3273/4000], Discriminator Loss: 0.0925, Generator Loss: 0.2977, Series Loss: 0.0060, Class Loss: 0.2435, Accuracy: 0.2778\n",
      "Epoch [3274/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2977, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3275/4000], Discriminator Loss: 0.0927, Generator Loss: 0.2978, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3276/4000], Discriminator Loss: 0.0927, Generator Loss: 0.2978, Series Loss: 0.0060, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [3277/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2978, Series Loss: 0.0061, Class Loss: 0.2437, Accuracy: 0.2778\n",
      "Epoch [3278/4000], Discriminator Loss: 0.0925, Generator Loss: 0.2977, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3279/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2973, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3280/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2975, Series Loss: 0.0061, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [3281/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2979, Series Loss: 0.0060, Class Loss: 0.2436, Accuracy: 0.2778\n",
      "Epoch [3282/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2974, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3283/4000], Discriminator Loss: 0.0925, Generator Loss: 0.2977, Series Loss: 0.0060, Class Loss: 0.2435, Accuracy: 0.2778\n",
      "Epoch [3284/4000], Discriminator Loss: 0.0925, Generator Loss: 0.2975, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.3025\n",
      "Epoch [3285/4000], Discriminator Loss: 0.0923, Generator Loss: 0.2975, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3286/4000], Discriminator Loss: 0.0927, Generator Loss: 0.2978, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.3025\n",
      "Epoch [3287/4000], Discriminator Loss: 0.0925, Generator Loss: 0.2976, Series Loss: 0.0060, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [3288/4000], Discriminator Loss: 0.0927, Generator Loss: 0.2975, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.3086\n",
      "Epoch [3289/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2973, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.3025\n",
      "Epoch [3290/4000], Discriminator Loss: 0.0927, Generator Loss: 0.2973, Series Loss: 0.0061, Class Loss: 0.2433, Accuracy: 0.2716\n",
      "Epoch [3291/4000], Discriminator Loss: 0.0926, Generator Loss: 0.2974, Series Loss: 0.0060, Class Loss: 0.2435, Accuracy: 0.2840\n",
      "Epoch [3292/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2974, Series Loss: 0.0060, Class Loss: 0.2434, Accuracy: 0.2963\n",
      "Epoch [3293/4000], Discriminator Loss: 0.0923, Generator Loss: 0.2975, Series Loss: 0.0060, Class Loss: 0.2434, Accuracy: 0.2963\n",
      "Epoch [3294/4000], Discriminator Loss: 0.0926, Generator Loss: 0.2973, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2840\n",
      "Epoch [3295/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2972, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2778\n",
      "Epoch [3296/4000], Discriminator Loss: 0.0927, Generator Loss: 0.2973, Series Loss: 0.0060, Class Loss: 0.2434, Accuracy: 0.3272\n",
      "Epoch [3297/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2969, Series Loss: 0.0060, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3298/4000], Discriminator Loss: 0.0920, Generator Loss: 0.2978, Series Loss: 0.0060, Class Loss: 0.2435, Accuracy: 0.2716\n",
      "Epoch [3299/4000], Discriminator Loss: 0.0925, Generator Loss: 0.2978, Series Loss: 0.0061, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [3300/4000], Discriminator Loss: 0.0925, Generator Loss: 0.2977, Series Loss: 0.0060, Class Loss: 0.2435, Accuracy: 0.2840\n",
      "Epoch [3301/4000], Discriminator Loss: 0.0922, Generator Loss: 0.2976, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3302/4000], Discriminator Loss: 0.0921, Generator Loss: 0.2977, Series Loss: 0.0059, Class Loss: 0.2435, Accuracy: 0.3457\n",
      "Epoch [3303/4000], Discriminator Loss: 0.0923, Generator Loss: 0.2978, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2840\n",
      "Epoch [3304/4000], Discriminator Loss: 0.0924, Generator Loss: 0.2976, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.2593\n",
      "Epoch [3305/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2980, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3306/4000], Discriminator Loss: 0.0925, Generator Loss: 0.2978, Series Loss: 0.0060, Class Loss: 0.2435, Accuracy: 0.2840\n",
      "Epoch [3307/4000], Discriminator Loss: 0.0927, Generator Loss: 0.2980, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3308/4000], Discriminator Loss: 0.0923, Generator Loss: 0.2981, Series Loss: 0.0060, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [3309/4000], Discriminator Loss: 0.0924, Generator Loss: 0.2980, Series Loss: 0.0060, Class Loss: 0.2434, Accuracy: 0.2963\n",
      "Epoch [3310/4000], Discriminator Loss: 0.0927, Generator Loss: 0.2978, Series Loss: 0.0060, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3311/4000], Discriminator Loss: 0.0926, Generator Loss: 0.2979, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3312/4000], Discriminator Loss: 0.0920, Generator Loss: 0.2981, Series Loss: 0.0061, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [3313/4000], Discriminator Loss: 0.0927, Generator Loss: 0.2979, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [3314/4000], Discriminator Loss: 0.0923, Generator Loss: 0.2976, Series Loss: 0.0060, Class Loss: 0.2434, Accuracy: 0.2716\n",
      "Epoch [3315/4000], Discriminator Loss: 0.0926, Generator Loss: 0.2979, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.3086\n",
      "Epoch [3316/4000], Discriminator Loss: 0.0926, Generator Loss: 0.2982, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.3210\n",
      "Epoch [3317/4000], Discriminator Loss: 0.0924, Generator Loss: 0.2978, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.2963\n",
      "Epoch [3318/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2979, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.2963\n",
      "Epoch [3319/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2978, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.3025\n",
      "Epoch [3320/4000], Discriminator Loss: 0.0924, Generator Loss: 0.2980, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.2778\n",
      "Epoch [3321/4000], Discriminator Loss: 0.0925, Generator Loss: 0.2979, Series Loss: 0.0062, Class Loss: 0.2434, Accuracy: 0.2963\n",
      "Epoch [3322/4000], Discriminator Loss: 0.0925, Generator Loss: 0.2982, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3323/4000], Discriminator Loss: 0.0925, Generator Loss: 0.2978, Series Loss: 0.0060, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3324/4000], Discriminator Loss: 0.0923, Generator Loss: 0.2976, Series Loss: 0.0061, Class Loss: 0.2433, Accuracy: 0.3025\n",
      "Epoch [3325/4000], Discriminator Loss: 0.0923, Generator Loss: 0.2980, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3326/4000], Discriminator Loss: 0.0926, Generator Loss: 0.2978, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3327/4000], Discriminator Loss: 0.0926, Generator Loss: 0.2980, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3328/4000], Discriminator Loss: 0.0926, Generator Loss: 0.2977, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.2778\n",
      "Epoch [3329/4000], Discriminator Loss: 0.0925, Generator Loss: 0.2978, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3330/4000], Discriminator Loss: 0.0922, Generator Loss: 0.2980, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2778\n",
      "Epoch [3331/4000], Discriminator Loss: 0.0925, Generator Loss: 0.2984, Series Loss: 0.0061, Class Loss: 0.2433, Accuracy: 0.3025\n",
      "Epoch [3332/4000], Discriminator Loss: 0.0923, Generator Loss: 0.2980, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3333/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2978, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.3086\n",
      "Epoch [3334/4000], Discriminator Loss: 0.0922, Generator Loss: 0.2979, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3335/4000], Discriminator Loss: 0.0925, Generator Loss: 0.2980, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3336/4000], Discriminator Loss: 0.0924, Generator Loss: 0.2980, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [3337/4000], Discriminator Loss: 0.0923, Generator Loss: 0.2979, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.3025\n",
      "Epoch [3338/4000], Discriminator Loss: 0.0923, Generator Loss: 0.2980, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3339/4000], Discriminator Loss: 0.0922, Generator Loss: 0.2981, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.3148\n",
      "Epoch [3340/4000], Discriminator Loss: 0.0923, Generator Loss: 0.2985, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3341/4000], Discriminator Loss: 0.0925, Generator Loss: 0.2981, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.2778\n",
      "Epoch [3342/4000], Discriminator Loss: 0.0926, Generator Loss: 0.2982, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3272\n",
      "Epoch [3343/4000], Discriminator Loss: 0.0918, Generator Loss: 0.2984, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.3025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3344/4000], Discriminator Loss: 0.0922, Generator Loss: 0.2980, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3345/4000], Discriminator Loss: 0.0920, Generator Loss: 0.2978, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3346/4000], Discriminator Loss: 0.0922, Generator Loss: 0.2977, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3347/4000], Discriminator Loss: 0.0921, Generator Loss: 0.2977, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2840\n",
      "Epoch [3348/4000], Discriminator Loss: 0.0922, Generator Loss: 0.2979, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3148\n",
      "Epoch [3349/4000], Discriminator Loss: 0.0920, Generator Loss: 0.2978, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3350/4000], Discriminator Loss: 0.0923, Generator Loss: 0.2977, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.3025\n",
      "Epoch [3351/4000], Discriminator Loss: 0.0922, Generator Loss: 0.2978, Series Loss: 0.0060, Class Loss: 0.2434, Accuracy: 0.3148\n",
      "Epoch [3352/4000], Discriminator Loss: 0.0923, Generator Loss: 0.2980, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3353/4000], Discriminator Loss: 0.0924, Generator Loss: 0.2985, Series Loss: 0.0061, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [3354/4000], Discriminator Loss: 0.0922, Generator Loss: 0.2977, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.2963\n",
      "Epoch [3355/4000], Discriminator Loss: 0.0925, Generator Loss: 0.2977, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.3086\n",
      "Epoch [3356/4000], Discriminator Loss: 0.0921, Generator Loss: 0.2979, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3272\n",
      "Epoch [3357/4000], Discriminator Loss: 0.0925, Generator Loss: 0.2978, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3358/4000], Discriminator Loss: 0.0918, Generator Loss: 0.2979, Series Loss: 0.0060, Class Loss: 0.2435, Accuracy: 0.3210\n",
      "Epoch [3359/4000], Discriminator Loss: 0.0926, Generator Loss: 0.2972, Series Loss: 0.0060, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [3360/4000], Discriminator Loss: 0.0927, Generator Loss: 0.2976, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3361/4000], Discriminator Loss: 0.0925, Generator Loss: 0.2976, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.3148\n",
      "Epoch [3362/4000], Discriminator Loss: 0.0923, Generator Loss: 0.2981, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [3363/4000], Discriminator Loss: 0.0927, Generator Loss: 0.2977, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3364/4000], Discriminator Loss: 0.0920, Generator Loss: 0.2980, Series Loss: 0.0060, Class Loss: 0.2435, Accuracy: 0.3148\n",
      "Epoch [3365/4000], Discriminator Loss: 0.0925, Generator Loss: 0.2978, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [3366/4000], Discriminator Loss: 0.0923, Generator Loss: 0.2979, Series Loss: 0.0061, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [3367/4000], Discriminator Loss: 0.0924, Generator Loss: 0.2980, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [3368/4000], Discriminator Loss: 0.0925, Generator Loss: 0.2981, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3369/4000], Discriminator Loss: 0.0923, Generator Loss: 0.2980, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3370/4000], Discriminator Loss: 0.0925, Generator Loss: 0.2977, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.2901\n",
      "Epoch [3371/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2981, Series Loss: 0.0060, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [3372/4000], Discriminator Loss: 0.0926, Generator Loss: 0.2978, Series Loss: 0.0062, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [3373/4000], Discriminator Loss: 0.0927, Generator Loss: 0.2978, Series Loss: 0.0062, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [3374/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2972, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.2963\n",
      "Epoch [3375/4000], Discriminator Loss: 0.0927, Generator Loss: 0.2973, Series Loss: 0.0060, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [3376/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2975, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.2901\n",
      "Epoch [3377/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2979, Series Loss: 0.0061, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [3378/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2975, Series Loss: 0.0061, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [3379/4000], Discriminator Loss: 0.0927, Generator Loss: 0.2975, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3380/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2978, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3148\n",
      "Epoch [3381/4000], Discriminator Loss: 0.0927, Generator Loss: 0.2982, Series Loss: 0.0062, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [3382/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2977, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3383/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2977, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3384/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2982, Series Loss: 0.0063, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [3385/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2979, Series Loss: 0.0062, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [3386/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2979, Series Loss: 0.0061, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3387/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2973, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2716\n",
      "Epoch [3388/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2974, Series Loss: 0.0062, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [3389/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2974, Series Loss: 0.0062, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [3390/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2972, Series Loss: 0.0062, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3391/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2973, Series Loss: 0.0063, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [3392/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2971, Series Loss: 0.0061, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [3393/4000], Discriminator Loss: 0.0947, Generator Loss: 0.2966, Series Loss: 0.0062, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3394/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2971, Series Loss: 0.0061, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [3395/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2974, Series Loss: 0.0061, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3396/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2973, Series Loss: 0.0061, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [3397/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2977, Series Loss: 0.0059, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [3398/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2971, Series Loss: 0.0061, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [3399/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2968, Series Loss: 0.0060, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3400/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2967, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3401/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2966, Series Loss: 0.0060, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3402/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2966, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3403/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2971, Series Loss: 0.0060, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [3404/4000], Discriminator Loss: 0.0944, Generator Loss: 0.2966, Series Loss: 0.0060, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [3405/4000], Discriminator Loss: 0.0946, Generator Loss: 0.2966, Series Loss: 0.0060, Class Loss: 0.2437, Accuracy: 0.2778\n",
      "Epoch [3406/4000], Discriminator Loss: 0.0945, Generator Loss: 0.2968, Series Loss: 0.0060, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [3407/4000], Discriminator Loss: 0.0944, Generator Loss: 0.2969, Series Loss: 0.0060, Class Loss: 0.2437, Accuracy: 0.2901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3408/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2972, Series Loss: 0.0060, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [3409/4000], Discriminator Loss: 0.0946, Generator Loss: 0.2972, Series Loss: 0.0061, Class Loss: 0.2434, Accuracy: 0.3086\n",
      "Epoch [3410/4000], Discriminator Loss: 0.0946, Generator Loss: 0.2971, Series Loss: 0.0060, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3411/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2973, Series Loss: 0.0061, Class Loss: 0.2435, Accuracy: 0.2840\n",
      "Epoch [3412/4000], Discriminator Loss: 0.0944, Generator Loss: 0.2972, Series Loss: 0.0060, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3413/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2976, Series Loss: 0.0060, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [3414/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2972, Series Loss: 0.0059, Class Loss: 0.2436, Accuracy: 0.2716\n",
      "Epoch [3415/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2974, Series Loss: 0.0060, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [3416/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2964, Series Loss: 0.0060, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3417/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2964, Series Loss: 0.0060, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [3418/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2965, Series Loss: 0.0059, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [3419/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2970, Series Loss: 0.0060, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [3420/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2969, Series Loss: 0.0061, Class Loss: 0.2438, Accuracy: 0.3025\n",
      "Epoch [3421/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2975, Series Loss: 0.0060, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [3422/4000], Discriminator Loss: 0.0945, Generator Loss: 0.2967, Series Loss: 0.0059, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [3423/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2972, Series Loss: 0.0060, Class Loss: 0.2435, Accuracy: 0.2840\n",
      "Epoch [3424/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2972, Series Loss: 0.0060, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [3425/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2968, Series Loss: 0.0059, Class Loss: 0.2435, Accuracy: 0.2840\n",
      "Epoch [3426/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2968, Series Loss: 0.0059, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3427/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2971, Series Loss: 0.0060, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [3428/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2973, Series Loss: 0.0059, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [3429/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2974, Series Loss: 0.0060, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3430/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2973, Series Loss: 0.0060, Class Loss: 0.2436, Accuracy: 0.3210\n",
      "Epoch [3431/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2971, Series Loss: 0.0060, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3432/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2970, Series Loss: 0.0059, Class Loss: 0.2435, Accuracy: 0.2840\n",
      "Epoch [3433/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2973, Series Loss: 0.0060, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [3434/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2967, Series Loss: 0.0059, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3435/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2967, Series Loss: 0.0060, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3436/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2970, Series Loss: 0.0059, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3437/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2971, Series Loss: 0.0059, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3438/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2971, Series Loss: 0.0059, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [3439/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2966, Series Loss: 0.0059, Class Loss: 0.2436, Accuracy: 0.2778\n",
      "Epoch [3440/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2965, Series Loss: 0.0059, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3441/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2966, Series Loss: 0.0059, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [3442/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2967, Series Loss: 0.0060, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [3443/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2969, Series Loss: 0.0059, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [3444/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2968, Series Loss: 0.0059, Class Loss: 0.2435, Accuracy: 0.2840\n",
      "Epoch [3445/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2968, Series Loss: 0.0060, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3446/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2973, Series Loss: 0.0059, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3447/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2972, Series Loss: 0.0060, Class Loss: 0.2437, Accuracy: 0.2716\n",
      "Epoch [3448/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2971, Series Loss: 0.0060, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3449/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2968, Series Loss: 0.0060, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3450/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2969, Series Loss: 0.0060, Class Loss: 0.2437, Accuracy: 0.2778\n",
      "Epoch [3451/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2966, Series Loss: 0.0059, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3452/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2965, Series Loss: 0.0059, Class Loss: 0.2435, Accuracy: 0.2840\n",
      "Epoch [3453/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2969, Series Loss: 0.0059, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3454/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2968, Series Loss: 0.0059, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3455/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2967, Series Loss: 0.0060, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [3456/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2970, Series Loss: 0.0059, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [3457/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2965, Series Loss: 0.0059, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3458/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2966, Series Loss: 0.0059, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3459/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2968, Series Loss: 0.0060, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3460/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2966, Series Loss: 0.0059, Class Loss: 0.2435, Accuracy: 0.2716\n",
      "Epoch [3461/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2972, Series Loss: 0.0060, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [3462/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2972, Series Loss: 0.0059, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3463/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2970, Series Loss: 0.0060, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [3464/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2974, Series Loss: 0.0060, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3465/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2971, Series Loss: 0.0059, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3466/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2972, Series Loss: 0.0058, Class Loss: 0.2435, Accuracy: 0.2778\n",
      "Epoch [3467/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2974, Series Loss: 0.0059, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3468/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2966, Series Loss: 0.0059, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3469/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2972, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [3470/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2970, Series Loss: 0.0059, Class Loss: 0.2437, Accuracy: 0.2654\n",
      "Epoch [3471/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2975, Series Loss: 0.0059, Class Loss: 0.2437, Accuracy: 0.2654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3472/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2971, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3473/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2968, Series Loss: 0.0059, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3474/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2967, Series Loss: 0.0060, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [3475/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2966, Series Loss: 0.0059, Class Loss: 0.2434, Accuracy: 0.2716\n",
      "Epoch [3476/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2967, Series Loss: 0.0058, Class Loss: 0.2435, Accuracy: 0.2778\n",
      "Epoch [3477/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2966, Series Loss: 0.0058, Class Loss: 0.2434, Accuracy: 0.2901\n",
      "Epoch [3478/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2968, Series Loss: 0.0057, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3479/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2966, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [3480/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2970, Series Loss: 0.0057, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3481/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2972, Series Loss: 0.0059, Class Loss: 0.2435, Accuracy: 0.2840\n",
      "Epoch [3482/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2969, Series Loss: 0.0059, Class Loss: 0.2435, Accuracy: 0.2778\n",
      "Epoch [3483/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2967, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [3484/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2967, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [3485/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2970, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [3486/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2967, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2716\n",
      "Epoch [3487/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2969, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2840\n",
      "Epoch [3488/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2974, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2840\n",
      "Epoch [3489/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2970, Series Loss: 0.0058, Class Loss: 0.2435, Accuracy: 0.2778\n",
      "Epoch [3490/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2968, Series Loss: 0.0059, Class Loss: 0.2435, Accuracy: 0.2840\n",
      "Epoch [3491/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2966, Series Loss: 0.0058, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3492/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2964, Series Loss: 0.0059, Class Loss: 0.2434, Accuracy: 0.3086\n",
      "Epoch [3493/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2968, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [3494/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2967, Series Loss: 0.0058, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3495/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2968, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3496/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2968, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.3272\n",
      "Epoch [3497/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2969, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [3498/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2967, Series Loss: 0.0057, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3499/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2966, Series Loss: 0.0058, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [3500/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2966, Series Loss: 0.0059, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [3501/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2970, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2840\n",
      "Epoch [3502/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2968, Series Loss: 0.0059, Class Loss: 0.2436, Accuracy: 0.2593\n",
      "Epoch [3503/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2967, Series Loss: 0.0058, Class Loss: 0.2435, Accuracy: 0.3272\n",
      "Epoch [3504/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2967, Series Loss: 0.0057, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3505/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2966, Series Loss: 0.0059, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3506/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2967, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.3210\n",
      "Epoch [3507/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2966, Series Loss: 0.0057, Class Loss: 0.2435, Accuracy: 0.2593\n",
      "Epoch [3508/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2962, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2778\n",
      "Epoch [3509/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2962, Series Loss: 0.0058, Class Loss: 0.2434, Accuracy: 0.3025\n",
      "Epoch [3510/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2963, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2778\n",
      "Epoch [3511/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2969, Series Loss: 0.0058, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3512/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2966, Series Loss: 0.0056, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [3513/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2968, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [3514/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2965, Series Loss: 0.0058, Class Loss: 0.2435, Accuracy: 0.2654\n",
      "Epoch [3515/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2964, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [3516/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2965, Series Loss: 0.0058, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3517/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2968, Series Loss: 0.0058, Class Loss: 0.2435, Accuracy: 0.2716\n",
      "Epoch [3518/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2967, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [3519/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2968, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2840\n",
      "Epoch [3520/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2965, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2778\n",
      "Epoch [3521/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2965, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [3522/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2973, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [3523/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2971, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2716\n",
      "Epoch [3524/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2973, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3525/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2972, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3526/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2969, Series Loss: 0.0058, Class Loss: 0.2435, Accuracy: 0.2716\n",
      "Epoch [3527/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2973, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2778\n",
      "Epoch [3528/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2973, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2778\n",
      "Epoch [3529/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2969, Series Loss: 0.0059, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3530/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2971, Series Loss: 0.0059, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [3531/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2967, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [3532/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2966, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [3533/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2969, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [3534/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2970, Series Loss: 0.0059, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3535/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2968, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3536/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2966, Series Loss: 0.0058, Class Loss: 0.2435, Accuracy: 0.2840\n",
      "Epoch [3537/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2967, Series Loss: 0.0058, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3538/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2969, Series Loss: 0.0057, Class Loss: 0.2435, Accuracy: 0.3148\n",
      "Epoch [3539/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2967, Series Loss: 0.0058, Class Loss: 0.2435, Accuracy: 0.2840\n",
      "Epoch [3540/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2968, Series Loss: 0.0057, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3541/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2973, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.2654\n",
      "Epoch [3542/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2968, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [3543/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2963, Series Loss: 0.0058, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3544/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2968, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2778\n",
      "Epoch [3545/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2968, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [3546/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2969, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2654\n",
      "Epoch [3547/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2976, Series Loss: 0.0058, Class Loss: 0.2435, Accuracy: 0.2778\n",
      "Epoch [3548/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2973, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.2778\n",
      "Epoch [3549/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2973, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2778\n",
      "Epoch [3550/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2971, Series Loss: 0.0056, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [3551/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2974, Series Loss: 0.0058, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3552/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2978, Series Loss: 0.0058, Class Loss: 0.2435, Accuracy: 0.2840\n",
      "Epoch [3553/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2976, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2840\n",
      "Epoch [3554/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2975, Series Loss: 0.0059, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [3555/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2975, Series Loss: 0.0058, Class Loss: 0.2439, Accuracy: 0.2593\n",
      "Epoch [3556/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2971, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3557/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2973, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [3558/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2973, Series Loss: 0.0058, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3559/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2973, Series Loss: 0.0057, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3560/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2968, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2778\n",
      "Epoch [3561/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2969, Series Loss: 0.0057, Class Loss: 0.2435, Accuracy: 0.3210\n",
      "Epoch [3562/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2969, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [3563/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2972, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3564/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2972, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2716\n",
      "Epoch [3565/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2967, Series Loss: 0.0058, Class Loss: 0.2435, Accuracy: 0.2778\n",
      "Epoch [3566/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2968, Series Loss: 0.0057, Class Loss: 0.2435, Accuracy: 0.2778\n",
      "Epoch [3567/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2971, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.3519\n",
      "Epoch [3568/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2967, Series Loss: 0.0057, Class Loss: 0.2434, Accuracy: 0.2840\n",
      "Epoch [3569/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2968, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.3210\n",
      "Epoch [3570/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2973, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [3571/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2970, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.3210\n",
      "Epoch [3572/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2967, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3573/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2968, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2778\n",
      "Epoch [3574/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2971, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.3210\n",
      "Epoch [3575/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2971, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [3576/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2975, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [3577/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2968, Series Loss: 0.0058, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3578/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2966, Series Loss: 0.0057, Class Loss: 0.2435, Accuracy: 0.2840\n",
      "Epoch [3579/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2970, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [3580/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2969, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [3581/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2965, Series Loss: 0.0058, Class Loss: 0.2435, Accuracy: 0.3272\n",
      "Epoch [3582/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2974, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [3583/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2965, Series Loss: 0.0057, Class Loss: 0.2435, Accuracy: 0.3086\n",
      "Epoch [3584/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2969, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2593\n",
      "Epoch [3585/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2971, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.3395\n",
      "Epoch [3586/4000], Discriminator Loss: 0.0925, Generator Loss: 0.2974, Series Loss: 0.0056, Class Loss: 0.2435, Accuracy: 0.3148\n",
      "Epoch [3587/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2972, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [3588/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2970, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.3210\n",
      "Epoch [3589/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2967, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [3590/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2971, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3591/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2974, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3592/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2977, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [3593/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2976, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.3210\n",
      "Epoch [3594/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2976, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2716\n",
      "Epoch [3595/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2970, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3596/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2969, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.3272\n",
      "Epoch [3597/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2970, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.3210\n",
      "Epoch [3598/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2974, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [3599/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2971, Series Loss: 0.0059, Class Loss: 0.2435, Accuracy: 0.2654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3600/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2971, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3601/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2967, Series Loss: 0.0058, Class Loss: 0.2435, Accuracy: 0.2778\n",
      "Epoch [3602/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2972, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2778\n",
      "Epoch [3603/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2968, Series Loss: 0.0058, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3604/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2969, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2593\n",
      "Epoch [3605/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2970, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [3606/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2973, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [3607/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2969, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3608/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2972, Series Loss: 0.0059, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [3609/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2970, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2716\n",
      "Epoch [3610/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2973, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [3611/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2972, Series Loss: 0.0058, Class Loss: 0.2435, Accuracy: 0.2840\n",
      "Epoch [3612/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2975, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2716\n",
      "Epoch [3613/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2973, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [3614/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2973, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2716\n",
      "Epoch [3615/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2973, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [3616/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2971, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3617/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2967, Series Loss: 0.0058, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3618/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2970, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2778\n",
      "Epoch [3619/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2969, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2716\n",
      "Epoch [3620/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2971, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2778\n",
      "Epoch [3621/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2967, Series Loss: 0.0057, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3622/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2969, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3623/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2968, Series Loss: 0.0057, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3624/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2969, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2778\n",
      "Epoch [3625/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2970, Series Loss: 0.0057, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3626/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2969, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [3627/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2969, Series Loss: 0.0058, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3628/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2974, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [3629/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2973, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [3630/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2974, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2778\n",
      "Epoch [3631/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2970, Series Loss: 0.0058, Class Loss: 0.2434, Accuracy: 0.2901\n",
      "Epoch [3632/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2972, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2778\n",
      "Epoch [3633/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2970, Series Loss: 0.0057, Class Loss: 0.2435, Accuracy: 0.2716\n",
      "Epoch [3634/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2980, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [3635/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2974, Series Loss: 0.0058, Class Loss: 0.2435, Accuracy: 0.2778\n",
      "Epoch [3636/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2972, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [3637/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2970, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2654\n",
      "Epoch [3638/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2973, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2654\n",
      "Epoch [3639/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2970, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [3640/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2969, Series Loss: 0.0058, Class Loss: 0.2438, Accuracy: 0.2963\n",
      "Epoch [3641/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2969, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [3642/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2973, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [3643/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2967, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [3644/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2967, Series Loss: 0.0058, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3645/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2970, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2654\n",
      "Epoch [3646/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2970, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3647/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2968, Series Loss: 0.0057, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3648/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2971, Series Loss: 0.0057, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3649/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2971, Series Loss: 0.0056, Class Loss: 0.2437, Accuracy: 0.2840\n",
      "Epoch [3650/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2972, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [3651/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2975, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3652/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2968, Series Loss: 0.0057, Class Loss: 0.2435, Accuracy: 0.3210\n",
      "Epoch [3653/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2970, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2654\n",
      "Epoch [3654/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2966, Series Loss: 0.0057, Class Loss: 0.2435, Accuracy: 0.3148\n",
      "Epoch [3655/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2969, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.3210\n",
      "Epoch [3656/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2971, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [3657/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2968, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.2716\n",
      "Epoch [3658/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2969, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3659/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2969, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [3660/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2965, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.2840\n",
      "Epoch [3661/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2965, Series Loss: 0.0056, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3662/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2966, Series Loss: 0.0056, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [3663/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2965, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3664/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2968, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [3665/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2969, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [3666/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2971, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [3667/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2970, Series Loss: 0.0056, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [3668/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2975, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [3669/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2974, Series Loss: 0.0056, Class Loss: 0.2436, Accuracy: 0.3272\n",
      "Epoch [3670/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2974, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.2716\n",
      "Epoch [3671/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2974, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.2778\n",
      "Epoch [3672/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2972, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [3673/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2972, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [3674/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2973, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [3675/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2970, Series Loss: 0.0056, Class Loss: 0.2436, Accuracy: 0.3395\n",
      "Epoch [3676/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2971, Series Loss: 0.0057, Class Loss: 0.2438, Accuracy: 0.2963\n",
      "Epoch [3677/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2976, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [3678/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2974, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2778\n",
      "Epoch [3679/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2971, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [3680/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2967, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.2716\n",
      "Epoch [3681/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2974, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [3682/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2967, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3683/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2968, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [3684/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2967, Series Loss: 0.0058, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3685/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2975, Series Loss: 0.0057, Class Loss: 0.2435, Accuracy: 0.2840\n",
      "Epoch [3686/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2970, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [3687/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2968, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2654\n",
      "Epoch [3688/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2963, Series Loss: 0.0057, Class Loss: 0.2435, Accuracy: 0.2840\n",
      "Epoch [3689/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2965, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.2840\n",
      "Epoch [3690/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2972, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.2593\n",
      "Epoch [3691/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2969, Series Loss: 0.0057, Class Loss: 0.2435, Accuracy: 0.2778\n",
      "Epoch [3692/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2968, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.2840\n",
      "Epoch [3693/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2972, Series Loss: 0.0057, Class Loss: 0.2438, Accuracy: 0.3148\n",
      "Epoch [3694/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2968, Series Loss: 0.0057, Class Loss: 0.2435, Accuracy: 0.2778\n",
      "Epoch [3695/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2966, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2654\n",
      "Epoch [3696/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2970, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [3697/4000], Discriminator Loss: 0.0944, Generator Loss: 0.2968, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2840\n",
      "Epoch [3698/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2972, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.2840\n",
      "Epoch [3699/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2972, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2654\n",
      "Epoch [3700/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2975, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2840\n",
      "Epoch [3701/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2972, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3702/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2973, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [3703/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2973, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [3704/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2972, Series Loss: 0.0059, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3705/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2969, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3706/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2974, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2840\n",
      "Epoch [3707/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2971, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3708/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2971, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.2778\n",
      "Epoch [3709/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2971, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.2840\n",
      "Epoch [3710/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2974, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [3711/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2969, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [3712/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2971, Series Loss: 0.0058, Class Loss: 0.2438, Accuracy: 0.2407\n",
      "Epoch [3713/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2974, Series Loss: 0.0058, Class Loss: 0.2439, Accuracy: 0.2778\n",
      "Epoch [3714/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2971, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2716\n",
      "Epoch [3715/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2974, Series Loss: 0.0058, Class Loss: 0.2438, Accuracy: 0.2840\n",
      "Epoch [3716/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2971, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [3717/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2972, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [3718/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2970, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [3719/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2974, Series Loss: 0.0058, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3720/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2972, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [3721/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2968, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3722/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2964, Series Loss: 0.0057, Class Loss: 0.2435, Accuracy: 0.2778\n",
      "Epoch [3723/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2971, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [3724/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2966, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2716\n",
      "Epoch [3725/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2968, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2778\n",
      "Epoch [3726/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2971, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2778\n",
      "Epoch [3727/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2966, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3728/4000], Discriminator Loss: 0.0930, Generator Loss: 0.2968, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3729/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2966, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [3730/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2971, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [3731/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2971, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [3732/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2977, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [3733/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2971, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2840\n",
      "Epoch [3734/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2971, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3735/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2969, Series Loss: 0.0058, Class Loss: 0.2435, Accuracy: 0.2716\n",
      "Epoch [3736/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2969, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2778\n",
      "Epoch [3737/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2970, Series Loss: 0.0058, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3738/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2976, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [3739/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2980, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [3740/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2973, Series Loss: 0.0059, Class Loss: 0.2438, Accuracy: 0.2654\n",
      "Epoch [3741/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2974, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [3742/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2972, Series Loss: 0.0059, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [3743/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2966, Series Loss: 0.0058, Class Loss: 0.2435, Accuracy: 0.3148\n",
      "Epoch [3744/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2970, Series Loss: 0.0059, Class Loss: 0.2437, Accuracy: 0.2840\n",
      "Epoch [3745/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2973, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.3086\n",
      "Epoch [3746/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2977, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2778\n",
      "Epoch [3747/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2972, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [3748/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2972, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.2840\n",
      "Epoch [3749/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2978, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [3750/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2973, Series Loss: 0.0058, Class Loss: 0.2438, Accuracy: 0.2531\n",
      "Epoch [3751/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2972, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2654\n",
      "Epoch [3752/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2968, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2654\n",
      "Epoch [3753/4000], Discriminator Loss: 0.0928, Generator Loss: 0.2975, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2654\n",
      "Epoch [3754/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2968, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2778\n",
      "Epoch [3755/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2974, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [3756/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2972, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2778\n",
      "Epoch [3757/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2977, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2778\n",
      "Epoch [3758/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2969, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [3759/4000], Discriminator Loss: 0.0931, Generator Loss: 0.2973, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2778\n",
      "Epoch [3760/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2967, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [3761/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2973, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [3762/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2969, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2778\n",
      "Epoch [3763/4000], Discriminator Loss: 0.0932, Generator Loss: 0.2971, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [3764/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2971, Series Loss: 0.0057, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3765/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2971, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2654\n",
      "Epoch [3766/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2971, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [3767/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2965, Series Loss: 0.0058, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3768/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2974, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.2716\n",
      "Epoch [3769/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2972, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2778\n",
      "Epoch [3770/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2971, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [3771/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2971, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [3772/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2974, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3773/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2966, Series Loss: 0.0057, Class Loss: 0.2434, Accuracy: 0.2716\n",
      "Epoch [3774/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2969, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [3775/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2974, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [3776/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2975, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.2778\n",
      "Epoch [3777/4000], Discriminator Loss: 0.0929, Generator Loss: 0.2973, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.2840\n",
      "Epoch [3778/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2972, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [3779/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2970, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2716\n",
      "Epoch [3780/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2974, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [3781/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2972, Series Loss: 0.0058, Class Loss: 0.2435, Accuracy: 0.3025\n",
      "Epoch [3782/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2970, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2469\n",
      "Epoch [3783/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2974, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2778\n",
      "Epoch [3784/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2973, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2778\n",
      "Epoch [3785/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2976, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2716\n",
      "Epoch [3786/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2971, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2778\n",
      "Epoch [3787/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2977, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2840\n",
      "Epoch [3788/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2973, Series Loss: 0.0058, Class Loss: 0.2438, Accuracy: 0.2716\n",
      "Epoch [3789/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2971, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [3790/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2969, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [3791/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2971, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3792/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2973, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [3793/4000], Discriminator Loss: 0.0946, Generator Loss: 0.2971, Series Loss: 0.0058, Class Loss: 0.2438, Accuracy: 0.2593\n",
      "Epoch [3794/4000], Discriminator Loss: 0.0944, Generator Loss: 0.2969, Series Loss: 0.0057, Class Loss: 0.2435, Accuracy: 0.2716\n",
      "Epoch [3795/4000], Discriminator Loss: 0.0946, Generator Loss: 0.2971, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [3796/4000], Discriminator Loss: 0.0944, Generator Loss: 0.2967, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2778\n",
      "Epoch [3797/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2970, Series Loss: 0.0057, Class Loss: 0.2438, Accuracy: 0.2593\n",
      "Epoch [3798/4000], Discriminator Loss: 0.0944, Generator Loss: 0.2971, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2778\n",
      "Epoch [3799/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2970, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.2531\n",
      "Epoch [3800/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2968, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.2593\n",
      "Epoch [3801/4000], Discriminator Loss: 0.0945, Generator Loss: 0.2969, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2778\n",
      "Epoch [3802/4000], Discriminator Loss: 0.0948, Generator Loss: 0.2966, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2778\n",
      "Epoch [3803/4000], Discriminator Loss: 0.0947, Generator Loss: 0.2968, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2593\n",
      "Epoch [3804/4000], Discriminator Loss: 0.0947, Generator Loss: 0.2971, Series Loss: 0.0058, Class Loss: 0.2438, Accuracy: 0.2716\n",
      "Epoch [3805/4000], Discriminator Loss: 0.0945, Generator Loss: 0.2970, Series Loss: 0.0058, Class Loss: 0.2439, Accuracy: 0.2901\n",
      "Epoch [3806/4000], Discriminator Loss: 0.0947, Generator Loss: 0.2967, Series Loss: 0.0058, Class Loss: 0.2439, Accuracy: 0.2778\n",
      "Epoch [3807/4000], Discriminator Loss: 0.0946, Generator Loss: 0.2969, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.2716\n",
      "Epoch [3808/4000], Discriminator Loss: 0.0949, Generator Loss: 0.2966, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2778\n",
      "Epoch [3809/4000], Discriminator Loss: 0.0951, Generator Loss: 0.2965, Series Loss: 0.0057, Class Loss: 0.2435, Accuracy: 0.2840\n",
      "Epoch [3810/4000], Discriminator Loss: 0.0948, Generator Loss: 0.2971, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2840\n",
      "Epoch [3811/4000], Discriminator Loss: 0.0951, Generator Loss: 0.2967, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2593\n",
      "Epoch [3812/4000], Discriminator Loss: 0.0948, Generator Loss: 0.2967, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [3813/4000], Discriminator Loss: 0.0946, Generator Loss: 0.2968, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [3814/4000], Discriminator Loss: 0.0946, Generator Loss: 0.2963, Series Loss: 0.0059, Class Loss: 0.2436, Accuracy: 0.2654\n",
      "Epoch [3815/4000], Discriminator Loss: 0.0948, Generator Loss: 0.2963, Series Loss: 0.0058, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3816/4000], Discriminator Loss: 0.0950, Generator Loss: 0.2962, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2531\n",
      "Epoch [3817/4000], Discriminator Loss: 0.0951, Generator Loss: 0.2963, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3818/4000], Discriminator Loss: 0.0944, Generator Loss: 0.2964, Series Loss: 0.0058, Class Loss: 0.2434, Accuracy: 0.2840\n",
      "Epoch [3819/4000], Discriminator Loss: 0.0955, Generator Loss: 0.2968, Series Loss: 0.0059, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [3820/4000], Discriminator Loss: 0.0951, Generator Loss: 0.2968, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [3821/4000], Discriminator Loss: 0.0945, Generator Loss: 0.2973, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3822/4000], Discriminator Loss: 0.0949, Generator Loss: 0.2968, Series Loss: 0.0058, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3823/4000], Discriminator Loss: 0.0945, Generator Loss: 0.2968, Series Loss: 0.0059, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [3824/4000], Discriminator Loss: 0.0945, Generator Loss: 0.2964, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2654\n",
      "Epoch [3825/4000], Discriminator Loss: 0.0949, Generator Loss: 0.2965, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [3826/4000], Discriminator Loss: 0.0945, Generator Loss: 0.2966, Series Loss: 0.0057, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3827/4000], Discriminator Loss: 0.0951, Generator Loss: 0.2969, Series Loss: 0.0058, Class Loss: 0.2438, Accuracy: 0.2901\n",
      "Epoch [3828/4000], Discriminator Loss: 0.0947, Generator Loss: 0.2966, Series Loss: 0.0058, Class Loss: 0.2438, Accuracy: 0.2840\n",
      "Epoch [3829/4000], Discriminator Loss: 0.0949, Generator Loss: 0.2967, Series Loss: 0.0058, Class Loss: 0.2438, Accuracy: 0.2963\n",
      "Epoch [3830/4000], Discriminator Loss: 0.0945, Generator Loss: 0.2964, Series Loss: 0.0058, Class Loss: 0.2435, Accuracy: 0.2716\n",
      "Epoch [3831/4000], Discriminator Loss: 0.0950, Generator Loss: 0.2965, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [3832/4000], Discriminator Loss: 0.0945, Generator Loss: 0.2966, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [3833/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2968, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2654\n",
      "Epoch [3834/4000], Discriminator Loss: 0.0946, Generator Loss: 0.2973, Series Loss: 0.0058, Class Loss: 0.2435, Accuracy: 0.2778\n",
      "Epoch [3835/4000], Discriminator Loss: 0.0945, Generator Loss: 0.2970, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [3836/4000], Discriminator Loss: 0.0948, Generator Loss: 0.2969, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2716\n",
      "Epoch [3837/4000], Discriminator Loss: 0.0945, Generator Loss: 0.2969, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2654\n",
      "Epoch [3838/4000], Discriminator Loss: 0.0944, Generator Loss: 0.2970, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2778\n",
      "Epoch [3839/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2966, Series Loss: 0.0058, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3840/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2966, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [3841/4000], Discriminator Loss: 0.0947, Generator Loss: 0.2969, Series Loss: 0.0059, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [3842/4000], Discriminator Loss: 0.0945, Generator Loss: 0.2970, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2840\n",
      "Epoch [3843/4000], Discriminator Loss: 0.0945, Generator Loss: 0.2970, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3844/4000], Discriminator Loss: 0.0945, Generator Loss: 0.2974, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.2840\n",
      "Epoch [3845/4000], Discriminator Loss: 0.0946, Generator Loss: 0.2971, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [3846/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2970, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.3148\n",
      "Epoch [3847/4000], Discriminator Loss: 0.0946, Generator Loss: 0.2967, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2716\n",
      "Epoch [3848/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2971, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.3086\n",
      "Epoch [3849/4000], Discriminator Loss: 0.0944, Generator Loss: 0.2967, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [3850/4000], Discriminator Loss: 0.0945, Generator Loss: 0.2966, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3851/4000], Discriminator Loss: 0.0947, Generator Loss: 0.2965, Series Loss: 0.0057, Class Loss: 0.2435, Accuracy: 0.2840\n",
      "Epoch [3852/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2969, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3853/4000], Discriminator Loss: 0.0945, Generator Loss: 0.2968, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.2716\n",
      "Epoch [3854/4000], Discriminator Loss: 0.0945, Generator Loss: 0.2968, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [3855/4000], Discriminator Loss: 0.0948, Generator Loss: 0.2969, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.2901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3856/4000], Discriminator Loss: 0.0946, Generator Loss: 0.2969, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3857/4000], Discriminator Loss: 0.0949, Generator Loss: 0.2969, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3858/4000], Discriminator Loss: 0.0946, Generator Loss: 0.2972, Series Loss: 0.0059, Class Loss: 0.2437, Accuracy: 0.2778\n",
      "Epoch [3859/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2972, Series Loss: 0.0056, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [3860/4000], Discriminator Loss: 0.0946, Generator Loss: 0.2969, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.2840\n",
      "Epoch [3861/4000], Discriminator Loss: 0.0946, Generator Loss: 0.2967, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.2778\n",
      "Epoch [3862/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2970, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [3863/4000], Discriminator Loss: 0.0945, Generator Loss: 0.2967, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2654\n",
      "Epoch [3864/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2971, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2716\n",
      "Epoch [3865/4000], Discriminator Loss: 0.0947, Generator Loss: 0.2965, Series Loss: 0.0058, Class Loss: 0.2438, Accuracy: 0.2840\n",
      "Epoch [3866/4000], Discriminator Loss: 0.0949, Generator Loss: 0.2967, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [3867/4000], Discriminator Loss: 0.0946, Generator Loss: 0.2962, Series Loss: 0.0057, Class Loss: 0.2435, Accuracy: 0.2593\n",
      "Epoch [3868/4000], Discriminator Loss: 0.0948, Generator Loss: 0.2964, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2716\n",
      "Epoch [3869/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2964, Series Loss: 0.0057, Class Loss: 0.2438, Accuracy: 0.2840\n",
      "Epoch [3870/4000], Discriminator Loss: 0.0945, Generator Loss: 0.2967, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [3871/4000], Discriminator Loss: 0.0946, Generator Loss: 0.2966, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [3872/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2966, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2778\n",
      "Epoch [3873/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2969, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [3874/4000], Discriminator Loss: 0.0946, Generator Loss: 0.2971, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3875/4000], Discriminator Loss: 0.0945, Generator Loss: 0.2965, Series Loss: 0.0057, Class Loss: 0.2435, Accuracy: 0.2716\n",
      "Epoch [3876/4000], Discriminator Loss: 0.0946, Generator Loss: 0.2967, Series Loss: 0.0058, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3877/4000], Discriminator Loss: 0.0948, Generator Loss: 0.2970, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [3878/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2972, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3879/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2971, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [3880/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2973, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [3881/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2970, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [3882/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2970, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [3883/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2966, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [3884/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2968, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.3148\n",
      "Epoch [3885/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2969, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2778\n",
      "Epoch [3886/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2966, Series Loss: 0.0057, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3887/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2966, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2778\n",
      "Epoch [3888/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2969, Series Loss: 0.0057, Class Loss: 0.2435, Accuracy: 0.2778\n",
      "Epoch [3889/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2972, Series Loss: 0.0058, Class Loss: 0.2435, Accuracy: 0.2963\n",
      "Epoch [3890/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2969, Series Loss: 0.0058, Class Loss: 0.2435, Accuracy: 0.2716\n",
      "Epoch [3891/4000], Discriminator Loss: 0.0944, Generator Loss: 0.2969, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2716\n",
      "Epoch [3892/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2976, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2716\n",
      "Epoch [3893/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2973, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3894/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2971, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [3895/4000], Discriminator Loss: 0.0945, Generator Loss: 0.2971, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [3896/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2977, Series Loss: 0.0058, Class Loss: 0.2438, Accuracy: 0.2716\n",
      "Epoch [3897/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2971, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2778\n",
      "Epoch [3898/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2972, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2654\n",
      "Epoch [3899/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2974, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2716\n",
      "Epoch [3900/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2970, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2778\n",
      "Epoch [3901/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2971, Series Loss: 0.0059, Class Loss: 0.2436, Accuracy: 0.2716\n",
      "Epoch [3902/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2970, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [3903/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2969, Series Loss: 0.0058, Class Loss: 0.2435, Accuracy: 0.2593\n",
      "Epoch [3904/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2973, Series Loss: 0.0058, Class Loss: 0.2435, Accuracy: 0.2778\n",
      "Epoch [3905/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2971, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2778\n",
      "Epoch [3906/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2972, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2716\n",
      "Epoch [3907/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2972, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2593\n",
      "Epoch [3908/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2971, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [3909/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2970, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2716\n",
      "Epoch [3910/4000], Discriminator Loss: 0.0935, Generator Loss: 0.2965, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2531\n",
      "Epoch [3911/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2968, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3912/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2970, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2778\n",
      "Epoch [3913/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2970, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2716\n",
      "Epoch [3914/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2965, Series Loss: 0.0058, Class Loss: 0.2435, Accuracy: 0.2716\n",
      "Epoch [3915/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2966, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [3916/4000], Discriminator Loss: 0.0947, Generator Loss: 0.2966, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2840\n",
      "Epoch [3917/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2972, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [3918/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2969, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2654\n",
      "Epoch [3919/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2967, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3920/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2968, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2593\n",
      "Epoch [3921/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2968, Series Loss: 0.0056, Class Loss: 0.2436, Accuracy: 0.2654\n",
      "Epoch [3922/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2967, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.3025\n",
      "Epoch [3923/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2972, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.3025\n",
      "Epoch [3924/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2971, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2716\n",
      "Epoch [3925/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2972, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [3926/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2974, Series Loss: 0.0056, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3927/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2972, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2469\n",
      "Epoch [3928/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2971, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.2901\n",
      "Epoch [3929/4000], Discriminator Loss: 0.0945, Generator Loss: 0.2969, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2778\n",
      "Epoch [3930/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2971, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2963\n",
      "Epoch [3931/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2972, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [3932/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2971, Series Loss: 0.0056, Class Loss: 0.2436, Accuracy: 0.2654\n",
      "Epoch [3933/4000], Discriminator Loss: 0.0945, Generator Loss: 0.2969, Series Loss: 0.0057, Class Loss: 0.2435, Accuracy: 0.2716\n",
      "Epoch [3934/4000], Discriminator Loss: 0.0945, Generator Loss: 0.2971, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2778\n",
      "Epoch [3935/4000], Discriminator Loss: 0.0946, Generator Loss: 0.2972, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2901\n",
      "Epoch [3936/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2967, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [3937/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2971, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [3938/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2966, Series Loss: 0.0057, Class Loss: 0.2435, Accuracy: 0.2778\n",
      "Epoch [3939/4000], Discriminator Loss: 0.0950, Generator Loss: 0.2966, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.2778\n",
      "Epoch [3940/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2973, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2531\n",
      "Epoch [3941/4000], Discriminator Loss: 0.0944, Generator Loss: 0.2968, Series Loss: 0.0056, Class Loss: 0.2438, Accuracy: 0.2901\n",
      "Epoch [3942/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2972, Series Loss: 0.0057, Class Loss: 0.2438, Accuracy: 0.2469\n",
      "Epoch [3943/4000], Discriminator Loss: 0.0944, Generator Loss: 0.2969, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.2593\n",
      "Epoch [3944/4000], Discriminator Loss: 0.0945, Generator Loss: 0.2971, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.2716\n",
      "Epoch [3945/4000], Discriminator Loss: 0.0944, Generator Loss: 0.2969, Series Loss: 0.0056, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [3946/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2974, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2716\n",
      "Epoch [3947/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2976, Series Loss: 0.0058, Class Loss: 0.2437, Accuracy: 0.2716\n",
      "Epoch [3948/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2972, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2654\n",
      "Epoch [3949/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2972, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [3950/4000], Discriminator Loss: 0.0945, Generator Loss: 0.2969, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2716\n",
      "Epoch [3951/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2968, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.2778\n",
      "Epoch [3952/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2971, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2778\n",
      "Epoch [3953/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2968, Series Loss: 0.0057, Class Loss: 0.2435, Accuracy: 0.2593\n",
      "Epoch [3954/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2971, Series Loss: 0.0057, Class Loss: 0.2435, Accuracy: 0.2593\n",
      "Epoch [3955/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2970, Series Loss: 0.0058, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [3956/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2965, Series Loss: 0.0057, Class Loss: 0.2435, Accuracy: 0.2778\n",
      "Epoch [3957/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2970, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [3958/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2967, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.2778\n",
      "Epoch [3959/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2966, Series Loss: 0.0056, Class Loss: 0.2437, Accuracy: 0.2778\n",
      "Epoch [3960/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2968, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [3961/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2970, Series Loss: 0.0056, Class Loss: 0.2436, Accuracy: 0.2778\n",
      "Epoch [3962/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2966, Series Loss: 0.0057, Class Loss: 0.2435, Accuracy: 0.2778\n",
      "Epoch [3963/4000], Discriminator Loss: 0.0933, Generator Loss: 0.2966, Series Loss: 0.0056, Class Loss: 0.2436, Accuracy: 0.2593\n",
      "Epoch [3964/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2962, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [3965/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2966, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.2654\n",
      "Epoch [3966/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2963, Series Loss: 0.0055, Class Loss: 0.2435, Accuracy: 0.2716\n",
      "Epoch [3967/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2969, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2716\n",
      "Epoch [3968/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2970, Series Loss: 0.0057, Class Loss: 0.2435, Accuracy: 0.2901\n",
      "Epoch [3969/4000], Discriminator Loss: 0.0944, Generator Loss: 0.2966, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2531\n",
      "Epoch [3970/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2973, Series Loss: 0.0056, Class Loss: 0.2436, Accuracy: 0.2716\n",
      "Epoch [3971/4000], Discriminator Loss: 0.0934, Generator Loss: 0.2972, Series Loss: 0.0057, Class Loss: 0.2435, Accuracy: 0.2778\n",
      "Epoch [3972/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2968, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2593\n",
      "Epoch [3973/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2968, Series Loss: 0.0056, Class Loss: 0.2437, Accuracy: 0.2593\n",
      "Epoch [3974/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2972, Series Loss: 0.0056, Class Loss: 0.2437, Accuracy: 0.2840\n",
      "Epoch [3975/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2968, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.2716\n",
      "Epoch [3976/4000], Discriminator Loss: 0.0944, Generator Loss: 0.2970, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.2654\n",
      "Epoch [3977/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2970, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.2716\n",
      "Epoch [3978/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2969, Series Loss: 0.0056, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [3979/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2972, Series Loss: 0.0056, Class Loss: 0.2436, Accuracy: 0.2778\n",
      "Epoch [3980/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2971, Series Loss: 0.0056, Class Loss: 0.2435, Accuracy: 0.2654\n",
      "Epoch [3981/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2970, Series Loss: 0.0056, Class Loss: 0.2435, Accuracy: 0.2778\n",
      "Epoch [3982/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2970, Series Loss: 0.0056, Class Loss: 0.2436, Accuracy: 0.2963\n",
      "Epoch [3983/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2966, Series Loss: 0.0056, Class Loss: 0.2436, Accuracy: 0.2654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3984/4000], Discriminator Loss: 0.0941, Generator Loss: 0.2968, Series Loss: 0.0057, Class Loss: 0.2437, Accuracy: 0.2531\n",
      "Epoch [3985/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2969, Series Loss: 0.0056, Class Loss: 0.2436, Accuracy: 0.2840\n",
      "Epoch [3986/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2968, Series Loss: 0.0056, Class Loss: 0.2436, Accuracy: 0.2593\n",
      "Epoch [3987/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2970, Series Loss: 0.0056, Class Loss: 0.2435, Accuracy: 0.2654\n",
      "Epoch [3988/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2971, Series Loss: 0.0056, Class Loss: 0.2436, Accuracy: 0.2654\n",
      "Epoch [3989/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2971, Series Loss: 0.0056, Class Loss: 0.2434, Accuracy: 0.2716\n",
      "Epoch [3990/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2969, Series Loss: 0.0056, Class Loss: 0.2437, Accuracy: 0.2716\n",
      "Epoch [3991/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2968, Series Loss: 0.0056, Class Loss: 0.2434, Accuracy: 0.2778\n",
      "Epoch [3992/4000], Discriminator Loss: 0.0942, Generator Loss: 0.2967, Series Loss: 0.0056, Class Loss: 0.2436, Accuracy: 0.2593\n",
      "Epoch [3993/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2967, Series Loss: 0.0055, Class Loss: 0.2436, Accuracy: 0.2654\n",
      "Epoch [3994/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2967, Series Loss: 0.0056, Class Loss: 0.2436, Accuracy: 0.2593\n",
      "Epoch [3995/4000], Discriminator Loss: 0.0943, Generator Loss: 0.2971, Series Loss: 0.0056, Class Loss: 0.2436, Accuracy: 0.2654\n",
      "Epoch [3996/4000], Discriminator Loss: 0.0940, Generator Loss: 0.2970, Series Loss: 0.0057, Class Loss: 0.2436, Accuracy: 0.2593\n",
      "Epoch [3997/4000], Discriminator Loss: 0.0939, Generator Loss: 0.2970, Series Loss: 0.0056, Class Loss: 0.2435, Accuracy: 0.2778\n",
      "Epoch [3998/4000], Discriminator Loss: 0.0937, Generator Loss: 0.2973, Series Loss: 0.0056, Class Loss: 0.2436, Accuracy: 0.2778\n",
      "Epoch [3999/4000], Discriminator Loss: 0.0938, Generator Loss: 0.2966, Series Loss: 0.0056, Class Loss: 0.2436, Accuracy: 0.2654\n",
      "Epoch [4000/4000], Discriminator Loss: 0.0936, Generator Loss: 0.2969, Series Loss: 0.0056, Class Loss: 0.2436, Accuracy: 0.2778\n"
     ]
    }
   ],
   "source": [
    "#训练循环\n",
    "for epoch in range(epoch_num):\n",
    "    #初始化损失值\n",
    "    D_epoch_loss = 0\n",
    "    G_epoch_loss = 0\n",
    "    C_epoch_loss = 0\n",
    "    S_epoch_loss = 0\n",
    "    acc_num = 0\n",
    "    item_num = 0\n",
    "    count = len(dataloader.dataset) #返回批次数\n",
    "    #对数据集进行迭代\n",
    "    for step,(img,label) in enumerate(dataloader):\n",
    "        img =img.to(device) #把数据放到设备上\n",
    "        label = label.to(device)\n",
    "        size = img.shape[0] #img的第一位是size,获取批次的大小\n",
    "        random_seed = torch.randn(size,100,device=device)\n",
    "        item_num += size\n",
    "        \n",
    "        #判别器训练(真实图片的损失和生成图片的损失),损失的构建和优化\n",
    "        d_optimizer.zero_grad()#梯度归零\n",
    "        #判别器对于真实图片产生的损失\n",
    "        real_output = dis(label,img) #判别器输入真实的图片，real_output对真实图片的预测结果\n",
    "        d_real_loss = loss_fn(real_output,\n",
    "                              torch.ones_like(real_output,device=device)\n",
    "                              )\n",
    "        d_real_loss.backward()#计算梯度\n",
    "        \n",
    "        #在生成器上去计算生成器的损失，优化目标是判别器上的参数\n",
    "        generated_img = gen(random_seed,label) #得到生成的图片\n",
    "        \n",
    "        #因为优化目标是判别器，所以对生成器上的优化目标进行截断\n",
    "        generated_img = torch.reshape(generated_img, (generated_img.size(0), generated_img.size(2)))\n",
    "        fake_output = dis(label,generated_img.detach()) #判别器输入生成的图片，fake_output对生成图片的预测;detach会截断梯度，梯度就不会再传递到gen模型中了\n",
    "        #判别器在生成图像上产生的损失\n",
    "        d_fake_loss = loss_fn(fake_output,\n",
    "                              torch.zeros_like(fake_output,device=device)\n",
    "                              )\n",
    "        d_fake_loss.backward()\n",
    "        #判别器损失\n",
    "        disc_loss = d_real_loss + d_fake_loss\n",
    "        #判别器优化\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        \n",
    "        #生成器上损失的构建和优化\n",
    "        g_optimizer.zero_grad() #先将生成器上的梯度置零\n",
    "        fake_output = dis(label,generated_img)\n",
    "        class_output = cls(torch.reshape(generated_img, (generated_img.size(0), 1, generated_img.size(1))))\n",
    "        cls_loss = class_loss(class_output, label)\n",
    "        series_loss = continue_loss(generated_img)\n",
    "        for i in range(size):\n",
    "            if class_output[i][torch.argmax(label[i])] >= 0.5:\n",
    "                acc_num += 1\n",
    "        gen_loss = loss_fn(fake_output,\n",
    "                              torch.ones_like(fake_output,device=device)\n",
    "                          ) + series_loss + cls_loss\n",
    "        gen_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        #累计每一个批次的loss\n",
    "        with torch.no_grad():\n",
    "            D_epoch_loss +=disc_loss\n",
    "            G_epoch_loss +=gen_loss\n",
    "            S_epoch_loss +=series_loss\n",
    "            C_epoch_loss +=cls_loss\n",
    "    #求平均损失\n",
    "    with torch.no_grad():\n",
    "        D_epoch_loss /=count\n",
    "        G_epoch_loss /=count\n",
    "        S_epoch_loss /=(count * continue_loss_weight)\n",
    "        C_epoch_loss /=(count * class_loss_weight)\n",
    "        acc = acc_num / item_num\n",
    "        D_loss.append(D_epoch_loss)\n",
    "        G_loss.append(G_epoch_loss)\n",
    "        S_loss.append(S_epoch_loss)\n",
    "        C_loss.append(C_epoch_loss)\n",
    "        accs.append(acc)\n",
    "        print(f\"Epoch [{epoch + 1}/{epoch_num}], \"\n",
    "              f\"Discriminator Loss: {D_epoch_loss:.4f}, \"\n",
    "              f\"Generator Loss: {G_epoch_loss:.4f}, \"\n",
    "              f\"Series Loss: {S_epoch_loss:.4f}, \"\n",
    "              f\"Class Loss: {C_epoch_loss:.4f}, \"\n",
    "              f\"Accuracy: {acc:.4f}\")\n",
    "        if acc > 0.8:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52ffa546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9e600d2a00>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g_curve = [i.cpu() for i in G_loss]\n",
    "plt.plot(g_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38eb3bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9e498656a0>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "d_curve = [i.cpu() for i in D_loss]\n",
    "plt.plot(d_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "463f9c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9e497dcc70>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "s_curve = [i.cpu() for i in S_loss]\n",
    "plt.plot(s_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9efa5b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9e49722b20>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "c_curve = [i.cpu() for i in C_loss]\n",
    "plt.plot(c_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cada92de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9e495e3c40>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a_curve = [i for i in accs]\n",
    "plt.plot(a_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dddb84a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = generated_img.cpu().detach()\n",
    "# output = torch.reshape(output, (output.size(1), output.size(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f3dac15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9e4960e970>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(output.numpy()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d22f52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose_list(my_list):\n",
    "    transposed_list = list(zip(*my_list))\n",
    "    for i in range(len(transposed_list)):\n",
    "        transposed_list[i] = list(transposed_list[i])\n",
    "    return transposed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d119ae78",
   "metadata": {},
   "outputs": [],
   "source": [
    "transposed_list = transpose_list(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53827e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9e48a14c10>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(series[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee133abc",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 23.69 GiB total capacity; 1.56 GiB already allocated; 10.81 MiB free; 1.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m generated_img \u001b[38;5;241m=\u001b[39m gen(random_seed,label) \u001b[38;5;66;03m#得到生成的图片\u001b[39;00m\n\u001b[1;32m     10\u001b[0m generated_img \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mreshape(generated_img, (generated_img\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), generated_img\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m2\u001b[39m)))\n\u001b[0;32m---> 11\u001b[0m class_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerated_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerated_img\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerated_img\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m auth\u001b[38;5;241m.\u001b[39mappend(class_output)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/can_ppg/transformer.py:44\u001b[0m, in \u001b[0;36mTransformerClassifier.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     42\u001b[0m     x \u001b[38;5;241m=\u001b[39m conv_block(x)\n\u001b[1;32m     43\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Reshape to (batch_size, hidden_size, seq_len)\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Average the sequence dimension\u001b[39;00m\n\u001b[1;32m     46\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(x))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/transformer.py:280\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[0;34m(self, src, mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    277\u001b[0m         src_key_padding_mask_for_layers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 280\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask_for_layers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n\u001b[1;32m    283\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_padded_tensor(\u001b[38;5;241m0.\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/transformer.py:538\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    536\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x))\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 538\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sa_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    539\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(x))\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/transformer.py:546\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sa_block\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor,\n\u001b[1;32m    545\u001b[0m               attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 546\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(x)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/activation.py:1167\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights)\u001b[0m\n\u001b[1;32m   1156\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1157\u001b[0m         query, key, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[1;32m   1158\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_bias,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1164\u001b[0m         q_proj_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_proj_weight, k_proj_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_proj_weight,\n\u001b[1;32m   1165\u001b[0m         v_proj_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_proj_weight, average_attn_weights\u001b[38;5;241m=\u001b[39maverage_attn_weights)\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1167\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1169\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1170\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1171\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[1;32m   1176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/functional.py:5106\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights)\u001b[0m\n\u001b[1;32m   5104\u001b[0m     k \u001b[38;5;241m=\u001b[39m static_k\n\u001b[1;32m   5105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m static_v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 5106\u001b[0m     v \u001b[38;5;241m=\u001b[39m \u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontiguous\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(v\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], bsz \u001b[38;5;241m*\u001b[39m num_heads, head_dim)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   5107\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5108\u001b[0m     \u001b[38;5;66;03m# TODO finish disentangling control flow so we don't do in-projections when statics are passed\u001b[39;00m\n\u001b[1;32m   5109\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m static_v\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m==\u001b[39m bsz \u001b[38;5;241m*\u001b[39m num_heads, \\\n\u001b[1;32m   5110\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpecting static_v.size(0) of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbsz \u001b[38;5;241m*\u001b[39m num_heads\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstatic_v\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 23.69 GiB total capacity; 1.56 GiB already allocated; 10.81 MiB free; 1.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "auth = []\n",
    "for step,(img,label) in enumerate(dataloader):\n",
    "        img =img.to(device) #把数据放到设备上\n",
    "        label = label.to(device)\n",
    "        size = img.shape[0] #img的第一位是size,获取批次的大小\n",
    "        random_seed = torch.randn(size,100,device=device)\n",
    "        \n",
    "        #在生成器上去计算生成器的损失，优化目标是判别器上的参数\n",
    "        generated_img = gen(random_seed,label) #得到生成的图片\n",
    "        generated_img = torch.reshape(generated_img, (generated_img.size(0), generated_img.size(2)))\n",
    "        class_output = cls(torch.reshape(generated_img, (generated_img.size(0), 1, generated_img.size(1))))\n",
    "        auth.append(class_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b8f055",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f212dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'seed{}'.format(seed) + 'G{}'.format(generator_rate) + 'D{}'.format(discriminator_rate)\n",
    "isExists=os.path.exists(path)\n",
    "if not isExists:\n",
    "    os.mkdir(path)\n",
    "path = path + '/S{}'.format(continue_loss_weight) + 'C{}'.format(class_loss_weight)\n",
    "os.mkdir(path)\n",
    "torch.save(gen, path + '/generator.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e103dde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(dis, path + \"/discriminator.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc12f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "code = []\n",
    "for _, (_, _) in enumerate(dataloader):\n",
    "    random_seed = torch.randn(size,100,device=device)\n",
    "    code.append(random_seed.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f0388c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf42e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(path + '/code.npy', code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d2c6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(accs, path + '/accs.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d70990",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
