{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9eebafaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入库\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "import torchvision #加载图片\n",
    "from torchvision import transforms #图片变换\n",
    "\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    " \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt #绘图\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "from preprocess import Process\n",
    "from transformer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f369c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 32\n",
    "def get_random_seed(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "get_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a98ad843",
   "metadata": {},
   "outputs": [],
   "source": [
    "#独热编码\n",
    "def one_hot(x,class_count=10):\n",
    "    return torch.eye(class_count)[x,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64c2d341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject 13 abandoned\n",
      "subject 16 abandoned\n",
      "subject 17 abandoned\n",
      "subject 18 abandoned\n",
      "subject 20 abandoned\n",
      "subject 26 abandoned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhz/anaconda3/lib/python3.9/site-packages/scipy/interpolate/fitpack2.py:280: UserWarning: \n",
      "The maximal number of iterations maxit (set to 20 by the program)\n",
      "allowed for finding a smoothing spline with fp=s has been reached: s\n",
      "too small.\n",
      "There is an approximation returned but the corresponding weighted sum\n",
      "of squared residuals does not satisfy the condition abs(fp-s)/s < tol.\n",
      "  warnings.warn(message)\n",
      "/home/dhz/anaconda3/lib/python3.9/site-packages/numpy/ma/core.py:5244: RuntimeWarning: Mean of empty slice.\n",
      "  result = super().mean(axis=axis, dtype=dtype, **kwargs)[()]\n",
      "/home/dhz/anaconda3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3723: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject 42 abandoned\n",
      "subject 47 abandoned\n",
      "subject 48 abandoned\n",
      "subject 50 abandoned\n"
     ]
    }
   ],
   "source": [
    "series = []\n",
    "items = 3\n",
    "step = 3\n",
    "subject_num = 0\n",
    "\n",
    "for num in range(2, 66):\n",
    "    try:\n",
    "        series += Process(num).prepro(1024, step, items)\n",
    "        subject_num += 1\n",
    "    except:\n",
    "        print(f'subject {num} abandoned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c6e9e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, series, items, subject_num):\n",
    "        self.series = series\n",
    "        self.codes = []\n",
    "        self.subject_num = subject_num\n",
    "        self.labels = np.zeros((len(self.series), self.subject_num), dtype='double')\n",
    "        for i in range(self.subject_num):\n",
    "            for j in range(items):\n",
    "                self.labels[i + j][i] = 1.0            \n",
    "\n",
    "    # need to overload\n",
    "    def __len__(self):\n",
    "        return len(self.series)\n",
    "\n",
    "    # need to overload\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.series[idx]), torch.tensor(self.labels[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "463a2d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset(series, items=items, subject_num=subject_num)\n",
    "dataloader = torch.utils.data.DataLoader(dataset,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0415007e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义生成器\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, subject_num):\n",
    "        super(Generator,self).__init__()\n",
    "        self.linear1 = nn.Linear(100,512)\n",
    "        self.bn1=nn.BatchNorm1d(512)\n",
    "        self.subject_num = subject_num\n",
    "        self.linear2 = nn.Linear(subject_num,512)\n",
    "        self.bn2=nn.BatchNorm1d(512)\n",
    "        \n",
    "        self.deconv1 = nn.Conv1d(1, 3, kernel_size=2, padding='same')\n",
    "        self.bn3=nn.BatchNorm1d(3)\n",
    "        self.deconv2 = nn.Conv1d(3, 6, kernel_size=2, padding='same')\n",
    "        self.bn4=nn.BatchNorm1d(6)\n",
    "        self.deconv3 = nn.Conv1d(6, 1, kernel_size=2, padding='same')\n",
    "        \n",
    "    def forward(self,x1,x2):\n",
    "        x1=F.relu(self.linear1(x1.to(torch.float64)))\n",
    "        x1=self.bn1(x1)\n",
    "        x2=F.relu(self.linear2(x2))\n",
    "        x2=self.bn2(x2)\n",
    "        x=torch.cat([x1,x2],axis=1)\n",
    "        x=F.relu(self.deconv1(torch.reshape(x, (x.size(0), 1, x.size(1)))))\n",
    "        x=self.bn3(x)\n",
    "        x=F.relu(self.deconv2(x))\n",
    "        x=self.bn4(x)\n",
    "        x=torch.tanh(self.deconv3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c55045ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义判别器\n",
    "#输入：1，28，28图片和长度为10的condition\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, subject_num):\n",
    "        super(Discriminator,self).__init__()\n",
    "        self.subject_num = subject_num\n",
    "        self.linear = nn.Linear(self.subject_num,1024)\n",
    "        self.conv1 = nn.Conv1d(1,32,kernel_size=2,padding='same')\n",
    "        self.conv2 = nn.Conv1d(32,128,kernel_size=2,padding='same')\n",
    "        self.bn = nn.BatchNorm1d(128)\n",
    "        self.fc = nn.Linear(2048,1)\n",
    "    def forward(self,x1,x2): #x1代表label,x2代表image\n",
    "        x1=F.leaky_relu(self.linear(x1))\n",
    "        x=torch.cat([x1,x2],axis=1)            \n",
    "        x= F.dropout1d(F.leaky_relu(self.conv1(torch.reshape(x, (x.size(0), 1, x.size(1))))))\n",
    "        x= F.dropout1d(F.leaky_relu(self.conv2(x)))\n",
    "        x = self.bn(x)\n",
    "        x = torch.sigmoid(self.fc(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b06c0a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContinuityLoss(nn.Module):\n",
    "    def __init__(self, weight=1.0):\n",
    "        super(ContinuityLoss, self).__init__()\n",
    "        self.weight = weight\n",
    "        \n",
    "    def forward(self, predictions):\n",
    "        diff = predictions[:][1:] - predictions[:][:-1]\n",
    "        loss = torch.mean(torch.abs(diff))\n",
    "        return loss * self.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55bc25ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxValueLoss(nn.Module):\n",
    "    def __init__(self, weight=1.0):\n",
    "        super(MaxValueLoss, self).__init__()\n",
    "        self.weight = weight\n",
    "        self.MCE = nn.CrossEntropyLoss()\n",
    "    def forward(self, input1):\n",
    "        input2 = torch.zeros_like(input1)\n",
    "        types = torch.argmax(input1, dim = 0, keepdim=False)\n",
    "        for i in range(input1.size(0)):\n",
    "            input2[i][types[i]] = 1\n",
    "        loss = self.MCE(input1, input2)\n",
    "        return loss * self.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86bdfd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassLoss(nn.Module):\n",
    "    def __init__(self, weight=1.0):\n",
    "        super(ClassLoss, self).__init__()\n",
    "        self.weight = weight\n",
    "    def forward(self, input1, input2):\n",
    "        diff = input1 - input2\n",
    "        loss = torch.mean(torch.abs(diff))\n",
    "        return loss * self.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64a75c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassLoss(nn.Module):\n",
    "    def __init__(self, weight=1.0):\n",
    "        super(ClassLoss, self).__init__()\n",
    "        self.weight = weight\n",
    "        self.MCE = nn.CrossEntropyLoss()\n",
    "    def forward(self, input1, input2):\n",
    "        loss = self.MCE(input1, input2)\n",
    "        return loss * self.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be96d7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#设备的配置\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#初化生成器和判别器把他们放到相应的设备上\n",
    "gen = Generator(subject_num).to(device)\n",
    "gen = gen.double()\n",
    "dis = Discriminator(subject_num).to(device)\n",
    "dis = dis.double()\n",
    "cls = torch.load(\"classification\").to(device)\n",
    "cls = cls.double()\n",
    "#交叉熵损失函数\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "continue_loss_weight = 1\n",
    "continue_loss = ContinuityLoss(weight=continue_loss_weight)\n",
    "class_loss_weight = 0.5\n",
    "class_loss = ClassLoss(weight=class_loss_weight)\n",
    "#训练器的优化器\n",
    "discriminator_rate = 1e-5\n",
    "generator_rate = 1e-4\n",
    "d_optimizer = torch.optim.Adam(dis.parameters(),lr=discriminator_rate)\n",
    "#训练生成器的优化器\n",
    "g_optimizer = torch.optim.Adam(gen.parameters(),lr=generator_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3004abc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#设置生成绘图图片的随机张量，这里可视化16张图片\n",
    "#生成16个长度为100的随机正态分布张量\n",
    "noise_seed = torch.randn(16,100,device=device)\n",
    "label_seed = torch.randint(0,subject_num,size=(16,))\n",
    "label_seed_onehot = one_hot(label_seed, class_count=subject_num).to(device)\n",
    " \n",
    "D_loss = [] #记录训练过程中判别器的损失\n",
    "G_loss = [] #记录训练过程中生成器的损失\n",
    "S_loss = []\n",
    "C_loss = []\n",
    "accs = []\n",
    "epoch_num = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77dc5c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhz/anaconda3/lib/python3.9/site-packages/torch/nn/modules/conv.py:309: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:895.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/4000], Discriminator Loss: 0.1067, Generator Loss: 0.2034, Series Loss: 0.0261, Class Loss: 0.2496, Accuracy: 0.0741\n",
      "Epoch [2/4000], Discriminator Loss: 0.1031, Generator Loss: 0.2006, Series Loss: 0.0259, Class Loss: 0.2494, Accuracy: 0.0864\n",
      "Epoch [3/4000], Discriminator Loss: 0.1004, Generator Loss: 0.1987, Series Loss: 0.0255, Class Loss: 0.2492, Accuracy: 0.1049\n",
      "Epoch [4/4000], Discriminator Loss: 0.0986, Generator Loss: 0.1974, Series Loss: 0.0251, Class Loss: 0.2491, Accuracy: 0.0926\n",
      "Epoch [5/4000], Discriminator Loss: 0.0970, Generator Loss: 0.1965, Series Loss: 0.0248, Class Loss: 0.2492, Accuracy: 0.1049\n",
      "Epoch [6/4000], Discriminator Loss: 0.0961, Generator Loss: 0.1958, Series Loss: 0.0245, Class Loss: 0.2492, Accuracy: 0.0926\n",
      "Epoch [7/4000], Discriminator Loss: 0.0955, Generator Loss: 0.1951, Series Loss: 0.0240, Class Loss: 0.2490, Accuracy: 0.1173\n",
      "Epoch [8/4000], Discriminator Loss: 0.0958, Generator Loss: 0.1946, Series Loss: 0.0237, Class Loss: 0.2489, Accuracy: 0.1173\n",
      "Epoch [9/4000], Discriminator Loss: 0.0956, Generator Loss: 0.1943, Series Loss: 0.0233, Class Loss: 0.2489, Accuracy: 0.1049\n",
      "Epoch [10/4000], Discriminator Loss: 0.0956, Generator Loss: 0.1938, Series Loss: 0.0231, Class Loss: 0.2488, Accuracy: 0.1235\n",
      "Epoch [11/4000], Discriminator Loss: 0.0954, Generator Loss: 0.1938, Series Loss: 0.0228, Class Loss: 0.2489, Accuracy: 0.1049\n",
      "Epoch [12/4000], Discriminator Loss: 0.0955, Generator Loss: 0.1932, Series Loss: 0.0224, Class Loss: 0.2487, Accuracy: 0.1173\n",
      "Epoch [13/4000], Discriminator Loss: 0.0954, Generator Loss: 0.1929, Series Loss: 0.0220, Class Loss: 0.2487, Accuracy: 0.1667\n",
      "Epoch [14/4000], Discriminator Loss: 0.0956, Generator Loss: 0.1925, Series Loss: 0.0218, Class Loss: 0.2487, Accuracy: 0.1420\n",
      "Epoch [15/4000], Discriminator Loss: 0.0953, Generator Loss: 0.1922, Series Loss: 0.0215, Class Loss: 0.2485, Accuracy: 0.1543\n",
      "Epoch [16/4000], Discriminator Loss: 0.0953, Generator Loss: 0.1918, Series Loss: 0.0211, Class Loss: 0.2485, Accuracy: 0.1420\n",
      "Epoch [17/4000], Discriminator Loss: 0.0953, Generator Loss: 0.1917, Series Loss: 0.0209, Class Loss: 0.2483, Accuracy: 0.1667\n",
      "Epoch [18/4000], Discriminator Loss: 0.0951, Generator Loss: 0.1916, Series Loss: 0.0205, Class Loss: 0.2484, Accuracy: 0.1605\n",
      "Epoch [19/4000], Discriminator Loss: 0.0953, Generator Loss: 0.1910, Series Loss: 0.0202, Class Loss: 0.2484, Accuracy: 0.1543\n",
      "Epoch [20/4000], Discriminator Loss: 0.0953, Generator Loss: 0.1905, Series Loss: 0.0199, Class Loss: 0.2482, Accuracy: 0.1667\n",
      "Epoch [21/4000], Discriminator Loss: 0.0950, Generator Loss: 0.1906, Series Loss: 0.0197, Class Loss: 0.2483, Accuracy: 0.1481\n",
      "Epoch [22/4000], Discriminator Loss: 0.0952, Generator Loss: 0.1898, Series Loss: 0.0193, Class Loss: 0.2482, Accuracy: 0.1420\n",
      "Epoch [23/4000], Discriminator Loss: 0.0950, Generator Loss: 0.1897, Series Loss: 0.0190, Class Loss: 0.2481, Accuracy: 0.1543\n",
      "Epoch [24/4000], Discriminator Loss: 0.0950, Generator Loss: 0.1892, Series Loss: 0.0187, Class Loss: 0.2482, Accuracy: 0.1296\n",
      "Epoch [25/4000], Discriminator Loss: 0.0952, Generator Loss: 0.1891, Series Loss: 0.0185, Class Loss: 0.2481, Accuracy: 0.1605\n",
      "Epoch [26/4000], Discriminator Loss: 0.0951, Generator Loss: 0.1887, Series Loss: 0.0181, Class Loss: 0.2480, Accuracy: 0.1358\n",
      "Epoch [27/4000], Discriminator Loss: 0.0951, Generator Loss: 0.1884, Series Loss: 0.0178, Class Loss: 0.2482, Accuracy: 0.1296\n",
      "Epoch [28/4000], Discriminator Loss: 0.0953, Generator Loss: 0.1882, Series Loss: 0.0176, Class Loss: 0.2479, Accuracy: 0.1481\n",
      "Epoch [29/4000], Discriminator Loss: 0.0954, Generator Loss: 0.1876, Series Loss: 0.0174, Class Loss: 0.2477, Accuracy: 0.1481\n",
      "Epoch [30/4000], Discriminator Loss: 0.0952, Generator Loss: 0.1876, Series Loss: 0.0171, Class Loss: 0.2477, Accuracy: 0.1358\n",
      "Epoch [31/4000], Discriminator Loss: 0.0951, Generator Loss: 0.1870, Series Loss: 0.0167, Class Loss: 0.2477, Accuracy: 0.1358\n",
      "Epoch [32/4000], Discriminator Loss: 0.0949, Generator Loss: 0.1868, Series Loss: 0.0165, Class Loss: 0.2476, Accuracy: 0.1543\n",
      "Epoch [33/4000], Discriminator Loss: 0.0950, Generator Loss: 0.1866, Series Loss: 0.0162, Class Loss: 0.2477, Accuracy: 0.1358\n",
      "Epoch [34/4000], Discriminator Loss: 0.0949, Generator Loss: 0.1864, Series Loss: 0.0159, Class Loss: 0.2477, Accuracy: 0.1358\n",
      "Epoch [35/4000], Discriminator Loss: 0.0952, Generator Loss: 0.1862, Series Loss: 0.0159, Class Loss: 0.2475, Accuracy: 0.1420\n",
      "Epoch [36/4000], Discriminator Loss: 0.0950, Generator Loss: 0.1860, Series Loss: 0.0156, Class Loss: 0.2475, Accuracy: 0.1358\n",
      "Epoch [37/4000], Discriminator Loss: 0.0952, Generator Loss: 0.1855, Series Loss: 0.0153, Class Loss: 0.2476, Accuracy: 0.1420\n",
      "Epoch [38/4000], Discriminator Loss: 0.0953, Generator Loss: 0.1852, Series Loss: 0.0150, Class Loss: 0.2476, Accuracy: 0.1605\n",
      "Epoch [39/4000], Discriminator Loss: 0.0951, Generator Loss: 0.1848, Series Loss: 0.0148, Class Loss: 0.2474, Accuracy: 0.1420\n",
      "Epoch [40/4000], Discriminator Loss: 0.0950, Generator Loss: 0.1846, Series Loss: 0.0144, Class Loss: 0.2473, Accuracy: 0.1358\n",
      "Epoch [41/4000], Discriminator Loss: 0.0950, Generator Loss: 0.1844, Series Loss: 0.0143, Class Loss: 0.2474, Accuracy: 0.1358\n",
      "Epoch [42/4000], Discriminator Loss: 0.0948, Generator Loss: 0.1844, Series Loss: 0.0141, Class Loss: 0.2474, Accuracy: 0.1358\n",
      "Epoch [43/4000], Discriminator Loss: 0.0949, Generator Loss: 0.1838, Series Loss: 0.0137, Class Loss: 0.2474, Accuracy: 0.1420\n",
      "Epoch [44/4000], Discriminator Loss: 0.0951, Generator Loss: 0.1838, Series Loss: 0.0135, Class Loss: 0.2474, Accuracy: 0.1481\n",
      "Epoch [45/4000], Discriminator Loss: 0.0955, Generator Loss: 0.1834, Series Loss: 0.0133, Class Loss: 0.2474, Accuracy: 0.1358\n",
      "Epoch [46/4000], Discriminator Loss: 0.0954, Generator Loss: 0.1835, Series Loss: 0.0131, Class Loss: 0.2474, Accuracy: 0.1667\n",
      "Epoch [47/4000], Discriminator Loss: 0.0953, Generator Loss: 0.1828, Series Loss: 0.0128, Class Loss: 0.2472, Accuracy: 0.1420\n",
      "Epoch [48/4000], Discriminator Loss: 0.0953, Generator Loss: 0.1826, Series Loss: 0.0126, Class Loss: 0.2473, Accuracy: 0.1420\n",
      "Epoch [49/4000], Discriminator Loss: 0.0952, Generator Loss: 0.1823, Series Loss: 0.0124, Class Loss: 0.2473, Accuracy: 0.1358\n",
      "Epoch [50/4000], Discriminator Loss: 0.0951, Generator Loss: 0.1821, Series Loss: 0.0122, Class Loss: 0.2470, Accuracy: 0.1358\n",
      "Epoch [51/4000], Discriminator Loss: 0.0956, Generator Loss: 0.1818, Series Loss: 0.0120, Class Loss: 0.2471, Accuracy: 0.1605\n",
      "Epoch [52/4000], Discriminator Loss: 0.0954, Generator Loss: 0.1816, Series Loss: 0.0118, Class Loss: 0.2470, Accuracy: 0.1667\n",
      "Epoch [53/4000], Discriminator Loss: 0.0953, Generator Loss: 0.1814, Series Loss: 0.0115, Class Loss: 0.2470, Accuracy: 0.1605\n",
      "Epoch [54/4000], Discriminator Loss: 0.0950, Generator Loss: 0.1810, Series Loss: 0.0113, Class Loss: 0.2469, Accuracy: 0.1667\n",
      "Epoch [55/4000], Discriminator Loss: 0.0953, Generator Loss: 0.1809, Series Loss: 0.0111, Class Loss: 0.2471, Accuracy: 0.1420\n",
      "Epoch [56/4000], Discriminator Loss: 0.0953, Generator Loss: 0.1805, Series Loss: 0.0109, Class Loss: 0.2470, Accuracy: 0.1296\n",
      "Epoch [57/4000], Discriminator Loss: 0.0952, Generator Loss: 0.1803, Series Loss: 0.0107, Class Loss: 0.2470, Accuracy: 0.1296\n",
      "Epoch [58/4000], Discriminator Loss: 0.0951, Generator Loss: 0.1800, Series Loss: 0.0105, Class Loss: 0.2468, Accuracy: 0.1667\n",
      "Epoch [59/4000], Discriminator Loss: 0.0949, Generator Loss: 0.1799, Series Loss: 0.0103, Class Loss: 0.2469, Accuracy: 0.1605\n",
      "Epoch [60/4000], Discriminator Loss: 0.0952, Generator Loss: 0.1798, Series Loss: 0.0101, Class Loss: 0.2469, Accuracy: 0.1481\n",
      "Epoch [61/4000], Discriminator Loss: 0.0953, Generator Loss: 0.1797, Series Loss: 0.0099, Class Loss: 0.2469, Accuracy: 0.1420\n",
      "Epoch [62/4000], Discriminator Loss: 0.0954, Generator Loss: 0.1795, Series Loss: 0.0097, Class Loss: 0.2468, Accuracy: 0.1790\n",
      "Epoch [63/4000], Discriminator Loss: 0.0959, Generator Loss: 0.1794, Series Loss: 0.0096, Class Loss: 0.2469, Accuracy: 0.1605\n",
      "Epoch [64/4000], Discriminator Loss: 0.0951, Generator Loss: 0.1791, Series Loss: 0.0094, Class Loss: 0.2468, Accuracy: 0.1605\n",
      "Epoch [65/4000], Discriminator Loss: 0.0953, Generator Loss: 0.1786, Series Loss: 0.0091, Class Loss: 0.2467, Accuracy: 0.1605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [66/4000], Discriminator Loss: 0.0948, Generator Loss: 0.1789, Series Loss: 0.0090, Class Loss: 0.2467, Accuracy: 0.1790\n",
      "Epoch [67/4000], Discriminator Loss: 0.0951, Generator Loss: 0.1784, Series Loss: 0.0088, Class Loss: 0.2466, Accuracy: 0.1790\n",
      "Epoch [68/4000], Discriminator Loss: 0.0950, Generator Loss: 0.1783, Series Loss: 0.0086, Class Loss: 0.2465, Accuracy: 0.1790\n",
      "Epoch [69/4000], Discriminator Loss: 0.0952, Generator Loss: 0.1782, Series Loss: 0.0086, Class Loss: 0.2466, Accuracy: 0.1728\n",
      "Epoch [70/4000], Discriminator Loss: 0.0946, Generator Loss: 0.1780, Series Loss: 0.0084, Class Loss: 0.2465, Accuracy: 0.1728\n",
      "Epoch [71/4000], Discriminator Loss: 0.0949, Generator Loss: 0.1781, Series Loss: 0.0082, Class Loss: 0.2466, Accuracy: 0.1605\n",
      "Epoch [72/4000], Discriminator Loss: 0.0948, Generator Loss: 0.1778, Series Loss: 0.0081, Class Loss: 0.2465, Accuracy: 0.1605\n",
      "Epoch [73/4000], Discriminator Loss: 0.0951, Generator Loss: 0.1776, Series Loss: 0.0080, Class Loss: 0.2465, Accuracy: 0.1852\n",
      "Epoch [74/4000], Discriminator Loss: 0.0951, Generator Loss: 0.1776, Series Loss: 0.0078, Class Loss: 0.2465, Accuracy: 0.1914\n",
      "Epoch [75/4000], Discriminator Loss: 0.0948, Generator Loss: 0.1773, Series Loss: 0.0076, Class Loss: 0.2464, Accuracy: 0.1728\n",
      "Epoch [76/4000], Discriminator Loss: 0.0949, Generator Loss: 0.1774, Series Loss: 0.0076, Class Loss: 0.2466, Accuracy: 0.1667\n",
      "Epoch [77/4000], Discriminator Loss: 0.0950, Generator Loss: 0.1773, Series Loss: 0.0075, Class Loss: 0.2463, Accuracy: 0.1790\n",
      "Epoch [78/4000], Discriminator Loss: 0.0945, Generator Loss: 0.1771, Series Loss: 0.0073, Class Loss: 0.2464, Accuracy: 0.1667\n",
      "Epoch [79/4000], Discriminator Loss: 0.0944, Generator Loss: 0.1769, Series Loss: 0.0072, Class Loss: 0.2463, Accuracy: 0.1852\n",
      "Epoch [80/4000], Discriminator Loss: 0.0946, Generator Loss: 0.1769, Series Loss: 0.0071, Class Loss: 0.2463, Accuracy: 0.1543\n",
      "Epoch [81/4000], Discriminator Loss: 0.0950, Generator Loss: 0.1769, Series Loss: 0.0069, Class Loss: 0.2464, Accuracy: 0.1852\n",
      "Epoch [82/4000], Discriminator Loss: 0.0945, Generator Loss: 0.1766, Series Loss: 0.0069, Class Loss: 0.2462, Accuracy: 0.2099\n",
      "Epoch [83/4000], Discriminator Loss: 0.0941, Generator Loss: 0.1765, Series Loss: 0.0068, Class Loss: 0.2462, Accuracy: 0.1914\n",
      "Epoch [84/4000], Discriminator Loss: 0.0946, Generator Loss: 0.1765, Series Loss: 0.0067, Class Loss: 0.2462, Accuracy: 0.1914\n",
      "Epoch [85/4000], Discriminator Loss: 0.0945, Generator Loss: 0.1764, Series Loss: 0.0066, Class Loss: 0.2462, Accuracy: 0.1852\n",
      "Epoch [86/4000], Discriminator Loss: 0.0943, Generator Loss: 0.1763, Series Loss: 0.0065, Class Loss: 0.2462, Accuracy: 0.1790\n",
      "Epoch [87/4000], Discriminator Loss: 0.0942, Generator Loss: 0.1761, Series Loss: 0.0064, Class Loss: 0.2462, Accuracy: 0.1975\n",
      "Epoch [88/4000], Discriminator Loss: 0.0942, Generator Loss: 0.1759, Series Loss: 0.0063, Class Loss: 0.2460, Accuracy: 0.1975\n",
      "Epoch [89/4000], Discriminator Loss: 0.0939, Generator Loss: 0.1761, Series Loss: 0.0062, Class Loss: 0.2461, Accuracy: 0.1914\n",
      "Epoch [90/4000], Discriminator Loss: 0.0940, Generator Loss: 0.1760, Series Loss: 0.0062, Class Loss: 0.2459, Accuracy: 0.1790\n",
      "Epoch [91/4000], Discriminator Loss: 0.0942, Generator Loss: 0.1758, Series Loss: 0.0061, Class Loss: 0.2460, Accuracy: 0.1975\n",
      "Epoch [92/4000], Discriminator Loss: 0.0940, Generator Loss: 0.1759, Series Loss: 0.0060, Class Loss: 0.2460, Accuracy: 0.1975\n",
      "Epoch [93/4000], Discriminator Loss: 0.0940, Generator Loss: 0.1758, Series Loss: 0.0059, Class Loss: 0.2459, Accuracy: 0.1975\n",
      "Epoch [94/4000], Discriminator Loss: 0.0940, Generator Loss: 0.1758, Series Loss: 0.0059, Class Loss: 0.2458, Accuracy: 0.1914\n",
      "Epoch [95/4000], Discriminator Loss: 0.0934, Generator Loss: 0.1758, Series Loss: 0.0058, Class Loss: 0.2460, Accuracy: 0.1728\n",
      "Epoch [96/4000], Discriminator Loss: 0.0937, Generator Loss: 0.1756, Series Loss: 0.0057, Class Loss: 0.2459, Accuracy: 0.1975\n",
      "Epoch [97/4000], Discriminator Loss: 0.0938, Generator Loss: 0.1757, Series Loss: 0.0057, Class Loss: 0.2459, Accuracy: 0.1914\n",
      "Epoch [98/4000], Discriminator Loss: 0.0937, Generator Loss: 0.1755, Series Loss: 0.0056, Class Loss: 0.2459, Accuracy: 0.1914\n",
      "Epoch [99/4000], Discriminator Loss: 0.0938, Generator Loss: 0.1754, Series Loss: 0.0056, Class Loss: 0.2458, Accuracy: 0.2037\n",
      "Epoch [100/4000], Discriminator Loss: 0.0938, Generator Loss: 0.1754, Series Loss: 0.0055, Class Loss: 0.2457, Accuracy: 0.2037\n",
      "Epoch [101/4000], Discriminator Loss: 0.0938, Generator Loss: 0.1752, Series Loss: 0.0055, Class Loss: 0.2456, Accuracy: 0.1914\n",
      "Epoch [102/4000], Discriminator Loss: 0.0935, Generator Loss: 0.1753, Series Loss: 0.0054, Class Loss: 0.2457, Accuracy: 0.1914\n",
      "Epoch [103/4000], Discriminator Loss: 0.0936, Generator Loss: 0.1752, Series Loss: 0.0053, Class Loss: 0.2456, Accuracy: 0.2099\n",
      "Epoch [104/4000], Discriminator Loss: 0.0935, Generator Loss: 0.1752, Series Loss: 0.0053, Class Loss: 0.2455, Accuracy: 0.2037\n",
      "Epoch [105/4000], Discriminator Loss: 0.0932, Generator Loss: 0.1751, Series Loss: 0.0052, Class Loss: 0.2456, Accuracy: 0.2099\n",
      "Epoch [106/4000], Discriminator Loss: 0.0935, Generator Loss: 0.1752, Series Loss: 0.0052, Class Loss: 0.2456, Accuracy: 0.1914\n",
      "Epoch [107/4000], Discriminator Loss: 0.0935, Generator Loss: 0.1752, Series Loss: 0.0051, Class Loss: 0.2457, Accuracy: 0.2037\n",
      "Epoch [108/4000], Discriminator Loss: 0.0934, Generator Loss: 0.1750, Series Loss: 0.0051, Class Loss: 0.2455, Accuracy: 0.2037\n",
      "Epoch [109/4000], Discriminator Loss: 0.0937, Generator Loss: 0.1750, Series Loss: 0.0050, Class Loss: 0.2455, Accuracy: 0.2037\n",
      "Epoch [110/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1749, Series Loss: 0.0050, Class Loss: 0.2456, Accuracy: 0.1852\n",
      "Epoch [111/4000], Discriminator Loss: 0.0932, Generator Loss: 0.1747, Series Loss: 0.0049, Class Loss: 0.2455, Accuracy: 0.1975\n",
      "Epoch [112/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1749, Series Loss: 0.0049, Class Loss: 0.2456, Accuracy: 0.2037\n",
      "Epoch [113/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1748, Series Loss: 0.0048, Class Loss: 0.2455, Accuracy: 0.2222\n",
      "Epoch [114/4000], Discriminator Loss: 0.0932, Generator Loss: 0.1745, Series Loss: 0.0048, Class Loss: 0.2455, Accuracy: 0.2099\n",
      "Epoch [115/4000], Discriminator Loss: 0.0932, Generator Loss: 0.1745, Series Loss: 0.0048, Class Loss: 0.2455, Accuracy: 0.2037\n",
      "Epoch [116/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1747, Series Loss: 0.0048, Class Loss: 0.2454, Accuracy: 0.2160\n",
      "Epoch [117/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1745, Series Loss: 0.0046, Class Loss: 0.2453, Accuracy: 0.2284\n",
      "Epoch [118/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1745, Series Loss: 0.0046, Class Loss: 0.2454, Accuracy: 0.2099\n",
      "Epoch [119/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1745, Series Loss: 0.0046, Class Loss: 0.2454, Accuracy: 0.2222\n",
      "Epoch [120/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1744, Series Loss: 0.0046, Class Loss: 0.2452, Accuracy: 0.2160\n",
      "Epoch [121/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1745, Series Loss: 0.0045, Class Loss: 0.2453, Accuracy: 0.2037\n",
      "Epoch [122/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1744, Series Loss: 0.0045, Class Loss: 0.2452, Accuracy: 0.2284\n",
      "Epoch [123/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1744, Series Loss: 0.0045, Class Loss: 0.2453, Accuracy: 0.2346\n",
      "Epoch [124/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1743, Series Loss: 0.0044, Class Loss: 0.2453, Accuracy: 0.2160\n",
      "Epoch [125/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1744, Series Loss: 0.0044, Class Loss: 0.2453, Accuracy: 0.2160\n",
      "Epoch [126/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1742, Series Loss: 0.0043, Class Loss: 0.2452, Accuracy: 0.1975\n",
      "Epoch [127/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1743, Series Loss: 0.0043, Class Loss: 0.2453, Accuracy: 0.2160\n",
      "Epoch [128/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1740, Series Loss: 0.0043, Class Loss: 0.2451, Accuracy: 0.2407\n",
      "Epoch [129/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1742, Series Loss: 0.0043, Class Loss: 0.2452, Accuracy: 0.2160\n",
      "Epoch [130/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1742, Series Loss: 0.0043, Class Loss: 0.2453, Accuracy: 0.2037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [131/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1742, Series Loss: 0.0042, Class Loss: 0.2452, Accuracy: 0.2346\n",
      "Epoch [132/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1742, Series Loss: 0.0042, Class Loss: 0.2451, Accuracy: 0.2407\n",
      "Epoch [133/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1741, Series Loss: 0.0042, Class Loss: 0.2450, Accuracy: 0.2222\n",
      "Epoch [134/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1739, Series Loss: 0.0041, Class Loss: 0.2450, Accuracy: 0.2407\n",
      "Epoch [135/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1741, Series Loss: 0.0041, Class Loss: 0.2452, Accuracy: 0.2284\n",
      "Epoch [136/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1740, Series Loss: 0.0041, Class Loss: 0.2451, Accuracy: 0.2531\n",
      "Epoch [137/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1738, Series Loss: 0.0040, Class Loss: 0.2451, Accuracy: 0.2407\n",
      "Epoch [138/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1740, Series Loss: 0.0040, Class Loss: 0.2451, Accuracy: 0.2407\n",
      "Epoch [139/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1740, Series Loss: 0.0040, Class Loss: 0.2450, Accuracy: 0.2840\n",
      "Epoch [140/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1739, Series Loss: 0.0040, Class Loss: 0.2450, Accuracy: 0.2654\n",
      "Epoch [141/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1738, Series Loss: 0.0039, Class Loss: 0.2450, Accuracy: 0.3025\n",
      "Epoch [142/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1739, Series Loss: 0.0039, Class Loss: 0.2448, Accuracy: 0.2716\n",
      "Epoch [143/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1737, Series Loss: 0.0038, Class Loss: 0.2448, Accuracy: 0.2716\n",
      "Epoch [144/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1737, Series Loss: 0.0038, Class Loss: 0.2448, Accuracy: 0.2901\n",
      "Epoch [145/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1737, Series Loss: 0.0038, Class Loss: 0.2449, Accuracy: 0.2840\n",
      "Epoch [146/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1739, Series Loss: 0.0038, Class Loss: 0.2450, Accuracy: 0.3025\n",
      "Epoch [147/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1737, Series Loss: 0.0038, Class Loss: 0.2449, Accuracy: 0.3210\n",
      "Epoch [148/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1737, Series Loss: 0.0037, Class Loss: 0.2449, Accuracy: 0.3272\n",
      "Epoch [149/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1737, Series Loss: 0.0037, Class Loss: 0.2450, Accuracy: 0.3457\n",
      "Epoch [150/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1736, Series Loss: 0.0037, Class Loss: 0.2448, Accuracy: 0.3457\n",
      "Epoch [151/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1736, Series Loss: 0.0037, Class Loss: 0.2449, Accuracy: 0.3704\n",
      "Epoch [152/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1735, Series Loss: 0.0036, Class Loss: 0.2448, Accuracy: 0.3765\n",
      "Epoch [153/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1735, Series Loss: 0.0036, Class Loss: 0.2448, Accuracy: 0.4136\n",
      "Epoch [154/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1735, Series Loss: 0.0036, Class Loss: 0.2449, Accuracy: 0.3951\n",
      "Epoch [155/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1735, Series Loss: 0.0035, Class Loss: 0.2447, Accuracy: 0.3704\n",
      "Epoch [156/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1735, Series Loss: 0.0035, Class Loss: 0.2448, Accuracy: 0.3580\n",
      "Epoch [157/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1735, Series Loss: 0.0035, Class Loss: 0.2448, Accuracy: 0.4136\n",
      "Epoch [158/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1734, Series Loss: 0.0035, Class Loss: 0.2447, Accuracy: 0.4012\n",
      "Epoch [159/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1734, Series Loss: 0.0034, Class Loss: 0.2448, Accuracy: 0.4753\n",
      "Epoch [160/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1734, Series Loss: 0.0034, Class Loss: 0.2447, Accuracy: 0.4444\n",
      "Epoch [161/4000], Discriminator Loss: 0.0909, Generator Loss: 0.1734, Series Loss: 0.0034, Class Loss: 0.2447, Accuracy: 0.4630\n",
      "Epoch [162/4000], Discriminator Loss: 0.0911, Generator Loss: 0.1733, Series Loss: 0.0034, Class Loss: 0.2447, Accuracy: 0.4630\n",
      "Epoch [163/4000], Discriminator Loss: 0.0909, Generator Loss: 0.1732, Series Loss: 0.0034, Class Loss: 0.2446, Accuracy: 0.5185\n",
      "Epoch [164/4000], Discriminator Loss: 0.0911, Generator Loss: 0.1733, Series Loss: 0.0034, Class Loss: 0.2447, Accuracy: 0.4753\n",
      "Epoch [165/4000], Discriminator Loss: 0.0910, Generator Loss: 0.1733, Series Loss: 0.0033, Class Loss: 0.2446, Accuracy: 0.5062\n",
      "Epoch [166/4000], Discriminator Loss: 0.0910, Generator Loss: 0.1733, Series Loss: 0.0033, Class Loss: 0.2446, Accuracy: 0.4753\n",
      "Epoch [167/4000], Discriminator Loss: 0.0910, Generator Loss: 0.1732, Series Loss: 0.0033, Class Loss: 0.2447, Accuracy: 0.5123\n",
      "Epoch [168/4000], Discriminator Loss: 0.0908, Generator Loss: 0.1733, Series Loss: 0.0033, Class Loss: 0.2446, Accuracy: 0.4815\n",
      "Epoch [169/4000], Discriminator Loss: 0.0908, Generator Loss: 0.1733, Series Loss: 0.0032, Class Loss: 0.2447, Accuracy: 0.5309\n",
      "Epoch [170/4000], Discriminator Loss: 0.0908, Generator Loss: 0.1733, Series Loss: 0.0032, Class Loss: 0.2448, Accuracy: 0.5617\n",
      "Epoch [171/4000], Discriminator Loss: 0.0910, Generator Loss: 0.1731, Series Loss: 0.0032, Class Loss: 0.2446, Accuracy: 0.5494\n",
      "Epoch [172/4000], Discriminator Loss: 0.0904, Generator Loss: 0.1732, Series Loss: 0.0032, Class Loss: 0.2445, Accuracy: 0.5062\n",
      "Epoch [173/4000], Discriminator Loss: 0.0903, Generator Loss: 0.1730, Series Loss: 0.0032, Class Loss: 0.2445, Accuracy: 0.5556\n",
      "Epoch [174/4000], Discriminator Loss: 0.0907, Generator Loss: 0.1731, Series Loss: 0.0032, Class Loss: 0.2446, Accuracy: 0.5185\n",
      "Epoch [175/4000], Discriminator Loss: 0.0904, Generator Loss: 0.1732, Series Loss: 0.0032, Class Loss: 0.2446, Accuracy: 0.5247\n",
      "Epoch [176/4000], Discriminator Loss: 0.0904, Generator Loss: 0.1729, Series Loss: 0.0031, Class Loss: 0.2443, Accuracy: 0.5802\n",
      "Epoch [177/4000], Discriminator Loss: 0.0904, Generator Loss: 0.1731, Series Loss: 0.0031, Class Loss: 0.2447, Accuracy: 0.5247\n",
      "Epoch [178/4000], Discriminator Loss: 0.0906, Generator Loss: 0.1731, Series Loss: 0.0031, Class Loss: 0.2447, Accuracy: 0.5926\n",
      "Epoch [179/4000], Discriminator Loss: 0.0905, Generator Loss: 0.1732, Series Loss: 0.0031, Class Loss: 0.2448, Accuracy: 0.5617\n",
      "Epoch [180/4000], Discriminator Loss: 0.0902, Generator Loss: 0.1731, Series Loss: 0.0031, Class Loss: 0.2446, Accuracy: 0.5679\n",
      "Epoch [181/4000], Discriminator Loss: 0.0901, Generator Loss: 0.1730, Series Loss: 0.0030, Class Loss: 0.2446, Accuracy: 0.5864\n",
      "Epoch [182/4000], Discriminator Loss: 0.0904, Generator Loss: 0.1730, Series Loss: 0.0030, Class Loss: 0.2444, Accuracy: 0.6111\n",
      "Epoch [183/4000], Discriminator Loss: 0.0903, Generator Loss: 0.1730, Series Loss: 0.0030, Class Loss: 0.2443, Accuracy: 0.5802\n",
      "Epoch [184/4000], Discriminator Loss: 0.0902, Generator Loss: 0.1731, Series Loss: 0.0030, Class Loss: 0.2445, Accuracy: 0.5864\n",
      "Epoch [185/4000], Discriminator Loss: 0.0903, Generator Loss: 0.1729, Series Loss: 0.0030, Class Loss: 0.2444, Accuracy: 0.6173\n",
      "Epoch [186/4000], Discriminator Loss: 0.0899, Generator Loss: 0.1729, Series Loss: 0.0029, Class Loss: 0.2445, Accuracy: 0.5802\n",
      "Epoch [187/4000], Discriminator Loss: 0.0899, Generator Loss: 0.1730, Series Loss: 0.0029, Class Loss: 0.2444, Accuracy: 0.5741\n",
      "Epoch [188/4000], Discriminator Loss: 0.0899, Generator Loss: 0.1729, Series Loss: 0.0029, Class Loss: 0.2444, Accuracy: 0.6173\n",
      "Epoch [189/4000], Discriminator Loss: 0.0899, Generator Loss: 0.1730, Series Loss: 0.0029, Class Loss: 0.2446, Accuracy: 0.5679\n",
      "Epoch [190/4000], Discriminator Loss: 0.0898, Generator Loss: 0.1728, Series Loss: 0.0029, Class Loss: 0.2443, Accuracy: 0.6049\n",
      "Epoch [191/4000], Discriminator Loss: 0.0897, Generator Loss: 0.1730, Series Loss: 0.0029, Class Loss: 0.2445, Accuracy: 0.6049\n",
      "Epoch [192/4000], Discriminator Loss: 0.0898, Generator Loss: 0.1729, Series Loss: 0.0029, Class Loss: 0.2444, Accuracy: 0.6173\n",
      "Epoch [193/4000], Discriminator Loss: 0.0899, Generator Loss: 0.1728, Series Loss: 0.0028, Class Loss: 0.2443, Accuracy: 0.6235\n",
      "Epoch [194/4000], Discriminator Loss: 0.0903, Generator Loss: 0.1728, Series Loss: 0.0028, Class Loss: 0.2443, Accuracy: 0.6481\n",
      "Epoch [195/4000], Discriminator Loss: 0.0896, Generator Loss: 0.1729, Series Loss: 0.0028, Class Loss: 0.2443, Accuracy: 0.6111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [196/4000], Discriminator Loss: 0.0896, Generator Loss: 0.1730, Series Loss: 0.0028, Class Loss: 0.2443, Accuracy: 0.6420\n",
      "Epoch [197/4000], Discriminator Loss: 0.0897, Generator Loss: 0.1729, Series Loss: 0.0028, Class Loss: 0.2443, Accuracy: 0.6543\n",
      "Epoch [198/4000], Discriminator Loss: 0.0896, Generator Loss: 0.1727, Series Loss: 0.0028, Class Loss: 0.2442, Accuracy: 0.6173\n",
      "Epoch [199/4000], Discriminator Loss: 0.0895, Generator Loss: 0.1728, Series Loss: 0.0027, Class Loss: 0.2444, Accuracy: 0.6358\n",
      "Epoch [200/4000], Discriminator Loss: 0.0899, Generator Loss: 0.1729, Series Loss: 0.0027, Class Loss: 0.2443, Accuracy: 0.6420\n",
      "Epoch [201/4000], Discriminator Loss: 0.0896, Generator Loss: 0.1728, Series Loss: 0.0027, Class Loss: 0.2443, Accuracy: 0.6111\n",
      "Epoch [202/4000], Discriminator Loss: 0.0896, Generator Loss: 0.1728, Series Loss: 0.0027, Class Loss: 0.2443, Accuracy: 0.6728\n",
      "Epoch [203/4000], Discriminator Loss: 0.0895, Generator Loss: 0.1729, Series Loss: 0.0027, Class Loss: 0.2442, Accuracy: 0.5802\n",
      "Epoch [204/4000], Discriminator Loss: 0.0894, Generator Loss: 0.1728, Series Loss: 0.0027, Class Loss: 0.2443, Accuracy: 0.6049\n",
      "Epoch [205/4000], Discriminator Loss: 0.0894, Generator Loss: 0.1728, Series Loss: 0.0027, Class Loss: 0.2443, Accuracy: 0.6296\n",
      "Epoch [206/4000], Discriminator Loss: 0.0892, Generator Loss: 0.1728, Series Loss: 0.0027, Class Loss: 0.2443, Accuracy: 0.6543\n",
      "Epoch [207/4000], Discriminator Loss: 0.0893, Generator Loss: 0.1730, Series Loss: 0.0027, Class Loss: 0.2444, Accuracy: 0.6605\n",
      "Epoch [208/4000], Discriminator Loss: 0.0893, Generator Loss: 0.1727, Series Loss: 0.0026, Class Loss: 0.2443, Accuracy: 0.5926\n",
      "Epoch [209/4000], Discriminator Loss: 0.0893, Generator Loss: 0.1728, Series Loss: 0.0027, Class Loss: 0.2441, Accuracy: 0.6049\n",
      "Epoch [210/4000], Discriminator Loss: 0.0894, Generator Loss: 0.1729, Series Loss: 0.0026, Class Loss: 0.2443, Accuracy: 0.6358\n",
      "Epoch [211/4000], Discriminator Loss: 0.0891, Generator Loss: 0.1727, Series Loss: 0.0026, Class Loss: 0.2442, Accuracy: 0.6420\n",
      "Epoch [212/4000], Discriminator Loss: 0.0893, Generator Loss: 0.1726, Series Loss: 0.0026, Class Loss: 0.2440, Accuracy: 0.6358\n",
      "Epoch [213/4000], Discriminator Loss: 0.0888, Generator Loss: 0.1729, Series Loss: 0.0026, Class Loss: 0.2443, Accuracy: 0.5864\n",
      "Epoch [214/4000], Discriminator Loss: 0.0896, Generator Loss: 0.1728, Series Loss: 0.0026, Class Loss: 0.2444, Accuracy: 0.5926\n",
      "Epoch [215/4000], Discriminator Loss: 0.0890, Generator Loss: 0.1728, Series Loss: 0.0026, Class Loss: 0.2444, Accuracy: 0.5864\n",
      "Epoch [216/4000], Discriminator Loss: 0.0886, Generator Loss: 0.1728, Series Loss: 0.0026, Class Loss: 0.2442, Accuracy: 0.6111\n",
      "Epoch [217/4000], Discriminator Loss: 0.0891, Generator Loss: 0.1727, Series Loss: 0.0026, Class Loss: 0.2443, Accuracy: 0.6358\n",
      "Epoch [218/4000], Discriminator Loss: 0.0887, Generator Loss: 0.1728, Series Loss: 0.0025, Class Loss: 0.2443, Accuracy: 0.6235\n",
      "Epoch [219/4000], Discriminator Loss: 0.0887, Generator Loss: 0.1729, Series Loss: 0.0025, Class Loss: 0.2443, Accuracy: 0.6235\n",
      "Epoch [220/4000], Discriminator Loss: 0.0890, Generator Loss: 0.1729, Series Loss: 0.0025, Class Loss: 0.2440, Accuracy: 0.6296\n",
      "Epoch [221/4000], Discriminator Loss: 0.0886, Generator Loss: 0.1728, Series Loss: 0.0025, Class Loss: 0.2440, Accuracy: 0.5926\n",
      "Epoch [222/4000], Discriminator Loss: 0.0887, Generator Loss: 0.1728, Series Loss: 0.0025, Class Loss: 0.2442, Accuracy: 0.6358\n",
      "Epoch [223/4000], Discriminator Loss: 0.0883, Generator Loss: 0.1729, Series Loss: 0.0025, Class Loss: 0.2443, Accuracy: 0.5864\n",
      "Epoch [224/4000], Discriminator Loss: 0.0887, Generator Loss: 0.1728, Series Loss: 0.0025, Class Loss: 0.2441, Accuracy: 0.6173\n",
      "Epoch [225/4000], Discriminator Loss: 0.0885, Generator Loss: 0.1728, Series Loss: 0.0025, Class Loss: 0.2442, Accuracy: 0.6358\n",
      "Epoch [226/4000], Discriminator Loss: 0.0883, Generator Loss: 0.1729, Series Loss: 0.0025, Class Loss: 0.2440, Accuracy: 0.6049\n",
      "Epoch [227/4000], Discriminator Loss: 0.0884, Generator Loss: 0.1729, Series Loss: 0.0025, Class Loss: 0.2441, Accuracy: 0.6111\n",
      "Epoch [228/4000], Discriminator Loss: 0.0884, Generator Loss: 0.1729, Series Loss: 0.0025, Class Loss: 0.2440, Accuracy: 0.6296\n",
      "Epoch [229/4000], Discriminator Loss: 0.0885, Generator Loss: 0.1729, Series Loss: 0.0024, Class Loss: 0.2440, Accuracy: 0.6111\n",
      "Epoch [230/4000], Discriminator Loss: 0.0883, Generator Loss: 0.1729, Series Loss: 0.0024, Class Loss: 0.2441, Accuracy: 0.6296\n",
      "Epoch [231/4000], Discriminator Loss: 0.0884, Generator Loss: 0.1728, Series Loss: 0.0024, Class Loss: 0.2440, Accuracy: 0.5926\n",
      "Epoch [232/4000], Discriminator Loss: 0.0880, Generator Loss: 0.1729, Series Loss: 0.0024, Class Loss: 0.2440, Accuracy: 0.6049\n",
      "Epoch [233/4000], Discriminator Loss: 0.0880, Generator Loss: 0.1729, Series Loss: 0.0024, Class Loss: 0.2439, Accuracy: 0.6235\n",
      "Epoch [234/4000], Discriminator Loss: 0.0880, Generator Loss: 0.1732, Series Loss: 0.0024, Class Loss: 0.2441, Accuracy: 0.6111\n",
      "Epoch [235/4000], Discriminator Loss: 0.0878, Generator Loss: 0.1732, Series Loss: 0.0024, Class Loss: 0.2441, Accuracy: 0.6420\n",
      "Epoch [236/4000], Discriminator Loss: 0.0884, Generator Loss: 0.1730, Series Loss: 0.0024, Class Loss: 0.2441, Accuracy: 0.5494\n",
      "Epoch [237/4000], Discriminator Loss: 0.0879, Generator Loss: 0.1730, Series Loss: 0.0024, Class Loss: 0.2440, Accuracy: 0.6111\n",
      "Epoch [238/4000], Discriminator Loss: 0.0875, Generator Loss: 0.1733, Series Loss: 0.0024, Class Loss: 0.2440, Accuracy: 0.5679\n",
      "Epoch [239/4000], Discriminator Loss: 0.0878, Generator Loss: 0.1733, Series Loss: 0.0024, Class Loss: 0.2442, Accuracy: 0.5988\n",
      "Epoch [240/4000], Discriminator Loss: 0.0877, Generator Loss: 0.1732, Series Loss: 0.0024, Class Loss: 0.2441, Accuracy: 0.5185\n",
      "Epoch [241/4000], Discriminator Loss: 0.0880, Generator Loss: 0.1731, Series Loss: 0.0024, Class Loss: 0.2441, Accuracy: 0.6049\n",
      "Epoch [242/4000], Discriminator Loss: 0.0878, Generator Loss: 0.1732, Series Loss: 0.0024, Class Loss: 0.2441, Accuracy: 0.5679\n",
      "Epoch [243/4000], Discriminator Loss: 0.0879, Generator Loss: 0.1733, Series Loss: 0.0024, Class Loss: 0.2441, Accuracy: 0.6173\n",
      "Epoch [244/4000], Discriminator Loss: 0.0881, Generator Loss: 0.1732, Series Loss: 0.0024, Class Loss: 0.2442, Accuracy: 0.5494\n",
      "Epoch [245/4000], Discriminator Loss: 0.0876, Generator Loss: 0.1734, Series Loss: 0.0024, Class Loss: 0.2440, Accuracy: 0.5185\n",
      "Epoch [246/4000], Discriminator Loss: 0.0876, Generator Loss: 0.1734, Series Loss: 0.0024, Class Loss: 0.2441, Accuracy: 0.5247\n",
      "Epoch [247/4000], Discriminator Loss: 0.0872, Generator Loss: 0.1734, Series Loss: 0.0023, Class Loss: 0.2440, Accuracy: 0.5370\n",
      "Epoch [248/4000], Discriminator Loss: 0.0875, Generator Loss: 0.1733, Series Loss: 0.0023, Class Loss: 0.2439, Accuracy: 0.5617\n",
      "Epoch [249/4000], Discriminator Loss: 0.0873, Generator Loss: 0.1735, Series Loss: 0.0023, Class Loss: 0.2440, Accuracy: 0.5679\n",
      "Epoch [250/4000], Discriminator Loss: 0.0873, Generator Loss: 0.1736, Series Loss: 0.0023, Class Loss: 0.2440, Accuracy: 0.5432\n",
      "Epoch [251/4000], Discriminator Loss: 0.0873, Generator Loss: 0.1736, Series Loss: 0.0023, Class Loss: 0.2439, Accuracy: 0.5494\n",
      "Epoch [252/4000], Discriminator Loss: 0.0869, Generator Loss: 0.1737, Series Loss: 0.0023, Class Loss: 0.2440, Accuracy: 0.5185\n",
      "Epoch [253/4000], Discriminator Loss: 0.0871, Generator Loss: 0.1736, Series Loss: 0.0023, Class Loss: 0.2438, Accuracy: 0.5802\n",
      "Epoch [254/4000], Discriminator Loss: 0.0874, Generator Loss: 0.1737, Series Loss: 0.0023, Class Loss: 0.2439, Accuracy: 0.5370\n",
      "Epoch [255/4000], Discriminator Loss: 0.0866, Generator Loss: 0.1735, Series Loss: 0.0023, Class Loss: 0.2438, Accuracy: 0.5679\n",
      "Epoch [256/4000], Discriminator Loss: 0.0871, Generator Loss: 0.1738, Series Loss: 0.0023, Class Loss: 0.2439, Accuracy: 0.5556\n",
      "Epoch [257/4000], Discriminator Loss: 0.0868, Generator Loss: 0.1739, Series Loss: 0.0023, Class Loss: 0.2439, Accuracy: 0.5247\n",
      "Epoch [258/4000], Discriminator Loss: 0.0867, Generator Loss: 0.1737, Series Loss: 0.0023, Class Loss: 0.2440, Accuracy: 0.5309\n",
      "Epoch [259/4000], Discriminator Loss: 0.0869, Generator Loss: 0.1740, Series Loss: 0.0023, Class Loss: 0.2439, Accuracy: 0.5247\n",
      "Epoch [260/4000], Discriminator Loss: 0.0867, Generator Loss: 0.1738, Series Loss: 0.0023, Class Loss: 0.2439, Accuracy: 0.5802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [261/4000], Discriminator Loss: 0.0867, Generator Loss: 0.1740, Series Loss: 0.0023, Class Loss: 0.2438, Accuracy: 0.5309\n",
      "Epoch [262/4000], Discriminator Loss: 0.0865, Generator Loss: 0.1738, Series Loss: 0.0023, Class Loss: 0.2438, Accuracy: 0.5185\n",
      "Epoch [263/4000], Discriminator Loss: 0.0862, Generator Loss: 0.1739, Series Loss: 0.0023, Class Loss: 0.2439, Accuracy: 0.5432\n",
      "Epoch [264/4000], Discriminator Loss: 0.0861, Generator Loss: 0.1742, Series Loss: 0.0023, Class Loss: 0.2440, Accuracy: 0.5370\n",
      "Epoch [265/4000], Discriminator Loss: 0.0862, Generator Loss: 0.1742, Series Loss: 0.0023, Class Loss: 0.2438, Accuracy: 0.5494\n",
      "Epoch [266/4000], Discriminator Loss: 0.0866, Generator Loss: 0.1743, Series Loss: 0.0023, Class Loss: 0.2439, Accuracy: 0.5062\n",
      "Epoch [267/4000], Discriminator Loss: 0.0863, Generator Loss: 0.1741, Series Loss: 0.0023, Class Loss: 0.2439, Accuracy: 0.5741\n",
      "Epoch [268/4000], Discriminator Loss: 0.0863, Generator Loss: 0.1743, Series Loss: 0.0023, Class Loss: 0.2439, Accuracy: 0.5247\n",
      "Epoch [269/4000], Discriminator Loss: 0.0861, Generator Loss: 0.1744, Series Loss: 0.0023, Class Loss: 0.2437, Accuracy: 0.5123\n",
      "Epoch [270/4000], Discriminator Loss: 0.0862, Generator Loss: 0.1745, Series Loss: 0.0023, Class Loss: 0.2441, Accuracy: 0.4753\n",
      "Epoch [271/4000], Discriminator Loss: 0.0861, Generator Loss: 0.1749, Series Loss: 0.0023, Class Loss: 0.2439, Accuracy: 0.5370\n",
      "Epoch [272/4000], Discriminator Loss: 0.0864, Generator Loss: 0.1748, Series Loss: 0.0023, Class Loss: 0.2439, Accuracy: 0.4753\n",
      "Epoch [273/4000], Discriminator Loss: 0.0861, Generator Loss: 0.1742, Series Loss: 0.0023, Class Loss: 0.2438, Accuracy: 0.4938\n",
      "Epoch [274/4000], Discriminator Loss: 0.0860, Generator Loss: 0.1749, Series Loss: 0.0023, Class Loss: 0.2439, Accuracy: 0.4630\n",
      "Epoch [275/4000], Discriminator Loss: 0.0858, Generator Loss: 0.1744, Series Loss: 0.0024, Class Loss: 0.2438, Accuracy: 0.5000\n",
      "Epoch [276/4000], Discriminator Loss: 0.0857, Generator Loss: 0.1748, Series Loss: 0.0023, Class Loss: 0.2439, Accuracy: 0.4136\n",
      "Epoch [277/4000], Discriminator Loss: 0.0857, Generator Loss: 0.1748, Series Loss: 0.0023, Class Loss: 0.2440, Accuracy: 0.4691\n",
      "Epoch [278/4000], Discriminator Loss: 0.0860, Generator Loss: 0.1748, Series Loss: 0.0023, Class Loss: 0.2440, Accuracy: 0.5185\n",
      "Epoch [279/4000], Discriminator Loss: 0.0860, Generator Loss: 0.1745, Series Loss: 0.0024, Class Loss: 0.2438, Accuracy: 0.4444\n",
      "Epoch [280/4000], Discriminator Loss: 0.0855, Generator Loss: 0.1749, Series Loss: 0.0024, Class Loss: 0.2439, Accuracy: 0.4691\n",
      "Epoch [281/4000], Discriminator Loss: 0.0854, Generator Loss: 0.1751, Series Loss: 0.0024, Class Loss: 0.2438, Accuracy: 0.4753\n",
      "Epoch [282/4000], Discriminator Loss: 0.0859, Generator Loss: 0.1749, Series Loss: 0.0024, Class Loss: 0.2439, Accuracy: 0.4383\n",
      "Epoch [283/4000], Discriminator Loss: 0.0852, Generator Loss: 0.1752, Series Loss: 0.0024, Class Loss: 0.2439, Accuracy: 0.4568\n",
      "Epoch [284/4000], Discriminator Loss: 0.0858, Generator Loss: 0.1752, Series Loss: 0.0024, Class Loss: 0.2439, Accuracy: 0.4321\n",
      "Epoch [285/4000], Discriminator Loss: 0.0854, Generator Loss: 0.1751, Series Loss: 0.0024, Class Loss: 0.2439, Accuracy: 0.4691\n",
      "Epoch [286/4000], Discriminator Loss: 0.0857, Generator Loss: 0.1750, Series Loss: 0.0024, Class Loss: 0.2439, Accuracy: 0.4198\n",
      "Epoch [287/4000], Discriminator Loss: 0.0850, Generator Loss: 0.1755, Series Loss: 0.0024, Class Loss: 0.2439, Accuracy: 0.4444\n",
      "Epoch [288/4000], Discriminator Loss: 0.0852, Generator Loss: 0.1754, Series Loss: 0.0024, Class Loss: 0.2438, Accuracy: 0.4444\n",
      "Epoch [289/4000], Discriminator Loss: 0.0852, Generator Loss: 0.1754, Series Loss: 0.0024, Class Loss: 0.2439, Accuracy: 0.4012\n",
      "Epoch [290/4000], Discriminator Loss: 0.0856, Generator Loss: 0.1753, Series Loss: 0.0024, Class Loss: 0.2440, Accuracy: 0.4012\n",
      "Epoch [291/4000], Discriminator Loss: 0.0850, Generator Loss: 0.1755, Series Loss: 0.0024, Class Loss: 0.2438, Accuracy: 0.4074\n",
      "Epoch [292/4000], Discriminator Loss: 0.0848, Generator Loss: 0.1756, Series Loss: 0.0024, Class Loss: 0.2439, Accuracy: 0.3889\n",
      "Epoch [293/4000], Discriminator Loss: 0.0849, Generator Loss: 0.1753, Series Loss: 0.0024, Class Loss: 0.2438, Accuracy: 0.3765\n",
      "Epoch [294/4000], Discriminator Loss: 0.0850, Generator Loss: 0.1757, Series Loss: 0.0025, Class Loss: 0.2438, Accuracy: 0.4136\n",
      "Epoch [295/4000], Discriminator Loss: 0.0849, Generator Loss: 0.1758, Series Loss: 0.0025, Class Loss: 0.2440, Accuracy: 0.4074\n",
      "Epoch [296/4000], Discriminator Loss: 0.0847, Generator Loss: 0.1760, Series Loss: 0.0025, Class Loss: 0.2439, Accuracy: 0.4198\n",
      "Epoch [297/4000], Discriminator Loss: 0.0848, Generator Loss: 0.1761, Series Loss: 0.0025, Class Loss: 0.2438, Accuracy: 0.3889\n",
      "Epoch [298/4000], Discriminator Loss: 0.0848, Generator Loss: 0.1759, Series Loss: 0.0025, Class Loss: 0.2439, Accuracy: 0.4074\n",
      "Epoch [299/4000], Discriminator Loss: 0.0849, Generator Loss: 0.1761, Series Loss: 0.0025, Class Loss: 0.2440, Accuracy: 0.4012\n",
      "Epoch [300/4000], Discriminator Loss: 0.0847, Generator Loss: 0.1762, Series Loss: 0.0025, Class Loss: 0.2440, Accuracy: 0.3827\n",
      "Epoch [301/4000], Discriminator Loss: 0.0840, Generator Loss: 0.1759, Series Loss: 0.0025, Class Loss: 0.2439, Accuracy: 0.3519\n",
      "Epoch [302/4000], Discriminator Loss: 0.0847, Generator Loss: 0.1763, Series Loss: 0.0025, Class Loss: 0.2439, Accuracy: 0.4136\n",
      "Epoch [303/4000], Discriminator Loss: 0.0844, Generator Loss: 0.1760, Series Loss: 0.0025, Class Loss: 0.2438, Accuracy: 0.3642\n",
      "Epoch [304/4000], Discriminator Loss: 0.0843, Generator Loss: 0.1764, Series Loss: 0.0025, Class Loss: 0.2439, Accuracy: 0.3580\n",
      "Epoch [305/4000], Discriminator Loss: 0.0846, Generator Loss: 0.1762, Series Loss: 0.0025, Class Loss: 0.2439, Accuracy: 0.3889\n",
      "Epoch [306/4000], Discriminator Loss: 0.0842, Generator Loss: 0.1763, Series Loss: 0.0026, Class Loss: 0.2439, Accuracy: 0.3889\n",
      "Epoch [307/4000], Discriminator Loss: 0.0849, Generator Loss: 0.1765, Series Loss: 0.0026, Class Loss: 0.2438, Accuracy: 0.3765\n",
      "Epoch [308/4000], Discriminator Loss: 0.0843, Generator Loss: 0.1765, Series Loss: 0.0026, Class Loss: 0.2438, Accuracy: 0.3395\n",
      "Epoch [309/4000], Discriminator Loss: 0.0841, Generator Loss: 0.1767, Series Loss: 0.0026, Class Loss: 0.2441, Accuracy: 0.3827\n",
      "Epoch [310/4000], Discriminator Loss: 0.0846, Generator Loss: 0.1768, Series Loss: 0.0026, Class Loss: 0.2439, Accuracy: 0.3889\n",
      "Epoch [311/4000], Discriminator Loss: 0.0845, Generator Loss: 0.1767, Series Loss: 0.0026, Class Loss: 0.2438, Accuracy: 0.3395\n",
      "Epoch [312/4000], Discriminator Loss: 0.0841, Generator Loss: 0.1765, Series Loss: 0.0026, Class Loss: 0.2439, Accuracy: 0.3457\n",
      "Epoch [313/4000], Discriminator Loss: 0.0844, Generator Loss: 0.1770, Series Loss: 0.0026, Class Loss: 0.2439, Accuracy: 0.3457\n",
      "Epoch [314/4000], Discriminator Loss: 0.0842, Generator Loss: 0.1773, Series Loss: 0.0026, Class Loss: 0.2440, Accuracy: 0.3333\n",
      "Epoch [315/4000], Discriminator Loss: 0.0838, Generator Loss: 0.1769, Series Loss: 0.0027, Class Loss: 0.2441, Accuracy: 0.3210\n",
      "Epoch [316/4000], Discriminator Loss: 0.0840, Generator Loss: 0.1773, Series Loss: 0.0027, Class Loss: 0.2440, Accuracy: 0.3889\n",
      "Epoch [317/4000], Discriminator Loss: 0.0839, Generator Loss: 0.1771, Series Loss: 0.0027, Class Loss: 0.2438, Accuracy: 0.3395\n",
      "Epoch [318/4000], Discriminator Loss: 0.0841, Generator Loss: 0.1776, Series Loss: 0.0027, Class Loss: 0.2440, Accuracy: 0.3519\n",
      "Epoch [319/4000], Discriminator Loss: 0.0844, Generator Loss: 0.1770, Series Loss: 0.0027, Class Loss: 0.2440, Accuracy: 0.3580\n",
      "Epoch [320/4000], Discriminator Loss: 0.0838, Generator Loss: 0.1774, Series Loss: 0.0027, Class Loss: 0.2439, Accuracy: 0.3580\n",
      "Epoch [321/4000], Discriminator Loss: 0.0840, Generator Loss: 0.1774, Series Loss: 0.0027, Class Loss: 0.2440, Accuracy: 0.3333\n",
      "Epoch [322/4000], Discriminator Loss: 0.0841, Generator Loss: 0.1773, Series Loss: 0.0027, Class Loss: 0.2439, Accuracy: 0.3333\n",
      "Epoch [323/4000], Discriminator Loss: 0.0838, Generator Loss: 0.1775, Series Loss: 0.0027, Class Loss: 0.2440, Accuracy: 0.3395\n",
      "Epoch [324/4000], Discriminator Loss: 0.0840, Generator Loss: 0.1773, Series Loss: 0.0028, Class Loss: 0.2439, Accuracy: 0.3086\n",
      "Epoch [325/4000], Discriminator Loss: 0.0841, Generator Loss: 0.1775, Series Loss: 0.0028, Class Loss: 0.2439, Accuracy: 0.3025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [326/4000], Discriminator Loss: 0.0840, Generator Loss: 0.1769, Series Loss: 0.0028, Class Loss: 0.2439, Accuracy: 0.2901\n",
      "Epoch [327/4000], Discriminator Loss: 0.0840, Generator Loss: 0.1775, Series Loss: 0.0028, Class Loss: 0.2441, Accuracy: 0.3210\n",
      "Epoch [328/4000], Discriminator Loss: 0.0836, Generator Loss: 0.1773, Series Loss: 0.0028, Class Loss: 0.2439, Accuracy: 0.3272\n",
      "Epoch [329/4000], Discriminator Loss: 0.0836, Generator Loss: 0.1779, Series Loss: 0.0028, Class Loss: 0.2441, Accuracy: 0.3025\n",
      "Epoch [330/4000], Discriminator Loss: 0.0838, Generator Loss: 0.1778, Series Loss: 0.0028, Class Loss: 0.2440, Accuracy: 0.3395\n",
      "Epoch [331/4000], Discriminator Loss: 0.0836, Generator Loss: 0.1779, Series Loss: 0.0029, Class Loss: 0.2440, Accuracy: 0.2840\n",
      "Epoch [332/4000], Discriminator Loss: 0.0835, Generator Loss: 0.1781, Series Loss: 0.0029, Class Loss: 0.2439, Accuracy: 0.3148\n",
      "Epoch [333/4000], Discriminator Loss: 0.0839, Generator Loss: 0.1779, Series Loss: 0.0029, Class Loss: 0.2441, Accuracy: 0.3025\n",
      "Epoch [334/4000], Discriminator Loss: 0.0835, Generator Loss: 0.1782, Series Loss: 0.0029, Class Loss: 0.2441, Accuracy: 0.2901\n",
      "Epoch [335/4000], Discriminator Loss: 0.0831, Generator Loss: 0.1785, Series Loss: 0.0029, Class Loss: 0.2440, Accuracy: 0.2901\n",
      "Epoch [336/4000], Discriminator Loss: 0.0840, Generator Loss: 0.1782, Series Loss: 0.0029, Class Loss: 0.2441, Accuracy: 0.2778\n",
      "Epoch [337/4000], Discriminator Loss: 0.0833, Generator Loss: 0.1781, Series Loss: 0.0030, Class Loss: 0.2440, Accuracy: 0.2716\n",
      "Epoch [338/4000], Discriminator Loss: 0.0833, Generator Loss: 0.1782, Series Loss: 0.0030, Class Loss: 0.2440, Accuracy: 0.2654\n",
      "Epoch [339/4000], Discriminator Loss: 0.0836, Generator Loss: 0.1785, Series Loss: 0.0030, Class Loss: 0.2440, Accuracy: 0.2593\n",
      "Epoch [340/4000], Discriminator Loss: 0.0831, Generator Loss: 0.1784, Series Loss: 0.0030, Class Loss: 0.2441, Accuracy: 0.2901\n",
      "Epoch [341/4000], Discriminator Loss: 0.0837, Generator Loss: 0.1783, Series Loss: 0.0030, Class Loss: 0.2440, Accuracy: 0.2840\n",
      "Epoch [342/4000], Discriminator Loss: 0.0833, Generator Loss: 0.1784, Series Loss: 0.0030, Class Loss: 0.2441, Accuracy: 0.2716\n",
      "Epoch [343/4000], Discriminator Loss: 0.0837, Generator Loss: 0.1781, Series Loss: 0.0030, Class Loss: 0.2441, Accuracy: 0.2654\n",
      "Epoch [344/4000], Discriminator Loss: 0.0832, Generator Loss: 0.1787, Series Loss: 0.0031, Class Loss: 0.2441, Accuracy: 0.2901\n",
      "Epoch [345/4000], Discriminator Loss: 0.0833, Generator Loss: 0.1786, Series Loss: 0.0031, Class Loss: 0.2441, Accuracy: 0.2716\n",
      "Epoch [346/4000], Discriminator Loss: 0.0835, Generator Loss: 0.1782, Series Loss: 0.0031, Class Loss: 0.2440, Accuracy: 0.2531\n",
      "Epoch [347/4000], Discriminator Loss: 0.0833, Generator Loss: 0.1785, Series Loss: 0.0031, Class Loss: 0.2440, Accuracy: 0.2531\n",
      "Epoch [348/4000], Discriminator Loss: 0.0835, Generator Loss: 0.1784, Series Loss: 0.0031, Class Loss: 0.2442, Accuracy: 0.2716\n",
      "Epoch [349/4000], Discriminator Loss: 0.0838, Generator Loss: 0.1788, Series Loss: 0.0032, Class Loss: 0.2440, Accuracy: 0.2593\n",
      "Epoch [350/4000], Discriminator Loss: 0.0834, Generator Loss: 0.1788, Series Loss: 0.0032, Class Loss: 0.2442, Accuracy: 0.2593\n",
      "Epoch [351/4000], Discriminator Loss: 0.0831, Generator Loss: 0.1784, Series Loss: 0.0032, Class Loss: 0.2440, Accuracy: 0.2593\n",
      "Epoch [352/4000], Discriminator Loss: 0.0828, Generator Loss: 0.1788, Series Loss: 0.0032, Class Loss: 0.2441, Accuracy: 0.2593\n",
      "Epoch [353/4000], Discriminator Loss: 0.0830, Generator Loss: 0.1788, Series Loss: 0.0032, Class Loss: 0.2441, Accuracy: 0.2531\n",
      "Epoch [354/4000], Discriminator Loss: 0.0830, Generator Loss: 0.1795, Series Loss: 0.0033, Class Loss: 0.2441, Accuracy: 0.2531\n",
      "Epoch [355/4000], Discriminator Loss: 0.0829, Generator Loss: 0.1792, Series Loss: 0.0033, Class Loss: 0.2440, Accuracy: 0.2469\n",
      "Epoch [356/4000], Discriminator Loss: 0.0832, Generator Loss: 0.1788, Series Loss: 0.0033, Class Loss: 0.2441, Accuracy: 0.2531\n",
      "Epoch [357/4000], Discriminator Loss: 0.0829, Generator Loss: 0.1788, Series Loss: 0.0033, Class Loss: 0.2441, Accuracy: 0.2593\n",
      "Epoch [358/4000], Discriminator Loss: 0.0832, Generator Loss: 0.1789, Series Loss: 0.0033, Class Loss: 0.2441, Accuracy: 0.2531\n",
      "Epoch [359/4000], Discriminator Loss: 0.0825, Generator Loss: 0.1790, Series Loss: 0.0033, Class Loss: 0.2442, Accuracy: 0.2469\n",
      "Epoch [360/4000], Discriminator Loss: 0.0828, Generator Loss: 0.1792, Series Loss: 0.0034, Class Loss: 0.2443, Accuracy: 0.2469\n",
      "Epoch [361/4000], Discriminator Loss: 0.0832, Generator Loss: 0.1791, Series Loss: 0.0034, Class Loss: 0.2442, Accuracy: 0.2593\n",
      "Epoch [362/4000], Discriminator Loss: 0.0825, Generator Loss: 0.1797, Series Loss: 0.0035, Class Loss: 0.2441, Accuracy: 0.2593\n",
      "Epoch [363/4000], Discriminator Loss: 0.0827, Generator Loss: 0.1789, Series Loss: 0.0035, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [364/4000], Discriminator Loss: 0.0830, Generator Loss: 0.1794, Series Loss: 0.0035, Class Loss: 0.2442, Accuracy: 0.2407\n",
      "Epoch [365/4000], Discriminator Loss: 0.0831, Generator Loss: 0.1788, Series Loss: 0.0035, Class Loss: 0.2442, Accuracy: 0.2531\n",
      "Epoch [366/4000], Discriminator Loss: 0.0835, Generator Loss: 0.1793, Series Loss: 0.0035, Class Loss: 0.2441, Accuracy: 0.2407\n",
      "Epoch [367/4000], Discriminator Loss: 0.0831, Generator Loss: 0.1793, Series Loss: 0.0036, Class Loss: 0.2441, Accuracy: 0.2593\n",
      "Epoch [368/4000], Discriminator Loss: 0.0828, Generator Loss: 0.1794, Series Loss: 0.0036, Class Loss: 0.2442, Accuracy: 0.2469\n",
      "Epoch [369/4000], Discriminator Loss: 0.0828, Generator Loss: 0.1798, Series Loss: 0.0036, Class Loss: 0.2442, Accuracy: 0.2593\n",
      "Epoch [370/4000], Discriminator Loss: 0.0831, Generator Loss: 0.1792, Series Loss: 0.0037, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [371/4000], Discriminator Loss: 0.0823, Generator Loss: 0.1795, Series Loss: 0.0037, Class Loss: 0.2442, Accuracy: 0.2469\n",
      "Epoch [372/4000], Discriminator Loss: 0.0827, Generator Loss: 0.1800, Series Loss: 0.0037, Class Loss: 0.2443, Accuracy: 0.2346\n",
      "Epoch [373/4000], Discriminator Loss: 0.0830, Generator Loss: 0.1797, Series Loss: 0.0037, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [374/4000], Discriminator Loss: 0.0828, Generator Loss: 0.1797, Series Loss: 0.0038, Class Loss: 0.2442, Accuracy: 0.2531\n",
      "Epoch [375/4000], Discriminator Loss: 0.0832, Generator Loss: 0.1798, Series Loss: 0.0038, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [376/4000], Discriminator Loss: 0.0835, Generator Loss: 0.1795, Series Loss: 0.0039, Class Loss: 0.2442, Accuracy: 0.2469\n",
      "Epoch [377/4000], Discriminator Loss: 0.0824, Generator Loss: 0.1795, Series Loss: 0.0039, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [378/4000], Discriminator Loss: 0.0821, Generator Loss: 0.1798, Series Loss: 0.0040, Class Loss: 0.2445, Accuracy: 0.2407\n",
      "Epoch [379/4000], Discriminator Loss: 0.0828, Generator Loss: 0.1797, Series Loss: 0.0040, Class Loss: 0.2444, Accuracy: 0.2407\n",
      "Epoch [380/4000], Discriminator Loss: 0.0825, Generator Loss: 0.1800, Series Loss: 0.0040, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [381/4000], Discriminator Loss: 0.0833, Generator Loss: 0.1796, Series Loss: 0.0041, Class Loss: 0.2443, Accuracy: 0.2407\n",
      "Epoch [382/4000], Discriminator Loss: 0.0828, Generator Loss: 0.1795, Series Loss: 0.0041, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [383/4000], Discriminator Loss: 0.0825, Generator Loss: 0.1800, Series Loss: 0.0041, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [384/4000], Discriminator Loss: 0.0822, Generator Loss: 0.1802, Series Loss: 0.0042, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [385/4000], Discriminator Loss: 0.0827, Generator Loss: 0.1797, Series Loss: 0.0043, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [386/4000], Discriminator Loss: 0.0830, Generator Loss: 0.1794, Series Loss: 0.0043, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [387/4000], Discriminator Loss: 0.0833, Generator Loss: 0.1799, Series Loss: 0.0044, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [388/4000], Discriminator Loss: 0.0828, Generator Loss: 0.1798, Series Loss: 0.0045, Class Loss: 0.2443, Accuracy: 0.2407\n",
      "Epoch [389/4000], Discriminator Loss: 0.0826, Generator Loss: 0.1802, Series Loss: 0.0045, Class Loss: 0.2446, Accuracy: 0.2469\n",
      "Epoch [390/4000], Discriminator Loss: 0.0825, Generator Loss: 0.1804, Series Loss: 0.0046, Class Loss: 0.2446, Accuracy: 0.2469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [391/4000], Discriminator Loss: 0.0832, Generator Loss: 0.1799, Series Loss: 0.0046, Class Loss: 0.2447, Accuracy: 0.2346\n",
      "Epoch [392/4000], Discriminator Loss: 0.0821, Generator Loss: 0.1803, Series Loss: 0.0047, Class Loss: 0.2446, Accuracy: 0.2407\n",
      "Epoch [393/4000], Discriminator Loss: 0.0826, Generator Loss: 0.1799, Series Loss: 0.0048, Class Loss: 0.2445, Accuracy: 0.2407\n",
      "Epoch [394/4000], Discriminator Loss: 0.0827, Generator Loss: 0.1796, Series Loss: 0.0048, Class Loss: 0.2447, Accuracy: 0.2469\n",
      "Epoch [395/4000], Discriminator Loss: 0.0832, Generator Loss: 0.1800, Series Loss: 0.0048, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [396/4000], Discriminator Loss: 0.0834, Generator Loss: 0.1800, Series Loss: 0.0049, Class Loss: 0.2445, Accuracy: 0.2407\n",
      "Epoch [397/4000], Discriminator Loss: 0.0831, Generator Loss: 0.1801, Series Loss: 0.0050, Class Loss: 0.2447, Accuracy: 0.2469\n",
      "Epoch [398/4000], Discriminator Loss: 0.0833, Generator Loss: 0.1797, Series Loss: 0.0050, Class Loss: 0.2446, Accuracy: 0.2407\n",
      "Epoch [399/4000], Discriminator Loss: 0.0836, Generator Loss: 0.1800, Series Loss: 0.0051, Class Loss: 0.2447, Accuracy: 0.2407\n",
      "Epoch [400/4000], Discriminator Loss: 0.0840, Generator Loss: 0.1794, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2346\n",
      "Epoch [401/4000], Discriminator Loss: 0.0835, Generator Loss: 0.1798, Series Loss: 0.0052, Class Loss: 0.2447, Accuracy: 0.2531\n",
      "Epoch [402/4000], Discriminator Loss: 0.0834, Generator Loss: 0.1802, Series Loss: 0.0053, Class Loss: 0.2447, Accuracy: 0.2407\n",
      "Epoch [403/4000], Discriminator Loss: 0.0838, Generator Loss: 0.1803, Series Loss: 0.0053, Class Loss: 0.2447, Accuracy: 0.2469\n",
      "Epoch [404/4000], Discriminator Loss: 0.0837, Generator Loss: 0.1797, Series Loss: 0.0054, Class Loss: 0.2446, Accuracy: 0.2469\n",
      "Epoch [405/4000], Discriminator Loss: 0.0831, Generator Loss: 0.1800, Series Loss: 0.0054, Class Loss: 0.2447, Accuracy: 0.2469\n",
      "Epoch [406/4000], Discriminator Loss: 0.0843, Generator Loss: 0.1802, Series Loss: 0.0055, Class Loss: 0.2447, Accuracy: 0.2469\n",
      "Epoch [407/4000], Discriminator Loss: 0.0843, Generator Loss: 0.1794, Series Loss: 0.0055, Class Loss: 0.2446, Accuracy: 0.2469\n",
      "Epoch [408/4000], Discriminator Loss: 0.0840, Generator Loss: 0.1801, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2346\n",
      "Epoch [409/4000], Discriminator Loss: 0.0834, Generator Loss: 0.1803, Series Loss: 0.0056, Class Loss: 0.2447, Accuracy: 0.2469\n",
      "Epoch [410/4000], Discriminator Loss: 0.0837, Generator Loss: 0.1798, Series Loss: 0.0057, Class Loss: 0.2446, Accuracy: 0.2531\n",
      "Epoch [411/4000], Discriminator Loss: 0.0838, Generator Loss: 0.1797, Series Loss: 0.0058, Class Loss: 0.2446, Accuracy: 0.2407\n",
      "Epoch [412/4000], Discriminator Loss: 0.0836, Generator Loss: 0.1797, Series Loss: 0.0058, Class Loss: 0.2446, Accuracy: 0.2407\n",
      "Epoch [413/4000], Discriminator Loss: 0.0841, Generator Loss: 0.1798, Series Loss: 0.0060, Class Loss: 0.2446, Accuracy: 0.2531\n",
      "Epoch [414/4000], Discriminator Loss: 0.0841, Generator Loss: 0.1799, Series Loss: 0.0059, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [415/4000], Discriminator Loss: 0.0838, Generator Loss: 0.1798, Series Loss: 0.0060, Class Loss: 0.2446, Accuracy: 0.2407\n",
      "Epoch [416/4000], Discriminator Loss: 0.0839, Generator Loss: 0.1799, Series Loss: 0.0060, Class Loss: 0.2445, Accuracy: 0.2407\n",
      "Epoch [417/4000], Discriminator Loss: 0.0846, Generator Loss: 0.1802, Series Loss: 0.0062, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [418/4000], Discriminator Loss: 0.0843, Generator Loss: 0.1796, Series Loss: 0.0062, Class Loss: 0.2445, Accuracy: 0.2407\n",
      "Epoch [419/4000], Discriminator Loss: 0.0851, Generator Loss: 0.1800, Series Loss: 0.0062, Class Loss: 0.2446, Accuracy: 0.2469\n",
      "Epoch [420/4000], Discriminator Loss: 0.0847, Generator Loss: 0.1800, Series Loss: 0.0063, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [421/4000], Discriminator Loss: 0.0848, Generator Loss: 0.1803, Series Loss: 0.0065, Class Loss: 0.2447, Accuracy: 0.2222\n",
      "Epoch [422/4000], Discriminator Loss: 0.0849, Generator Loss: 0.1799, Series Loss: 0.0065, Class Loss: 0.2446, Accuracy: 0.2531\n",
      "Epoch [423/4000], Discriminator Loss: 0.0851, Generator Loss: 0.1802, Series Loss: 0.0066, Class Loss: 0.2446, Accuracy: 0.2346\n",
      "Epoch [424/4000], Discriminator Loss: 0.0856, Generator Loss: 0.1795, Series Loss: 0.0066, Class Loss: 0.2447, Accuracy: 0.2407\n",
      "Epoch [425/4000], Discriminator Loss: 0.0851, Generator Loss: 0.1803, Series Loss: 0.0067, Class Loss: 0.2446, Accuracy: 0.2407\n",
      "Epoch [426/4000], Discriminator Loss: 0.0851, Generator Loss: 0.1799, Series Loss: 0.0068, Class Loss: 0.2446, Accuracy: 0.2531\n",
      "Epoch [427/4000], Discriminator Loss: 0.0860, Generator Loss: 0.1797, Series Loss: 0.0069, Class Loss: 0.2445, Accuracy: 0.2284\n",
      "Epoch [428/4000], Discriminator Loss: 0.0860, Generator Loss: 0.1799, Series Loss: 0.0069, Class Loss: 0.2448, Accuracy: 0.2469\n",
      "Epoch [429/4000], Discriminator Loss: 0.0849, Generator Loss: 0.1806, Series Loss: 0.0070, Class Loss: 0.2446, Accuracy: 0.2469\n",
      "Epoch [430/4000], Discriminator Loss: 0.0854, Generator Loss: 0.1796, Series Loss: 0.0070, Class Loss: 0.2446, Accuracy: 0.2407\n",
      "Epoch [431/4000], Discriminator Loss: 0.0850, Generator Loss: 0.1803, Series Loss: 0.0072, Class Loss: 0.2446, Accuracy: 0.2407\n",
      "Epoch [432/4000], Discriminator Loss: 0.0859, Generator Loss: 0.1799, Series Loss: 0.0072, Class Loss: 0.2447, Accuracy: 0.2346\n",
      "Epoch [433/4000], Discriminator Loss: 0.0854, Generator Loss: 0.1801, Series Loss: 0.0074, Class Loss: 0.2446, Accuracy: 0.2469\n",
      "Epoch [434/4000], Discriminator Loss: 0.0862, Generator Loss: 0.1799, Series Loss: 0.0074, Class Loss: 0.2447, Accuracy: 0.2469\n",
      "Epoch [435/4000], Discriminator Loss: 0.0861, Generator Loss: 0.1800, Series Loss: 0.0076, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [436/4000], Discriminator Loss: 0.0866, Generator Loss: 0.1807, Series Loss: 0.0076, Class Loss: 0.2446, Accuracy: 0.2469\n",
      "Epoch [437/4000], Discriminator Loss: 0.0864, Generator Loss: 0.1805, Series Loss: 0.0077, Class Loss: 0.2445, Accuracy: 0.2346\n",
      "Epoch [438/4000], Discriminator Loss: 0.0866, Generator Loss: 0.1798, Series Loss: 0.0077, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [439/4000], Discriminator Loss: 0.0867, Generator Loss: 0.1804, Series Loss: 0.0078, Class Loss: 0.2446, Accuracy: 0.2346\n",
      "Epoch [440/4000], Discriminator Loss: 0.0863, Generator Loss: 0.1807, Series Loss: 0.0079, Class Loss: 0.2447, Accuracy: 0.2407\n",
      "Epoch [441/4000], Discriminator Loss: 0.0876, Generator Loss: 0.1802, Series Loss: 0.0079, Class Loss: 0.2446, Accuracy: 0.2407\n",
      "Epoch [442/4000], Discriminator Loss: 0.0867, Generator Loss: 0.1808, Series Loss: 0.0080, Class Loss: 0.2447, Accuracy: 0.2407\n",
      "Epoch [443/4000], Discriminator Loss: 0.0864, Generator Loss: 0.1808, Series Loss: 0.0081, Class Loss: 0.2447, Accuracy: 0.2284\n",
      "Epoch [444/4000], Discriminator Loss: 0.0867, Generator Loss: 0.1805, Series Loss: 0.0082, Class Loss: 0.2446, Accuracy: 0.2407\n",
      "Epoch [445/4000], Discriminator Loss: 0.0878, Generator Loss: 0.1810, Series Loss: 0.0083, Class Loss: 0.2446, Accuracy: 0.2407\n",
      "Epoch [446/4000], Discriminator Loss: 0.0863, Generator Loss: 0.1813, Series Loss: 0.0084, Class Loss: 0.2445, Accuracy: 0.2407\n",
      "Epoch [447/4000], Discriminator Loss: 0.0868, Generator Loss: 0.1808, Series Loss: 0.0084, Class Loss: 0.2447, Accuracy: 0.2531\n",
      "Epoch [448/4000], Discriminator Loss: 0.0869, Generator Loss: 0.1817, Series Loss: 0.0085, Class Loss: 0.2446, Accuracy: 0.2469\n",
      "Epoch [449/4000], Discriminator Loss: 0.0868, Generator Loss: 0.1808, Series Loss: 0.0085, Class Loss: 0.2445, Accuracy: 0.2407\n",
      "Epoch [450/4000], Discriminator Loss: 0.0875, Generator Loss: 0.1813, Series Loss: 0.0086, Class Loss: 0.2447, Accuracy: 0.2469\n",
      "Epoch [451/4000], Discriminator Loss: 0.0874, Generator Loss: 0.1809, Series Loss: 0.0087, Class Loss: 0.2446, Accuracy: 0.2531\n",
      "Epoch [452/4000], Discriminator Loss: 0.0879, Generator Loss: 0.1806, Series Loss: 0.0088, Class Loss: 0.2446, Accuracy: 0.2469\n",
      "Epoch [453/4000], Discriminator Loss: 0.0877, Generator Loss: 0.1811, Series Loss: 0.0089, Class Loss: 0.2446, Accuracy: 0.2469\n",
      "Epoch [454/4000], Discriminator Loss: 0.0884, Generator Loss: 0.1804, Series Loss: 0.0089, Class Loss: 0.2447, Accuracy: 0.2593\n",
      "Epoch [455/4000], Discriminator Loss: 0.0885, Generator Loss: 0.1813, Series Loss: 0.0089, Class Loss: 0.2447, Accuracy: 0.2346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [456/4000], Discriminator Loss: 0.0883, Generator Loss: 0.1813, Series Loss: 0.0090, Class Loss: 0.2446, Accuracy: 0.2531\n",
      "Epoch [457/4000], Discriminator Loss: 0.0880, Generator Loss: 0.1813, Series Loss: 0.0091, Class Loss: 0.2446, Accuracy: 0.2346\n",
      "Epoch [458/4000], Discriminator Loss: 0.0886, Generator Loss: 0.1808, Series Loss: 0.0092, Class Loss: 0.2446, Accuracy: 0.2531\n",
      "Epoch [459/4000], Discriminator Loss: 0.0886, Generator Loss: 0.1812, Series Loss: 0.0091, Class Loss: 0.2446, Accuracy: 0.2531\n",
      "Epoch [460/4000], Discriminator Loss: 0.0885, Generator Loss: 0.1813, Series Loss: 0.0093, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [461/4000], Discriminator Loss: 0.0881, Generator Loss: 0.1818, Series Loss: 0.0093, Class Loss: 0.2446, Accuracy: 0.2469\n",
      "Epoch [462/4000], Discriminator Loss: 0.0888, Generator Loss: 0.1817, Series Loss: 0.0093, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [463/4000], Discriminator Loss: 0.0886, Generator Loss: 0.1819, Series Loss: 0.0094, Class Loss: 0.2447, Accuracy: 0.2346\n",
      "Epoch [464/4000], Discriminator Loss: 0.0892, Generator Loss: 0.1816, Series Loss: 0.0094, Class Loss: 0.2446, Accuracy: 0.2716\n",
      "Epoch [465/4000], Discriminator Loss: 0.0888, Generator Loss: 0.1822, Series Loss: 0.0094, Class Loss: 0.2447, Accuracy: 0.2531\n",
      "Epoch [466/4000], Discriminator Loss: 0.0893, Generator Loss: 0.1818, Series Loss: 0.0094, Class Loss: 0.2447, Accuracy: 0.2654\n",
      "Epoch [467/4000], Discriminator Loss: 0.0894, Generator Loss: 0.1812, Series Loss: 0.0095, Class Loss: 0.2447, Accuracy: 0.2593\n",
      "Epoch [468/4000], Discriminator Loss: 0.0894, Generator Loss: 0.1810, Series Loss: 0.0096, Class Loss: 0.2446, Accuracy: 0.2716\n",
      "Epoch [469/4000], Discriminator Loss: 0.0893, Generator Loss: 0.1813, Series Loss: 0.0096, Class Loss: 0.2446, Accuracy: 0.2469\n",
      "Epoch [470/4000], Discriminator Loss: 0.0887, Generator Loss: 0.1812, Series Loss: 0.0097, Class Loss: 0.2447, Accuracy: 0.2593\n",
      "Epoch [471/4000], Discriminator Loss: 0.0895, Generator Loss: 0.1817, Series Loss: 0.0097, Class Loss: 0.2448, Accuracy: 0.2469\n",
      "Epoch [472/4000], Discriminator Loss: 0.0885, Generator Loss: 0.1817, Series Loss: 0.0097, Class Loss: 0.2447, Accuracy: 0.2654\n",
      "Epoch [473/4000], Discriminator Loss: 0.0889, Generator Loss: 0.1815, Series Loss: 0.0097, Class Loss: 0.2447, Accuracy: 0.2469\n",
      "Epoch [474/4000], Discriminator Loss: 0.0892, Generator Loss: 0.1819, Series Loss: 0.0098, Class Loss: 0.2448, Accuracy: 0.2531\n",
      "Epoch [475/4000], Discriminator Loss: 0.0893, Generator Loss: 0.1814, Series Loss: 0.0097, Class Loss: 0.2447, Accuracy: 0.2407\n",
      "Epoch [476/4000], Discriminator Loss: 0.0894, Generator Loss: 0.1816, Series Loss: 0.0098, Class Loss: 0.2447, Accuracy: 0.2469\n",
      "Epoch [477/4000], Discriminator Loss: 0.0891, Generator Loss: 0.1813, Series Loss: 0.0098, Class Loss: 0.2447, Accuracy: 0.2654\n",
      "Epoch [478/4000], Discriminator Loss: 0.0893, Generator Loss: 0.1819, Series Loss: 0.0098, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [479/4000], Discriminator Loss: 0.0893, Generator Loss: 0.1813, Series Loss: 0.0097, Class Loss: 0.2448, Accuracy: 0.2593\n",
      "Epoch [480/4000], Discriminator Loss: 0.0895, Generator Loss: 0.1815, Series Loss: 0.0097, Class Loss: 0.2448, Accuracy: 0.2593\n",
      "Epoch [481/4000], Discriminator Loss: 0.0887, Generator Loss: 0.1813, Series Loss: 0.0098, Class Loss: 0.2447, Accuracy: 0.2593\n",
      "Epoch [482/4000], Discriminator Loss: 0.0881, Generator Loss: 0.1821, Series Loss: 0.0098, Class Loss: 0.2447, Accuracy: 0.2716\n",
      "Epoch [483/4000], Discriminator Loss: 0.0895, Generator Loss: 0.1816, Series Loss: 0.0098, Class Loss: 0.2447, Accuracy: 0.2716\n",
      "Epoch [484/4000], Discriminator Loss: 0.0902, Generator Loss: 0.1807, Series Loss: 0.0098, Class Loss: 0.2448, Accuracy: 0.2469\n",
      "Epoch [485/4000], Discriminator Loss: 0.0889, Generator Loss: 0.1822, Series Loss: 0.0098, Class Loss: 0.2449, Accuracy: 0.2593\n",
      "Epoch [486/4000], Discriminator Loss: 0.0904, Generator Loss: 0.1813, Series Loss: 0.0098, Class Loss: 0.2448, Accuracy: 0.2593\n",
      "Epoch [487/4000], Discriminator Loss: 0.0892, Generator Loss: 0.1821, Series Loss: 0.0098, Class Loss: 0.2449, Accuracy: 0.2593\n",
      "Epoch [488/4000], Discriminator Loss: 0.0893, Generator Loss: 0.1815, Series Loss: 0.0098, Class Loss: 0.2448, Accuracy: 0.2840\n",
      "Epoch [489/4000], Discriminator Loss: 0.0895, Generator Loss: 0.1817, Series Loss: 0.0098, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [490/4000], Discriminator Loss: 0.0897, Generator Loss: 0.1812, Series Loss: 0.0098, Class Loss: 0.2447, Accuracy: 0.2654\n",
      "Epoch [491/4000], Discriminator Loss: 0.0900, Generator Loss: 0.1808, Series Loss: 0.0098, Class Loss: 0.2448, Accuracy: 0.2531\n",
      "Epoch [492/4000], Discriminator Loss: 0.0901, Generator Loss: 0.1820, Series Loss: 0.0098, Class Loss: 0.2449, Accuracy: 0.2716\n",
      "Epoch [493/4000], Discriminator Loss: 0.0886, Generator Loss: 0.1823, Series Loss: 0.0099, Class Loss: 0.2448, Accuracy: 0.2840\n",
      "Epoch [494/4000], Discriminator Loss: 0.0898, Generator Loss: 0.1814, Series Loss: 0.0099, Class Loss: 0.2447, Accuracy: 0.2778\n",
      "Epoch [495/4000], Discriminator Loss: 0.0894, Generator Loss: 0.1810, Series Loss: 0.0098, Class Loss: 0.2447, Accuracy: 0.2901\n",
      "Epoch [496/4000], Discriminator Loss: 0.0895, Generator Loss: 0.1814, Series Loss: 0.0098, Class Loss: 0.2448, Accuracy: 0.2778\n",
      "Epoch [497/4000], Discriminator Loss: 0.0887, Generator Loss: 0.1815, Series Loss: 0.0099, Class Loss: 0.2447, Accuracy: 0.2901\n",
      "Epoch [498/4000], Discriminator Loss: 0.0897, Generator Loss: 0.1812, Series Loss: 0.0099, Class Loss: 0.2448, Accuracy: 0.2840\n",
      "Epoch [499/4000], Discriminator Loss: 0.0900, Generator Loss: 0.1816, Series Loss: 0.0099, Class Loss: 0.2448, Accuracy: 0.3025\n",
      "Epoch [500/4000], Discriminator Loss: 0.0899, Generator Loss: 0.1817, Series Loss: 0.0098, Class Loss: 0.2448, Accuracy: 0.2840\n",
      "Epoch [501/4000], Discriminator Loss: 0.0903, Generator Loss: 0.1819, Series Loss: 0.0099, Class Loss: 0.2448, Accuracy: 0.2840\n",
      "Epoch [502/4000], Discriminator Loss: 0.0895, Generator Loss: 0.1817, Series Loss: 0.0097, Class Loss: 0.2448, Accuracy: 0.2778\n",
      "Epoch [503/4000], Discriminator Loss: 0.0905, Generator Loss: 0.1820, Series Loss: 0.0098, Class Loss: 0.2450, Accuracy: 0.2716\n",
      "Epoch [504/4000], Discriminator Loss: 0.0894, Generator Loss: 0.1824, Series Loss: 0.0098, Class Loss: 0.2448, Accuracy: 0.2901\n",
      "Epoch [505/4000], Discriminator Loss: 0.0900, Generator Loss: 0.1816, Series Loss: 0.0098, Class Loss: 0.2447, Accuracy: 0.2840\n",
      "Epoch [506/4000], Discriminator Loss: 0.0902, Generator Loss: 0.1817, Series Loss: 0.0098, Class Loss: 0.2449, Accuracy: 0.2901\n",
      "Epoch [507/4000], Discriminator Loss: 0.0905, Generator Loss: 0.1818, Series Loss: 0.0098, Class Loss: 0.2449, Accuracy: 0.3086\n",
      "Epoch [508/4000], Discriminator Loss: 0.0901, Generator Loss: 0.1817, Series Loss: 0.0097, Class Loss: 0.2448, Accuracy: 0.3025\n",
      "Epoch [509/4000], Discriminator Loss: 0.0901, Generator Loss: 0.1820, Series Loss: 0.0098, Class Loss: 0.2449, Accuracy: 0.2901\n",
      "Epoch [510/4000], Discriminator Loss: 0.0905, Generator Loss: 0.1817, Series Loss: 0.0097, Class Loss: 0.2448, Accuracy: 0.3086\n",
      "Epoch [511/4000], Discriminator Loss: 0.0901, Generator Loss: 0.1819, Series Loss: 0.0097, Class Loss: 0.2448, Accuracy: 0.3025\n",
      "Epoch [512/4000], Discriminator Loss: 0.0902, Generator Loss: 0.1813, Series Loss: 0.0096, Class Loss: 0.2448, Accuracy: 0.3086\n",
      "Epoch [513/4000], Discriminator Loss: 0.0898, Generator Loss: 0.1812, Series Loss: 0.0096, Class Loss: 0.2449, Accuracy: 0.3086\n",
      "Epoch [514/4000], Discriminator Loss: 0.0892, Generator Loss: 0.1824, Series Loss: 0.0096, Class Loss: 0.2450, Accuracy: 0.2963\n",
      "Epoch [515/4000], Discriminator Loss: 0.0893, Generator Loss: 0.1813, Series Loss: 0.0097, Class Loss: 0.2448, Accuracy: 0.3210\n",
      "Epoch [516/4000], Discriminator Loss: 0.0897, Generator Loss: 0.1825, Series Loss: 0.0098, Class Loss: 0.2449, Accuracy: 0.3086\n",
      "Epoch [517/4000], Discriminator Loss: 0.0909, Generator Loss: 0.1819, Series Loss: 0.0097, Class Loss: 0.2449, Accuracy: 0.3395\n",
      "Epoch [518/4000], Discriminator Loss: 0.0900, Generator Loss: 0.1816, Series Loss: 0.0097, Class Loss: 0.2449, Accuracy: 0.3148\n",
      "Epoch [519/4000], Discriminator Loss: 0.0897, Generator Loss: 0.1819, Series Loss: 0.0097, Class Loss: 0.2448, Accuracy: 0.3148\n",
      "Epoch [520/4000], Discriminator Loss: 0.0892, Generator Loss: 0.1818, Series Loss: 0.0096, Class Loss: 0.2450, Accuracy: 0.3210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [521/4000], Discriminator Loss: 0.0899, Generator Loss: 0.1818, Series Loss: 0.0097, Class Loss: 0.2449, Accuracy: 0.2963\n",
      "Epoch [522/4000], Discriminator Loss: 0.0892, Generator Loss: 0.1825, Series Loss: 0.0096, Class Loss: 0.2449, Accuracy: 0.3272\n",
      "Epoch [523/4000], Discriminator Loss: 0.0903, Generator Loss: 0.1824, Series Loss: 0.0097, Class Loss: 0.2448, Accuracy: 0.3580\n",
      "Epoch [524/4000], Discriminator Loss: 0.0889, Generator Loss: 0.1827, Series Loss: 0.0096, Class Loss: 0.2449, Accuracy: 0.3210\n",
      "Epoch [525/4000], Discriminator Loss: 0.0907, Generator Loss: 0.1820, Series Loss: 0.0096, Class Loss: 0.2450, Accuracy: 0.2963\n",
      "Epoch [526/4000], Discriminator Loss: 0.0904, Generator Loss: 0.1828, Series Loss: 0.0096, Class Loss: 0.2451, Accuracy: 0.3333\n",
      "Epoch [527/4000], Discriminator Loss: 0.0895, Generator Loss: 0.1819, Series Loss: 0.0096, Class Loss: 0.2450, Accuracy: 0.2963\n",
      "Epoch [528/4000], Discriminator Loss: 0.0893, Generator Loss: 0.1828, Series Loss: 0.0096, Class Loss: 0.2449, Accuracy: 0.3272\n",
      "Epoch [529/4000], Discriminator Loss: 0.0891, Generator Loss: 0.1829, Series Loss: 0.0096, Class Loss: 0.2450, Accuracy: 0.3148\n",
      "Epoch [530/4000], Discriminator Loss: 0.0900, Generator Loss: 0.1818, Series Loss: 0.0096, Class Loss: 0.2449, Accuracy: 0.3210\n",
      "Epoch [531/4000], Discriminator Loss: 0.0895, Generator Loss: 0.1822, Series Loss: 0.0096, Class Loss: 0.2450, Accuracy: 0.3148\n",
      "Epoch [532/4000], Discriminator Loss: 0.0909, Generator Loss: 0.1824, Series Loss: 0.0095, Class Loss: 0.2450, Accuracy: 0.3025\n",
      "Epoch [533/4000], Discriminator Loss: 0.0889, Generator Loss: 0.1830, Series Loss: 0.0097, Class Loss: 0.2450, Accuracy: 0.3272\n",
      "Epoch [534/4000], Discriminator Loss: 0.0901, Generator Loss: 0.1828, Series Loss: 0.0097, Class Loss: 0.2449, Accuracy: 0.3086\n",
      "Epoch [535/4000], Discriminator Loss: 0.0894, Generator Loss: 0.1825, Series Loss: 0.0097, Class Loss: 0.2450, Accuracy: 0.3086\n",
      "Epoch [536/4000], Discriminator Loss: 0.0898, Generator Loss: 0.1827, Series Loss: 0.0097, Class Loss: 0.2450, Accuracy: 0.3395\n",
      "Epoch [537/4000], Discriminator Loss: 0.0902, Generator Loss: 0.1827, Series Loss: 0.0097, Class Loss: 0.2449, Accuracy: 0.3519\n",
      "Epoch [538/4000], Discriminator Loss: 0.0899, Generator Loss: 0.1826, Series Loss: 0.0096, Class Loss: 0.2449, Accuracy: 0.3025\n",
      "Epoch [539/4000], Discriminator Loss: 0.0891, Generator Loss: 0.1827, Series Loss: 0.0096, Class Loss: 0.2450, Accuracy: 0.3148\n",
      "Epoch [540/4000], Discriminator Loss: 0.0900, Generator Loss: 0.1822, Series Loss: 0.0096, Class Loss: 0.2450, Accuracy: 0.3086\n",
      "Epoch [541/4000], Discriminator Loss: 0.0890, Generator Loss: 0.1831, Series Loss: 0.0097, Class Loss: 0.2449, Accuracy: 0.2963\n",
      "Epoch [542/4000], Discriminator Loss: 0.0885, Generator Loss: 0.1824, Series Loss: 0.0098, Class Loss: 0.2449, Accuracy: 0.3148\n",
      "Epoch [543/4000], Discriminator Loss: 0.0897, Generator Loss: 0.1831, Series Loss: 0.0098, Class Loss: 0.2449, Accuracy: 0.3272\n",
      "Epoch [544/4000], Discriminator Loss: 0.0894, Generator Loss: 0.1832, Series Loss: 0.0097, Class Loss: 0.2451, Accuracy: 0.3025\n",
      "Epoch [545/4000], Discriminator Loss: 0.0905, Generator Loss: 0.1820, Series Loss: 0.0097, Class Loss: 0.2449, Accuracy: 0.2963\n",
      "Epoch [546/4000], Discriminator Loss: 0.0893, Generator Loss: 0.1841, Series Loss: 0.0098, Class Loss: 0.2450, Accuracy: 0.2963\n",
      "Epoch [547/4000], Discriminator Loss: 0.0895, Generator Loss: 0.1833, Series Loss: 0.0098, Class Loss: 0.2451, Accuracy: 0.2901\n",
      "Epoch [548/4000], Discriminator Loss: 0.0899, Generator Loss: 0.1837, Series Loss: 0.0097, Class Loss: 0.2451, Accuracy: 0.3086\n",
      "Epoch [549/4000], Discriminator Loss: 0.0890, Generator Loss: 0.1834, Series Loss: 0.0098, Class Loss: 0.2450, Accuracy: 0.3210\n",
      "Epoch [550/4000], Discriminator Loss: 0.0896, Generator Loss: 0.1827, Series Loss: 0.0098, Class Loss: 0.2449, Accuracy: 0.2963\n",
      "Epoch [551/4000], Discriminator Loss: 0.0898, Generator Loss: 0.1826, Series Loss: 0.0097, Class Loss: 0.2449, Accuracy: 0.3086\n",
      "Epoch [552/4000], Discriminator Loss: 0.0898, Generator Loss: 0.1832, Series Loss: 0.0098, Class Loss: 0.2450, Accuracy: 0.2901\n",
      "Epoch [553/4000], Discriminator Loss: 0.0897, Generator Loss: 0.1838, Series Loss: 0.0097, Class Loss: 0.2449, Accuracy: 0.3210\n",
      "Epoch [554/4000], Discriminator Loss: 0.0895, Generator Loss: 0.1831, Series Loss: 0.0098, Class Loss: 0.2450, Accuracy: 0.3395\n",
      "Epoch [555/4000], Discriminator Loss: 0.0888, Generator Loss: 0.1836, Series Loss: 0.0098, Class Loss: 0.2450, Accuracy: 0.3333\n",
      "Epoch [556/4000], Discriminator Loss: 0.0900, Generator Loss: 0.1831, Series Loss: 0.0097, Class Loss: 0.2448, Accuracy: 0.3210\n",
      "Epoch [557/4000], Discriminator Loss: 0.0888, Generator Loss: 0.1835, Series Loss: 0.0098, Class Loss: 0.2450, Accuracy: 0.3272\n",
      "Epoch [558/4000], Discriminator Loss: 0.0889, Generator Loss: 0.1833, Series Loss: 0.0098, Class Loss: 0.2449, Accuracy: 0.3272\n",
      "Epoch [559/4000], Discriminator Loss: 0.0886, Generator Loss: 0.1845, Series Loss: 0.0097, Class Loss: 0.2449, Accuracy: 0.3025\n",
      "Epoch [560/4000], Discriminator Loss: 0.0894, Generator Loss: 0.1836, Series Loss: 0.0098, Class Loss: 0.2450, Accuracy: 0.3148\n",
      "Epoch [561/4000], Discriminator Loss: 0.0889, Generator Loss: 0.1835, Series Loss: 0.0097, Class Loss: 0.2449, Accuracy: 0.3086\n",
      "Epoch [562/4000], Discriminator Loss: 0.0891, Generator Loss: 0.1833, Series Loss: 0.0097, Class Loss: 0.2449, Accuracy: 0.3210\n",
      "Epoch [563/4000], Discriminator Loss: 0.0893, Generator Loss: 0.1829, Series Loss: 0.0097, Class Loss: 0.2449, Accuracy: 0.3519\n",
      "Epoch [564/4000], Discriminator Loss: 0.0901, Generator Loss: 0.1830, Series Loss: 0.0098, Class Loss: 0.2449, Accuracy: 0.3148\n",
      "Epoch [565/4000], Discriminator Loss: 0.0899, Generator Loss: 0.1831, Series Loss: 0.0098, Class Loss: 0.2449, Accuracy: 0.3148\n",
      "Epoch [566/4000], Discriminator Loss: 0.0892, Generator Loss: 0.1836, Series Loss: 0.0098, Class Loss: 0.2449, Accuracy: 0.3210\n",
      "Epoch [567/4000], Discriminator Loss: 0.0887, Generator Loss: 0.1837, Series Loss: 0.0098, Class Loss: 0.2450, Accuracy: 0.3272\n",
      "Epoch [568/4000], Discriminator Loss: 0.0894, Generator Loss: 0.1836, Series Loss: 0.0098, Class Loss: 0.2449, Accuracy: 0.3148\n",
      "Epoch [569/4000], Discriminator Loss: 0.0897, Generator Loss: 0.1836, Series Loss: 0.0098, Class Loss: 0.2448, Accuracy: 0.3086\n",
      "Epoch [570/4000], Discriminator Loss: 0.0887, Generator Loss: 0.1841, Series Loss: 0.0098, Class Loss: 0.2449, Accuracy: 0.3086\n",
      "Epoch [571/4000], Discriminator Loss: 0.0896, Generator Loss: 0.1842, Series Loss: 0.0098, Class Loss: 0.2449, Accuracy: 0.3086\n",
      "Epoch [572/4000], Discriminator Loss: 0.0893, Generator Loss: 0.1833, Series Loss: 0.0098, Class Loss: 0.2449, Accuracy: 0.3272\n",
      "Epoch [573/4000], Discriminator Loss: 0.0885, Generator Loss: 0.1844, Series Loss: 0.0097, Class Loss: 0.2449, Accuracy: 0.3025\n",
      "Epoch [574/4000], Discriminator Loss: 0.0892, Generator Loss: 0.1838, Series Loss: 0.0097, Class Loss: 0.2450, Accuracy: 0.3086\n",
      "Epoch [575/4000], Discriminator Loss: 0.0886, Generator Loss: 0.1843, Series Loss: 0.0097, Class Loss: 0.2450, Accuracy: 0.2963\n",
      "Epoch [576/4000], Discriminator Loss: 0.0895, Generator Loss: 0.1837, Series Loss: 0.0097, Class Loss: 0.2449, Accuracy: 0.3025\n",
      "Epoch [577/4000], Discriminator Loss: 0.0887, Generator Loss: 0.1836, Series Loss: 0.0097, Class Loss: 0.2450, Accuracy: 0.3086\n",
      "Epoch [578/4000], Discriminator Loss: 0.0898, Generator Loss: 0.1836, Series Loss: 0.0097, Class Loss: 0.2450, Accuracy: 0.3210\n",
      "Epoch [579/4000], Discriminator Loss: 0.0891, Generator Loss: 0.1838, Series Loss: 0.0097, Class Loss: 0.2450, Accuracy: 0.3148\n",
      "Epoch [580/4000], Discriminator Loss: 0.0899, Generator Loss: 0.1841, Series Loss: 0.0097, Class Loss: 0.2450, Accuracy: 0.3272\n",
      "Epoch [581/4000], Discriminator Loss: 0.0892, Generator Loss: 0.1834, Series Loss: 0.0098, Class Loss: 0.2450, Accuracy: 0.2901\n",
      "Epoch [582/4000], Discriminator Loss: 0.0887, Generator Loss: 0.1839, Series Loss: 0.0098, Class Loss: 0.2451, Accuracy: 0.3086\n",
      "Epoch [583/4000], Discriminator Loss: 0.0893, Generator Loss: 0.1841, Series Loss: 0.0097, Class Loss: 0.2450, Accuracy: 0.3086\n",
      "Epoch [584/4000], Discriminator Loss: 0.0902, Generator Loss: 0.1831, Series Loss: 0.0097, Class Loss: 0.2450, Accuracy: 0.2901\n",
      "Epoch [585/4000], Discriminator Loss: 0.0883, Generator Loss: 0.1837, Series Loss: 0.0097, Class Loss: 0.2449, Accuracy: 0.2901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [586/4000], Discriminator Loss: 0.0896, Generator Loss: 0.1835, Series Loss: 0.0097, Class Loss: 0.2449, Accuracy: 0.3086\n",
      "Epoch [587/4000], Discriminator Loss: 0.0880, Generator Loss: 0.1840, Series Loss: 0.0097, Class Loss: 0.2449, Accuracy: 0.2840\n",
      "Epoch [588/4000], Discriminator Loss: 0.0894, Generator Loss: 0.1833, Series Loss: 0.0097, Class Loss: 0.2449, Accuracy: 0.2901\n",
      "Epoch [589/4000], Discriminator Loss: 0.0895, Generator Loss: 0.1836, Series Loss: 0.0097, Class Loss: 0.2450, Accuracy: 0.3025\n",
      "Epoch [590/4000], Discriminator Loss: 0.0884, Generator Loss: 0.1840, Series Loss: 0.0098, Class Loss: 0.2448, Accuracy: 0.3025\n",
      "Epoch [591/4000], Discriminator Loss: 0.0896, Generator Loss: 0.1828, Series Loss: 0.0096, Class Loss: 0.2449, Accuracy: 0.2901\n",
      "Epoch [592/4000], Discriminator Loss: 0.0894, Generator Loss: 0.1837, Series Loss: 0.0097, Class Loss: 0.2451, Accuracy: 0.2778\n",
      "Epoch [593/4000], Discriminator Loss: 0.0893, Generator Loss: 0.1840, Series Loss: 0.0097, Class Loss: 0.2449, Accuracy: 0.2901\n",
      "Epoch [594/4000], Discriminator Loss: 0.0892, Generator Loss: 0.1843, Series Loss: 0.0097, Class Loss: 0.2450, Accuracy: 0.3086\n",
      "Epoch [595/4000], Discriminator Loss: 0.0888, Generator Loss: 0.1838, Series Loss: 0.0098, Class Loss: 0.2449, Accuracy: 0.3025\n",
      "Epoch [596/4000], Discriminator Loss: 0.0896, Generator Loss: 0.1830, Series Loss: 0.0097, Class Loss: 0.2449, Accuracy: 0.2901\n",
      "Epoch [597/4000], Discriminator Loss: 0.0882, Generator Loss: 0.1844, Series Loss: 0.0098, Class Loss: 0.2450, Accuracy: 0.2901\n",
      "Epoch [598/4000], Discriminator Loss: 0.0889, Generator Loss: 0.1839, Series Loss: 0.0098, Class Loss: 0.2449, Accuracy: 0.2778\n",
      "Epoch [599/4000], Discriminator Loss: 0.0894, Generator Loss: 0.1831, Series Loss: 0.0098, Class Loss: 0.2450, Accuracy: 0.2901\n",
      "Epoch [600/4000], Discriminator Loss: 0.0890, Generator Loss: 0.1835, Series Loss: 0.0098, Class Loss: 0.2451, Accuracy: 0.2840\n",
      "Epoch [601/4000], Discriminator Loss: 0.0892, Generator Loss: 0.1837, Series Loss: 0.0098, Class Loss: 0.2450, Accuracy: 0.2840\n",
      "Epoch [602/4000], Discriminator Loss: 0.0893, Generator Loss: 0.1839, Series Loss: 0.0098, Class Loss: 0.2449, Accuracy: 0.2840\n",
      "Epoch [603/4000], Discriminator Loss: 0.0888, Generator Loss: 0.1839, Series Loss: 0.0097, Class Loss: 0.2449, Accuracy: 0.2901\n",
      "Epoch [604/4000], Discriminator Loss: 0.0890, Generator Loss: 0.1842, Series Loss: 0.0098, Class Loss: 0.2451, Accuracy: 0.2840\n",
      "Epoch [605/4000], Discriminator Loss: 0.0889, Generator Loss: 0.1844, Series Loss: 0.0098, Class Loss: 0.2450, Accuracy: 0.2778\n",
      "Epoch [606/4000], Discriminator Loss: 0.0895, Generator Loss: 0.1841, Series Loss: 0.0097, Class Loss: 0.2449, Accuracy: 0.2901\n",
      "Epoch [607/4000], Discriminator Loss: 0.0904, Generator Loss: 0.1833, Series Loss: 0.0098, Class Loss: 0.2450, Accuracy: 0.2901\n",
      "Epoch [608/4000], Discriminator Loss: 0.0897, Generator Loss: 0.1833, Series Loss: 0.0098, Class Loss: 0.2450, Accuracy: 0.2901\n",
      "Epoch [609/4000], Discriminator Loss: 0.0900, Generator Loss: 0.1826, Series Loss: 0.0097, Class Loss: 0.2449, Accuracy: 0.2901\n",
      "Epoch [610/4000], Discriminator Loss: 0.0894, Generator Loss: 0.1844, Series Loss: 0.0098, Class Loss: 0.2449, Accuracy: 0.2778\n",
      "Epoch [611/4000], Discriminator Loss: 0.0902, Generator Loss: 0.1832, Series Loss: 0.0099, Class Loss: 0.2450, Accuracy: 0.2901\n",
      "Epoch [612/4000], Discriminator Loss: 0.0899, Generator Loss: 0.1838, Series Loss: 0.0098, Class Loss: 0.2450, Accuracy: 0.2840\n",
      "Epoch [613/4000], Discriminator Loss: 0.0891, Generator Loss: 0.1841, Series Loss: 0.0098, Class Loss: 0.2451, Accuracy: 0.2840\n",
      "Epoch [614/4000], Discriminator Loss: 0.0898, Generator Loss: 0.1840, Series Loss: 0.0098, Class Loss: 0.2450, Accuracy: 0.2963\n",
      "Epoch [615/4000], Discriminator Loss: 0.0890, Generator Loss: 0.1835, Series Loss: 0.0098, Class Loss: 0.2450, Accuracy: 0.2840\n",
      "Epoch [616/4000], Discriminator Loss: 0.0890, Generator Loss: 0.1842, Series Loss: 0.0100, Class Loss: 0.2448, Accuracy: 0.2840\n",
      "Epoch [617/4000], Discriminator Loss: 0.0894, Generator Loss: 0.1835, Series Loss: 0.0099, Class Loss: 0.2450, Accuracy: 0.2778\n",
      "Epoch [618/4000], Discriminator Loss: 0.0893, Generator Loss: 0.1836, Series Loss: 0.0099, Class Loss: 0.2450, Accuracy: 0.2840\n",
      "Epoch [619/4000], Discriminator Loss: 0.0904, Generator Loss: 0.1831, Series Loss: 0.0099, Class Loss: 0.2450, Accuracy: 0.2840\n",
      "Epoch [620/4000], Discriminator Loss: 0.0899, Generator Loss: 0.1830, Series Loss: 0.0099, Class Loss: 0.2449, Accuracy: 0.2778\n",
      "Epoch [621/4000], Discriminator Loss: 0.0890, Generator Loss: 0.1842, Series Loss: 0.0098, Class Loss: 0.2450, Accuracy: 0.2840\n",
      "Epoch [622/4000], Discriminator Loss: 0.0886, Generator Loss: 0.1836, Series Loss: 0.0099, Class Loss: 0.2449, Accuracy: 0.2840\n",
      "Epoch [623/4000], Discriminator Loss: 0.0894, Generator Loss: 0.1840, Series Loss: 0.0099, Class Loss: 0.2452, Accuracy: 0.2840\n",
      "Epoch [624/4000], Discriminator Loss: 0.0898, Generator Loss: 0.1838, Series Loss: 0.0100, Class Loss: 0.2450, Accuracy: 0.2901\n",
      "Epoch [625/4000], Discriminator Loss: 0.0892, Generator Loss: 0.1838, Series Loss: 0.0099, Class Loss: 0.2449, Accuracy: 0.2901\n",
      "Epoch [626/4000], Discriminator Loss: 0.0890, Generator Loss: 0.1838, Series Loss: 0.0099, Class Loss: 0.2450, Accuracy: 0.2901\n",
      "Epoch [627/4000], Discriminator Loss: 0.0887, Generator Loss: 0.1841, Series Loss: 0.0099, Class Loss: 0.2452, Accuracy: 0.2901\n",
      "Epoch [628/4000], Discriminator Loss: 0.0898, Generator Loss: 0.1835, Series Loss: 0.0099, Class Loss: 0.2450, Accuracy: 0.2840\n",
      "Epoch [629/4000], Discriminator Loss: 0.0896, Generator Loss: 0.1831, Series Loss: 0.0099, Class Loss: 0.2450, Accuracy: 0.2840\n",
      "Epoch [630/4000], Discriminator Loss: 0.0893, Generator Loss: 0.1834, Series Loss: 0.0099, Class Loss: 0.2450, Accuracy: 0.2840\n",
      "Epoch [631/4000], Discriminator Loss: 0.0901, Generator Loss: 0.1831, Series Loss: 0.0099, Class Loss: 0.2450, Accuracy: 0.2963\n",
      "Epoch [632/4000], Discriminator Loss: 0.0884, Generator Loss: 0.1835, Series Loss: 0.0099, Class Loss: 0.2448, Accuracy: 0.2901\n",
      "Epoch [633/4000], Discriminator Loss: 0.0889, Generator Loss: 0.1833, Series Loss: 0.0100, Class Loss: 0.2450, Accuracy: 0.2840\n",
      "Epoch [634/4000], Discriminator Loss: 0.0887, Generator Loss: 0.1833, Series Loss: 0.0100, Class Loss: 0.2450, Accuracy: 0.2901\n",
      "Epoch [635/4000], Discriminator Loss: 0.0888, Generator Loss: 0.1846, Series Loss: 0.0101, Class Loss: 0.2450, Accuracy: 0.3086\n",
      "Epoch [636/4000], Discriminator Loss: 0.0897, Generator Loss: 0.1838, Series Loss: 0.0101, Class Loss: 0.2448, Accuracy: 0.2840\n",
      "Epoch [637/4000], Discriminator Loss: 0.0892, Generator Loss: 0.1838, Series Loss: 0.0101, Class Loss: 0.2449, Accuracy: 0.2901\n",
      "Epoch [638/4000], Discriminator Loss: 0.0898, Generator Loss: 0.1843, Series Loss: 0.0100, Class Loss: 0.2450, Accuracy: 0.2901\n",
      "Epoch [639/4000], Discriminator Loss: 0.0896, Generator Loss: 0.1837, Series Loss: 0.0101, Class Loss: 0.2450, Accuracy: 0.2901\n",
      "Epoch [640/4000], Discriminator Loss: 0.0893, Generator Loss: 0.1837, Series Loss: 0.0100, Class Loss: 0.2451, Accuracy: 0.2963\n",
      "Epoch [641/4000], Discriminator Loss: 0.0891, Generator Loss: 0.1840, Series Loss: 0.0101, Class Loss: 0.2449, Accuracy: 0.3086\n",
      "Epoch [642/4000], Discriminator Loss: 0.0890, Generator Loss: 0.1840, Series Loss: 0.0101, Class Loss: 0.2449, Accuracy: 0.2901\n",
      "Epoch [643/4000], Discriminator Loss: 0.0899, Generator Loss: 0.1833, Series Loss: 0.0101, Class Loss: 0.2448, Accuracy: 0.2901\n",
      "Epoch [644/4000], Discriminator Loss: 0.0887, Generator Loss: 0.1842, Series Loss: 0.0101, Class Loss: 0.2451, Accuracy: 0.2963\n",
      "Epoch [645/4000], Discriminator Loss: 0.0895, Generator Loss: 0.1845, Series Loss: 0.0101, Class Loss: 0.2449, Accuracy: 0.2963\n",
      "Epoch [646/4000], Discriminator Loss: 0.0895, Generator Loss: 0.1839, Series Loss: 0.0101, Class Loss: 0.2450, Accuracy: 0.2963\n",
      "Epoch [647/4000], Discriminator Loss: 0.0881, Generator Loss: 0.1840, Series Loss: 0.0101, Class Loss: 0.2449, Accuracy: 0.3025\n",
      "Epoch [648/4000], Discriminator Loss: 0.0890, Generator Loss: 0.1840, Series Loss: 0.0102, Class Loss: 0.2449, Accuracy: 0.3025\n",
      "Epoch [649/4000], Discriminator Loss: 0.0901, Generator Loss: 0.1835, Series Loss: 0.0101, Class Loss: 0.2449, Accuracy: 0.2901\n",
      "Epoch [650/4000], Discriminator Loss: 0.0891, Generator Loss: 0.1844, Series Loss: 0.0101, Class Loss: 0.2449, Accuracy: 0.3148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [651/4000], Discriminator Loss: 0.0892, Generator Loss: 0.1837, Series Loss: 0.0101, Class Loss: 0.2449, Accuracy: 0.2963\n",
      "Epoch [652/4000], Discriminator Loss: 0.0890, Generator Loss: 0.1839, Series Loss: 0.0101, Class Loss: 0.2449, Accuracy: 0.2901\n",
      "Epoch [653/4000], Discriminator Loss: 0.0900, Generator Loss: 0.1836, Series Loss: 0.0101, Class Loss: 0.2449, Accuracy: 0.2840\n",
      "Epoch [654/4000], Discriminator Loss: 0.0894, Generator Loss: 0.1845, Series Loss: 0.0101, Class Loss: 0.2449, Accuracy: 0.2901\n",
      "Epoch [655/4000], Discriminator Loss: 0.0893, Generator Loss: 0.1843, Series Loss: 0.0102, Class Loss: 0.2450, Accuracy: 0.2901\n",
      "Epoch [656/4000], Discriminator Loss: 0.0893, Generator Loss: 0.1839, Series Loss: 0.0102, Class Loss: 0.2449, Accuracy: 0.2901\n",
      "Epoch [657/4000], Discriminator Loss: 0.0894, Generator Loss: 0.1840, Series Loss: 0.0102, Class Loss: 0.2449, Accuracy: 0.3025\n",
      "Epoch [658/4000], Discriminator Loss: 0.0887, Generator Loss: 0.1847, Series Loss: 0.0101, Class Loss: 0.2449, Accuracy: 0.2963\n",
      "Epoch [659/4000], Discriminator Loss: 0.0896, Generator Loss: 0.1843, Series Loss: 0.0101, Class Loss: 0.2449, Accuracy: 0.2901\n",
      "Epoch [660/4000], Discriminator Loss: 0.0894, Generator Loss: 0.1838, Series Loss: 0.0103, Class Loss: 0.2450, Accuracy: 0.2963\n",
      "Epoch [661/4000], Discriminator Loss: 0.0895, Generator Loss: 0.1833, Series Loss: 0.0102, Class Loss: 0.2449, Accuracy: 0.2840\n",
      "Epoch [662/4000], Discriminator Loss: 0.0897, Generator Loss: 0.1846, Series Loss: 0.0102, Class Loss: 0.2450, Accuracy: 0.2840\n",
      "Epoch [663/4000], Discriminator Loss: 0.0894, Generator Loss: 0.1845, Series Loss: 0.0102, Class Loss: 0.2449, Accuracy: 0.2963\n",
      "Epoch [664/4000], Discriminator Loss: 0.0892, Generator Loss: 0.1842, Series Loss: 0.0103, Class Loss: 0.2449, Accuracy: 0.2901\n",
      "Epoch [665/4000], Discriminator Loss: 0.0892, Generator Loss: 0.1841, Series Loss: 0.0102, Class Loss: 0.2449, Accuracy: 0.2901\n",
      "Epoch [666/4000], Discriminator Loss: 0.0891, Generator Loss: 0.1841, Series Loss: 0.0102, Class Loss: 0.2449, Accuracy: 0.2778\n",
      "Epoch [667/4000], Discriminator Loss: 0.0889, Generator Loss: 0.1849, Series Loss: 0.0103, Class Loss: 0.2449, Accuracy: 0.2963\n",
      "Epoch [668/4000], Discriminator Loss: 0.0903, Generator Loss: 0.1842, Series Loss: 0.0102, Class Loss: 0.2449, Accuracy: 0.2901\n",
      "Epoch [669/4000], Discriminator Loss: 0.0897, Generator Loss: 0.1835, Series Loss: 0.0102, Class Loss: 0.2448, Accuracy: 0.2963\n",
      "Epoch [670/4000], Discriminator Loss: 0.0896, Generator Loss: 0.1843, Series Loss: 0.0103, Class Loss: 0.2448, Accuracy: 0.2901\n",
      "Epoch [671/4000], Discriminator Loss: 0.0894, Generator Loss: 0.1842, Series Loss: 0.0102, Class Loss: 0.2448, Accuracy: 0.2716\n",
      "Epoch [672/4000], Discriminator Loss: 0.0890, Generator Loss: 0.1841, Series Loss: 0.0103, Class Loss: 0.2450, Accuracy: 0.2778\n",
      "Epoch [673/4000], Discriminator Loss: 0.0895, Generator Loss: 0.1844, Series Loss: 0.0103, Class Loss: 0.2448, Accuracy: 0.2778\n",
      "Epoch [674/4000], Discriminator Loss: 0.0888, Generator Loss: 0.1847, Series Loss: 0.0102, Class Loss: 0.2449, Accuracy: 0.2840\n",
      "Epoch [675/4000], Discriminator Loss: 0.0898, Generator Loss: 0.1845, Series Loss: 0.0103, Class Loss: 0.2449, Accuracy: 0.3025\n",
      "Epoch [676/4000], Discriminator Loss: 0.0888, Generator Loss: 0.1847, Series Loss: 0.0103, Class Loss: 0.2449, Accuracy: 0.2840\n",
      "Epoch [677/4000], Discriminator Loss: 0.0893, Generator Loss: 0.1846, Series Loss: 0.0102, Class Loss: 0.2450, Accuracy: 0.2901\n",
      "Epoch [678/4000], Discriminator Loss: 0.0887, Generator Loss: 0.1842, Series Loss: 0.0103, Class Loss: 0.2448, Accuracy: 0.2901\n",
      "Epoch [679/4000], Discriminator Loss: 0.0888, Generator Loss: 0.1846, Series Loss: 0.0103, Class Loss: 0.2450, Accuracy: 0.2840\n",
      "Epoch [680/4000], Discriminator Loss: 0.0895, Generator Loss: 0.1849, Series Loss: 0.0104, Class Loss: 0.2448, Accuracy: 0.2840\n",
      "Epoch [681/4000], Discriminator Loss: 0.0904, Generator Loss: 0.1840, Series Loss: 0.0103, Class Loss: 0.2449, Accuracy: 0.2901\n",
      "Epoch [682/4000], Discriminator Loss: 0.0890, Generator Loss: 0.1845, Series Loss: 0.0103, Class Loss: 0.2448, Accuracy: 0.2840\n",
      "Epoch [683/4000], Discriminator Loss: 0.0896, Generator Loss: 0.1858, Series Loss: 0.0104, Class Loss: 0.2450, Accuracy: 0.2901\n",
      "Epoch [684/4000], Discriminator Loss: 0.0892, Generator Loss: 0.1846, Series Loss: 0.0104, Class Loss: 0.2449, Accuracy: 0.2901\n",
      "Epoch [685/4000], Discriminator Loss: 0.0897, Generator Loss: 0.1844, Series Loss: 0.0103, Class Loss: 0.2448, Accuracy: 0.2901\n",
      "Epoch [686/4000], Discriminator Loss: 0.0893, Generator Loss: 0.1847, Series Loss: 0.0104, Class Loss: 0.2448, Accuracy: 0.2901\n",
      "Epoch [687/4000], Discriminator Loss: 0.0896, Generator Loss: 0.1855, Series Loss: 0.0104, Class Loss: 0.2450, Accuracy: 0.2901\n",
      "Epoch [688/4000], Discriminator Loss: 0.0891, Generator Loss: 0.1848, Series Loss: 0.0104, Class Loss: 0.2449, Accuracy: 0.2840\n",
      "Epoch [689/4000], Discriminator Loss: 0.0893, Generator Loss: 0.1847, Series Loss: 0.0104, Class Loss: 0.2450, Accuracy: 0.2778\n",
      "Epoch [690/4000], Discriminator Loss: 0.0897, Generator Loss: 0.1847, Series Loss: 0.0104, Class Loss: 0.2449, Accuracy: 0.3025\n",
      "Epoch [691/4000], Discriminator Loss: 0.0893, Generator Loss: 0.1846, Series Loss: 0.0103, Class Loss: 0.2449, Accuracy: 0.2778\n",
      "Epoch [692/4000], Discriminator Loss: 0.0891, Generator Loss: 0.1846, Series Loss: 0.0104, Class Loss: 0.2449, Accuracy: 0.3025\n",
      "Epoch [693/4000], Discriminator Loss: 0.0901, Generator Loss: 0.1842, Series Loss: 0.0104, Class Loss: 0.2448, Accuracy: 0.2901\n",
      "Epoch [694/4000], Discriminator Loss: 0.0895, Generator Loss: 0.1846, Series Loss: 0.0103, Class Loss: 0.2448, Accuracy: 0.2963\n",
      "Epoch [695/4000], Discriminator Loss: 0.0887, Generator Loss: 0.1854, Series Loss: 0.0104, Class Loss: 0.2449, Accuracy: 0.3086\n",
      "Epoch [696/4000], Discriminator Loss: 0.0888, Generator Loss: 0.1852, Series Loss: 0.0104, Class Loss: 0.2449, Accuracy: 0.2840\n",
      "Epoch [697/4000], Discriminator Loss: 0.0891, Generator Loss: 0.1854, Series Loss: 0.0104, Class Loss: 0.2449, Accuracy: 0.2901\n",
      "Epoch [698/4000], Discriminator Loss: 0.0895, Generator Loss: 0.1849, Series Loss: 0.0105, Class Loss: 0.2450, Accuracy: 0.2901\n",
      "Epoch [699/4000], Discriminator Loss: 0.0897, Generator Loss: 0.1847, Series Loss: 0.0105, Class Loss: 0.2448, Accuracy: 0.2840\n",
      "Epoch [700/4000], Discriminator Loss: 0.0899, Generator Loss: 0.1847, Series Loss: 0.0105, Class Loss: 0.2448, Accuracy: 0.2840\n",
      "Epoch [701/4000], Discriminator Loss: 0.0885, Generator Loss: 0.1849, Series Loss: 0.0105, Class Loss: 0.2448, Accuracy: 0.3025\n",
      "Epoch [702/4000], Discriminator Loss: 0.0897, Generator Loss: 0.1845, Series Loss: 0.0104, Class Loss: 0.2448, Accuracy: 0.2901\n",
      "Epoch [703/4000], Discriminator Loss: 0.0893, Generator Loss: 0.1843, Series Loss: 0.0104, Class Loss: 0.2449, Accuracy: 0.3025\n",
      "Epoch [704/4000], Discriminator Loss: 0.0892, Generator Loss: 0.1841, Series Loss: 0.0103, Class Loss: 0.2449, Accuracy: 0.2840\n",
      "Epoch [705/4000], Discriminator Loss: 0.0895, Generator Loss: 0.1846, Series Loss: 0.0103, Class Loss: 0.2448, Accuracy: 0.3025\n",
      "Epoch [706/4000], Discriminator Loss: 0.0895, Generator Loss: 0.1844, Series Loss: 0.0103, Class Loss: 0.2448, Accuracy: 0.2901\n",
      "Epoch [707/4000], Discriminator Loss: 0.0896, Generator Loss: 0.1851, Series Loss: 0.0103, Class Loss: 0.2449, Accuracy: 0.3025\n",
      "Epoch [708/4000], Discriminator Loss: 0.0896, Generator Loss: 0.1842, Series Loss: 0.0103, Class Loss: 0.2448, Accuracy: 0.2840\n",
      "Epoch [709/4000], Discriminator Loss: 0.0902, Generator Loss: 0.1843, Series Loss: 0.0103, Class Loss: 0.2448, Accuracy: 0.2901\n",
      "Epoch [710/4000], Discriminator Loss: 0.0903, Generator Loss: 0.1841, Series Loss: 0.0102, Class Loss: 0.2447, Accuracy: 0.3086\n",
      "Epoch [711/4000], Discriminator Loss: 0.0889, Generator Loss: 0.1850, Series Loss: 0.0102, Class Loss: 0.2449, Accuracy: 0.2901\n",
      "Epoch [712/4000], Discriminator Loss: 0.0896, Generator Loss: 0.1840, Series Loss: 0.0102, Class Loss: 0.2448, Accuracy: 0.2901\n",
      "Epoch [713/4000], Discriminator Loss: 0.0888, Generator Loss: 0.1841, Series Loss: 0.0102, Class Loss: 0.2448, Accuracy: 0.2840\n",
      "Epoch [714/4000], Discriminator Loss: 0.0898, Generator Loss: 0.1840, Series Loss: 0.0102, Class Loss: 0.2448, Accuracy: 0.2840\n",
      "Epoch [715/4000], Discriminator Loss: 0.0899, Generator Loss: 0.1838, Series Loss: 0.0102, Class Loss: 0.2447, Accuracy: 0.2778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [716/4000], Discriminator Loss: 0.0895, Generator Loss: 0.1839, Series Loss: 0.0102, Class Loss: 0.2448, Accuracy: 0.2963\n",
      "Epoch [717/4000], Discriminator Loss: 0.0901, Generator Loss: 0.1839, Series Loss: 0.0101, Class Loss: 0.2449, Accuracy: 0.2840\n",
      "Epoch [718/4000], Discriminator Loss: 0.0897, Generator Loss: 0.1834, Series Loss: 0.0100, Class Loss: 0.2447, Accuracy: 0.3025\n",
      "Epoch [719/4000], Discriminator Loss: 0.0897, Generator Loss: 0.1838, Series Loss: 0.0101, Class Loss: 0.2448, Accuracy: 0.2840\n",
      "Epoch [720/4000], Discriminator Loss: 0.0898, Generator Loss: 0.1836, Series Loss: 0.0101, Class Loss: 0.2449, Accuracy: 0.2840\n",
      "Epoch [721/4000], Discriminator Loss: 0.0903, Generator Loss: 0.1835, Series Loss: 0.0101, Class Loss: 0.2449, Accuracy: 0.2963\n",
      "Epoch [722/4000], Discriminator Loss: 0.0903, Generator Loss: 0.1835, Series Loss: 0.0102, Class Loss: 0.2448, Accuracy: 0.2840\n",
      "Epoch [723/4000], Discriminator Loss: 0.0894, Generator Loss: 0.1838, Series Loss: 0.0103, Class Loss: 0.2449, Accuracy: 0.2778\n",
      "Epoch [724/4000], Discriminator Loss: 0.0894, Generator Loss: 0.1843, Series Loss: 0.0101, Class Loss: 0.2448, Accuracy: 0.3025\n",
      "Epoch [725/4000], Discriminator Loss: 0.0892, Generator Loss: 0.1835, Series Loss: 0.0100, Class Loss: 0.2447, Accuracy: 0.2963\n",
      "Epoch [726/4000], Discriminator Loss: 0.0892, Generator Loss: 0.1840, Series Loss: 0.0101, Class Loss: 0.2447, Accuracy: 0.2901\n",
      "Epoch [727/4000], Discriminator Loss: 0.0897, Generator Loss: 0.1841, Series Loss: 0.0100, Class Loss: 0.2448, Accuracy: 0.2840\n",
      "Epoch [728/4000], Discriminator Loss: 0.0895, Generator Loss: 0.1834, Series Loss: 0.0101, Class Loss: 0.2447, Accuracy: 0.2963\n",
      "Epoch [729/4000], Discriminator Loss: 0.0898, Generator Loss: 0.1838, Series Loss: 0.0099, Class Loss: 0.2447, Accuracy: 0.2901\n",
      "Epoch [730/4000], Discriminator Loss: 0.0893, Generator Loss: 0.1850, Series Loss: 0.0100, Class Loss: 0.2448, Accuracy: 0.2901\n",
      "Epoch [731/4000], Discriminator Loss: 0.0893, Generator Loss: 0.1848, Series Loss: 0.0099, Class Loss: 0.2446, Accuracy: 0.2963\n",
      "Epoch [732/4000], Discriminator Loss: 0.0895, Generator Loss: 0.1842, Series Loss: 0.0099, Class Loss: 0.2448, Accuracy: 0.2840\n",
      "Epoch [733/4000], Discriminator Loss: 0.0894, Generator Loss: 0.1843, Series Loss: 0.0100, Class Loss: 0.2449, Accuracy: 0.2963\n",
      "Epoch [734/4000], Discriminator Loss: 0.0898, Generator Loss: 0.1837, Series Loss: 0.0100, Class Loss: 0.2448, Accuracy: 0.2901\n",
      "Epoch [735/4000], Discriminator Loss: 0.0896, Generator Loss: 0.1840, Series Loss: 0.0099, Class Loss: 0.2447, Accuracy: 0.2840\n",
      "Epoch [736/4000], Discriminator Loss: 0.0898, Generator Loss: 0.1838, Series Loss: 0.0099, Class Loss: 0.2448, Accuracy: 0.2840\n",
      "Epoch [737/4000], Discriminator Loss: 0.0896, Generator Loss: 0.1849, Series Loss: 0.0100, Class Loss: 0.2447, Accuracy: 0.2840\n",
      "Epoch [738/4000], Discriminator Loss: 0.0897, Generator Loss: 0.1844, Series Loss: 0.0100, Class Loss: 0.2447, Accuracy: 0.2840\n",
      "Epoch [739/4000], Discriminator Loss: 0.0904, Generator Loss: 0.1837, Series Loss: 0.0099, Class Loss: 0.2446, Accuracy: 0.3025\n",
      "Epoch [740/4000], Discriminator Loss: 0.0897, Generator Loss: 0.1832, Series Loss: 0.0100, Class Loss: 0.2448, Accuracy: 0.2963\n",
      "Epoch [741/4000], Discriminator Loss: 0.0900, Generator Loss: 0.1838, Series Loss: 0.0099, Class Loss: 0.2448, Accuracy: 0.3025\n",
      "Epoch [742/4000], Discriminator Loss: 0.0895, Generator Loss: 0.1849, Series Loss: 0.0100, Class Loss: 0.2447, Accuracy: 0.3025\n",
      "Epoch [743/4000], Discriminator Loss: 0.0887, Generator Loss: 0.1839, Series Loss: 0.0100, Class Loss: 0.2446, Accuracy: 0.2840\n",
      "Epoch [744/4000], Discriminator Loss: 0.0902, Generator Loss: 0.1843, Series Loss: 0.0099, Class Loss: 0.2447, Accuracy: 0.2901\n",
      "Epoch [745/4000], Discriminator Loss: 0.0904, Generator Loss: 0.1839, Series Loss: 0.0098, Class Loss: 0.2447, Accuracy: 0.2963\n",
      "Epoch [746/4000], Discriminator Loss: 0.0896, Generator Loss: 0.1835, Series Loss: 0.0099, Class Loss: 0.2448, Accuracy: 0.2901\n",
      "Epoch [747/4000], Discriminator Loss: 0.0901, Generator Loss: 0.1838, Series Loss: 0.0099, Class Loss: 0.2447, Accuracy: 0.2901\n",
      "Epoch [748/4000], Discriminator Loss: 0.0898, Generator Loss: 0.1839, Series Loss: 0.0099, Class Loss: 0.2446, Accuracy: 0.2963\n",
      "Epoch [749/4000], Discriminator Loss: 0.0894, Generator Loss: 0.1840, Series Loss: 0.0100, Class Loss: 0.2447, Accuracy: 0.2963\n",
      "Epoch [750/4000], Discriminator Loss: 0.0906, Generator Loss: 0.1834, Series Loss: 0.0099, Class Loss: 0.2447, Accuracy: 0.2963\n",
      "Epoch [751/4000], Discriminator Loss: 0.0891, Generator Loss: 0.1840, Series Loss: 0.0100, Class Loss: 0.2446, Accuracy: 0.3025\n",
      "Epoch [752/4000], Discriminator Loss: 0.0899, Generator Loss: 0.1846, Series Loss: 0.0100, Class Loss: 0.2448, Accuracy: 0.2778\n",
      "Epoch [753/4000], Discriminator Loss: 0.0902, Generator Loss: 0.1834, Series Loss: 0.0099, Class Loss: 0.2447, Accuracy: 0.3025\n",
      "Epoch [754/4000], Discriminator Loss: 0.0900, Generator Loss: 0.1837, Series Loss: 0.0099, Class Loss: 0.2448, Accuracy: 0.2901\n",
      "Epoch [755/4000], Discriminator Loss: 0.0899, Generator Loss: 0.1844, Series Loss: 0.0099, Class Loss: 0.2448, Accuracy: 0.3025\n",
      "Epoch [756/4000], Discriminator Loss: 0.0900, Generator Loss: 0.1838, Series Loss: 0.0100, Class Loss: 0.2446, Accuracy: 0.2963\n",
      "Epoch [757/4000], Discriminator Loss: 0.0903, Generator Loss: 0.1830, Series Loss: 0.0099, Class Loss: 0.2447, Accuracy: 0.3086\n",
      "Epoch [758/4000], Discriminator Loss: 0.0903, Generator Loss: 0.1842, Series Loss: 0.0100, Class Loss: 0.2448, Accuracy: 0.2840\n",
      "Epoch [759/4000], Discriminator Loss: 0.0902, Generator Loss: 0.1837, Series Loss: 0.0099, Class Loss: 0.2447, Accuracy: 0.2901\n",
      "Epoch [760/4000], Discriminator Loss: 0.0896, Generator Loss: 0.1836, Series Loss: 0.0099, Class Loss: 0.2447, Accuracy: 0.2963\n",
      "Epoch [761/4000], Discriminator Loss: 0.0900, Generator Loss: 0.1838, Series Loss: 0.0098, Class Loss: 0.2447, Accuracy: 0.2901\n",
      "Epoch [762/4000], Discriminator Loss: 0.0897, Generator Loss: 0.1835, Series Loss: 0.0100, Class Loss: 0.2448, Accuracy: 0.2963\n",
      "Epoch [763/4000], Discriminator Loss: 0.0910, Generator Loss: 0.1833, Series Loss: 0.0098, Class Loss: 0.2447, Accuracy: 0.2840\n",
      "Epoch [764/4000], Discriminator Loss: 0.0896, Generator Loss: 0.1842, Series Loss: 0.0099, Class Loss: 0.2446, Accuracy: 0.2840\n",
      "Epoch [765/4000], Discriminator Loss: 0.0895, Generator Loss: 0.1841, Series Loss: 0.0098, Class Loss: 0.2448, Accuracy: 0.2963\n",
      "Epoch [766/4000], Discriminator Loss: 0.0906, Generator Loss: 0.1832, Series Loss: 0.0098, Class Loss: 0.2446, Accuracy: 0.2963\n",
      "Epoch [767/4000], Discriminator Loss: 0.0901, Generator Loss: 0.1826, Series Loss: 0.0098, Class Loss: 0.2447, Accuracy: 0.3025\n",
      "Epoch [768/4000], Discriminator Loss: 0.0896, Generator Loss: 0.1834, Series Loss: 0.0099, Class Loss: 0.2446, Accuracy: 0.3025\n",
      "Epoch [769/4000], Discriminator Loss: 0.0896, Generator Loss: 0.1829, Series Loss: 0.0098, Class Loss: 0.2446, Accuracy: 0.2901\n",
      "Epoch [770/4000], Discriminator Loss: 0.0903, Generator Loss: 0.1830, Series Loss: 0.0098, Class Loss: 0.2447, Accuracy: 0.2963\n",
      "Epoch [771/4000], Discriminator Loss: 0.0893, Generator Loss: 0.1833, Series Loss: 0.0097, Class Loss: 0.2447, Accuracy: 0.2963\n",
      "Epoch [772/4000], Discriminator Loss: 0.0906, Generator Loss: 0.1833, Series Loss: 0.0098, Class Loss: 0.2446, Accuracy: 0.3025\n",
      "Epoch [773/4000], Discriminator Loss: 0.0899, Generator Loss: 0.1838, Series Loss: 0.0098, Class Loss: 0.2448, Accuracy: 0.2901\n",
      "Epoch [774/4000], Discriminator Loss: 0.0898, Generator Loss: 0.1834, Series Loss: 0.0099, Class Loss: 0.2448, Accuracy: 0.2840\n",
      "Epoch [775/4000], Discriminator Loss: 0.0896, Generator Loss: 0.1832, Series Loss: 0.0099, Class Loss: 0.2448, Accuracy: 0.3025\n",
      "Epoch [776/4000], Discriminator Loss: 0.0899, Generator Loss: 0.1832, Series Loss: 0.0098, Class Loss: 0.2448, Accuracy: 0.3086\n",
      "Epoch [777/4000], Discriminator Loss: 0.0902, Generator Loss: 0.1832, Series Loss: 0.0098, Class Loss: 0.2448, Accuracy: 0.2901\n",
      "Epoch [778/4000], Discriminator Loss: 0.0895, Generator Loss: 0.1831, Series Loss: 0.0098, Class Loss: 0.2446, Accuracy: 0.3086\n",
      "Epoch [779/4000], Discriminator Loss: 0.0902, Generator Loss: 0.1833, Series Loss: 0.0099, Class Loss: 0.2446, Accuracy: 0.2778\n",
      "Epoch [780/4000], Discriminator Loss: 0.0899, Generator Loss: 0.1835, Series Loss: 0.0098, Class Loss: 0.2447, Accuracy: 0.3086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [781/4000], Discriminator Loss: 0.0911, Generator Loss: 0.1822, Series Loss: 0.0097, Class Loss: 0.2447, Accuracy: 0.2840\n",
      "Epoch [782/4000], Discriminator Loss: 0.0904, Generator Loss: 0.1833, Series Loss: 0.0097, Class Loss: 0.2448, Accuracy: 0.2901\n",
      "Epoch [783/4000], Discriminator Loss: 0.0901, Generator Loss: 0.1832, Series Loss: 0.0097, Class Loss: 0.2447, Accuracy: 0.3025\n",
      "Epoch [784/4000], Discriminator Loss: 0.0895, Generator Loss: 0.1828, Series Loss: 0.0097, Class Loss: 0.2448, Accuracy: 0.2901\n",
      "Epoch [785/4000], Discriminator Loss: 0.0906, Generator Loss: 0.1825, Series Loss: 0.0098, Class Loss: 0.2446, Accuracy: 0.2901\n",
      "Epoch [786/4000], Discriminator Loss: 0.0896, Generator Loss: 0.1830, Series Loss: 0.0097, Class Loss: 0.2447, Accuracy: 0.3025\n",
      "Epoch [787/4000], Discriminator Loss: 0.0894, Generator Loss: 0.1840, Series Loss: 0.0098, Class Loss: 0.2447, Accuracy: 0.2901\n",
      "Epoch [788/4000], Discriminator Loss: 0.0899, Generator Loss: 0.1835, Series Loss: 0.0099, Class Loss: 0.2447, Accuracy: 0.2963\n",
      "Epoch [789/4000], Discriminator Loss: 0.0901, Generator Loss: 0.1827, Series Loss: 0.0098, Class Loss: 0.2448, Accuracy: 0.2840\n",
      "Epoch [790/4000], Discriminator Loss: 0.0904, Generator Loss: 0.1826, Series Loss: 0.0097, Class Loss: 0.2445, Accuracy: 0.2840\n",
      "Epoch [791/4000], Discriminator Loss: 0.0904, Generator Loss: 0.1834, Series Loss: 0.0098, Class Loss: 0.2447, Accuracy: 0.3086\n",
      "Epoch [792/4000], Discriminator Loss: 0.0895, Generator Loss: 0.1830, Series Loss: 0.0097, Class Loss: 0.2447, Accuracy: 0.2963\n",
      "Epoch [793/4000], Discriminator Loss: 0.0899, Generator Loss: 0.1828, Series Loss: 0.0096, Class Loss: 0.2448, Accuracy: 0.2901\n",
      "Epoch [794/4000], Discriminator Loss: 0.0901, Generator Loss: 0.1822, Series Loss: 0.0097, Class Loss: 0.2446, Accuracy: 0.3086\n",
      "Epoch [795/4000], Discriminator Loss: 0.0905, Generator Loss: 0.1822, Series Loss: 0.0096, Class Loss: 0.2446, Accuracy: 0.2901\n",
      "Epoch [796/4000], Discriminator Loss: 0.0903, Generator Loss: 0.1825, Series Loss: 0.0097, Class Loss: 0.2447, Accuracy: 0.2963\n",
      "Epoch [797/4000], Discriminator Loss: 0.0903, Generator Loss: 0.1824, Series Loss: 0.0097, Class Loss: 0.2447, Accuracy: 0.3148\n",
      "Epoch [798/4000], Discriminator Loss: 0.0902, Generator Loss: 0.1830, Series Loss: 0.0097, Class Loss: 0.2446, Accuracy: 0.3025\n",
      "Epoch [799/4000], Discriminator Loss: 0.0897, Generator Loss: 0.1834, Series Loss: 0.0097, Class Loss: 0.2446, Accuracy: 0.2963\n",
      "Epoch [800/4000], Discriminator Loss: 0.0902, Generator Loss: 0.1830, Series Loss: 0.0097, Class Loss: 0.2446, Accuracy: 0.2778\n",
      "Epoch [801/4000], Discriminator Loss: 0.0903, Generator Loss: 0.1829, Series Loss: 0.0096, Class Loss: 0.2446, Accuracy: 0.2963\n",
      "Epoch [802/4000], Discriminator Loss: 0.0905, Generator Loss: 0.1824, Series Loss: 0.0096, Class Loss: 0.2447, Accuracy: 0.2840\n",
      "Epoch [803/4000], Discriminator Loss: 0.0895, Generator Loss: 0.1831, Series Loss: 0.0097, Class Loss: 0.2446, Accuracy: 0.2901\n",
      "Epoch [804/4000], Discriminator Loss: 0.0902, Generator Loss: 0.1828, Series Loss: 0.0098, Class Loss: 0.2446, Accuracy: 0.2963\n",
      "Epoch [805/4000], Discriminator Loss: 0.0907, Generator Loss: 0.1822, Series Loss: 0.0097, Class Loss: 0.2446, Accuracy: 0.2840\n",
      "Epoch [806/4000], Discriminator Loss: 0.0899, Generator Loss: 0.1826, Series Loss: 0.0097, Class Loss: 0.2446, Accuracy: 0.2963\n",
      "Epoch [807/4000], Discriminator Loss: 0.0899, Generator Loss: 0.1831, Series Loss: 0.0097, Class Loss: 0.2447, Accuracy: 0.3025\n",
      "Epoch [808/4000], Discriminator Loss: 0.0903, Generator Loss: 0.1823, Series Loss: 0.0096, Class Loss: 0.2447, Accuracy: 0.3086\n",
      "Epoch [809/4000], Discriminator Loss: 0.0906, Generator Loss: 0.1826, Series Loss: 0.0096, Class Loss: 0.2447, Accuracy: 0.2901\n",
      "Epoch [810/4000], Discriminator Loss: 0.0903, Generator Loss: 0.1820, Series Loss: 0.0097, Class Loss: 0.2447, Accuracy: 0.2963\n",
      "Epoch [811/4000], Discriminator Loss: 0.0904, Generator Loss: 0.1821, Series Loss: 0.0097, Class Loss: 0.2447, Accuracy: 0.2901\n",
      "Epoch [812/4000], Discriminator Loss: 0.0894, Generator Loss: 0.1831, Series Loss: 0.0097, Class Loss: 0.2447, Accuracy: 0.3025\n",
      "Epoch [813/4000], Discriminator Loss: 0.0903, Generator Loss: 0.1825, Series Loss: 0.0096, Class Loss: 0.2447, Accuracy: 0.2901\n",
      "Epoch [814/4000], Discriminator Loss: 0.0903, Generator Loss: 0.1824, Series Loss: 0.0096, Class Loss: 0.2448, Accuracy: 0.2963\n",
      "Epoch [815/4000], Discriminator Loss: 0.0907, Generator Loss: 0.1825, Series Loss: 0.0096, Class Loss: 0.2446, Accuracy: 0.2901\n",
      "Epoch [816/4000], Discriminator Loss: 0.0898, Generator Loss: 0.1830, Series Loss: 0.0096, Class Loss: 0.2447, Accuracy: 0.2963\n",
      "Epoch [817/4000], Discriminator Loss: 0.0895, Generator Loss: 0.1830, Series Loss: 0.0096, Class Loss: 0.2447, Accuracy: 0.2901\n",
      "Epoch [818/4000], Discriminator Loss: 0.0908, Generator Loss: 0.1816, Series Loss: 0.0095, Class Loss: 0.2446, Accuracy: 0.3086\n",
      "Epoch [819/4000], Discriminator Loss: 0.0895, Generator Loss: 0.1824, Series Loss: 0.0096, Class Loss: 0.2447, Accuracy: 0.2963\n",
      "Epoch [820/4000], Discriminator Loss: 0.0900, Generator Loss: 0.1827, Series Loss: 0.0097, Class Loss: 0.2446, Accuracy: 0.2963\n",
      "Epoch [821/4000], Discriminator Loss: 0.0903, Generator Loss: 0.1830, Series Loss: 0.0097, Class Loss: 0.2447, Accuracy: 0.2901\n",
      "Epoch [822/4000], Discriminator Loss: 0.0900, Generator Loss: 0.1827, Series Loss: 0.0096, Class Loss: 0.2446, Accuracy: 0.2901\n",
      "Epoch [823/4000], Discriminator Loss: 0.0905, Generator Loss: 0.1817, Series Loss: 0.0097, Class Loss: 0.2446, Accuracy: 0.2963\n",
      "Epoch [824/4000], Discriminator Loss: 0.0907, Generator Loss: 0.1826, Series Loss: 0.0097, Class Loss: 0.2446, Accuracy: 0.2840\n",
      "Epoch [825/4000], Discriminator Loss: 0.0904, Generator Loss: 0.1825, Series Loss: 0.0096, Class Loss: 0.2446, Accuracy: 0.3086\n",
      "Epoch [826/4000], Discriminator Loss: 0.0904, Generator Loss: 0.1823, Series Loss: 0.0096, Class Loss: 0.2445, Accuracy: 0.2901\n",
      "Epoch [827/4000], Discriminator Loss: 0.0903, Generator Loss: 0.1818, Series Loss: 0.0096, Class Loss: 0.2448, Accuracy: 0.2778\n",
      "Epoch [828/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1820, Series Loss: 0.0096, Class Loss: 0.2448, Accuracy: 0.2901\n",
      "Epoch [829/4000], Discriminator Loss: 0.0902, Generator Loss: 0.1824, Series Loss: 0.0096, Class Loss: 0.2446, Accuracy: 0.2901\n",
      "Epoch [830/4000], Discriminator Loss: 0.0906, Generator Loss: 0.1829, Series Loss: 0.0095, Class Loss: 0.2447, Accuracy: 0.2840\n",
      "Epoch [831/4000], Discriminator Loss: 0.0903, Generator Loss: 0.1822, Series Loss: 0.0097, Class Loss: 0.2447, Accuracy: 0.2840\n",
      "Epoch [832/4000], Discriminator Loss: 0.0901, Generator Loss: 0.1817, Series Loss: 0.0095, Class Loss: 0.2446, Accuracy: 0.2778\n",
      "Epoch [833/4000], Discriminator Loss: 0.0910, Generator Loss: 0.1816, Series Loss: 0.0095, Class Loss: 0.2447, Accuracy: 0.2963\n",
      "Epoch [834/4000], Discriminator Loss: 0.0909, Generator Loss: 0.1823, Series Loss: 0.0095, Class Loss: 0.2447, Accuracy: 0.2840\n",
      "Epoch [835/4000], Discriminator Loss: 0.0900, Generator Loss: 0.1825, Series Loss: 0.0095, Class Loss: 0.2446, Accuracy: 0.2963\n",
      "Epoch [836/4000], Discriminator Loss: 0.0902, Generator Loss: 0.1823, Series Loss: 0.0095, Class Loss: 0.2447, Accuracy: 0.2901\n",
      "Epoch [837/4000], Discriminator Loss: 0.0907, Generator Loss: 0.1821, Series Loss: 0.0096, Class Loss: 0.2446, Accuracy: 0.2901\n",
      "Epoch [838/4000], Discriminator Loss: 0.0909, Generator Loss: 0.1819, Series Loss: 0.0094, Class Loss: 0.2447, Accuracy: 0.2778\n",
      "Epoch [839/4000], Discriminator Loss: 0.0902, Generator Loss: 0.1834, Series Loss: 0.0096, Class Loss: 0.2448, Accuracy: 0.2901\n",
      "Epoch [840/4000], Discriminator Loss: 0.0904, Generator Loss: 0.1824, Series Loss: 0.0096, Class Loss: 0.2446, Accuracy: 0.2778\n",
      "Epoch [841/4000], Discriminator Loss: 0.0905, Generator Loss: 0.1820, Series Loss: 0.0096, Class Loss: 0.2447, Accuracy: 0.2840\n",
      "Epoch [842/4000], Discriminator Loss: 0.0905, Generator Loss: 0.1821, Series Loss: 0.0095, Class Loss: 0.2447, Accuracy: 0.2840\n",
      "Epoch [843/4000], Discriminator Loss: 0.0908, Generator Loss: 0.1818, Series Loss: 0.0095, Class Loss: 0.2446, Accuracy: 0.2901\n",
      "Epoch [844/4000], Discriminator Loss: 0.0911, Generator Loss: 0.1818, Series Loss: 0.0095, Class Loss: 0.2448, Accuracy: 0.2840\n",
      "Epoch [845/4000], Discriminator Loss: 0.0905, Generator Loss: 0.1826, Series Loss: 0.0095, Class Loss: 0.2447, Accuracy: 0.2901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [846/4000], Discriminator Loss: 0.0907, Generator Loss: 0.1814, Series Loss: 0.0095, Class Loss: 0.2447, Accuracy: 0.2840\n",
      "Epoch [847/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1821, Series Loss: 0.0096, Class Loss: 0.2446, Accuracy: 0.2901\n",
      "Epoch [848/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1821, Series Loss: 0.0095, Class Loss: 0.2447, Accuracy: 0.3025\n",
      "Epoch [849/4000], Discriminator Loss: 0.0911, Generator Loss: 0.1826, Series Loss: 0.0095, Class Loss: 0.2448, Accuracy: 0.2963\n",
      "Epoch [850/4000], Discriminator Loss: 0.0903, Generator Loss: 0.1827, Series Loss: 0.0096, Class Loss: 0.2447, Accuracy: 0.2963\n",
      "Epoch [851/4000], Discriminator Loss: 0.0906, Generator Loss: 0.1818, Series Loss: 0.0094, Class Loss: 0.2445, Accuracy: 0.2963\n",
      "Epoch [852/4000], Discriminator Loss: 0.0901, Generator Loss: 0.1824, Series Loss: 0.0095, Class Loss: 0.2446, Accuracy: 0.2901\n",
      "Epoch [853/4000], Discriminator Loss: 0.0906, Generator Loss: 0.1822, Series Loss: 0.0095, Class Loss: 0.2446, Accuracy: 0.2901\n",
      "Epoch [854/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1820, Series Loss: 0.0094, Class Loss: 0.2447, Accuracy: 0.2901\n",
      "Epoch [855/4000], Discriminator Loss: 0.0911, Generator Loss: 0.1818, Series Loss: 0.0094, Class Loss: 0.2448, Accuracy: 0.2901\n",
      "Epoch [856/4000], Discriminator Loss: 0.0911, Generator Loss: 0.1812, Series Loss: 0.0095, Class Loss: 0.2447, Accuracy: 0.2901\n",
      "Epoch [857/4000], Discriminator Loss: 0.0909, Generator Loss: 0.1812, Series Loss: 0.0094, Class Loss: 0.2447, Accuracy: 0.2840\n",
      "Epoch [858/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1815, Series Loss: 0.0094, Class Loss: 0.2448, Accuracy: 0.3086\n",
      "Epoch [859/4000], Discriminator Loss: 0.0911, Generator Loss: 0.1818, Series Loss: 0.0095, Class Loss: 0.2446, Accuracy: 0.3025\n",
      "Epoch [860/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1823, Series Loss: 0.0095, Class Loss: 0.2447, Accuracy: 0.2963\n",
      "Epoch [861/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1819, Series Loss: 0.0094, Class Loss: 0.2447, Accuracy: 0.2778\n",
      "Epoch [862/4000], Discriminator Loss: 0.0911, Generator Loss: 0.1817, Series Loss: 0.0094, Class Loss: 0.2446, Accuracy: 0.2840\n",
      "Epoch [863/4000], Discriminator Loss: 0.0907, Generator Loss: 0.1820, Series Loss: 0.0094, Class Loss: 0.2447, Accuracy: 0.2901\n",
      "Epoch [864/4000], Discriminator Loss: 0.0906, Generator Loss: 0.1822, Series Loss: 0.0093, Class Loss: 0.2446, Accuracy: 0.2901\n",
      "Epoch [865/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1815, Series Loss: 0.0092, Class Loss: 0.2447, Accuracy: 0.2901\n",
      "Epoch [866/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1821, Series Loss: 0.0094, Class Loss: 0.2446, Accuracy: 0.3025\n",
      "Epoch [867/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1821, Series Loss: 0.0093, Class Loss: 0.2447, Accuracy: 0.3025\n",
      "Epoch [868/4000], Discriminator Loss: 0.0911, Generator Loss: 0.1818, Series Loss: 0.0094, Class Loss: 0.2447, Accuracy: 0.2778\n",
      "Epoch [869/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1816, Series Loss: 0.0093, Class Loss: 0.2448, Accuracy: 0.2963\n",
      "Epoch [870/4000], Discriminator Loss: 0.0910, Generator Loss: 0.1819, Series Loss: 0.0094, Class Loss: 0.2449, Accuracy: 0.2840\n",
      "Epoch [871/4000], Discriminator Loss: 0.0909, Generator Loss: 0.1822, Series Loss: 0.0093, Class Loss: 0.2447, Accuracy: 0.2778\n",
      "Epoch [872/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1819, Series Loss: 0.0093, Class Loss: 0.2448, Accuracy: 0.2963\n",
      "Epoch [873/4000], Discriminator Loss: 0.0907, Generator Loss: 0.1818, Series Loss: 0.0094, Class Loss: 0.2448, Accuracy: 0.2963\n",
      "Epoch [874/4000], Discriminator Loss: 0.0906, Generator Loss: 0.1818, Series Loss: 0.0093, Class Loss: 0.2447, Accuracy: 0.2840\n",
      "Epoch [875/4000], Discriminator Loss: 0.0900, Generator Loss: 0.1816, Series Loss: 0.0093, Class Loss: 0.2446, Accuracy: 0.2963\n",
      "Epoch [876/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1817, Series Loss: 0.0093, Class Loss: 0.2448, Accuracy: 0.2963\n",
      "Epoch [877/4000], Discriminator Loss: 0.0906, Generator Loss: 0.1818, Series Loss: 0.0093, Class Loss: 0.2446, Accuracy: 0.3025\n",
      "Epoch [878/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1816, Series Loss: 0.0093, Class Loss: 0.2447, Accuracy: 0.2963\n",
      "Epoch [879/4000], Discriminator Loss: 0.0909, Generator Loss: 0.1819, Series Loss: 0.0094, Class Loss: 0.2447, Accuracy: 0.2901\n",
      "Epoch [880/4000], Discriminator Loss: 0.0907, Generator Loss: 0.1816, Series Loss: 0.0092, Class Loss: 0.2448, Accuracy: 0.3025\n",
      "Epoch [881/4000], Discriminator Loss: 0.0907, Generator Loss: 0.1817, Series Loss: 0.0093, Class Loss: 0.2447, Accuracy: 0.2840\n",
      "Epoch [882/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1818, Series Loss: 0.0093, Class Loss: 0.2447, Accuracy: 0.3025\n",
      "Epoch [883/4000], Discriminator Loss: 0.0910, Generator Loss: 0.1824, Series Loss: 0.0094, Class Loss: 0.2447, Accuracy: 0.2901\n",
      "Epoch [884/4000], Discriminator Loss: 0.0908, Generator Loss: 0.1822, Series Loss: 0.0093, Class Loss: 0.2447, Accuracy: 0.2963\n",
      "Epoch [885/4000], Discriminator Loss: 0.0908, Generator Loss: 0.1817, Series Loss: 0.0092, Class Loss: 0.2446, Accuracy: 0.3025\n",
      "Epoch [886/4000], Discriminator Loss: 0.0908, Generator Loss: 0.1817, Series Loss: 0.0093, Class Loss: 0.2447, Accuracy: 0.2963\n",
      "Epoch [887/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1813, Series Loss: 0.0094, Class Loss: 0.2448, Accuracy: 0.2840\n",
      "Epoch [888/4000], Discriminator Loss: 0.0905, Generator Loss: 0.1817, Series Loss: 0.0093, Class Loss: 0.2446, Accuracy: 0.2840\n",
      "Epoch [889/4000], Discriminator Loss: 0.0908, Generator Loss: 0.1816, Series Loss: 0.0093, Class Loss: 0.2447, Accuracy: 0.3025\n",
      "Epoch [890/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1814, Series Loss: 0.0094, Class Loss: 0.2446, Accuracy: 0.3086\n",
      "Epoch [891/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1824, Series Loss: 0.0093, Class Loss: 0.2446, Accuracy: 0.2901\n",
      "Epoch [892/4000], Discriminator Loss: 0.0908, Generator Loss: 0.1822, Series Loss: 0.0093, Class Loss: 0.2447, Accuracy: 0.2963\n",
      "Epoch [893/4000], Discriminator Loss: 0.0904, Generator Loss: 0.1822, Series Loss: 0.0093, Class Loss: 0.2448, Accuracy: 0.2901\n",
      "Epoch [894/4000], Discriminator Loss: 0.0903, Generator Loss: 0.1815, Series Loss: 0.0092, Class Loss: 0.2447, Accuracy: 0.2963\n",
      "Epoch [895/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1814, Series Loss: 0.0092, Class Loss: 0.2447, Accuracy: 0.2901\n",
      "Epoch [896/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1816, Series Loss: 0.0092, Class Loss: 0.2447, Accuracy: 0.3025\n",
      "Epoch [897/4000], Discriminator Loss: 0.0908, Generator Loss: 0.1816, Series Loss: 0.0091, Class Loss: 0.2448, Accuracy: 0.2901\n",
      "Epoch [898/4000], Discriminator Loss: 0.0911, Generator Loss: 0.1824, Series Loss: 0.0093, Class Loss: 0.2446, Accuracy: 0.2840\n",
      "Epoch [899/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1826, Series Loss: 0.0092, Class Loss: 0.2447, Accuracy: 0.2963\n",
      "Epoch [900/4000], Discriminator Loss: 0.0907, Generator Loss: 0.1818, Series Loss: 0.0092, Class Loss: 0.2447, Accuracy: 0.2901\n",
      "Epoch [901/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1814, Series Loss: 0.0091, Class Loss: 0.2448, Accuracy: 0.3025\n",
      "Epoch [902/4000], Discriminator Loss: 0.0908, Generator Loss: 0.1818, Series Loss: 0.0091, Class Loss: 0.2447, Accuracy: 0.2840\n",
      "Epoch [903/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1818, Series Loss: 0.0093, Class Loss: 0.2447, Accuracy: 0.2901\n",
      "Epoch [904/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1810, Series Loss: 0.0092, Class Loss: 0.2446, Accuracy: 0.3025\n",
      "Epoch [905/4000], Discriminator Loss: 0.0910, Generator Loss: 0.1813, Series Loss: 0.0093, Class Loss: 0.2446, Accuracy: 0.3025\n",
      "Epoch [906/4000], Discriminator Loss: 0.0903, Generator Loss: 0.1820, Series Loss: 0.0094, Class Loss: 0.2448, Accuracy: 0.2778\n",
      "Epoch [907/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1812, Series Loss: 0.0091, Class Loss: 0.2447, Accuracy: 0.3025\n",
      "Epoch [908/4000], Discriminator Loss: 0.0902, Generator Loss: 0.1821, Series Loss: 0.0092, Class Loss: 0.2447, Accuracy: 0.3025\n",
      "Epoch [909/4000], Discriminator Loss: 0.0903, Generator Loss: 0.1810, Series Loss: 0.0092, Class Loss: 0.2447, Accuracy: 0.2963\n",
      "Epoch [910/4000], Discriminator Loss: 0.0903, Generator Loss: 0.1817, Series Loss: 0.0092, Class Loss: 0.2447, Accuracy: 0.2901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [911/4000], Discriminator Loss: 0.0909, Generator Loss: 0.1818, Series Loss: 0.0092, Class Loss: 0.2448, Accuracy: 0.2778\n",
      "Epoch [912/4000], Discriminator Loss: 0.0905, Generator Loss: 0.1826, Series Loss: 0.0093, Class Loss: 0.2447, Accuracy: 0.2963\n",
      "Epoch [913/4000], Discriminator Loss: 0.0903, Generator Loss: 0.1824, Series Loss: 0.0093, Class Loss: 0.2448, Accuracy: 0.2778\n",
      "Epoch [914/4000], Discriminator Loss: 0.0904, Generator Loss: 0.1824, Series Loss: 0.0092, Class Loss: 0.2448, Accuracy: 0.2840\n",
      "Epoch [915/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1815, Series Loss: 0.0092, Class Loss: 0.2447, Accuracy: 0.2901\n",
      "Epoch [916/4000], Discriminator Loss: 0.0910, Generator Loss: 0.1821, Series Loss: 0.0094, Class Loss: 0.2446, Accuracy: 0.2901\n",
      "Epoch [917/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1819, Series Loss: 0.0092, Class Loss: 0.2447, Accuracy: 0.2963\n",
      "Epoch [918/4000], Discriminator Loss: 0.0911, Generator Loss: 0.1824, Series Loss: 0.0093, Class Loss: 0.2447, Accuracy: 0.2963\n",
      "Epoch [919/4000], Discriminator Loss: 0.0908, Generator Loss: 0.1823, Series Loss: 0.0092, Class Loss: 0.2447, Accuracy: 0.2963\n",
      "Epoch [920/4000], Discriminator Loss: 0.0911, Generator Loss: 0.1817, Series Loss: 0.0093, Class Loss: 0.2447, Accuracy: 0.2963\n",
      "Epoch [921/4000], Discriminator Loss: 0.0911, Generator Loss: 0.1821, Series Loss: 0.0093, Class Loss: 0.2448, Accuracy: 0.2901\n",
      "Epoch [922/4000], Discriminator Loss: 0.0905, Generator Loss: 0.1818, Series Loss: 0.0093, Class Loss: 0.2448, Accuracy: 0.2840\n",
      "Epoch [923/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1815, Series Loss: 0.0091, Class Loss: 0.2447, Accuracy: 0.2963\n",
      "Epoch [924/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1817, Series Loss: 0.0092, Class Loss: 0.2448, Accuracy: 0.2901\n",
      "Epoch [925/4000], Discriminator Loss: 0.0908, Generator Loss: 0.1815, Series Loss: 0.0092, Class Loss: 0.2447, Accuracy: 0.3025\n",
      "Epoch [926/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1811, Series Loss: 0.0093, Class Loss: 0.2447, Accuracy: 0.2716\n",
      "Epoch [927/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1814, Series Loss: 0.0093, Class Loss: 0.2446, Accuracy: 0.2963\n",
      "Epoch [928/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1815, Series Loss: 0.0094, Class Loss: 0.2446, Accuracy: 0.2778\n",
      "Epoch [929/4000], Discriminator Loss: 0.0909, Generator Loss: 0.1823, Series Loss: 0.0092, Class Loss: 0.2445, Accuracy: 0.3025\n",
      "Epoch [930/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1816, Series Loss: 0.0092, Class Loss: 0.2447, Accuracy: 0.3025\n",
      "Epoch [931/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1819, Series Loss: 0.0093, Class Loss: 0.2446, Accuracy: 0.2901\n",
      "Epoch [932/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1820, Series Loss: 0.0093, Class Loss: 0.2447, Accuracy: 0.2963\n",
      "Epoch [933/4000], Discriminator Loss: 0.0911, Generator Loss: 0.1819, Series Loss: 0.0093, Class Loss: 0.2448, Accuracy: 0.2901\n",
      "Epoch [934/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1812, Series Loss: 0.0093, Class Loss: 0.2447, Accuracy: 0.2778\n",
      "Epoch [935/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1812, Series Loss: 0.0094, Class Loss: 0.2447, Accuracy: 0.2840\n",
      "Epoch [936/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1810, Series Loss: 0.0092, Class Loss: 0.2449, Accuracy: 0.2963\n",
      "Epoch [937/4000], Discriminator Loss: 0.0905, Generator Loss: 0.1815, Series Loss: 0.0092, Class Loss: 0.2446, Accuracy: 0.2963\n",
      "Epoch [938/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1816, Series Loss: 0.0092, Class Loss: 0.2447, Accuracy: 0.3025\n",
      "Epoch [939/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1817, Series Loss: 0.0092, Class Loss: 0.2447, Accuracy: 0.2778\n",
      "Epoch [940/4000], Discriminator Loss: 0.0910, Generator Loss: 0.1825, Series Loss: 0.0093, Class Loss: 0.2446, Accuracy: 0.3025\n",
      "Epoch [941/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1821, Series Loss: 0.0093, Class Loss: 0.2448, Accuracy: 0.2716\n",
      "Epoch [942/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1814, Series Loss: 0.0092, Class Loss: 0.2446, Accuracy: 0.2840\n",
      "Epoch [943/4000], Discriminator Loss: 0.0908, Generator Loss: 0.1812, Series Loss: 0.0092, Class Loss: 0.2446, Accuracy: 0.2901\n",
      "Epoch [944/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1816, Series Loss: 0.0092, Class Loss: 0.2446, Accuracy: 0.2901\n",
      "Epoch [945/4000], Discriminator Loss: 0.0911, Generator Loss: 0.1819, Series Loss: 0.0091, Class Loss: 0.2447, Accuracy: 0.2963\n",
      "Epoch [946/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1810, Series Loss: 0.0092, Class Loss: 0.2447, Accuracy: 0.2901\n",
      "Epoch [947/4000], Discriminator Loss: 0.0909, Generator Loss: 0.1816, Series Loss: 0.0092, Class Loss: 0.2448, Accuracy: 0.2963\n",
      "Epoch [948/4000], Discriminator Loss: 0.0910, Generator Loss: 0.1813, Series Loss: 0.0091, Class Loss: 0.2448, Accuracy: 0.2901\n",
      "Epoch [949/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1818, Series Loss: 0.0090, Class Loss: 0.2447, Accuracy: 0.2963\n",
      "Epoch [950/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1822, Series Loss: 0.0091, Class Loss: 0.2447, Accuracy: 0.2963\n",
      "Epoch [951/4000], Discriminator Loss: 0.0904, Generator Loss: 0.1810, Series Loss: 0.0091, Class Loss: 0.2445, Accuracy: 0.2716\n",
      "Epoch [952/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1807, Series Loss: 0.0091, Class Loss: 0.2446, Accuracy: 0.2963\n",
      "Epoch [953/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1808, Series Loss: 0.0091, Class Loss: 0.2446, Accuracy: 0.3025\n",
      "Epoch [954/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1811, Series Loss: 0.0089, Class Loss: 0.2447, Accuracy: 0.3086\n",
      "Epoch [955/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1819, Series Loss: 0.0088, Class Loss: 0.2446, Accuracy: 0.2963\n",
      "Epoch [956/4000], Discriminator Loss: 0.0911, Generator Loss: 0.1821, Series Loss: 0.0091, Class Loss: 0.2447, Accuracy: 0.2716\n",
      "Epoch [957/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1818, Series Loss: 0.0091, Class Loss: 0.2447, Accuracy: 0.2963\n",
      "Epoch [958/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1812, Series Loss: 0.0091, Class Loss: 0.2447, Accuracy: 0.2840\n",
      "Epoch [959/4000], Discriminator Loss: 0.0910, Generator Loss: 0.1814, Series Loss: 0.0090, Class Loss: 0.2446, Accuracy: 0.2963\n",
      "Epoch [960/4000], Discriminator Loss: 0.0908, Generator Loss: 0.1812, Series Loss: 0.0091, Class Loss: 0.2446, Accuracy: 0.2840\n",
      "Epoch [961/4000], Discriminator Loss: 0.0911, Generator Loss: 0.1812, Series Loss: 0.0090, Class Loss: 0.2447, Accuracy: 0.2840\n",
      "Epoch [962/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1809, Series Loss: 0.0089, Class Loss: 0.2446, Accuracy: 0.3025\n",
      "Epoch [963/4000], Discriminator Loss: 0.0909, Generator Loss: 0.1817, Series Loss: 0.0090, Class Loss: 0.2446, Accuracy: 0.2716\n",
      "Epoch [964/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1818, Series Loss: 0.0090, Class Loss: 0.2448, Accuracy: 0.2778\n",
      "Epoch [965/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1823, Series Loss: 0.0090, Class Loss: 0.2447, Accuracy: 0.2840\n",
      "Epoch [966/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1810, Series Loss: 0.0090, Class Loss: 0.2447, Accuracy: 0.3025\n",
      "Epoch [967/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1811, Series Loss: 0.0089, Class Loss: 0.2448, Accuracy: 0.3025\n",
      "Epoch [968/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1817, Series Loss: 0.0090, Class Loss: 0.2446, Accuracy: 0.2901\n",
      "Epoch [969/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1819, Series Loss: 0.0090, Class Loss: 0.2447, Accuracy: 0.3025\n",
      "Epoch [970/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1820, Series Loss: 0.0092, Class Loss: 0.2446, Accuracy: 0.2840\n",
      "Epoch [971/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1820, Series Loss: 0.0090, Class Loss: 0.2447, Accuracy: 0.2778\n",
      "Epoch [972/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1808, Series Loss: 0.0089, Class Loss: 0.2448, Accuracy: 0.2778\n",
      "Epoch [973/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1810, Series Loss: 0.0091, Class Loss: 0.2446, Accuracy: 0.2778\n",
      "Epoch [974/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1818, Series Loss: 0.0091, Class Loss: 0.2447, Accuracy: 0.2778\n",
      "Epoch [975/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1813, Series Loss: 0.0090, Class Loss: 0.2447, Accuracy: 0.2716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [976/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1810, Series Loss: 0.0090, Class Loss: 0.2447, Accuracy: 0.2840\n",
      "Epoch [977/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1812, Series Loss: 0.0090, Class Loss: 0.2447, Accuracy: 0.2840\n",
      "Epoch [978/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1813, Series Loss: 0.0091, Class Loss: 0.2446, Accuracy: 0.2840\n",
      "Epoch [979/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1820, Series Loss: 0.0091, Class Loss: 0.2447, Accuracy: 0.2593\n",
      "Epoch [980/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1816, Series Loss: 0.0090, Class Loss: 0.2446, Accuracy: 0.2840\n",
      "Epoch [981/4000], Discriminator Loss: 0.0911, Generator Loss: 0.1815, Series Loss: 0.0091, Class Loss: 0.2447, Accuracy: 0.2778\n",
      "Epoch [982/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1811, Series Loss: 0.0090, Class Loss: 0.2446, Accuracy: 0.2778\n",
      "Epoch [983/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1814, Series Loss: 0.0090, Class Loss: 0.2447, Accuracy: 0.2840\n",
      "Epoch [984/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1815, Series Loss: 0.0091, Class Loss: 0.2445, Accuracy: 0.2840\n",
      "Epoch [985/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1816, Series Loss: 0.0092, Class Loss: 0.2447, Accuracy: 0.2654\n",
      "Epoch [986/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1813, Series Loss: 0.0091, Class Loss: 0.2445, Accuracy: 0.2963\n",
      "Epoch [987/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1808, Series Loss: 0.0090, Class Loss: 0.2447, Accuracy: 0.2840\n",
      "Epoch [988/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1804, Series Loss: 0.0091, Class Loss: 0.2447, Accuracy: 0.2840\n",
      "Epoch [989/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1809, Series Loss: 0.0091, Class Loss: 0.2446, Accuracy: 0.2901\n",
      "Epoch [990/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1808, Series Loss: 0.0090, Class Loss: 0.2447, Accuracy: 0.2778\n",
      "Epoch [991/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1810, Series Loss: 0.0090, Class Loss: 0.2446, Accuracy: 0.2840\n",
      "Epoch [992/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1820, Series Loss: 0.0092, Class Loss: 0.2446, Accuracy: 0.2778\n",
      "Epoch [993/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1810, Series Loss: 0.0090, Class Loss: 0.2446, Accuracy: 0.2840\n",
      "Epoch [994/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1811, Series Loss: 0.0091, Class Loss: 0.2446, Accuracy: 0.2716\n",
      "Epoch [995/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1812, Series Loss: 0.0092, Class Loss: 0.2446, Accuracy: 0.2778\n",
      "Epoch [996/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1807, Series Loss: 0.0089, Class Loss: 0.2446, Accuracy: 0.2901\n",
      "Epoch [997/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1808, Series Loss: 0.0091, Class Loss: 0.2446, Accuracy: 0.2901\n",
      "Epoch [998/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1807, Series Loss: 0.0090, Class Loss: 0.2446, Accuracy: 0.2901\n",
      "Epoch [999/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1815, Series Loss: 0.0090, Class Loss: 0.2446, Accuracy: 0.3025\n",
      "Epoch [1000/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1807, Series Loss: 0.0089, Class Loss: 0.2446, Accuracy: 0.2840\n",
      "Epoch [1001/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1802, Series Loss: 0.0089, Class Loss: 0.2446, Accuracy: 0.2901\n",
      "Epoch [1002/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1808, Series Loss: 0.0091, Class Loss: 0.2446, Accuracy: 0.2901\n",
      "Epoch [1003/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1809, Series Loss: 0.0090, Class Loss: 0.2446, Accuracy: 0.2963\n",
      "Epoch [1004/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1806, Series Loss: 0.0089, Class Loss: 0.2447, Accuracy: 0.3210\n",
      "Epoch [1005/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1806, Series Loss: 0.0090, Class Loss: 0.2446, Accuracy: 0.2963\n",
      "Epoch [1006/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1811, Series Loss: 0.0089, Class Loss: 0.2445, Accuracy: 0.3025\n",
      "Epoch [1007/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1811, Series Loss: 0.0089, Class Loss: 0.2447, Accuracy: 0.2778\n",
      "Epoch [1008/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1812, Series Loss: 0.0089, Class Loss: 0.2447, Accuracy: 0.3272\n",
      "Epoch [1009/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1814, Series Loss: 0.0089, Class Loss: 0.2447, Accuracy: 0.2716\n",
      "Epoch [1010/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1812, Series Loss: 0.0089, Class Loss: 0.2447, Accuracy: 0.3210\n",
      "Epoch [1011/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1810, Series Loss: 0.0089, Class Loss: 0.2446, Accuracy: 0.3086\n",
      "Epoch [1012/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1806, Series Loss: 0.0089, Class Loss: 0.2446, Accuracy: 0.3025\n",
      "Epoch [1013/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1805, Series Loss: 0.0089, Class Loss: 0.2445, Accuracy: 0.2840\n",
      "Epoch [1014/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1808, Series Loss: 0.0089, Class Loss: 0.2447, Accuracy: 0.3086\n",
      "Epoch [1015/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1806, Series Loss: 0.0090, Class Loss: 0.2447, Accuracy: 0.2963\n",
      "Epoch [1016/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1810, Series Loss: 0.0090, Class Loss: 0.2447, Accuracy: 0.2901\n",
      "Epoch [1017/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1811, Series Loss: 0.0089, Class Loss: 0.2447, Accuracy: 0.3333\n",
      "Epoch [1018/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1815, Series Loss: 0.0089, Class Loss: 0.2446, Accuracy: 0.2963\n",
      "Epoch [1019/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1808, Series Loss: 0.0089, Class Loss: 0.2446, Accuracy: 0.2963\n",
      "Epoch [1020/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1812, Series Loss: 0.0089, Class Loss: 0.2446, Accuracy: 0.2901\n",
      "Epoch [1021/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1811, Series Loss: 0.0090, Class Loss: 0.2446, Accuracy: 0.2963\n",
      "Epoch [1022/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1807, Series Loss: 0.0089, Class Loss: 0.2445, Accuracy: 0.2963\n",
      "Epoch [1023/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1816, Series Loss: 0.0089, Class Loss: 0.2446, Accuracy: 0.3148\n",
      "Epoch [1024/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1812, Series Loss: 0.0088, Class Loss: 0.2446, Accuracy: 0.3025\n",
      "Epoch [1025/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1815, Series Loss: 0.0088, Class Loss: 0.2446, Accuracy: 0.3210\n",
      "Epoch [1026/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1809, Series Loss: 0.0090, Class Loss: 0.2446, Accuracy: 0.2840\n",
      "Epoch [1027/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1815, Series Loss: 0.0089, Class Loss: 0.2446, Accuracy: 0.3025\n",
      "Epoch [1028/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1803, Series Loss: 0.0088, Class Loss: 0.2446, Accuracy: 0.2963\n",
      "Epoch [1029/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1809, Series Loss: 0.0089, Class Loss: 0.2446, Accuracy: 0.2963\n",
      "Epoch [1030/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1805, Series Loss: 0.0089, Class Loss: 0.2447, Accuracy: 0.2901\n",
      "Epoch [1031/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1805, Series Loss: 0.0088, Class Loss: 0.2446, Accuracy: 0.3025\n",
      "Epoch [1032/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1807, Series Loss: 0.0088, Class Loss: 0.2447, Accuracy: 0.3086\n",
      "Epoch [1033/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1807, Series Loss: 0.0089, Class Loss: 0.2447, Accuracy: 0.3086\n",
      "Epoch [1034/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1811, Series Loss: 0.0089, Class Loss: 0.2446, Accuracy: 0.3025\n",
      "Epoch [1035/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1805, Series Loss: 0.0089, Class Loss: 0.2446, Accuracy: 0.3086\n",
      "Epoch [1036/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1812, Series Loss: 0.0089, Class Loss: 0.2447, Accuracy: 0.2901\n",
      "Epoch [1037/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1810, Series Loss: 0.0088, Class Loss: 0.2445, Accuracy: 0.3086\n",
      "Epoch [1038/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1804, Series Loss: 0.0088, Class Loss: 0.2447, Accuracy: 0.3148\n",
      "Epoch [1039/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1810, Series Loss: 0.0089, Class Loss: 0.2447, Accuracy: 0.3086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1040/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1806, Series Loss: 0.0088, Class Loss: 0.2446, Accuracy: 0.3148\n",
      "Epoch [1041/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1808, Series Loss: 0.0088, Class Loss: 0.2446, Accuracy: 0.3086\n",
      "Epoch [1042/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1811, Series Loss: 0.0088, Class Loss: 0.2446, Accuracy: 0.2778\n",
      "Epoch [1043/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1806, Series Loss: 0.0088, Class Loss: 0.2446, Accuracy: 0.3025\n",
      "Epoch [1044/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1808, Series Loss: 0.0088, Class Loss: 0.2446, Accuracy: 0.2840\n",
      "Epoch [1045/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1810, Series Loss: 0.0089, Class Loss: 0.2447, Accuracy: 0.2840\n",
      "Epoch [1046/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1809, Series Loss: 0.0088, Class Loss: 0.2447, Accuracy: 0.2840\n",
      "Epoch [1047/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1807, Series Loss: 0.0088, Class Loss: 0.2446, Accuracy: 0.2901\n",
      "Epoch [1048/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1808, Series Loss: 0.0087, Class Loss: 0.2445, Accuracy: 0.2901\n",
      "Epoch [1049/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1812, Series Loss: 0.0088, Class Loss: 0.2447, Accuracy: 0.3025\n",
      "Epoch [1050/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1811, Series Loss: 0.0089, Class Loss: 0.2446, Accuracy: 0.3148\n",
      "Epoch [1051/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1804, Series Loss: 0.0088, Class Loss: 0.2445, Accuracy: 0.2963\n",
      "Epoch [1052/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1802, Series Loss: 0.0088, Class Loss: 0.2446, Accuracy: 0.2778\n",
      "Epoch [1053/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1810, Series Loss: 0.0088, Class Loss: 0.2447, Accuracy: 0.2901\n",
      "Epoch [1054/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1810, Series Loss: 0.0088, Class Loss: 0.2446, Accuracy: 0.2963\n",
      "Epoch [1055/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1815, Series Loss: 0.0088, Class Loss: 0.2447, Accuracy: 0.2963\n",
      "Epoch [1056/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1813, Series Loss: 0.0088, Class Loss: 0.2447, Accuracy: 0.3025\n",
      "Epoch [1057/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1817, Series Loss: 0.0089, Class Loss: 0.2446, Accuracy: 0.2840\n",
      "Epoch [1058/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1804, Series Loss: 0.0087, Class Loss: 0.2445, Accuracy: 0.3086\n",
      "Epoch [1059/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1807, Series Loss: 0.0087, Class Loss: 0.2446, Accuracy: 0.2901\n",
      "Epoch [1060/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1804, Series Loss: 0.0088, Class Loss: 0.2447, Accuracy: 0.3025\n",
      "Epoch [1061/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1805, Series Loss: 0.0087, Class Loss: 0.2446, Accuracy: 0.2963\n",
      "Epoch [1062/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1809, Series Loss: 0.0088, Class Loss: 0.2445, Accuracy: 0.3086\n",
      "Epoch [1063/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1809, Series Loss: 0.0088, Class Loss: 0.2446, Accuracy: 0.2901\n",
      "Epoch [1064/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1809, Series Loss: 0.0087, Class Loss: 0.2447, Accuracy: 0.2963\n",
      "Epoch [1065/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1805, Series Loss: 0.0087, Class Loss: 0.2447, Accuracy: 0.3025\n",
      "Epoch [1066/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1801, Series Loss: 0.0088, Class Loss: 0.2446, Accuracy: 0.3025\n",
      "Epoch [1067/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1802, Series Loss: 0.0087, Class Loss: 0.2446, Accuracy: 0.3148\n",
      "Epoch [1068/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1807, Series Loss: 0.0088, Class Loss: 0.2447, Accuracy: 0.2840\n",
      "Epoch [1069/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1807, Series Loss: 0.0087, Class Loss: 0.2446, Accuracy: 0.3025\n",
      "Epoch [1070/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1811, Series Loss: 0.0087, Class Loss: 0.2446, Accuracy: 0.3025\n",
      "Epoch [1071/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1810, Series Loss: 0.0087, Class Loss: 0.2446, Accuracy: 0.3025\n",
      "Epoch [1072/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1811, Series Loss: 0.0086, Class Loss: 0.2447, Accuracy: 0.3148\n",
      "Epoch [1073/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1808, Series Loss: 0.0088, Class Loss: 0.2447, Accuracy: 0.2901\n",
      "Epoch [1074/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1811, Series Loss: 0.0088, Class Loss: 0.2446, Accuracy: 0.3086\n",
      "Epoch [1075/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1811, Series Loss: 0.0087, Class Loss: 0.2446, Accuracy: 0.3025\n",
      "Epoch [1076/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1809, Series Loss: 0.0088, Class Loss: 0.2446, Accuracy: 0.3148\n",
      "Epoch [1077/4000], Discriminator Loss: 0.0935, Generator Loss: 0.1804, Series Loss: 0.0087, Class Loss: 0.2446, Accuracy: 0.3025\n",
      "Epoch [1078/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1810, Series Loss: 0.0087, Class Loss: 0.2446, Accuracy: 0.3086\n",
      "Epoch [1079/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1812, Series Loss: 0.0087, Class Loss: 0.2446, Accuracy: 0.3086\n",
      "Epoch [1080/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1804, Series Loss: 0.0088, Class Loss: 0.2445, Accuracy: 0.2901\n",
      "Epoch [1081/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1804, Series Loss: 0.0086, Class Loss: 0.2446, Accuracy: 0.3210\n",
      "Epoch [1082/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1802, Series Loss: 0.0088, Class Loss: 0.2447, Accuracy: 0.2840\n",
      "Epoch [1083/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1809, Series Loss: 0.0088, Class Loss: 0.2448, Accuracy: 0.2901\n",
      "Epoch [1084/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1803, Series Loss: 0.0087, Class Loss: 0.2446, Accuracy: 0.3086\n",
      "Epoch [1085/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1805, Series Loss: 0.0088, Class Loss: 0.2445, Accuracy: 0.3086\n",
      "Epoch [1086/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1803, Series Loss: 0.0087, Class Loss: 0.2447, Accuracy: 0.2901\n",
      "Epoch [1087/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1803, Series Loss: 0.0087, Class Loss: 0.2447, Accuracy: 0.3210\n",
      "Epoch [1088/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1801, Series Loss: 0.0086, Class Loss: 0.2446, Accuracy: 0.3210\n",
      "Epoch [1089/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1814, Series Loss: 0.0089, Class Loss: 0.2446, Accuracy: 0.3086\n",
      "Epoch [1090/4000], Discriminator Loss: 0.0932, Generator Loss: 0.1809, Series Loss: 0.0086, Class Loss: 0.2446, Accuracy: 0.3086\n",
      "Epoch [1091/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1805, Series Loss: 0.0087, Class Loss: 0.2447, Accuracy: 0.3025\n",
      "Epoch [1092/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1815, Series Loss: 0.0087, Class Loss: 0.2447, Accuracy: 0.2901\n",
      "Epoch [1093/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1804, Series Loss: 0.0087, Class Loss: 0.2446, Accuracy: 0.3025\n",
      "Epoch [1094/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1798, Series Loss: 0.0086, Class Loss: 0.2447, Accuracy: 0.2840\n",
      "Epoch [1095/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1810, Series Loss: 0.0086, Class Loss: 0.2447, Accuracy: 0.2963\n",
      "Epoch [1096/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1801, Series Loss: 0.0086, Class Loss: 0.2446, Accuracy: 0.3148\n",
      "Epoch [1097/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1802, Series Loss: 0.0087, Class Loss: 0.2447, Accuracy: 0.3210\n",
      "Epoch [1098/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1804, Series Loss: 0.0087, Class Loss: 0.2446, Accuracy: 0.2963\n",
      "Epoch [1099/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1809, Series Loss: 0.0088, Class Loss: 0.2446, Accuracy: 0.3086\n",
      "Epoch [1100/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1801, Series Loss: 0.0087, Class Loss: 0.2446, Accuracy: 0.2901\n",
      "Epoch [1101/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1807, Series Loss: 0.0087, Class Loss: 0.2446, Accuracy: 0.3148\n",
      "Epoch [1102/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1810, Series Loss: 0.0089, Class Loss: 0.2446, Accuracy: 0.3086\n",
      "Epoch [1103/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1804, Series Loss: 0.0087, Class Loss: 0.2446, Accuracy: 0.2901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1104/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1800, Series Loss: 0.0085, Class Loss: 0.2445, Accuracy: 0.2840\n",
      "Epoch [1105/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1804, Series Loss: 0.0086, Class Loss: 0.2446, Accuracy: 0.2963\n",
      "Epoch [1106/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1809, Series Loss: 0.0087, Class Loss: 0.2446, Accuracy: 0.2901\n",
      "Epoch [1107/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1803, Series Loss: 0.0086, Class Loss: 0.2448, Accuracy: 0.3086\n",
      "Epoch [1108/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1800, Series Loss: 0.0086, Class Loss: 0.2447, Accuracy: 0.3025\n",
      "Epoch [1109/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1801, Series Loss: 0.0086, Class Loss: 0.2446, Accuracy: 0.3025\n",
      "Epoch [1110/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1807, Series Loss: 0.0086, Class Loss: 0.2446, Accuracy: 0.2963\n",
      "Epoch [1111/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1798, Series Loss: 0.0086, Class Loss: 0.2447, Accuracy: 0.3025\n",
      "Epoch [1112/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1812, Series Loss: 0.0087, Class Loss: 0.2448, Accuracy: 0.2901\n",
      "Epoch [1113/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1807, Series Loss: 0.0086, Class Loss: 0.2445, Accuracy: 0.2901\n",
      "Epoch [1114/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1807, Series Loss: 0.0086, Class Loss: 0.2446, Accuracy: 0.3025\n",
      "Epoch [1115/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1811, Series Loss: 0.0086, Class Loss: 0.2446, Accuracy: 0.2901\n",
      "Epoch [1116/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1802, Series Loss: 0.0087, Class Loss: 0.2445, Accuracy: 0.2778\n",
      "Epoch [1117/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1804, Series Loss: 0.0086, Class Loss: 0.2445, Accuracy: 0.3025\n",
      "Epoch [1118/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1798, Series Loss: 0.0085, Class Loss: 0.2446, Accuracy: 0.2963\n",
      "Epoch [1119/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1811, Series Loss: 0.0088, Class Loss: 0.2447, Accuracy: 0.3086\n",
      "Epoch [1120/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1805, Series Loss: 0.0088, Class Loss: 0.2447, Accuracy: 0.3025\n",
      "Epoch [1121/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1806, Series Loss: 0.0086, Class Loss: 0.2446, Accuracy: 0.3086\n",
      "Epoch [1122/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1804, Series Loss: 0.0085, Class Loss: 0.2446, Accuracy: 0.3086\n",
      "Epoch [1123/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1803, Series Loss: 0.0087, Class Loss: 0.2446, Accuracy: 0.2901\n",
      "Epoch [1124/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1803, Series Loss: 0.0086, Class Loss: 0.2445, Accuracy: 0.2840\n",
      "Epoch [1125/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1805, Series Loss: 0.0087, Class Loss: 0.2446, Accuracy: 0.2901\n",
      "Epoch [1126/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1801, Series Loss: 0.0085, Class Loss: 0.2445, Accuracy: 0.2963\n",
      "Epoch [1127/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1812, Series Loss: 0.0086, Class Loss: 0.2447, Accuracy: 0.2963\n",
      "Epoch [1128/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1801, Series Loss: 0.0086, Class Loss: 0.2446, Accuracy: 0.2901\n",
      "Epoch [1129/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1804, Series Loss: 0.0085, Class Loss: 0.2446, Accuracy: 0.3086\n",
      "Epoch [1130/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1806, Series Loss: 0.0085, Class Loss: 0.2446, Accuracy: 0.3025\n",
      "Epoch [1131/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1804, Series Loss: 0.0086, Class Loss: 0.2447, Accuracy: 0.2901\n",
      "Epoch [1132/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1803, Series Loss: 0.0086, Class Loss: 0.2446, Accuracy: 0.2963\n",
      "Epoch [1133/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1804, Series Loss: 0.0086, Class Loss: 0.2446, Accuracy: 0.2840\n",
      "Epoch [1134/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1802, Series Loss: 0.0086, Class Loss: 0.2447, Accuracy: 0.2901\n",
      "Epoch [1135/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1805, Series Loss: 0.0085, Class Loss: 0.2446, Accuracy: 0.2901\n",
      "Epoch [1136/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1807, Series Loss: 0.0086, Class Loss: 0.2447, Accuracy: 0.2840\n",
      "Epoch [1137/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1809, Series Loss: 0.0087, Class Loss: 0.2446, Accuracy: 0.2901\n",
      "Epoch [1138/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1800, Series Loss: 0.0084, Class Loss: 0.2447, Accuracy: 0.2901\n",
      "Epoch [1139/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1805, Series Loss: 0.0086, Class Loss: 0.2447, Accuracy: 0.2901\n",
      "Epoch [1140/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1802, Series Loss: 0.0086, Class Loss: 0.2446, Accuracy: 0.3086\n",
      "Epoch [1141/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1798, Series Loss: 0.0085, Class Loss: 0.2446, Accuracy: 0.2963\n",
      "Epoch [1142/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1811, Series Loss: 0.0086, Class Loss: 0.2447, Accuracy: 0.3086\n",
      "Epoch [1143/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1805, Series Loss: 0.0085, Class Loss: 0.2447, Accuracy: 0.3025\n",
      "Epoch [1144/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1806, Series Loss: 0.0085, Class Loss: 0.2446, Accuracy: 0.3025\n",
      "Epoch [1145/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1806, Series Loss: 0.0085, Class Loss: 0.2446, Accuracy: 0.2963\n",
      "Epoch [1146/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1808, Series Loss: 0.0086, Class Loss: 0.2446, Accuracy: 0.2654\n",
      "Epoch [1147/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1808, Series Loss: 0.0086, Class Loss: 0.2447, Accuracy: 0.3025\n",
      "Epoch [1148/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1803, Series Loss: 0.0085, Class Loss: 0.2447, Accuracy: 0.3086\n",
      "Epoch [1149/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1808, Series Loss: 0.0085, Class Loss: 0.2446, Accuracy: 0.3148\n",
      "Epoch [1150/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1805, Series Loss: 0.0085, Class Loss: 0.2446, Accuracy: 0.2963\n",
      "Epoch [1151/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1804, Series Loss: 0.0085, Class Loss: 0.2446, Accuracy: 0.2963\n",
      "Epoch [1152/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1802, Series Loss: 0.0084, Class Loss: 0.2446, Accuracy: 0.2963\n",
      "Epoch [1153/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1798, Series Loss: 0.0084, Class Loss: 0.2446, Accuracy: 0.2654\n",
      "Epoch [1154/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1806, Series Loss: 0.0084, Class Loss: 0.2446, Accuracy: 0.2840\n",
      "Epoch [1155/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1804, Series Loss: 0.0085, Class Loss: 0.2446, Accuracy: 0.2716\n",
      "Epoch [1156/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1805, Series Loss: 0.0085, Class Loss: 0.2446, Accuracy: 0.3148\n",
      "Epoch [1157/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1802, Series Loss: 0.0084, Class Loss: 0.2445, Accuracy: 0.2901\n",
      "Epoch [1158/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1804, Series Loss: 0.0085, Class Loss: 0.2445, Accuracy: 0.3210\n",
      "Epoch [1159/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1808, Series Loss: 0.0085, Class Loss: 0.2447, Accuracy: 0.2963\n",
      "Epoch [1160/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1804, Series Loss: 0.0084, Class Loss: 0.2446, Accuracy: 0.2901\n",
      "Epoch [1161/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1803, Series Loss: 0.0084, Class Loss: 0.2445, Accuracy: 0.2963\n",
      "Epoch [1162/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1804, Series Loss: 0.0085, Class Loss: 0.2447, Accuracy: 0.3025\n",
      "Epoch [1163/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1806, Series Loss: 0.0084, Class Loss: 0.2447, Accuracy: 0.3086\n",
      "Epoch [1164/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1803, Series Loss: 0.0084, Class Loss: 0.2446, Accuracy: 0.3086\n",
      "Epoch [1165/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1798, Series Loss: 0.0085, Class Loss: 0.2446, Accuracy: 0.3210\n",
      "Epoch [1166/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1805, Series Loss: 0.0086, Class Loss: 0.2447, Accuracy: 0.3025\n",
      "Epoch [1167/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1801, Series Loss: 0.0083, Class Loss: 0.2446, Accuracy: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1168/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1799, Series Loss: 0.0082, Class Loss: 0.2445, Accuracy: 0.3395\n",
      "Epoch [1169/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1802, Series Loss: 0.0084, Class Loss: 0.2445, Accuracy: 0.3025\n",
      "Epoch [1170/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1804, Series Loss: 0.0084, Class Loss: 0.2446, Accuracy: 0.3086\n",
      "Epoch [1171/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1804, Series Loss: 0.0084, Class Loss: 0.2447, Accuracy: 0.3210\n",
      "Epoch [1172/4000], Discriminator Loss: 0.0935, Generator Loss: 0.1799, Series Loss: 0.0083, Class Loss: 0.2445, Accuracy: 0.3210\n",
      "Epoch [1173/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1806, Series Loss: 0.0084, Class Loss: 0.2447, Accuracy: 0.3519\n",
      "Epoch [1174/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1802, Series Loss: 0.0083, Class Loss: 0.2446, Accuracy: 0.3704\n",
      "Epoch [1175/4000], Discriminator Loss: 0.0936, Generator Loss: 0.1803, Series Loss: 0.0083, Class Loss: 0.2446, Accuracy: 0.2901\n",
      "Epoch [1176/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1801, Series Loss: 0.0084, Class Loss: 0.2446, Accuracy: 0.3086\n",
      "Epoch [1177/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1798, Series Loss: 0.0083, Class Loss: 0.2447, Accuracy: 0.3210\n",
      "Epoch [1178/4000], Discriminator Loss: 0.0939, Generator Loss: 0.1799, Series Loss: 0.0085, Class Loss: 0.2445, Accuracy: 0.3210\n",
      "Epoch [1179/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1801, Series Loss: 0.0085, Class Loss: 0.2446, Accuracy: 0.2654\n",
      "Epoch [1180/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1797, Series Loss: 0.0083, Class Loss: 0.2445, Accuracy: 0.3025\n",
      "Epoch [1181/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1798, Series Loss: 0.0083, Class Loss: 0.2445, Accuracy: 0.3148\n",
      "Epoch [1182/4000], Discriminator Loss: 0.0937, Generator Loss: 0.1800, Series Loss: 0.0085, Class Loss: 0.2445, Accuracy: 0.3086\n",
      "Epoch [1183/4000], Discriminator Loss: 0.0932, Generator Loss: 0.1802, Series Loss: 0.0085, Class Loss: 0.2446, Accuracy: 0.3148\n",
      "Epoch [1184/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1805, Series Loss: 0.0086, Class Loss: 0.2446, Accuracy: 0.3086\n",
      "Epoch [1185/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1804, Series Loss: 0.0083, Class Loss: 0.2445, Accuracy: 0.3148\n",
      "Epoch [1186/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1802, Series Loss: 0.0085, Class Loss: 0.2446, Accuracy: 0.2963\n",
      "Epoch [1187/4000], Discriminator Loss: 0.0934, Generator Loss: 0.1797, Series Loss: 0.0083, Class Loss: 0.2448, Accuracy: 0.3025\n",
      "Epoch [1188/4000], Discriminator Loss: 0.0935, Generator Loss: 0.1799, Series Loss: 0.0084, Class Loss: 0.2446, Accuracy: 0.2963\n",
      "Epoch [1189/4000], Discriminator Loss: 0.0935, Generator Loss: 0.1800, Series Loss: 0.0084, Class Loss: 0.2446, Accuracy: 0.3025\n",
      "Epoch [1190/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1799, Series Loss: 0.0085, Class Loss: 0.2445, Accuracy: 0.3025\n",
      "Epoch [1191/4000], Discriminator Loss: 0.0932, Generator Loss: 0.1800, Series Loss: 0.0084, Class Loss: 0.2446, Accuracy: 0.3086\n",
      "Epoch [1192/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1803, Series Loss: 0.0083, Class Loss: 0.2446, Accuracy: 0.3148\n",
      "Epoch [1193/4000], Discriminator Loss: 0.0937, Generator Loss: 0.1801, Series Loss: 0.0084, Class Loss: 0.2445, Accuracy: 0.3086\n",
      "Epoch [1194/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1803, Series Loss: 0.0084, Class Loss: 0.2446, Accuracy: 0.2963\n",
      "Epoch [1195/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1800, Series Loss: 0.0083, Class Loss: 0.2446, Accuracy: 0.3025\n",
      "Epoch [1196/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1799, Series Loss: 0.0083, Class Loss: 0.2446, Accuracy: 0.3210\n",
      "Epoch [1197/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1800, Series Loss: 0.0084, Class Loss: 0.2447, Accuracy: 0.3025\n",
      "Epoch [1198/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1805, Series Loss: 0.0085, Class Loss: 0.2445, Accuracy: 0.3086\n",
      "Epoch [1199/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1802, Series Loss: 0.0084, Class Loss: 0.2445, Accuracy: 0.3210\n",
      "Epoch [1200/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1801, Series Loss: 0.0083, Class Loss: 0.2447, Accuracy: 0.3086\n",
      "Epoch [1201/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1800, Series Loss: 0.0083, Class Loss: 0.2446, Accuracy: 0.3210\n",
      "Epoch [1202/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1795, Series Loss: 0.0083, Class Loss: 0.2446, Accuracy: 0.3148\n",
      "Epoch [1203/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1794, Series Loss: 0.0083, Class Loss: 0.2446, Accuracy: 0.3210\n",
      "Epoch [1204/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1801, Series Loss: 0.0084, Class Loss: 0.2446, Accuracy: 0.3457\n",
      "Epoch [1205/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1804, Series Loss: 0.0085, Class Loss: 0.2447, Accuracy: 0.3333\n",
      "Epoch [1206/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1795, Series Loss: 0.0083, Class Loss: 0.2445, Accuracy: 0.3148\n",
      "Epoch [1207/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1800, Series Loss: 0.0082, Class Loss: 0.2445, Accuracy: 0.3086\n",
      "Epoch [1208/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1795, Series Loss: 0.0083, Class Loss: 0.2446, Accuracy: 0.3333\n",
      "Epoch [1209/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1800, Series Loss: 0.0082, Class Loss: 0.2446, Accuracy: 0.3272\n",
      "Epoch [1210/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1802, Series Loss: 0.0085, Class Loss: 0.2446, Accuracy: 0.3333\n",
      "Epoch [1211/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1798, Series Loss: 0.0083, Class Loss: 0.2446, Accuracy: 0.2963\n",
      "Epoch [1212/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1798, Series Loss: 0.0083, Class Loss: 0.2446, Accuracy: 0.3580\n",
      "Epoch [1213/4000], Discriminator Loss: 0.0938, Generator Loss: 0.1792, Series Loss: 0.0083, Class Loss: 0.2446, Accuracy: 0.3210\n",
      "Epoch [1214/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1798, Series Loss: 0.0084, Class Loss: 0.2446, Accuracy: 0.3272\n",
      "Epoch [1215/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1799, Series Loss: 0.0083, Class Loss: 0.2447, Accuracy: 0.3395\n",
      "Epoch [1216/4000], Discriminator Loss: 0.0932, Generator Loss: 0.1797, Series Loss: 0.0083, Class Loss: 0.2446, Accuracy: 0.3333\n",
      "Epoch [1217/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1797, Series Loss: 0.0083, Class Loss: 0.2445, Accuracy: 0.3086\n",
      "Epoch [1218/4000], Discriminator Loss: 0.0935, Generator Loss: 0.1801, Series Loss: 0.0082, Class Loss: 0.2446, Accuracy: 0.3519\n",
      "Epoch [1219/4000], Discriminator Loss: 0.0936, Generator Loss: 0.1803, Series Loss: 0.0083, Class Loss: 0.2446, Accuracy: 0.3519\n",
      "Epoch [1220/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1801, Series Loss: 0.0083, Class Loss: 0.2446, Accuracy: 0.4012\n",
      "Epoch [1221/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1800, Series Loss: 0.0083, Class Loss: 0.2446, Accuracy: 0.3272\n",
      "Epoch [1222/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1801, Series Loss: 0.0084, Class Loss: 0.2445, Accuracy: 0.3272\n",
      "Epoch [1223/4000], Discriminator Loss: 0.0937, Generator Loss: 0.1805, Series Loss: 0.0084, Class Loss: 0.2447, Accuracy: 0.3580\n",
      "Epoch [1224/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1804, Series Loss: 0.0084, Class Loss: 0.2445, Accuracy: 0.4012\n",
      "Epoch [1225/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1796, Series Loss: 0.0085, Class Loss: 0.2446, Accuracy: 0.3272\n",
      "Epoch [1226/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1795, Series Loss: 0.0083, Class Loss: 0.2445, Accuracy: 0.3642\n",
      "Epoch [1227/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1799, Series Loss: 0.0083, Class Loss: 0.2447, Accuracy: 0.3148\n",
      "Epoch [1228/4000], Discriminator Loss: 0.0932, Generator Loss: 0.1798, Series Loss: 0.0083, Class Loss: 0.2446, Accuracy: 0.3519\n",
      "Epoch [1229/4000], Discriminator Loss: 0.0935, Generator Loss: 0.1794, Series Loss: 0.0084, Class Loss: 0.2446, Accuracy: 0.3025\n",
      "Epoch [1230/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1798, Series Loss: 0.0083, Class Loss: 0.2446, Accuracy: 0.3148\n",
      "Epoch [1231/4000], Discriminator Loss: 0.0937, Generator Loss: 0.1798, Series Loss: 0.0083, Class Loss: 0.2446, Accuracy: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1232/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1802, Series Loss: 0.0084, Class Loss: 0.2445, Accuracy: 0.3148\n",
      "Epoch [1233/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1798, Series Loss: 0.0083, Class Loss: 0.2446, Accuracy: 0.3272\n",
      "Epoch [1234/4000], Discriminator Loss: 0.0934, Generator Loss: 0.1793, Series Loss: 0.0083, Class Loss: 0.2445, Accuracy: 0.3333\n",
      "Epoch [1235/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1799, Series Loss: 0.0083, Class Loss: 0.2446, Accuracy: 0.3580\n",
      "Epoch [1236/4000], Discriminator Loss: 0.0936, Generator Loss: 0.1796, Series Loss: 0.0083, Class Loss: 0.2447, Accuracy: 0.3457\n",
      "Epoch [1237/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1801, Series Loss: 0.0082, Class Loss: 0.2446, Accuracy: 0.3210\n",
      "Epoch [1238/4000], Discriminator Loss: 0.0932, Generator Loss: 0.1799, Series Loss: 0.0083, Class Loss: 0.2445, Accuracy: 0.3333\n",
      "Epoch [1239/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1797, Series Loss: 0.0081, Class Loss: 0.2446, Accuracy: 0.3580\n",
      "Epoch [1240/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1800, Series Loss: 0.0082, Class Loss: 0.2445, Accuracy: 0.3457\n",
      "Epoch [1241/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1799, Series Loss: 0.0083, Class Loss: 0.2445, Accuracy: 0.3333\n",
      "Epoch [1242/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1798, Series Loss: 0.0082, Class Loss: 0.2447, Accuracy: 0.3457\n",
      "Epoch [1243/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1794, Series Loss: 0.0082, Class Loss: 0.2444, Accuracy: 0.3457\n",
      "Epoch [1244/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1802, Series Loss: 0.0082, Class Loss: 0.2447, Accuracy: 0.3457\n",
      "Epoch [1245/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1798, Series Loss: 0.0083, Class Loss: 0.2446, Accuracy: 0.3519\n",
      "Epoch [1246/4000], Discriminator Loss: 0.0934, Generator Loss: 0.1799, Series Loss: 0.0082, Class Loss: 0.2446, Accuracy: 0.3272\n",
      "Epoch [1247/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1801, Series Loss: 0.0081, Class Loss: 0.2447, Accuracy: 0.3519\n",
      "Epoch [1248/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1797, Series Loss: 0.0082, Class Loss: 0.2445, Accuracy: 0.3704\n",
      "Epoch [1249/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1804, Series Loss: 0.0082, Class Loss: 0.2446, Accuracy: 0.3704\n",
      "Epoch [1250/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1804, Series Loss: 0.0083, Class Loss: 0.2446, Accuracy: 0.3272\n",
      "Epoch [1251/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1804, Series Loss: 0.0083, Class Loss: 0.2446, Accuracy: 0.3148\n",
      "Epoch [1252/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1800, Series Loss: 0.0081, Class Loss: 0.2448, Accuracy: 0.3704\n",
      "Epoch [1253/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1800, Series Loss: 0.0082, Class Loss: 0.2445, Accuracy: 0.3457\n",
      "Epoch [1254/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1803, Series Loss: 0.0083, Class Loss: 0.2446, Accuracy: 0.3704\n",
      "Epoch [1255/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1799, Series Loss: 0.0082, Class Loss: 0.2446, Accuracy: 0.3272\n",
      "Epoch [1256/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1795, Series Loss: 0.0082, Class Loss: 0.2446, Accuracy: 0.3272\n",
      "Epoch [1257/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1801, Series Loss: 0.0081, Class Loss: 0.2445, Accuracy: 0.3457\n",
      "Epoch [1258/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1800, Series Loss: 0.0082, Class Loss: 0.2446, Accuracy: 0.3086\n",
      "Epoch [1259/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1800, Series Loss: 0.0081, Class Loss: 0.2446, Accuracy: 0.3457\n",
      "Epoch [1260/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1798, Series Loss: 0.0081, Class Loss: 0.2446, Accuracy: 0.3210\n",
      "Epoch [1261/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1801, Series Loss: 0.0081, Class Loss: 0.2445, Accuracy: 0.3580\n",
      "Epoch [1262/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1798, Series Loss: 0.0081, Class Loss: 0.2445, Accuracy: 0.3395\n",
      "Epoch [1263/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1801, Series Loss: 0.0081, Class Loss: 0.2446, Accuracy: 0.3272\n",
      "Epoch [1264/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1800, Series Loss: 0.0080, Class Loss: 0.2445, Accuracy: 0.3333\n",
      "Epoch [1265/4000], Discriminator Loss: 0.0934, Generator Loss: 0.1800, Series Loss: 0.0080, Class Loss: 0.2447, Accuracy: 0.3210\n",
      "Epoch [1266/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1801, Series Loss: 0.0081, Class Loss: 0.2447, Accuracy: 0.3580\n",
      "Epoch [1267/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1799, Series Loss: 0.0081, Class Loss: 0.2446, Accuracy: 0.3148\n",
      "Epoch [1268/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1799, Series Loss: 0.0081, Class Loss: 0.2445, Accuracy: 0.3457\n",
      "Epoch [1269/4000], Discriminator Loss: 0.0934, Generator Loss: 0.1800, Series Loss: 0.0081, Class Loss: 0.2446, Accuracy: 0.3704\n",
      "Epoch [1270/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1799, Series Loss: 0.0081, Class Loss: 0.2445, Accuracy: 0.3333\n",
      "Epoch [1271/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1796, Series Loss: 0.0080, Class Loss: 0.2445, Accuracy: 0.3889\n",
      "Epoch [1272/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1799, Series Loss: 0.0081, Class Loss: 0.2446, Accuracy: 0.3519\n",
      "Epoch [1273/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1796, Series Loss: 0.0080, Class Loss: 0.2446, Accuracy: 0.3333\n",
      "Epoch [1274/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1799, Series Loss: 0.0080, Class Loss: 0.2446, Accuracy: 0.3765\n",
      "Epoch [1275/4000], Discriminator Loss: 0.0932, Generator Loss: 0.1795, Series Loss: 0.0080, Class Loss: 0.2445, Accuracy: 0.3210\n",
      "Epoch [1276/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1802, Series Loss: 0.0081, Class Loss: 0.2446, Accuracy: 0.3148\n",
      "Epoch [1277/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1801, Series Loss: 0.0081, Class Loss: 0.2446, Accuracy: 0.3457\n",
      "Epoch [1278/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1800, Series Loss: 0.0081, Class Loss: 0.2446, Accuracy: 0.3210\n",
      "Epoch [1279/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1798, Series Loss: 0.0080, Class Loss: 0.2446, Accuracy: 0.3642\n",
      "Epoch [1280/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1800, Series Loss: 0.0080, Class Loss: 0.2445, Accuracy: 0.3889\n",
      "Epoch [1281/4000], Discriminator Loss: 0.0935, Generator Loss: 0.1800, Series Loss: 0.0081, Class Loss: 0.2446, Accuracy: 0.3580\n",
      "Epoch [1282/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1799, Series Loss: 0.0080, Class Loss: 0.2446, Accuracy: 0.3889\n",
      "Epoch [1283/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1804, Series Loss: 0.0080, Class Loss: 0.2444, Accuracy: 0.4259\n",
      "Epoch [1284/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1805, Series Loss: 0.0081, Class Loss: 0.2445, Accuracy: 0.3827\n",
      "Epoch [1285/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1800, Series Loss: 0.0080, Class Loss: 0.2444, Accuracy: 0.3580\n",
      "Epoch [1286/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1798, Series Loss: 0.0080, Class Loss: 0.2445, Accuracy: 0.3457\n",
      "Epoch [1287/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1796, Series Loss: 0.0081, Class Loss: 0.2445, Accuracy: 0.3519\n",
      "Epoch [1288/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1803, Series Loss: 0.0080, Class Loss: 0.2446, Accuracy: 0.3457\n",
      "Epoch [1289/4000], Discriminator Loss: 0.0932, Generator Loss: 0.1800, Series Loss: 0.0080, Class Loss: 0.2444, Accuracy: 0.3765\n",
      "Epoch [1290/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1801, Series Loss: 0.0079, Class Loss: 0.2447, Accuracy: 0.3765\n",
      "Epoch [1291/4000], Discriminator Loss: 0.0932, Generator Loss: 0.1795, Series Loss: 0.0081, Class Loss: 0.2446, Accuracy: 0.3457\n",
      "Epoch [1292/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1796, Series Loss: 0.0081, Class Loss: 0.2447, Accuracy: 0.3765\n",
      "Epoch [1293/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1797, Series Loss: 0.0080, Class Loss: 0.2444, Accuracy: 0.3519\n",
      "Epoch [1294/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1800, Series Loss: 0.0080, Class Loss: 0.2447, Accuracy: 0.3580\n",
      "Epoch [1295/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1795, Series Loss: 0.0080, Class Loss: 0.2446, Accuracy: 0.3642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1296/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1801, Series Loss: 0.0079, Class Loss: 0.2447, Accuracy: 0.3148\n",
      "Epoch [1297/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1800, Series Loss: 0.0081, Class Loss: 0.2446, Accuracy: 0.3519\n",
      "Epoch [1298/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1805, Series Loss: 0.0080, Class Loss: 0.2446, Accuracy: 0.3333\n",
      "Epoch [1299/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1805, Series Loss: 0.0080, Class Loss: 0.2446, Accuracy: 0.3272\n",
      "Epoch [1300/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1800, Series Loss: 0.0081, Class Loss: 0.2446, Accuracy: 0.3148\n",
      "Epoch [1301/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1797, Series Loss: 0.0081, Class Loss: 0.2446, Accuracy: 0.3272\n",
      "Epoch [1302/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1799, Series Loss: 0.0081, Class Loss: 0.2446, Accuracy: 0.3395\n",
      "Epoch [1303/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1800, Series Loss: 0.0080, Class Loss: 0.2446, Accuracy: 0.3395\n",
      "Epoch [1304/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1803, Series Loss: 0.0081, Class Loss: 0.2446, Accuracy: 0.3519\n",
      "Epoch [1305/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1795, Series Loss: 0.0079, Class Loss: 0.2446, Accuracy: 0.3642\n",
      "Epoch [1306/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1794, Series Loss: 0.0080, Class Loss: 0.2444, Accuracy: 0.4012\n",
      "Epoch [1307/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1798, Series Loss: 0.0078, Class Loss: 0.2446, Accuracy: 0.3827\n",
      "Epoch [1308/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1804, Series Loss: 0.0080, Class Loss: 0.2445, Accuracy: 0.3827\n",
      "Epoch [1309/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1799, Series Loss: 0.0079, Class Loss: 0.2445, Accuracy: 0.3395\n",
      "Epoch [1310/4000], Discriminator Loss: 0.0936, Generator Loss: 0.1795, Series Loss: 0.0079, Class Loss: 0.2446, Accuracy: 0.3457\n",
      "Epoch [1311/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1797, Series Loss: 0.0080, Class Loss: 0.2446, Accuracy: 0.3457\n",
      "Epoch [1312/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1800, Series Loss: 0.0078, Class Loss: 0.2446, Accuracy: 0.3457\n",
      "Epoch [1313/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1804, Series Loss: 0.0079, Class Loss: 0.2446, Accuracy: 0.3704\n",
      "Epoch [1314/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1800, Series Loss: 0.0078, Class Loss: 0.2446, Accuracy: 0.3765\n",
      "Epoch [1315/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1799, Series Loss: 0.0079, Class Loss: 0.2446, Accuracy: 0.3457\n",
      "Epoch [1316/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1799, Series Loss: 0.0080, Class Loss: 0.2445, Accuracy: 0.3889\n",
      "Epoch [1317/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1800, Series Loss: 0.0080, Class Loss: 0.2446, Accuracy: 0.3272\n",
      "Epoch [1318/4000], Discriminator Loss: 0.0932, Generator Loss: 0.1796, Series Loss: 0.0078, Class Loss: 0.2445, Accuracy: 0.3333\n",
      "Epoch [1319/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1797, Series Loss: 0.0079, Class Loss: 0.2446, Accuracy: 0.3395\n",
      "Epoch [1320/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1797, Series Loss: 0.0078, Class Loss: 0.2445, Accuracy: 0.3951\n",
      "Epoch [1321/4000], Discriminator Loss: 0.0932, Generator Loss: 0.1797, Series Loss: 0.0079, Class Loss: 0.2445, Accuracy: 0.3765\n",
      "Epoch [1322/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1796, Series Loss: 0.0081, Class Loss: 0.2446, Accuracy: 0.3148\n",
      "Epoch [1323/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1801, Series Loss: 0.0079, Class Loss: 0.2446, Accuracy: 0.3827\n",
      "Epoch [1324/4000], Discriminator Loss: 0.0932, Generator Loss: 0.1800, Series Loss: 0.0079, Class Loss: 0.2445, Accuracy: 0.3951\n",
      "Epoch [1325/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1803, Series Loss: 0.0081, Class Loss: 0.2446, Accuracy: 0.3457\n",
      "Epoch [1326/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1799, Series Loss: 0.0081, Class Loss: 0.2445, Accuracy: 0.3642\n",
      "Epoch [1327/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1799, Series Loss: 0.0080, Class Loss: 0.2447, Accuracy: 0.3519\n",
      "Epoch [1328/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1799, Series Loss: 0.0080, Class Loss: 0.2446, Accuracy: 0.3272\n",
      "Epoch [1329/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1797, Series Loss: 0.0080, Class Loss: 0.2445, Accuracy: 0.3642\n",
      "Epoch [1330/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1790, Series Loss: 0.0079, Class Loss: 0.2444, Accuracy: 0.3333\n",
      "Epoch [1331/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1799, Series Loss: 0.0081, Class Loss: 0.2445, Accuracy: 0.3642\n",
      "Epoch [1332/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1801, Series Loss: 0.0080, Class Loss: 0.2446, Accuracy: 0.3210\n",
      "Epoch [1333/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1803, Series Loss: 0.0080, Class Loss: 0.2446, Accuracy: 0.3457\n",
      "Epoch [1334/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1799, Series Loss: 0.0082, Class Loss: 0.2445, Accuracy: 0.3210\n",
      "Epoch [1335/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1801, Series Loss: 0.0080, Class Loss: 0.2446, Accuracy: 0.3272\n",
      "Epoch [1336/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1802, Series Loss: 0.0078, Class Loss: 0.2446, Accuracy: 0.3580\n",
      "Epoch [1337/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1803, Series Loss: 0.0080, Class Loss: 0.2446, Accuracy: 0.3333\n",
      "Epoch [1338/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1798, Series Loss: 0.0079, Class Loss: 0.2446, Accuracy: 0.3642\n",
      "Epoch [1339/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1797, Series Loss: 0.0078, Class Loss: 0.2445, Accuracy: 0.3704\n",
      "Epoch [1340/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1800, Series Loss: 0.0081, Class Loss: 0.2446, Accuracy: 0.4012\n",
      "Epoch [1341/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1797, Series Loss: 0.0078, Class Loss: 0.2446, Accuracy: 0.3951\n",
      "Epoch [1342/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1797, Series Loss: 0.0080, Class Loss: 0.2445, Accuracy: 0.4074\n",
      "Epoch [1343/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1796, Series Loss: 0.0080, Class Loss: 0.2444, Accuracy: 0.3395\n",
      "Epoch [1344/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1801, Series Loss: 0.0079, Class Loss: 0.2446, Accuracy: 0.4444\n",
      "Epoch [1345/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1797, Series Loss: 0.0080, Class Loss: 0.2445, Accuracy: 0.3457\n",
      "Epoch [1346/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1802, Series Loss: 0.0078, Class Loss: 0.2446, Accuracy: 0.3765\n",
      "Epoch [1347/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1796, Series Loss: 0.0079, Class Loss: 0.2445, Accuracy: 0.3457\n",
      "Epoch [1348/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1802, Series Loss: 0.0080, Class Loss: 0.2445, Accuracy: 0.4074\n",
      "Epoch [1349/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1798, Series Loss: 0.0079, Class Loss: 0.2445, Accuracy: 0.4012\n",
      "Epoch [1350/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1797, Series Loss: 0.0080, Class Loss: 0.2445, Accuracy: 0.3765\n",
      "Epoch [1351/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1793, Series Loss: 0.0079, Class Loss: 0.2445, Accuracy: 0.4198\n",
      "Epoch [1352/4000], Discriminator Loss: 0.0936, Generator Loss: 0.1799, Series Loss: 0.0080, Class Loss: 0.2446, Accuracy: 0.3765\n",
      "Epoch [1353/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1797, Series Loss: 0.0078, Class Loss: 0.2446, Accuracy: 0.4136\n",
      "Epoch [1354/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1796, Series Loss: 0.0079, Class Loss: 0.2445, Accuracy: 0.3642\n",
      "Epoch [1355/4000], Discriminator Loss: 0.0934, Generator Loss: 0.1794, Series Loss: 0.0079, Class Loss: 0.2444, Accuracy: 0.3951\n",
      "Epoch [1356/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1796, Series Loss: 0.0078, Class Loss: 0.2447, Accuracy: 0.3580\n",
      "Epoch [1357/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1798, Series Loss: 0.0079, Class Loss: 0.2446, Accuracy: 0.3642\n",
      "Epoch [1358/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1796, Series Loss: 0.0080, Class Loss: 0.2446, Accuracy: 0.3765\n",
      "Epoch [1359/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1790, Series Loss: 0.0079, Class Loss: 0.2446, Accuracy: 0.3704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1360/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1792, Series Loss: 0.0078, Class Loss: 0.2445, Accuracy: 0.4321\n",
      "Epoch [1361/4000], Discriminator Loss: 0.0934, Generator Loss: 0.1793, Series Loss: 0.0079, Class Loss: 0.2445, Accuracy: 0.3395\n",
      "Epoch [1362/4000], Discriminator Loss: 0.0940, Generator Loss: 0.1792, Series Loss: 0.0079, Class Loss: 0.2446, Accuracy: 0.3765\n",
      "Epoch [1363/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1794, Series Loss: 0.0078, Class Loss: 0.2446, Accuracy: 0.4506\n",
      "Epoch [1364/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1795, Series Loss: 0.0078, Class Loss: 0.2446, Accuracy: 0.4568\n",
      "Epoch [1365/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1794, Series Loss: 0.0077, Class Loss: 0.2445, Accuracy: 0.4630\n",
      "Epoch [1366/4000], Discriminator Loss: 0.0934, Generator Loss: 0.1797, Series Loss: 0.0079, Class Loss: 0.2445, Accuracy: 0.4074\n",
      "Epoch [1367/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1798, Series Loss: 0.0078, Class Loss: 0.2446, Accuracy: 0.4198\n",
      "Epoch [1368/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1790, Series Loss: 0.0079, Class Loss: 0.2446, Accuracy: 0.3765\n",
      "Epoch [1369/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1791, Series Loss: 0.0079, Class Loss: 0.2446, Accuracy: 0.3519\n",
      "Epoch [1370/4000], Discriminator Loss: 0.0935, Generator Loss: 0.1792, Series Loss: 0.0080, Class Loss: 0.2445, Accuracy: 0.3519\n",
      "Epoch [1371/4000], Discriminator Loss: 0.0939, Generator Loss: 0.1794, Series Loss: 0.0079, Class Loss: 0.2445, Accuracy: 0.3951\n",
      "Epoch [1372/4000], Discriminator Loss: 0.0932, Generator Loss: 0.1791, Series Loss: 0.0078, Class Loss: 0.2446, Accuracy: 0.3210\n",
      "Epoch [1373/4000], Discriminator Loss: 0.0935, Generator Loss: 0.1793, Series Loss: 0.0079, Class Loss: 0.2446, Accuracy: 0.3642\n",
      "Epoch [1374/4000], Discriminator Loss: 0.0937, Generator Loss: 0.1797, Series Loss: 0.0078, Class Loss: 0.2446, Accuracy: 0.3457\n",
      "Epoch [1375/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1801, Series Loss: 0.0078, Class Loss: 0.2445, Accuracy: 0.4136\n",
      "Epoch [1376/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1792, Series Loss: 0.0079, Class Loss: 0.2445, Accuracy: 0.4074\n",
      "Epoch [1377/4000], Discriminator Loss: 0.0937, Generator Loss: 0.1794, Series Loss: 0.0079, Class Loss: 0.2446, Accuracy: 0.3395\n",
      "Epoch [1378/4000], Discriminator Loss: 0.0935, Generator Loss: 0.1788, Series Loss: 0.0078, Class Loss: 0.2445, Accuracy: 0.3333\n",
      "Epoch [1379/4000], Discriminator Loss: 0.0934, Generator Loss: 0.1794, Series Loss: 0.0079, Class Loss: 0.2446, Accuracy: 0.3148\n",
      "Epoch [1380/4000], Discriminator Loss: 0.0935, Generator Loss: 0.1794, Series Loss: 0.0078, Class Loss: 0.2445, Accuracy: 0.3272\n",
      "Epoch [1381/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1793, Series Loss: 0.0077, Class Loss: 0.2445, Accuracy: 0.3272\n",
      "Epoch [1382/4000], Discriminator Loss: 0.0941, Generator Loss: 0.1789, Series Loss: 0.0079, Class Loss: 0.2445, Accuracy: 0.2840\n",
      "Epoch [1383/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1792, Series Loss: 0.0078, Class Loss: 0.2446, Accuracy: 0.3210\n",
      "Epoch [1384/4000], Discriminator Loss: 0.0938, Generator Loss: 0.1791, Series Loss: 0.0079, Class Loss: 0.2445, Accuracy: 0.3272\n",
      "Epoch [1385/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1791, Series Loss: 0.0080, Class Loss: 0.2445, Accuracy: 0.3210\n",
      "Epoch [1386/4000], Discriminator Loss: 0.0934, Generator Loss: 0.1791, Series Loss: 0.0078, Class Loss: 0.2445, Accuracy: 0.3148\n",
      "Epoch [1387/4000], Discriminator Loss: 0.0937, Generator Loss: 0.1791, Series Loss: 0.0078, Class Loss: 0.2445, Accuracy: 0.3148\n",
      "Epoch [1388/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1789, Series Loss: 0.0078, Class Loss: 0.2445, Accuracy: 0.3025\n",
      "Epoch [1389/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1795, Series Loss: 0.0078, Class Loss: 0.2446, Accuracy: 0.3025\n",
      "Epoch [1390/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1790, Series Loss: 0.0078, Class Loss: 0.2447, Accuracy: 0.3086\n",
      "Epoch [1391/4000], Discriminator Loss: 0.0934, Generator Loss: 0.1791, Series Loss: 0.0080, Class Loss: 0.2445, Accuracy: 0.3148\n",
      "Epoch [1392/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1787, Series Loss: 0.0078, Class Loss: 0.2445, Accuracy: 0.2840\n",
      "Epoch [1393/4000], Discriminator Loss: 0.0936, Generator Loss: 0.1787, Series Loss: 0.0078, Class Loss: 0.2445, Accuracy: 0.2840\n",
      "Epoch [1394/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1789, Series Loss: 0.0080, Class Loss: 0.2445, Accuracy: 0.3210\n",
      "Epoch [1395/4000], Discriminator Loss: 0.0936, Generator Loss: 0.1788, Series Loss: 0.0077, Class Loss: 0.2446, Accuracy: 0.3210\n",
      "Epoch [1396/4000], Discriminator Loss: 0.0932, Generator Loss: 0.1795, Series Loss: 0.0078, Class Loss: 0.2445, Accuracy: 0.3210\n",
      "Epoch [1397/4000], Discriminator Loss: 0.0932, Generator Loss: 0.1792, Series Loss: 0.0077, Class Loss: 0.2446, Accuracy: 0.3395\n",
      "Epoch [1398/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1790, Series Loss: 0.0078, Class Loss: 0.2445, Accuracy: 0.3210\n",
      "Epoch [1399/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1792, Series Loss: 0.0078, Class Loss: 0.2446, Accuracy: 0.3086\n",
      "Epoch [1400/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1796, Series Loss: 0.0078, Class Loss: 0.2445, Accuracy: 0.3148\n",
      "Epoch [1401/4000], Discriminator Loss: 0.0932, Generator Loss: 0.1796, Series Loss: 0.0079, Class Loss: 0.2445, Accuracy: 0.3272\n",
      "Epoch [1402/4000], Discriminator Loss: 0.0935, Generator Loss: 0.1792, Series Loss: 0.0078, Class Loss: 0.2445, Accuracy: 0.3272\n",
      "Epoch [1403/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1790, Series Loss: 0.0077, Class Loss: 0.2444, Accuracy: 0.3333\n",
      "Epoch [1404/4000], Discriminator Loss: 0.0937, Generator Loss: 0.1790, Series Loss: 0.0077, Class Loss: 0.2445, Accuracy: 0.2963\n",
      "Epoch [1405/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1794, Series Loss: 0.0078, Class Loss: 0.2446, Accuracy: 0.3210\n",
      "Epoch [1406/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1792, Series Loss: 0.0079, Class Loss: 0.2446, Accuracy: 0.3025\n",
      "Epoch [1407/4000], Discriminator Loss: 0.0938, Generator Loss: 0.1785, Series Loss: 0.0077, Class Loss: 0.2445, Accuracy: 0.3210\n",
      "Epoch [1408/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1791, Series Loss: 0.0078, Class Loss: 0.2446, Accuracy: 0.3333\n",
      "Epoch [1409/4000], Discriminator Loss: 0.0934, Generator Loss: 0.1794, Series Loss: 0.0077, Class Loss: 0.2445, Accuracy: 0.3025\n",
      "Epoch [1410/4000], Discriminator Loss: 0.0932, Generator Loss: 0.1795, Series Loss: 0.0078, Class Loss: 0.2445, Accuracy: 0.3272\n",
      "Epoch [1411/4000], Discriminator Loss: 0.0936, Generator Loss: 0.1796, Series Loss: 0.0078, Class Loss: 0.2445, Accuracy: 0.2963\n",
      "Epoch [1412/4000], Discriminator Loss: 0.0938, Generator Loss: 0.1793, Series Loss: 0.0077, Class Loss: 0.2445, Accuracy: 0.3025\n",
      "Epoch [1413/4000], Discriminator Loss: 0.0938, Generator Loss: 0.1789, Series Loss: 0.0079, Class Loss: 0.2446, Accuracy: 0.3025\n",
      "Epoch [1414/4000], Discriminator Loss: 0.0938, Generator Loss: 0.1795, Series Loss: 0.0077, Class Loss: 0.2445, Accuracy: 0.3086\n",
      "Epoch [1415/4000], Discriminator Loss: 0.0932, Generator Loss: 0.1792, Series Loss: 0.0077, Class Loss: 0.2446, Accuracy: 0.3148\n",
      "Epoch [1416/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1797, Series Loss: 0.0078, Class Loss: 0.2446, Accuracy: 0.3333\n",
      "Epoch [1417/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1791, Series Loss: 0.0077, Class Loss: 0.2444, Accuracy: 0.3210\n",
      "Epoch [1418/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1793, Series Loss: 0.0077, Class Loss: 0.2445, Accuracy: 0.3395\n",
      "Epoch [1419/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1790, Series Loss: 0.0077, Class Loss: 0.2444, Accuracy: 0.3395\n",
      "Epoch [1420/4000], Discriminator Loss: 0.0934, Generator Loss: 0.1793, Series Loss: 0.0077, Class Loss: 0.2444, Accuracy: 0.3272\n",
      "Epoch [1421/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1793, Series Loss: 0.0076, Class Loss: 0.2445, Accuracy: 0.3333\n",
      "Epoch [1422/4000], Discriminator Loss: 0.0934, Generator Loss: 0.1792, Series Loss: 0.0076, Class Loss: 0.2447, Accuracy: 0.3272\n",
      "Epoch [1423/4000], Discriminator Loss: 0.0934, Generator Loss: 0.1788, Series Loss: 0.0078, Class Loss: 0.2445, Accuracy: 0.3210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1424/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1797, Series Loss: 0.0077, Class Loss: 0.2446, Accuracy: 0.3210\n",
      "Epoch [1425/4000], Discriminator Loss: 0.0937, Generator Loss: 0.1789, Series Loss: 0.0076, Class Loss: 0.2445, Accuracy: 0.3333\n",
      "Epoch [1426/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1794, Series Loss: 0.0077, Class Loss: 0.2445, Accuracy: 0.3272\n",
      "Epoch [1427/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1797, Series Loss: 0.0077, Class Loss: 0.2446, Accuracy: 0.3272\n",
      "Epoch [1428/4000], Discriminator Loss: 0.0936, Generator Loss: 0.1791, Series Loss: 0.0077, Class Loss: 0.2446, Accuracy: 0.3086\n",
      "Epoch [1429/4000], Discriminator Loss: 0.0935, Generator Loss: 0.1795, Series Loss: 0.0078, Class Loss: 0.2445, Accuracy: 0.3086\n",
      "Epoch [1430/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1796, Series Loss: 0.0077, Class Loss: 0.2445, Accuracy: 0.3025\n",
      "Epoch [1431/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1795, Series Loss: 0.0077, Class Loss: 0.2446, Accuracy: 0.3086\n",
      "Epoch [1432/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1793, Series Loss: 0.0077, Class Loss: 0.2446, Accuracy: 0.3210\n",
      "Epoch [1433/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1795, Series Loss: 0.0077, Class Loss: 0.2445, Accuracy: 0.2963\n",
      "Epoch [1434/4000], Discriminator Loss: 0.0940, Generator Loss: 0.1790, Series Loss: 0.0077, Class Loss: 0.2445, Accuracy: 0.3025\n",
      "Epoch [1435/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1789, Series Loss: 0.0076, Class Loss: 0.2444, Accuracy: 0.3519\n",
      "Epoch [1436/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1792, Series Loss: 0.0076, Class Loss: 0.2446, Accuracy: 0.3272\n",
      "Epoch [1437/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1795, Series Loss: 0.0076, Class Loss: 0.2445, Accuracy: 0.3086\n",
      "Epoch [1438/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1793, Series Loss: 0.0076, Class Loss: 0.2446, Accuracy: 0.3272\n",
      "Epoch [1439/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1790, Series Loss: 0.0076, Class Loss: 0.2446, Accuracy: 0.3148\n",
      "Epoch [1440/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1793, Series Loss: 0.0076, Class Loss: 0.2445, Accuracy: 0.3457\n",
      "Epoch [1441/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1793, Series Loss: 0.0076, Class Loss: 0.2444, Accuracy: 0.3580\n",
      "Epoch [1442/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1792, Series Loss: 0.0076, Class Loss: 0.2445, Accuracy: 0.3086\n",
      "Epoch [1443/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1794, Series Loss: 0.0076, Class Loss: 0.2444, Accuracy: 0.3148\n",
      "Epoch [1444/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1791, Series Loss: 0.0076, Class Loss: 0.2446, Accuracy: 0.3210\n",
      "Epoch [1445/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1794, Series Loss: 0.0077, Class Loss: 0.2445, Accuracy: 0.3395\n",
      "Epoch [1446/4000], Discriminator Loss: 0.0935, Generator Loss: 0.1793, Series Loss: 0.0076, Class Loss: 0.2444, Accuracy: 0.3519\n",
      "Epoch [1447/4000], Discriminator Loss: 0.0934, Generator Loss: 0.1792, Series Loss: 0.0076, Class Loss: 0.2446, Accuracy: 0.3210\n",
      "Epoch [1448/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1791, Series Loss: 0.0075, Class Loss: 0.2445, Accuracy: 0.3395\n",
      "Epoch [1449/4000], Discriminator Loss: 0.0935, Generator Loss: 0.1788, Series Loss: 0.0076, Class Loss: 0.2446, Accuracy: 0.3148\n",
      "Epoch [1450/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1786, Series Loss: 0.0075, Class Loss: 0.2445, Accuracy: 0.3210\n",
      "Epoch [1451/4000], Discriminator Loss: 0.0938, Generator Loss: 0.1786, Series Loss: 0.0076, Class Loss: 0.2445, Accuracy: 0.2963\n",
      "Epoch [1452/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1793, Series Loss: 0.0077, Class Loss: 0.2445, Accuracy: 0.3580\n",
      "Epoch [1453/4000], Discriminator Loss: 0.0935, Generator Loss: 0.1793, Series Loss: 0.0075, Class Loss: 0.2446, Accuracy: 0.3086\n",
      "Epoch [1454/4000], Discriminator Loss: 0.0935, Generator Loss: 0.1797, Series Loss: 0.0077, Class Loss: 0.2445, Accuracy: 0.3148\n",
      "Epoch [1455/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1790, Series Loss: 0.0076, Class Loss: 0.2445, Accuracy: 0.3642\n",
      "Epoch [1456/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1794, Series Loss: 0.0075, Class Loss: 0.2445, Accuracy: 0.3704\n",
      "Epoch [1457/4000], Discriminator Loss: 0.0935, Generator Loss: 0.1790, Series Loss: 0.0075, Class Loss: 0.2446, Accuracy: 0.3827\n",
      "Epoch [1458/4000], Discriminator Loss: 0.0932, Generator Loss: 0.1793, Series Loss: 0.0076, Class Loss: 0.2444, Accuracy: 0.3395\n",
      "Epoch [1459/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1793, Series Loss: 0.0074, Class Loss: 0.2446, Accuracy: 0.4012\n",
      "Epoch [1460/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1791, Series Loss: 0.0075, Class Loss: 0.2445, Accuracy: 0.3642\n",
      "Epoch [1461/4000], Discriminator Loss: 0.0934, Generator Loss: 0.1789, Series Loss: 0.0075, Class Loss: 0.2445, Accuracy: 0.3642\n",
      "Epoch [1462/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1796, Series Loss: 0.0075, Class Loss: 0.2446, Accuracy: 0.3704\n",
      "Epoch [1463/4000], Discriminator Loss: 0.0932, Generator Loss: 0.1790, Series Loss: 0.0075, Class Loss: 0.2445, Accuracy: 0.3519\n",
      "Epoch [1464/4000], Discriminator Loss: 0.0937, Generator Loss: 0.1791, Series Loss: 0.0076, Class Loss: 0.2444, Accuracy: 0.3457\n",
      "Epoch [1465/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1790, Series Loss: 0.0074, Class Loss: 0.2445, Accuracy: 0.4259\n",
      "Epoch [1466/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1797, Series Loss: 0.0076, Class Loss: 0.2445, Accuracy: 0.3889\n",
      "Epoch [1467/4000], Discriminator Loss: 0.0937, Generator Loss: 0.1793, Series Loss: 0.0076, Class Loss: 0.2446, Accuracy: 0.4012\n",
      "Epoch [1468/4000], Discriminator Loss: 0.0937, Generator Loss: 0.1787, Series Loss: 0.0075, Class Loss: 0.2445, Accuracy: 0.3827\n",
      "Epoch [1469/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1788, Series Loss: 0.0076, Class Loss: 0.2444, Accuracy: 0.3519\n",
      "Epoch [1470/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1788, Series Loss: 0.0075, Class Loss: 0.2445, Accuracy: 0.4012\n",
      "Epoch [1471/4000], Discriminator Loss: 0.0934, Generator Loss: 0.1790, Series Loss: 0.0075, Class Loss: 0.2446, Accuracy: 0.3580\n",
      "Epoch [1472/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1789, Series Loss: 0.0076, Class Loss: 0.2446, Accuracy: 0.3519\n",
      "Epoch [1473/4000], Discriminator Loss: 0.0935, Generator Loss: 0.1791, Series Loss: 0.0075, Class Loss: 0.2447, Accuracy: 0.3827\n",
      "Epoch [1474/4000], Discriminator Loss: 0.0938, Generator Loss: 0.1789, Series Loss: 0.0076, Class Loss: 0.2446, Accuracy: 0.3765\n",
      "Epoch [1475/4000], Discriminator Loss: 0.0934, Generator Loss: 0.1789, Series Loss: 0.0075, Class Loss: 0.2446, Accuracy: 0.4074\n",
      "Epoch [1476/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1787, Series Loss: 0.0075, Class Loss: 0.2445, Accuracy: 0.3765\n",
      "Epoch [1477/4000], Discriminator Loss: 0.0937, Generator Loss: 0.1787, Series Loss: 0.0075, Class Loss: 0.2445, Accuracy: 0.4012\n",
      "Epoch [1478/4000], Discriminator Loss: 0.0934, Generator Loss: 0.1788, Series Loss: 0.0074, Class Loss: 0.2445, Accuracy: 0.3457\n",
      "Epoch [1479/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1792, Series Loss: 0.0075, Class Loss: 0.2445, Accuracy: 0.3889\n",
      "Epoch [1480/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1787, Series Loss: 0.0074, Class Loss: 0.2444, Accuracy: 0.4136\n",
      "Epoch [1481/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1787, Series Loss: 0.0075, Class Loss: 0.2445, Accuracy: 0.3889\n",
      "Epoch [1482/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1794, Series Loss: 0.0075, Class Loss: 0.2445, Accuracy: 0.4444\n",
      "Epoch [1483/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1794, Series Loss: 0.0075, Class Loss: 0.2446, Accuracy: 0.3395\n",
      "Epoch [1484/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1787, Series Loss: 0.0075, Class Loss: 0.2445, Accuracy: 0.3395\n",
      "Epoch [1485/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1787, Series Loss: 0.0074, Class Loss: 0.2446, Accuracy: 0.4136\n",
      "Epoch [1486/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1788, Series Loss: 0.0075, Class Loss: 0.2445, Accuracy: 0.3580\n",
      "Epoch [1487/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1788, Series Loss: 0.0076, Class Loss: 0.2444, Accuracy: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1488/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1787, Series Loss: 0.0076, Class Loss: 0.2446, Accuracy: 0.3457\n",
      "Epoch [1489/4000], Discriminator Loss: 0.0934, Generator Loss: 0.1788, Series Loss: 0.0076, Class Loss: 0.2445, Accuracy: 0.3395\n",
      "Epoch [1490/4000], Discriminator Loss: 0.0932, Generator Loss: 0.1790, Series Loss: 0.0075, Class Loss: 0.2444, Accuracy: 0.3333\n",
      "Epoch [1491/4000], Discriminator Loss: 0.0932, Generator Loss: 0.1788, Series Loss: 0.0075, Class Loss: 0.2445, Accuracy: 0.3642\n",
      "Epoch [1492/4000], Discriminator Loss: 0.0934, Generator Loss: 0.1788, Series Loss: 0.0075, Class Loss: 0.2445, Accuracy: 0.3395\n",
      "Epoch [1493/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1792, Series Loss: 0.0075, Class Loss: 0.2445, Accuracy: 0.3333\n",
      "Epoch [1494/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1792, Series Loss: 0.0075, Class Loss: 0.2444, Accuracy: 0.3272\n",
      "Epoch [1495/4000], Discriminator Loss: 0.0932, Generator Loss: 0.1790, Series Loss: 0.0074, Class Loss: 0.2445, Accuracy: 0.3642\n",
      "Epoch [1496/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1790, Series Loss: 0.0074, Class Loss: 0.2444, Accuracy: 0.3642\n",
      "Epoch [1497/4000], Discriminator Loss: 0.0936, Generator Loss: 0.1792, Series Loss: 0.0075, Class Loss: 0.2445, Accuracy: 0.3210\n",
      "Epoch [1498/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1790, Series Loss: 0.0075, Class Loss: 0.2444, Accuracy: 0.3395\n",
      "Epoch [1499/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1788, Series Loss: 0.0075, Class Loss: 0.2444, Accuracy: 0.3519\n",
      "Epoch [1500/4000], Discriminator Loss: 0.0932, Generator Loss: 0.1789, Series Loss: 0.0075, Class Loss: 0.2444, Accuracy: 0.3333\n",
      "Epoch [1501/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1792, Series Loss: 0.0075, Class Loss: 0.2445, Accuracy: 0.3333\n",
      "Epoch [1502/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1792, Series Loss: 0.0074, Class Loss: 0.2444, Accuracy: 0.3457\n",
      "Epoch [1503/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1788, Series Loss: 0.0074, Class Loss: 0.2445, Accuracy: 0.3642\n",
      "Epoch [1504/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1790, Series Loss: 0.0076, Class Loss: 0.2444, Accuracy: 0.3519\n",
      "Epoch [1505/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1792, Series Loss: 0.0075, Class Loss: 0.2446, Accuracy: 0.3457\n",
      "Epoch [1506/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1791, Series Loss: 0.0074, Class Loss: 0.2444, Accuracy: 0.3272\n",
      "Epoch [1507/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1793, Series Loss: 0.0075, Class Loss: 0.2446, Accuracy: 0.3457\n",
      "Epoch [1508/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1795, Series Loss: 0.0075, Class Loss: 0.2446, Accuracy: 0.3210\n",
      "Epoch [1509/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1794, Series Loss: 0.0075, Class Loss: 0.2445, Accuracy: 0.3210\n",
      "Epoch [1510/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1793, Series Loss: 0.0075, Class Loss: 0.2445, Accuracy: 0.3272\n",
      "Epoch [1511/4000], Discriminator Loss: 0.0934, Generator Loss: 0.1790, Series Loss: 0.0074, Class Loss: 0.2445, Accuracy: 0.3395\n",
      "Epoch [1512/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1791, Series Loss: 0.0075, Class Loss: 0.2445, Accuracy: 0.3025\n",
      "Epoch [1513/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1796, Series Loss: 0.0074, Class Loss: 0.2444, Accuracy: 0.3457\n",
      "Epoch [1514/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1795, Series Loss: 0.0073, Class Loss: 0.2445, Accuracy: 0.3333\n",
      "Epoch [1515/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1790, Series Loss: 0.0074, Class Loss: 0.2444, Accuracy: 0.3333\n",
      "Epoch [1516/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1791, Series Loss: 0.0075, Class Loss: 0.2445, Accuracy: 0.3210\n",
      "Epoch [1517/4000], Discriminator Loss: 0.0934, Generator Loss: 0.1786, Series Loss: 0.0074, Class Loss: 0.2445, Accuracy: 0.3272\n",
      "Epoch [1518/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1787, Series Loss: 0.0075, Class Loss: 0.2445, Accuracy: 0.2963\n",
      "Epoch [1519/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1792, Series Loss: 0.0075, Class Loss: 0.2444, Accuracy: 0.3272\n",
      "Epoch [1520/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1793, Series Loss: 0.0075, Class Loss: 0.2444, Accuracy: 0.3333\n",
      "Epoch [1521/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1794, Series Loss: 0.0074, Class Loss: 0.2444, Accuracy: 0.3272\n",
      "Epoch [1522/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1790, Series Loss: 0.0074, Class Loss: 0.2444, Accuracy: 0.3519\n",
      "Epoch [1523/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1790, Series Loss: 0.0074, Class Loss: 0.2446, Accuracy: 0.3457\n",
      "Epoch [1524/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1789, Series Loss: 0.0075, Class Loss: 0.2445, Accuracy: 0.3210\n",
      "Epoch [1525/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1785, Series Loss: 0.0073, Class Loss: 0.2445, Accuracy: 0.3395\n",
      "Epoch [1526/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1788, Series Loss: 0.0075, Class Loss: 0.2444, Accuracy: 0.3395\n",
      "Epoch [1527/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1787, Series Loss: 0.0074, Class Loss: 0.2444, Accuracy: 0.3519\n",
      "Epoch [1528/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1786, Series Loss: 0.0074, Class Loss: 0.2443, Accuracy: 0.3395\n",
      "Epoch [1529/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1789, Series Loss: 0.0073, Class Loss: 0.2445, Accuracy: 0.3457\n",
      "Epoch [1530/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1792, Series Loss: 0.0073, Class Loss: 0.2446, Accuracy: 0.3827\n",
      "Epoch [1531/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1794, Series Loss: 0.0074, Class Loss: 0.2443, Accuracy: 0.3210\n",
      "Epoch [1532/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1790, Series Loss: 0.0073, Class Loss: 0.2445, Accuracy: 0.3272\n",
      "Epoch [1533/4000], Discriminator Loss: 0.0936, Generator Loss: 0.1787, Series Loss: 0.0074, Class Loss: 0.2443, Accuracy: 0.3519\n",
      "Epoch [1534/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1790, Series Loss: 0.0074, Class Loss: 0.2444, Accuracy: 0.3642\n",
      "Epoch [1535/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1796, Series Loss: 0.0073, Class Loss: 0.2444, Accuracy: 0.3704\n",
      "Epoch [1536/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1790, Series Loss: 0.0074, Class Loss: 0.2445, Accuracy: 0.3272\n",
      "Epoch [1537/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1792, Series Loss: 0.0074, Class Loss: 0.2445, Accuracy: 0.3086\n",
      "Epoch [1538/4000], Discriminator Loss: 0.0932, Generator Loss: 0.1791, Series Loss: 0.0074, Class Loss: 0.2444, Accuracy: 0.3889\n",
      "Epoch [1539/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1788, Series Loss: 0.0074, Class Loss: 0.2444, Accuracy: 0.3210\n",
      "Epoch [1540/4000], Discriminator Loss: 0.0932, Generator Loss: 0.1789, Series Loss: 0.0075, Class Loss: 0.2445, Accuracy: 0.3395\n",
      "Epoch [1541/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1788, Series Loss: 0.0074, Class Loss: 0.2444, Accuracy: 0.3765\n",
      "Epoch [1542/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1787, Series Loss: 0.0073, Class Loss: 0.2445, Accuracy: 0.3519\n",
      "Epoch [1543/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1786, Series Loss: 0.0075, Class Loss: 0.2445, Accuracy: 0.3272\n",
      "Epoch [1544/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1785, Series Loss: 0.0073, Class Loss: 0.2445, Accuracy: 0.3827\n",
      "Epoch [1545/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1792, Series Loss: 0.0075, Class Loss: 0.2444, Accuracy: 0.3765\n",
      "Epoch [1546/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1785, Series Loss: 0.0073, Class Loss: 0.2445, Accuracy: 0.3642\n",
      "Epoch [1547/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1787, Series Loss: 0.0073, Class Loss: 0.2444, Accuracy: 0.3333\n",
      "Epoch [1548/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1782, Series Loss: 0.0073, Class Loss: 0.2444, Accuracy: 0.3457\n",
      "Epoch [1549/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1788, Series Loss: 0.0074, Class Loss: 0.2444, Accuracy: 0.3642\n",
      "Epoch [1550/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1790, Series Loss: 0.0073, Class Loss: 0.2444, Accuracy: 0.3642\n",
      "Epoch [1551/4000], Discriminator Loss: 0.0935, Generator Loss: 0.1793, Series Loss: 0.0074, Class Loss: 0.2445, Accuracy: 0.3395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1552/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1789, Series Loss: 0.0073, Class Loss: 0.2444, Accuracy: 0.3642\n",
      "Epoch [1553/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1789, Series Loss: 0.0073, Class Loss: 0.2444, Accuracy: 0.3580\n",
      "Epoch [1554/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1785, Series Loss: 0.0073, Class Loss: 0.2444, Accuracy: 0.3086\n",
      "Epoch [1555/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1788, Series Loss: 0.0074, Class Loss: 0.2443, Accuracy: 0.3333\n",
      "Epoch [1556/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1782, Series Loss: 0.0074, Class Loss: 0.2445, Accuracy: 0.3333\n",
      "Epoch [1557/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1784, Series Loss: 0.0073, Class Loss: 0.2446, Accuracy: 0.3210\n",
      "Epoch [1558/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1785, Series Loss: 0.0074, Class Loss: 0.2445, Accuracy: 0.3333\n",
      "Epoch [1559/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1789, Series Loss: 0.0074, Class Loss: 0.2443, Accuracy: 0.3148\n",
      "Epoch [1560/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1788, Series Loss: 0.0073, Class Loss: 0.2444, Accuracy: 0.3086\n",
      "Epoch [1561/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1788, Series Loss: 0.0073, Class Loss: 0.2444, Accuracy: 0.3148\n",
      "Epoch [1562/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1791, Series Loss: 0.0073, Class Loss: 0.2446, Accuracy: 0.3086\n",
      "Epoch [1563/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1787, Series Loss: 0.0074, Class Loss: 0.2444, Accuracy: 0.3148\n",
      "Epoch [1564/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1790, Series Loss: 0.0073, Class Loss: 0.2444, Accuracy: 0.3272\n",
      "Epoch [1565/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1785, Series Loss: 0.0073, Class Loss: 0.2443, Accuracy: 0.3086\n",
      "Epoch [1566/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1787, Series Loss: 0.0073, Class Loss: 0.2445, Accuracy: 0.3210\n",
      "Epoch [1567/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1788, Series Loss: 0.0072, Class Loss: 0.2444, Accuracy: 0.3025\n",
      "Epoch [1568/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1789, Series Loss: 0.0073, Class Loss: 0.2444, Accuracy: 0.3333\n",
      "Epoch [1569/4000], Discriminator Loss: 0.0932, Generator Loss: 0.1785, Series Loss: 0.0073, Class Loss: 0.2446, Accuracy: 0.2840\n",
      "Epoch [1570/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1787, Series Loss: 0.0072, Class Loss: 0.2444, Accuracy: 0.3086\n",
      "Epoch [1571/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1788, Series Loss: 0.0072, Class Loss: 0.2444, Accuracy: 0.3272\n",
      "Epoch [1572/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1788, Series Loss: 0.0073, Class Loss: 0.2444, Accuracy: 0.3025\n",
      "Epoch [1573/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1787, Series Loss: 0.0073, Class Loss: 0.2444, Accuracy: 0.3333\n",
      "Epoch [1574/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1788, Series Loss: 0.0073, Class Loss: 0.2445, Accuracy: 0.3086\n",
      "Epoch [1575/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1785, Series Loss: 0.0072, Class Loss: 0.2444, Accuracy: 0.3333\n",
      "Epoch [1576/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1785, Series Loss: 0.0073, Class Loss: 0.2445, Accuracy: 0.3333\n",
      "Epoch [1577/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1785, Series Loss: 0.0072, Class Loss: 0.2444, Accuracy: 0.3210\n",
      "Epoch [1578/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1788, Series Loss: 0.0072, Class Loss: 0.2445, Accuracy: 0.3272\n",
      "Epoch [1579/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1785, Series Loss: 0.0073, Class Loss: 0.2445, Accuracy: 0.3272\n",
      "Epoch [1580/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1792, Series Loss: 0.0073, Class Loss: 0.2446, Accuracy: 0.2963\n",
      "Epoch [1581/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1784, Series Loss: 0.0073, Class Loss: 0.2444, Accuracy: 0.3457\n",
      "Epoch [1582/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1784, Series Loss: 0.0072, Class Loss: 0.2445, Accuracy: 0.3272\n",
      "Epoch [1583/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1781, Series Loss: 0.0071, Class Loss: 0.2444, Accuracy: 0.2716\n",
      "Epoch [1584/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1780, Series Loss: 0.0071, Class Loss: 0.2444, Accuracy: 0.3148\n",
      "Epoch [1585/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1785, Series Loss: 0.0072, Class Loss: 0.2444, Accuracy: 0.3210\n",
      "Epoch [1586/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1794, Series Loss: 0.0074, Class Loss: 0.2444, Accuracy: 0.3148\n",
      "Epoch [1587/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1784, Series Loss: 0.0072, Class Loss: 0.2444, Accuracy: 0.3086\n",
      "Epoch [1588/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1789, Series Loss: 0.0073, Class Loss: 0.2444, Accuracy: 0.3333\n",
      "Epoch [1589/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1787, Series Loss: 0.0071, Class Loss: 0.2444, Accuracy: 0.3457\n",
      "Epoch [1590/4000], Discriminator Loss: 0.0934, Generator Loss: 0.1788, Series Loss: 0.0073, Class Loss: 0.2444, Accuracy: 0.3086\n",
      "Epoch [1591/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1789, Series Loss: 0.0072, Class Loss: 0.2444, Accuracy: 0.3272\n",
      "Epoch [1592/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1788, Series Loss: 0.0071, Class Loss: 0.2444, Accuracy: 0.3333\n",
      "Epoch [1593/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1788, Series Loss: 0.0072, Class Loss: 0.2445, Accuracy: 0.2778\n",
      "Epoch [1594/4000], Discriminator Loss: 0.0934, Generator Loss: 0.1782, Series Loss: 0.0072, Class Loss: 0.2446, Accuracy: 0.3025\n",
      "Epoch [1595/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1793, Series Loss: 0.0072, Class Loss: 0.2445, Accuracy: 0.3210\n",
      "Epoch [1596/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1787, Series Loss: 0.0072, Class Loss: 0.2443, Accuracy: 0.2963\n",
      "Epoch [1597/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1786, Series Loss: 0.0072, Class Loss: 0.2445, Accuracy: 0.3086\n",
      "Epoch [1598/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1787, Series Loss: 0.0073, Class Loss: 0.2444, Accuracy: 0.3086\n",
      "Epoch [1599/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1784, Series Loss: 0.0071, Class Loss: 0.2444, Accuracy: 0.3272\n",
      "Epoch [1600/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1787, Series Loss: 0.0072, Class Loss: 0.2444, Accuracy: 0.3210\n",
      "Epoch [1601/4000], Discriminator Loss: 0.0935, Generator Loss: 0.1786, Series Loss: 0.0072, Class Loss: 0.2444, Accuracy: 0.3210\n",
      "Epoch [1602/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1787, Series Loss: 0.0072, Class Loss: 0.2445, Accuracy: 0.3210\n",
      "Epoch [1603/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1789, Series Loss: 0.0072, Class Loss: 0.2444, Accuracy: 0.3086\n",
      "Epoch [1604/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1784, Series Loss: 0.0072, Class Loss: 0.2444, Accuracy: 0.3086\n",
      "Epoch [1605/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1787, Series Loss: 0.0073, Class Loss: 0.2444, Accuracy: 0.3148\n",
      "Epoch [1606/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1787, Series Loss: 0.0071, Class Loss: 0.2445, Accuracy: 0.2963\n",
      "Epoch [1607/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1785, Series Loss: 0.0071, Class Loss: 0.2445, Accuracy: 0.2963\n",
      "Epoch [1608/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1787, Series Loss: 0.0073, Class Loss: 0.2445, Accuracy: 0.2901\n",
      "Epoch [1609/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1792, Series Loss: 0.0073, Class Loss: 0.2445, Accuracy: 0.3272\n",
      "Epoch [1610/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1787, Series Loss: 0.0072, Class Loss: 0.2445, Accuracy: 0.3148\n",
      "Epoch [1611/4000], Discriminator Loss: 0.0932, Generator Loss: 0.1788, Series Loss: 0.0072, Class Loss: 0.2445, Accuracy: 0.3086\n",
      "Epoch [1612/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1789, Series Loss: 0.0072, Class Loss: 0.2443, Accuracy: 0.3272\n",
      "Epoch [1613/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1790, Series Loss: 0.0073, Class Loss: 0.2445, Accuracy: 0.3025\n",
      "Epoch [1614/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1790, Series Loss: 0.0073, Class Loss: 0.2444, Accuracy: 0.2716\n",
      "Epoch [1615/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1797, Series Loss: 0.0072, Class Loss: 0.2444, Accuracy: 0.3395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1616/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1792, Series Loss: 0.0072, Class Loss: 0.2445, Accuracy: 0.3210\n",
      "Epoch [1617/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1785, Series Loss: 0.0072, Class Loss: 0.2444, Accuracy: 0.3025\n",
      "Epoch [1618/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1788, Series Loss: 0.0072, Class Loss: 0.2443, Accuracy: 0.3086\n",
      "Epoch [1619/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1791, Series Loss: 0.0072, Class Loss: 0.2444, Accuracy: 0.3210\n",
      "Epoch [1620/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1785, Series Loss: 0.0072, Class Loss: 0.2444, Accuracy: 0.2963\n",
      "Epoch [1621/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1788, Series Loss: 0.0073, Class Loss: 0.2444, Accuracy: 0.3272\n",
      "Epoch [1622/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1784, Series Loss: 0.0071, Class Loss: 0.2443, Accuracy: 0.3210\n",
      "Epoch [1623/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1787, Series Loss: 0.0073, Class Loss: 0.2443, Accuracy: 0.2901\n",
      "Epoch [1624/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1783, Series Loss: 0.0072, Class Loss: 0.2444, Accuracy: 0.2963\n",
      "Epoch [1625/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1784, Series Loss: 0.0072, Class Loss: 0.2444, Accuracy: 0.3086\n",
      "Epoch [1626/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1788, Series Loss: 0.0071, Class Loss: 0.2445, Accuracy: 0.3025\n",
      "Epoch [1627/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1782, Series Loss: 0.0072, Class Loss: 0.2444, Accuracy: 0.3519\n",
      "Epoch [1628/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1785, Series Loss: 0.0071, Class Loss: 0.2444, Accuracy: 0.2901\n",
      "Epoch [1629/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1785, Series Loss: 0.0071, Class Loss: 0.2445, Accuracy: 0.2901\n",
      "Epoch [1630/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1789, Series Loss: 0.0073, Class Loss: 0.2445, Accuracy: 0.3148\n",
      "Epoch [1631/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1785, Series Loss: 0.0071, Class Loss: 0.2444, Accuracy: 0.3210\n",
      "Epoch [1632/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1784, Series Loss: 0.0072, Class Loss: 0.2445, Accuracy: 0.3272\n",
      "Epoch [1633/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1781, Series Loss: 0.0070, Class Loss: 0.2445, Accuracy: 0.3025\n",
      "Epoch [1634/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1782, Series Loss: 0.0072, Class Loss: 0.2445, Accuracy: 0.3025\n",
      "Epoch [1635/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1783, Series Loss: 0.0071, Class Loss: 0.2443, Accuracy: 0.3086\n",
      "Epoch [1636/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1782, Series Loss: 0.0071, Class Loss: 0.2444, Accuracy: 0.3210\n",
      "Epoch [1637/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1787, Series Loss: 0.0071, Class Loss: 0.2443, Accuracy: 0.3272\n",
      "Epoch [1638/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1785, Series Loss: 0.0071, Class Loss: 0.2444, Accuracy: 0.3272\n",
      "Epoch [1639/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1786, Series Loss: 0.0072, Class Loss: 0.2444, Accuracy: 0.3333\n",
      "Epoch [1640/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1782, Series Loss: 0.0070, Class Loss: 0.2444, Accuracy: 0.3148\n",
      "Epoch [1641/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1781, Series Loss: 0.0071, Class Loss: 0.2445, Accuracy: 0.3272\n",
      "Epoch [1642/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1783, Series Loss: 0.0070, Class Loss: 0.2444, Accuracy: 0.3642\n",
      "Epoch [1643/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1787, Series Loss: 0.0072, Class Loss: 0.2444, Accuracy: 0.2840\n",
      "Epoch [1644/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1784, Series Loss: 0.0070, Class Loss: 0.2444, Accuracy: 0.3580\n",
      "Epoch [1645/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1781, Series Loss: 0.0070, Class Loss: 0.2445, Accuracy: 0.3086\n",
      "Epoch [1646/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1779, Series Loss: 0.0071, Class Loss: 0.2445, Accuracy: 0.3148\n",
      "Epoch [1647/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1785, Series Loss: 0.0071, Class Loss: 0.2445, Accuracy: 0.3025\n",
      "Epoch [1648/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1780, Series Loss: 0.0070, Class Loss: 0.2445, Accuracy: 0.3519\n",
      "Epoch [1649/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1783, Series Loss: 0.0070, Class Loss: 0.2444, Accuracy: 0.3086\n",
      "Epoch [1650/4000], Discriminator Loss: 0.0932, Generator Loss: 0.1782, Series Loss: 0.0071, Class Loss: 0.2444, Accuracy: 0.3148\n",
      "Epoch [1651/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1784, Series Loss: 0.0072, Class Loss: 0.2444, Accuracy: 0.3333\n",
      "Epoch [1652/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1782, Series Loss: 0.0071, Class Loss: 0.2444, Accuracy: 0.3025\n",
      "Epoch [1653/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1786, Series Loss: 0.0071, Class Loss: 0.2443, Accuracy: 0.3272\n",
      "Epoch [1654/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1788, Series Loss: 0.0071, Class Loss: 0.2445, Accuracy: 0.3086\n",
      "Epoch [1655/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1790, Series Loss: 0.0071, Class Loss: 0.2446, Accuracy: 0.3086\n",
      "Epoch [1656/4000], Discriminator Loss: 0.0935, Generator Loss: 0.1780, Series Loss: 0.0070, Class Loss: 0.2445, Accuracy: 0.3272\n",
      "Epoch [1657/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1783, Series Loss: 0.0071, Class Loss: 0.2444, Accuracy: 0.3519\n",
      "Epoch [1658/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1789, Series Loss: 0.0071, Class Loss: 0.2444, Accuracy: 0.2901\n",
      "Epoch [1659/4000], Discriminator Loss: 0.0932, Generator Loss: 0.1783, Series Loss: 0.0070, Class Loss: 0.2444, Accuracy: 0.2963\n",
      "Epoch [1660/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1782, Series Loss: 0.0071, Class Loss: 0.2444, Accuracy: 0.3086\n",
      "Epoch [1661/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1784, Series Loss: 0.0072, Class Loss: 0.2444, Accuracy: 0.2901\n",
      "Epoch [1662/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1792, Series Loss: 0.0072, Class Loss: 0.2444, Accuracy: 0.2963\n",
      "Epoch [1663/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1784, Series Loss: 0.0072, Class Loss: 0.2444, Accuracy: 0.2901\n",
      "Epoch [1664/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1787, Series Loss: 0.0072, Class Loss: 0.2444, Accuracy: 0.3148\n",
      "Epoch [1665/4000], Discriminator Loss: 0.0936, Generator Loss: 0.1784, Series Loss: 0.0072, Class Loss: 0.2444, Accuracy: 0.3025\n",
      "Epoch [1666/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1781, Series Loss: 0.0072, Class Loss: 0.2444, Accuracy: 0.2963\n",
      "Epoch [1667/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1784, Series Loss: 0.0072, Class Loss: 0.2444, Accuracy: 0.3272\n",
      "Epoch [1668/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1782, Series Loss: 0.0070, Class Loss: 0.2444, Accuracy: 0.3025\n",
      "Epoch [1669/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1781, Series Loss: 0.0070, Class Loss: 0.2444, Accuracy: 0.3025\n",
      "Epoch [1670/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1787, Series Loss: 0.0071, Class Loss: 0.2444, Accuracy: 0.3025\n",
      "Epoch [1671/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1786, Series Loss: 0.0071, Class Loss: 0.2445, Accuracy: 0.3148\n",
      "Epoch [1672/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1787, Series Loss: 0.0071, Class Loss: 0.2444, Accuracy: 0.3148\n",
      "Epoch [1673/4000], Discriminator Loss: 0.0932, Generator Loss: 0.1780, Series Loss: 0.0071, Class Loss: 0.2444, Accuracy: 0.2778\n",
      "Epoch [1674/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1783, Series Loss: 0.0070, Class Loss: 0.2444, Accuracy: 0.3210\n",
      "Epoch [1675/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1786, Series Loss: 0.0071, Class Loss: 0.2445, Accuracy: 0.3210\n",
      "Epoch [1676/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1787, Series Loss: 0.0070, Class Loss: 0.2445, Accuracy: 0.2963\n",
      "Epoch [1677/4000], Discriminator Loss: 0.0932, Generator Loss: 0.1785, Series Loss: 0.0070, Class Loss: 0.2444, Accuracy: 0.3025\n",
      "Epoch [1678/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1786, Series Loss: 0.0071, Class Loss: 0.2443, Accuracy: 0.3457\n",
      "Epoch [1679/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1787, Series Loss: 0.0071, Class Loss: 0.2444, Accuracy: 0.3395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1680/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1784, Series Loss: 0.0070, Class Loss: 0.2445, Accuracy: 0.3148\n",
      "Epoch [1681/4000], Discriminator Loss: 0.0932, Generator Loss: 0.1779, Series Loss: 0.0070, Class Loss: 0.2443, Accuracy: 0.3148\n",
      "Epoch [1682/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1779, Series Loss: 0.0070, Class Loss: 0.2444, Accuracy: 0.3272\n",
      "Epoch [1683/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1778, Series Loss: 0.0071, Class Loss: 0.2445, Accuracy: 0.3210\n",
      "Epoch [1684/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1785, Series Loss: 0.0070, Class Loss: 0.2444, Accuracy: 0.3148\n",
      "Epoch [1685/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1785, Series Loss: 0.0071, Class Loss: 0.2443, Accuracy: 0.3148\n",
      "Epoch [1686/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1785, Series Loss: 0.0070, Class Loss: 0.2444, Accuracy: 0.3025\n",
      "Epoch [1687/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1787, Series Loss: 0.0071, Class Loss: 0.2444, Accuracy: 0.2901\n",
      "Epoch [1688/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1787, Series Loss: 0.0071, Class Loss: 0.2443, Accuracy: 0.3086\n",
      "Epoch [1689/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1784, Series Loss: 0.0070, Class Loss: 0.2443, Accuracy: 0.3086\n",
      "Epoch [1690/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1782, Series Loss: 0.0070, Class Loss: 0.2444, Accuracy: 0.3086\n",
      "Epoch [1691/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1785, Series Loss: 0.0071, Class Loss: 0.2445, Accuracy: 0.2901\n",
      "Epoch [1692/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1790, Series Loss: 0.0071, Class Loss: 0.2444, Accuracy: 0.3272\n",
      "Epoch [1693/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1789, Series Loss: 0.0070, Class Loss: 0.2445, Accuracy: 0.3272\n",
      "Epoch [1694/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1788, Series Loss: 0.0070, Class Loss: 0.2445, Accuracy: 0.3025\n",
      "Epoch [1695/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1789, Series Loss: 0.0071, Class Loss: 0.2445, Accuracy: 0.2901\n",
      "Epoch [1696/4000], Discriminator Loss: 0.0932, Generator Loss: 0.1786, Series Loss: 0.0070, Class Loss: 0.2444, Accuracy: 0.3210\n",
      "Epoch [1697/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1783, Series Loss: 0.0071, Class Loss: 0.2444, Accuracy: 0.2963\n",
      "Epoch [1698/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1785, Series Loss: 0.0071, Class Loss: 0.2443, Accuracy: 0.3086\n",
      "Epoch [1699/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1788, Series Loss: 0.0071, Class Loss: 0.2444, Accuracy: 0.3148\n",
      "Epoch [1700/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1787, Series Loss: 0.0071, Class Loss: 0.2444, Accuracy: 0.3086\n",
      "Epoch [1701/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1781, Series Loss: 0.0069, Class Loss: 0.2445, Accuracy: 0.3148\n",
      "Epoch [1702/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1788, Series Loss: 0.0071, Class Loss: 0.2444, Accuracy: 0.3086\n",
      "Epoch [1703/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1780, Series Loss: 0.0069, Class Loss: 0.2445, Accuracy: 0.3086\n",
      "Epoch [1704/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1784, Series Loss: 0.0071, Class Loss: 0.2443, Accuracy: 0.3086\n",
      "Epoch [1705/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1785, Series Loss: 0.0070, Class Loss: 0.2444, Accuracy: 0.3148\n",
      "Epoch [1706/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1784, Series Loss: 0.0071, Class Loss: 0.2444, Accuracy: 0.2963\n",
      "Epoch [1707/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1783, Series Loss: 0.0070, Class Loss: 0.2444, Accuracy: 0.3086\n",
      "Epoch [1708/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1784, Series Loss: 0.0070, Class Loss: 0.2445, Accuracy: 0.2963\n",
      "Epoch [1709/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1784, Series Loss: 0.0070, Class Loss: 0.2445, Accuracy: 0.3333\n",
      "Epoch [1710/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1781, Series Loss: 0.0069, Class Loss: 0.2444, Accuracy: 0.3086\n",
      "Epoch [1711/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1784, Series Loss: 0.0069, Class Loss: 0.2443, Accuracy: 0.3148\n",
      "Epoch [1712/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1781, Series Loss: 0.0069, Class Loss: 0.2444, Accuracy: 0.2963\n",
      "Epoch [1713/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1782, Series Loss: 0.0069, Class Loss: 0.2444, Accuracy: 0.2840\n",
      "Epoch [1714/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1782, Series Loss: 0.0071, Class Loss: 0.2445, Accuracy: 0.2716\n",
      "Epoch [1715/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1780, Series Loss: 0.0069, Class Loss: 0.2444, Accuracy: 0.3210\n",
      "Epoch [1716/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1776, Series Loss: 0.0069, Class Loss: 0.2444, Accuracy: 0.3086\n",
      "Epoch [1717/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1787, Series Loss: 0.0071, Class Loss: 0.2444, Accuracy: 0.2963\n",
      "Epoch [1718/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1781, Series Loss: 0.0069, Class Loss: 0.2444, Accuracy: 0.3148\n",
      "Epoch [1719/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1779, Series Loss: 0.0069, Class Loss: 0.2444, Accuracy: 0.3210\n",
      "Epoch [1720/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1782, Series Loss: 0.0070, Class Loss: 0.2444, Accuracy: 0.3148\n",
      "Epoch [1721/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1783, Series Loss: 0.0069, Class Loss: 0.2444, Accuracy: 0.3086\n",
      "Epoch [1722/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1783, Series Loss: 0.0069, Class Loss: 0.2444, Accuracy: 0.3025\n",
      "Epoch [1723/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1775, Series Loss: 0.0069, Class Loss: 0.2443, Accuracy: 0.3272\n",
      "Epoch [1724/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1783, Series Loss: 0.0070, Class Loss: 0.2443, Accuracy: 0.3025\n",
      "Epoch [1725/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1780, Series Loss: 0.0070, Class Loss: 0.2445, Accuracy: 0.3025\n",
      "Epoch [1726/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1783, Series Loss: 0.0069, Class Loss: 0.2444, Accuracy: 0.3086\n",
      "Epoch [1727/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1783, Series Loss: 0.0069, Class Loss: 0.2444, Accuracy: 0.3148\n",
      "Epoch [1728/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1785, Series Loss: 0.0069, Class Loss: 0.2444, Accuracy: 0.3025\n",
      "Epoch [1729/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1786, Series Loss: 0.0068, Class Loss: 0.2445, Accuracy: 0.3086\n",
      "Epoch [1730/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1786, Series Loss: 0.0069, Class Loss: 0.2444, Accuracy: 0.2901\n",
      "Epoch [1731/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1787, Series Loss: 0.0068, Class Loss: 0.2444, Accuracy: 0.3086\n",
      "Epoch [1732/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1785, Series Loss: 0.0070, Class Loss: 0.2444, Accuracy: 0.3210\n",
      "Epoch [1733/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1781, Series Loss: 0.0069, Class Loss: 0.2444, Accuracy: 0.3148\n",
      "Epoch [1734/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1780, Series Loss: 0.0069, Class Loss: 0.2445, Accuracy: 0.3148\n",
      "Epoch [1735/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1783, Series Loss: 0.0070, Class Loss: 0.2445, Accuracy: 0.2778\n",
      "Epoch [1736/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1780, Series Loss: 0.0068, Class Loss: 0.2444, Accuracy: 0.3148\n",
      "Epoch [1737/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1785, Series Loss: 0.0070, Class Loss: 0.2444, Accuracy: 0.3025\n",
      "Epoch [1738/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1780, Series Loss: 0.0069, Class Loss: 0.2444, Accuracy: 0.3025\n",
      "Epoch [1739/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1780, Series Loss: 0.0068, Class Loss: 0.2445, Accuracy: 0.2963\n",
      "Epoch [1740/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1787, Series Loss: 0.0069, Class Loss: 0.2443, Accuracy: 0.3333\n",
      "Epoch [1741/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1783, Series Loss: 0.0069, Class Loss: 0.2445, Accuracy: 0.3025\n",
      "Epoch [1742/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1782, Series Loss: 0.0068, Class Loss: 0.2444, Accuracy: 0.3025\n",
      "Epoch [1743/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1784, Series Loss: 0.0070, Class Loss: 0.2443, Accuracy: 0.3148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1744/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1785, Series Loss: 0.0070, Class Loss: 0.2445, Accuracy: 0.2840\n",
      "Epoch [1745/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1782, Series Loss: 0.0069, Class Loss: 0.2445, Accuracy: 0.3025\n",
      "Epoch [1746/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1787, Series Loss: 0.0069, Class Loss: 0.2443, Accuracy: 0.2901\n",
      "Epoch [1747/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1782, Series Loss: 0.0069, Class Loss: 0.2445, Accuracy: 0.3148\n",
      "Epoch [1748/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1778, Series Loss: 0.0069, Class Loss: 0.2443, Accuracy: 0.3148\n",
      "Epoch [1749/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1784, Series Loss: 0.0069, Class Loss: 0.2445, Accuracy: 0.2840\n",
      "Epoch [1750/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1780, Series Loss: 0.0069, Class Loss: 0.2444, Accuracy: 0.3025\n",
      "Epoch [1751/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1779, Series Loss: 0.0070, Class Loss: 0.2443, Accuracy: 0.2778\n",
      "Epoch [1752/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1779, Series Loss: 0.0067, Class Loss: 0.2445, Accuracy: 0.2963\n",
      "Epoch [1753/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1779, Series Loss: 0.0069, Class Loss: 0.2443, Accuracy: 0.3025\n",
      "Epoch [1754/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1781, Series Loss: 0.0068, Class Loss: 0.2445, Accuracy: 0.2716\n",
      "Epoch [1755/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1776, Series Loss: 0.0067, Class Loss: 0.2444, Accuracy: 0.2901\n",
      "Epoch [1756/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1781, Series Loss: 0.0069, Class Loss: 0.2444, Accuracy: 0.3025\n",
      "Epoch [1757/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1784, Series Loss: 0.0068, Class Loss: 0.2444, Accuracy: 0.2901\n",
      "Epoch [1758/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1785, Series Loss: 0.0070, Class Loss: 0.2444, Accuracy: 0.3086\n",
      "Epoch [1759/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1781, Series Loss: 0.0068, Class Loss: 0.2444, Accuracy: 0.3025\n",
      "Epoch [1760/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1786, Series Loss: 0.0069, Class Loss: 0.2445, Accuracy: 0.2901\n",
      "Epoch [1761/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1780, Series Loss: 0.0068, Class Loss: 0.2444, Accuracy: 0.2963\n",
      "Epoch [1762/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1781, Series Loss: 0.0068, Class Loss: 0.2444, Accuracy: 0.2901\n",
      "Epoch [1763/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1782, Series Loss: 0.0069, Class Loss: 0.2444, Accuracy: 0.3086\n",
      "Epoch [1764/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1781, Series Loss: 0.0068, Class Loss: 0.2444, Accuracy: 0.2963\n",
      "Epoch [1765/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1781, Series Loss: 0.0069, Class Loss: 0.2443, Accuracy: 0.3086\n",
      "Epoch [1766/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1778, Series Loss: 0.0069, Class Loss: 0.2444, Accuracy: 0.3025\n",
      "Epoch [1767/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1779, Series Loss: 0.0069, Class Loss: 0.2445, Accuracy: 0.2901\n",
      "Epoch [1768/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1777, Series Loss: 0.0068, Class Loss: 0.2443, Accuracy: 0.3025\n",
      "Epoch [1769/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1783, Series Loss: 0.0068, Class Loss: 0.2445, Accuracy: 0.2963\n",
      "Epoch [1770/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1780, Series Loss: 0.0068, Class Loss: 0.2443, Accuracy: 0.2778\n",
      "Epoch [1771/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1783, Series Loss: 0.0069, Class Loss: 0.2444, Accuracy: 0.3025\n",
      "Epoch [1772/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1781, Series Loss: 0.0069, Class Loss: 0.2443, Accuracy: 0.2963\n",
      "Epoch [1773/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1786, Series Loss: 0.0069, Class Loss: 0.2444, Accuracy: 0.3272\n",
      "Epoch [1774/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1785, Series Loss: 0.0069, Class Loss: 0.2444, Accuracy: 0.3086\n",
      "Epoch [1775/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1780, Series Loss: 0.0068, Class Loss: 0.2444, Accuracy: 0.3148\n",
      "Epoch [1776/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1781, Series Loss: 0.0069, Class Loss: 0.2444, Accuracy: 0.3025\n",
      "Epoch [1777/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1782, Series Loss: 0.0068, Class Loss: 0.2443, Accuracy: 0.3025\n",
      "Epoch [1778/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1781, Series Loss: 0.0067, Class Loss: 0.2443, Accuracy: 0.3086\n",
      "Epoch [1779/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1779, Series Loss: 0.0069, Class Loss: 0.2444, Accuracy: 0.2963\n",
      "Epoch [1780/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1781, Series Loss: 0.0068, Class Loss: 0.2444, Accuracy: 0.2963\n",
      "Epoch [1781/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1779, Series Loss: 0.0069, Class Loss: 0.2444, Accuracy: 0.3025\n",
      "Epoch [1782/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1782, Series Loss: 0.0068, Class Loss: 0.2443, Accuracy: 0.3025\n",
      "Epoch [1783/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1780, Series Loss: 0.0067, Class Loss: 0.2443, Accuracy: 0.2963\n",
      "Epoch [1784/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1780, Series Loss: 0.0068, Class Loss: 0.2444, Accuracy: 0.2840\n",
      "Epoch [1785/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1781, Series Loss: 0.0069, Class Loss: 0.2444, Accuracy: 0.3025\n",
      "Epoch [1786/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1790, Series Loss: 0.0069, Class Loss: 0.2445, Accuracy: 0.3210\n",
      "Epoch [1787/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1784, Series Loss: 0.0068, Class Loss: 0.2444, Accuracy: 0.2778\n",
      "Epoch [1788/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1784, Series Loss: 0.0069, Class Loss: 0.2442, Accuracy: 0.2840\n",
      "Epoch [1789/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1784, Series Loss: 0.0069, Class Loss: 0.2444, Accuracy: 0.3148\n",
      "Epoch [1790/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1782, Series Loss: 0.0068, Class Loss: 0.2444, Accuracy: 0.3272\n",
      "Epoch [1791/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1781, Series Loss: 0.0069, Class Loss: 0.2443, Accuracy: 0.2963\n",
      "Epoch [1792/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1782, Series Loss: 0.0068, Class Loss: 0.2444, Accuracy: 0.3148\n",
      "Epoch [1793/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1788, Series Loss: 0.0069, Class Loss: 0.2444, Accuracy: 0.3025\n",
      "Epoch [1794/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1779, Series Loss: 0.0067, Class Loss: 0.2443, Accuracy: 0.3519\n",
      "Epoch [1795/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1782, Series Loss: 0.0068, Class Loss: 0.2445, Accuracy: 0.3210\n",
      "Epoch [1796/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1783, Series Loss: 0.0068, Class Loss: 0.2443, Accuracy: 0.3086\n",
      "Epoch [1797/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1784, Series Loss: 0.0068, Class Loss: 0.2444, Accuracy: 0.3210\n",
      "Epoch [1798/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1781, Series Loss: 0.0067, Class Loss: 0.2445, Accuracy: 0.3086\n",
      "Epoch [1799/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1781, Series Loss: 0.0067, Class Loss: 0.2443, Accuracy: 0.2963\n",
      "Epoch [1800/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1782, Series Loss: 0.0068, Class Loss: 0.2444, Accuracy: 0.2901\n",
      "Epoch [1801/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1779, Series Loss: 0.0066, Class Loss: 0.2445, Accuracy: 0.3272\n",
      "Epoch [1802/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1780, Series Loss: 0.0067, Class Loss: 0.2445, Accuracy: 0.2963\n",
      "Epoch [1803/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1779, Series Loss: 0.0067, Class Loss: 0.2443, Accuracy: 0.3025\n",
      "Epoch [1804/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1787, Series Loss: 0.0067, Class Loss: 0.2444, Accuracy: 0.3025\n",
      "Epoch [1805/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1783, Series Loss: 0.0066, Class Loss: 0.2446, Accuracy: 0.3025\n",
      "Epoch [1806/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1782, Series Loss: 0.0068, Class Loss: 0.2444, Accuracy: 0.2840\n",
      "Epoch [1807/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1782, Series Loss: 0.0066, Class Loss: 0.2443, Accuracy: 0.2901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1808/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1784, Series Loss: 0.0069, Class Loss: 0.2444, Accuracy: 0.3272\n",
      "Epoch [1809/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1782, Series Loss: 0.0069, Class Loss: 0.2444, Accuracy: 0.3025\n",
      "Epoch [1810/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1781, Series Loss: 0.0067, Class Loss: 0.2444, Accuracy: 0.3086\n",
      "Epoch [1811/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1780, Series Loss: 0.0067, Class Loss: 0.2444, Accuracy: 0.3025\n",
      "Epoch [1812/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1779, Series Loss: 0.0067, Class Loss: 0.2443, Accuracy: 0.3086\n",
      "Epoch [1813/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1784, Series Loss: 0.0068, Class Loss: 0.2444, Accuracy: 0.2963\n",
      "Epoch [1814/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1784, Series Loss: 0.0068, Class Loss: 0.2443, Accuracy: 0.2778\n",
      "Epoch [1815/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1780, Series Loss: 0.0067, Class Loss: 0.2444, Accuracy: 0.2901\n",
      "Epoch [1816/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1779, Series Loss: 0.0068, Class Loss: 0.2444, Accuracy: 0.2901\n",
      "Epoch [1817/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1779, Series Loss: 0.0066, Class Loss: 0.2443, Accuracy: 0.2963\n",
      "Epoch [1818/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1775, Series Loss: 0.0067, Class Loss: 0.2444, Accuracy: 0.2963\n",
      "Epoch [1819/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1779, Series Loss: 0.0067, Class Loss: 0.2444, Accuracy: 0.2901\n",
      "Epoch [1820/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1785, Series Loss: 0.0067, Class Loss: 0.2445, Accuracy: 0.2901\n",
      "Epoch [1821/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1782, Series Loss: 0.0068, Class Loss: 0.2444, Accuracy: 0.3025\n",
      "Epoch [1822/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1778, Series Loss: 0.0067, Class Loss: 0.2444, Accuracy: 0.2901\n",
      "Epoch [1823/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1781, Series Loss: 0.0068, Class Loss: 0.2444, Accuracy: 0.2840\n",
      "Epoch [1824/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1780, Series Loss: 0.0068, Class Loss: 0.2444, Accuracy: 0.2778\n",
      "Epoch [1825/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1781, Series Loss: 0.0066, Class Loss: 0.2445, Accuracy: 0.2963\n",
      "Epoch [1826/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1782, Series Loss: 0.0066, Class Loss: 0.2443, Accuracy: 0.3148\n",
      "Epoch [1827/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1785, Series Loss: 0.0067, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [1828/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1782, Series Loss: 0.0068, Class Loss: 0.2444, Accuracy: 0.2901\n",
      "Epoch [1829/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1780, Series Loss: 0.0066, Class Loss: 0.2443, Accuracy: 0.2963\n",
      "Epoch [1830/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1781, Series Loss: 0.0067, Class Loss: 0.2444, Accuracy: 0.2901\n",
      "Epoch [1831/4000], Discriminator Loss: 0.0935, Generator Loss: 0.1780, Series Loss: 0.0066, Class Loss: 0.2444, Accuracy: 0.2901\n",
      "Epoch [1832/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1785, Series Loss: 0.0067, Class Loss: 0.2445, Accuracy: 0.3210\n",
      "Epoch [1833/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1779, Series Loss: 0.0067, Class Loss: 0.2444, Accuracy: 0.3086\n",
      "Epoch [1834/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1785, Series Loss: 0.0067, Class Loss: 0.2445, Accuracy: 0.2840\n",
      "Epoch [1835/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1781, Series Loss: 0.0066, Class Loss: 0.2445, Accuracy: 0.3025\n",
      "Epoch [1836/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1782, Series Loss: 0.0067, Class Loss: 0.2444, Accuracy: 0.2901\n",
      "Epoch [1837/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1780, Series Loss: 0.0066, Class Loss: 0.2444, Accuracy: 0.2840\n",
      "Epoch [1838/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1783, Series Loss: 0.0066, Class Loss: 0.2444, Accuracy: 0.3025\n",
      "Epoch [1839/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1781, Series Loss: 0.0066, Class Loss: 0.2444, Accuracy: 0.2840\n",
      "Epoch [1840/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1780, Series Loss: 0.0066, Class Loss: 0.2444, Accuracy: 0.3025\n",
      "Epoch [1841/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1786, Series Loss: 0.0067, Class Loss: 0.2445, Accuracy: 0.3025\n",
      "Epoch [1842/4000], Discriminator Loss: 0.0932, Generator Loss: 0.1780, Series Loss: 0.0066, Class Loss: 0.2444, Accuracy: 0.2963\n",
      "Epoch [1843/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1784, Series Loss: 0.0067, Class Loss: 0.2445, Accuracy: 0.2901\n",
      "Epoch [1844/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1776, Series Loss: 0.0066, Class Loss: 0.2443, Accuracy: 0.2840\n",
      "Epoch [1845/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1780, Series Loss: 0.0066, Class Loss: 0.2445, Accuracy: 0.3148\n",
      "Epoch [1846/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1779, Series Loss: 0.0067, Class Loss: 0.2444, Accuracy: 0.2901\n",
      "Epoch [1847/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1775, Series Loss: 0.0066, Class Loss: 0.2444, Accuracy: 0.3086\n",
      "Epoch [1848/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1781, Series Loss: 0.0068, Class Loss: 0.2443, Accuracy: 0.3086\n",
      "Epoch [1849/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1783, Series Loss: 0.0066, Class Loss: 0.2444, Accuracy: 0.2840\n",
      "Epoch [1850/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1782, Series Loss: 0.0066, Class Loss: 0.2445, Accuracy: 0.2901\n",
      "Epoch [1851/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1779, Series Loss: 0.0067, Class Loss: 0.2444, Accuracy: 0.2840\n",
      "Epoch [1852/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1782, Series Loss: 0.0067, Class Loss: 0.2444, Accuracy: 0.3025\n",
      "Epoch [1853/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1779, Series Loss: 0.0067, Class Loss: 0.2444, Accuracy: 0.2963\n",
      "Epoch [1854/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1777, Series Loss: 0.0067, Class Loss: 0.2444, Accuracy: 0.3272\n",
      "Epoch [1855/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1779, Series Loss: 0.0068, Class Loss: 0.2445, Accuracy: 0.3210\n",
      "Epoch [1856/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1784, Series Loss: 0.0066, Class Loss: 0.2445, Accuracy: 0.3148\n",
      "Epoch [1857/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1787, Series Loss: 0.0067, Class Loss: 0.2445, Accuracy: 0.3025\n",
      "Epoch [1858/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1784, Series Loss: 0.0068, Class Loss: 0.2445, Accuracy: 0.2963\n",
      "Epoch [1859/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1780, Series Loss: 0.0066, Class Loss: 0.2444, Accuracy: 0.2963\n",
      "Epoch [1860/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1782, Series Loss: 0.0067, Class Loss: 0.2444, Accuracy: 0.2963\n",
      "Epoch [1861/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1783, Series Loss: 0.0066, Class Loss: 0.2445, Accuracy: 0.2716\n",
      "Epoch [1862/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1776, Series Loss: 0.0066, Class Loss: 0.2444, Accuracy: 0.3025\n",
      "Epoch [1863/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1779, Series Loss: 0.0066, Class Loss: 0.2444, Accuracy: 0.2840\n",
      "Epoch [1864/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1777, Series Loss: 0.0067, Class Loss: 0.2444, Accuracy: 0.2963\n",
      "Epoch [1865/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1780, Series Loss: 0.0066, Class Loss: 0.2444, Accuracy: 0.3025\n",
      "Epoch [1866/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1777, Series Loss: 0.0067, Class Loss: 0.2444, Accuracy: 0.3025\n",
      "Epoch [1867/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1781, Series Loss: 0.0066, Class Loss: 0.2444, Accuracy: 0.3086\n",
      "Epoch [1868/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1780, Series Loss: 0.0066, Class Loss: 0.2443, Accuracy: 0.2963\n",
      "Epoch [1869/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1779, Series Loss: 0.0066, Class Loss: 0.2445, Accuracy: 0.3148\n",
      "Epoch [1870/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1779, Series Loss: 0.0066, Class Loss: 0.2444, Accuracy: 0.2901\n",
      "Epoch [1871/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1781, Series Loss: 0.0066, Class Loss: 0.2445, Accuracy: 0.2716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1872/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1780, Series Loss: 0.0066, Class Loss: 0.2444, Accuracy: 0.2963\n",
      "Epoch [1873/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1778, Series Loss: 0.0067, Class Loss: 0.2445, Accuracy: 0.3025\n",
      "Epoch [1874/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1777, Series Loss: 0.0066, Class Loss: 0.2445, Accuracy: 0.3148\n",
      "Epoch [1875/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1782, Series Loss: 0.0067, Class Loss: 0.2445, Accuracy: 0.2840\n",
      "Epoch [1876/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1780, Series Loss: 0.0066, Class Loss: 0.2444, Accuracy: 0.2778\n",
      "Epoch [1877/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1784, Series Loss: 0.0066, Class Loss: 0.2444, Accuracy: 0.2901\n",
      "Epoch [1878/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1777, Series Loss: 0.0066, Class Loss: 0.2444, Accuracy: 0.2840\n",
      "Epoch [1879/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1781, Series Loss: 0.0066, Class Loss: 0.2445, Accuracy: 0.2901\n",
      "Epoch [1880/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1775, Series Loss: 0.0065, Class Loss: 0.2444, Accuracy: 0.3086\n",
      "Epoch [1881/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1777, Series Loss: 0.0065, Class Loss: 0.2445, Accuracy: 0.3025\n",
      "Epoch [1882/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1780, Series Loss: 0.0066, Class Loss: 0.2443, Accuracy: 0.2901\n",
      "Epoch [1883/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1785, Series Loss: 0.0066, Class Loss: 0.2443, Accuracy: 0.2963\n",
      "Epoch [1884/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1779, Series Loss: 0.0066, Class Loss: 0.2444, Accuracy: 0.3086\n",
      "Epoch [1885/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1779, Series Loss: 0.0066, Class Loss: 0.2443, Accuracy: 0.2963\n",
      "Epoch [1886/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1778, Series Loss: 0.0066, Class Loss: 0.2443, Accuracy: 0.2901\n",
      "Epoch [1887/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1778, Series Loss: 0.0067, Class Loss: 0.2444, Accuracy: 0.2716\n",
      "Epoch [1888/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1776, Series Loss: 0.0065, Class Loss: 0.2444, Accuracy: 0.2963\n",
      "Epoch [1889/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1778, Series Loss: 0.0067, Class Loss: 0.2445, Accuracy: 0.2840\n",
      "Epoch [1890/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1774, Series Loss: 0.0065, Class Loss: 0.2443, Accuracy: 0.2963\n",
      "Epoch [1891/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1785, Series Loss: 0.0066, Class Loss: 0.2444, Accuracy: 0.3210\n",
      "Epoch [1892/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1778, Series Loss: 0.0065, Class Loss: 0.2445, Accuracy: 0.2901\n",
      "Epoch [1893/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1782, Series Loss: 0.0067, Class Loss: 0.2443, Accuracy: 0.3086\n",
      "Epoch [1894/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1777, Series Loss: 0.0066, Class Loss: 0.2445, Accuracy: 0.2901\n",
      "Epoch [1895/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1781, Series Loss: 0.0065, Class Loss: 0.2444, Accuracy: 0.2901\n",
      "Epoch [1896/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1772, Series Loss: 0.0065, Class Loss: 0.2443, Accuracy: 0.2963\n",
      "Epoch [1897/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1776, Series Loss: 0.0065, Class Loss: 0.2443, Accuracy: 0.2840\n",
      "Epoch [1898/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1773, Series Loss: 0.0065, Class Loss: 0.2443, Accuracy: 0.2716\n",
      "Epoch [1899/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1779, Series Loss: 0.0065, Class Loss: 0.2444, Accuracy: 0.2963\n",
      "Epoch [1900/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1783, Series Loss: 0.0066, Class Loss: 0.2444, Accuracy: 0.2963\n",
      "Epoch [1901/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1778, Series Loss: 0.0065, Class Loss: 0.2446, Accuracy: 0.2963\n",
      "Epoch [1902/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1781, Series Loss: 0.0065, Class Loss: 0.2445, Accuracy: 0.2840\n",
      "Epoch [1903/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1779, Series Loss: 0.0065, Class Loss: 0.2444, Accuracy: 0.3025\n",
      "Epoch [1904/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1777, Series Loss: 0.0065, Class Loss: 0.2445, Accuracy: 0.2901\n",
      "Epoch [1905/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1779, Series Loss: 0.0065, Class Loss: 0.2444, Accuracy: 0.2716\n",
      "Epoch [1906/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1777, Series Loss: 0.0065, Class Loss: 0.2444, Accuracy: 0.2901\n",
      "Epoch [1907/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1778, Series Loss: 0.0065, Class Loss: 0.2444, Accuracy: 0.2963\n",
      "Epoch [1908/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1778, Series Loss: 0.0065, Class Loss: 0.2444, Accuracy: 0.3025\n",
      "Epoch [1909/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1776, Series Loss: 0.0065, Class Loss: 0.2443, Accuracy: 0.2963\n",
      "Epoch [1910/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1777, Series Loss: 0.0065, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [1911/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1778, Series Loss: 0.0065, Class Loss: 0.2443, Accuracy: 0.2963\n",
      "Epoch [1912/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1773, Series Loss: 0.0065, Class Loss: 0.2444, Accuracy: 0.2840\n",
      "Epoch [1913/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1778, Series Loss: 0.0065, Class Loss: 0.2443, Accuracy: 0.2778\n",
      "Epoch [1914/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1776, Series Loss: 0.0065, Class Loss: 0.2444, Accuracy: 0.2963\n",
      "Epoch [1915/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1777, Series Loss: 0.0065, Class Loss: 0.2444, Accuracy: 0.2778\n",
      "Epoch [1916/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1780, Series Loss: 0.0064, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [1917/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1779, Series Loss: 0.0065, Class Loss: 0.2443, Accuracy: 0.2901\n",
      "Epoch [1918/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1778, Series Loss: 0.0064, Class Loss: 0.2444, Accuracy: 0.3025\n",
      "Epoch [1919/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1779, Series Loss: 0.0064, Class Loss: 0.2443, Accuracy: 0.3086\n",
      "Epoch [1920/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1780, Series Loss: 0.0064, Class Loss: 0.2444, Accuracy: 0.2840\n",
      "Epoch [1921/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1779, Series Loss: 0.0065, Class Loss: 0.2442, Accuracy: 0.2963\n",
      "Epoch [1922/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1778, Series Loss: 0.0065, Class Loss: 0.2444, Accuracy: 0.2840\n",
      "Epoch [1923/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1779, Series Loss: 0.0065, Class Loss: 0.2444, Accuracy: 0.3086\n",
      "Epoch [1924/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1780, Series Loss: 0.0066, Class Loss: 0.2444, Accuracy: 0.2963\n",
      "Epoch [1925/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1778, Series Loss: 0.0064, Class Loss: 0.2445, Accuracy: 0.2963\n",
      "Epoch [1926/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1774, Series Loss: 0.0065, Class Loss: 0.2443, Accuracy: 0.3086\n",
      "Epoch [1927/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1775, Series Loss: 0.0064, Class Loss: 0.2443, Accuracy: 0.2840\n",
      "Epoch [1928/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1774, Series Loss: 0.0065, Class Loss: 0.2444, Accuracy: 0.2901\n",
      "Epoch [1929/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1777, Series Loss: 0.0065, Class Loss: 0.2444, Accuracy: 0.3148\n",
      "Epoch [1930/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1778, Series Loss: 0.0065, Class Loss: 0.2444, Accuracy: 0.2840\n",
      "Epoch [1931/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1778, Series Loss: 0.0064, Class Loss: 0.2445, Accuracy: 0.2963\n",
      "Epoch [1932/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1778, Series Loss: 0.0063, Class Loss: 0.2443, Accuracy: 0.3086\n",
      "Epoch [1933/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1775, Series Loss: 0.0065, Class Loss: 0.2443, Accuracy: 0.2840\n",
      "Epoch [1934/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1779, Series Loss: 0.0064, Class Loss: 0.2443, Accuracy: 0.3086\n",
      "Epoch [1935/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1774, Series Loss: 0.0064, Class Loss: 0.2443, Accuracy: 0.2716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1936/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1776, Series Loss: 0.0064, Class Loss: 0.2444, Accuracy: 0.2778\n",
      "Epoch [1937/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1776, Series Loss: 0.0063, Class Loss: 0.2443, Accuracy: 0.2963\n",
      "Epoch [1938/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1775, Series Loss: 0.0064, Class Loss: 0.2443, Accuracy: 0.2901\n",
      "Epoch [1939/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1779, Series Loss: 0.0064, Class Loss: 0.2444, Accuracy: 0.2901\n",
      "Epoch [1940/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1778, Series Loss: 0.0064, Class Loss: 0.2445, Accuracy: 0.3086\n",
      "Epoch [1941/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1776, Series Loss: 0.0064, Class Loss: 0.2443, Accuracy: 0.2963\n",
      "Epoch [1942/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1780, Series Loss: 0.0065, Class Loss: 0.2443, Accuracy: 0.2963\n",
      "Epoch [1943/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1779, Series Loss: 0.0065, Class Loss: 0.2443, Accuracy: 0.2963\n",
      "Epoch [1944/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1775, Series Loss: 0.0063, Class Loss: 0.2443, Accuracy: 0.2840\n",
      "Epoch [1945/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1774, Series Loss: 0.0064, Class Loss: 0.2443, Accuracy: 0.3148\n",
      "Epoch [1946/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1775, Series Loss: 0.0064, Class Loss: 0.2443, Accuracy: 0.3086\n",
      "Epoch [1947/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1779, Series Loss: 0.0063, Class Loss: 0.2443, Accuracy: 0.3086\n",
      "Epoch [1948/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1774, Series Loss: 0.0064, Class Loss: 0.2444, Accuracy: 0.2778\n",
      "Epoch [1949/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1776, Series Loss: 0.0064, Class Loss: 0.2444, Accuracy: 0.3086\n",
      "Epoch [1950/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1775, Series Loss: 0.0063, Class Loss: 0.2442, Accuracy: 0.2901\n",
      "Epoch [1951/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1776, Series Loss: 0.0063, Class Loss: 0.2444, Accuracy: 0.2901\n",
      "Epoch [1952/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1777, Series Loss: 0.0064, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [1953/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1784, Series Loss: 0.0063, Class Loss: 0.2443, Accuracy: 0.2840\n",
      "Epoch [1954/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1775, Series Loss: 0.0064, Class Loss: 0.2444, Accuracy: 0.2901\n",
      "Epoch [1955/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1776, Series Loss: 0.0063, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [1956/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1778, Series Loss: 0.0063, Class Loss: 0.2442, Accuracy: 0.2963\n",
      "Epoch [1957/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1775, Series Loss: 0.0064, Class Loss: 0.2443, Accuracy: 0.3148\n",
      "Epoch [1958/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1776, Series Loss: 0.0064, Class Loss: 0.2444, Accuracy: 0.2840\n",
      "Epoch [1959/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1777, Series Loss: 0.0063, Class Loss: 0.2444, Accuracy: 0.2840\n",
      "Epoch [1960/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1775, Series Loss: 0.0063, Class Loss: 0.2443, Accuracy: 0.2840\n",
      "Epoch [1961/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1774, Series Loss: 0.0062, Class Loss: 0.2445, Accuracy: 0.3210\n",
      "Epoch [1962/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1773, Series Loss: 0.0064, Class Loss: 0.2444, Accuracy: 0.3333\n",
      "Epoch [1963/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1779, Series Loss: 0.0062, Class Loss: 0.2443, Accuracy: 0.3025\n",
      "Epoch [1964/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1777, Series Loss: 0.0063, Class Loss: 0.2445, Accuracy: 0.2840\n",
      "Epoch [1965/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1779, Series Loss: 0.0064, Class Loss: 0.2444, Accuracy: 0.3025\n",
      "Epoch [1966/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1779, Series Loss: 0.0063, Class Loss: 0.2445, Accuracy: 0.2778\n",
      "Epoch [1967/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1777, Series Loss: 0.0064, Class Loss: 0.2444, Accuracy: 0.3025\n",
      "Epoch [1968/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1777, Series Loss: 0.0063, Class Loss: 0.2444, Accuracy: 0.2963\n",
      "Epoch [1969/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1778, Series Loss: 0.0064, Class Loss: 0.2443, Accuracy: 0.3086\n",
      "Epoch [1970/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1776, Series Loss: 0.0064, Class Loss: 0.2443, Accuracy: 0.2778\n",
      "Epoch [1971/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1775, Series Loss: 0.0063, Class Loss: 0.2444, Accuracy: 0.3025\n",
      "Epoch [1972/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1776, Series Loss: 0.0062, Class Loss: 0.2445, Accuracy: 0.2778\n",
      "Epoch [1973/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1777, Series Loss: 0.0063, Class Loss: 0.2444, Accuracy: 0.2963\n",
      "Epoch [1974/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1777, Series Loss: 0.0062, Class Loss: 0.2443, Accuracy: 0.2901\n",
      "Epoch [1975/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1775, Series Loss: 0.0062, Class Loss: 0.2445, Accuracy: 0.2778\n",
      "Epoch [1976/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1780, Series Loss: 0.0063, Class Loss: 0.2445, Accuracy: 0.2840\n",
      "Epoch [1977/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1782, Series Loss: 0.0062, Class Loss: 0.2445, Accuracy: 0.2716\n",
      "Epoch [1978/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1777, Series Loss: 0.0063, Class Loss: 0.2443, Accuracy: 0.3148\n",
      "Epoch [1979/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1779, Series Loss: 0.0063, Class Loss: 0.2443, Accuracy: 0.2840\n",
      "Epoch [1980/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1778, Series Loss: 0.0062, Class Loss: 0.2444, Accuracy: 0.2778\n",
      "Epoch [1981/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1777, Series Loss: 0.0062, Class Loss: 0.2445, Accuracy: 0.2840\n",
      "Epoch [1982/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1779, Series Loss: 0.0062, Class Loss: 0.2445, Accuracy: 0.2840\n",
      "Epoch [1983/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1780, Series Loss: 0.0063, Class Loss: 0.2444, Accuracy: 0.3025\n",
      "Epoch [1984/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1781, Series Loss: 0.0062, Class Loss: 0.2445, Accuracy: 0.3086\n",
      "Epoch [1985/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1780, Series Loss: 0.0061, Class Loss: 0.2443, Accuracy: 0.2778\n",
      "Epoch [1986/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1781, Series Loss: 0.0063, Class Loss: 0.2445, Accuracy: 0.2407\n",
      "Epoch [1987/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1784, Series Loss: 0.0062, Class Loss: 0.2445, Accuracy: 0.2840\n",
      "Epoch [1988/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1775, Series Loss: 0.0063, Class Loss: 0.2444, Accuracy: 0.2778\n",
      "Epoch [1989/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1776, Series Loss: 0.0063, Class Loss: 0.2444, Accuracy: 0.2963\n",
      "Epoch [1990/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1774, Series Loss: 0.0063, Class Loss: 0.2444, Accuracy: 0.2778\n",
      "Epoch [1991/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1778, Series Loss: 0.0063, Class Loss: 0.2443, Accuracy: 0.2963\n",
      "Epoch [1992/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1781, Series Loss: 0.0063, Class Loss: 0.2444, Accuracy: 0.2963\n",
      "Epoch [1993/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1775, Series Loss: 0.0063, Class Loss: 0.2445, Accuracy: 0.2901\n",
      "Epoch [1994/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1776, Series Loss: 0.0063, Class Loss: 0.2443, Accuracy: 0.2778\n",
      "Epoch [1995/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1779, Series Loss: 0.0063, Class Loss: 0.2443, Accuracy: 0.2840\n",
      "Epoch [1996/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1780, Series Loss: 0.0062, Class Loss: 0.2443, Accuracy: 0.2901\n",
      "Epoch [1997/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1776, Series Loss: 0.0062, Class Loss: 0.2445, Accuracy: 0.2716\n",
      "Epoch [1998/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1783, Series Loss: 0.0062, Class Loss: 0.2443, Accuracy: 0.2840\n",
      "Epoch [1999/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1772, Series Loss: 0.0062, Class Loss: 0.2444, Accuracy: 0.2840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2000/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1774, Series Loss: 0.0062, Class Loss: 0.2443, Accuracy: 0.3086\n",
      "Epoch [2001/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1779, Series Loss: 0.0063, Class Loss: 0.2443, Accuracy: 0.2901\n",
      "Epoch [2002/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1775, Series Loss: 0.0063, Class Loss: 0.2443, Accuracy: 0.2778\n",
      "Epoch [2003/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1778, Series Loss: 0.0062, Class Loss: 0.2444, Accuracy: 0.2963\n",
      "Epoch [2004/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1784, Series Loss: 0.0062, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [2005/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1777, Series Loss: 0.0062, Class Loss: 0.2444, Accuracy: 0.2963\n",
      "Epoch [2006/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1784, Series Loss: 0.0062, Class Loss: 0.2445, Accuracy: 0.2840\n",
      "Epoch [2007/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1778, Series Loss: 0.0062, Class Loss: 0.2443, Accuracy: 0.2716\n",
      "Epoch [2008/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1780, Series Loss: 0.0062, Class Loss: 0.2444, Accuracy: 0.2778\n",
      "Epoch [2009/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1779, Series Loss: 0.0062, Class Loss: 0.2444, Accuracy: 0.2716\n",
      "Epoch [2010/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1775, Series Loss: 0.0062, Class Loss: 0.2444, Accuracy: 0.2716\n",
      "Epoch [2011/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1773, Series Loss: 0.0062, Class Loss: 0.2443, Accuracy: 0.2901\n",
      "Epoch [2012/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1777, Series Loss: 0.0062, Class Loss: 0.2445, Accuracy: 0.2840\n",
      "Epoch [2013/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1773, Series Loss: 0.0062, Class Loss: 0.2443, Accuracy: 0.2716\n",
      "Epoch [2014/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1778, Series Loss: 0.0063, Class Loss: 0.2444, Accuracy: 0.2778\n",
      "Epoch [2015/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1779, Series Loss: 0.0062, Class Loss: 0.2444, Accuracy: 0.2716\n",
      "Epoch [2016/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1781, Series Loss: 0.0063, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2017/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1777, Series Loss: 0.0062, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [2018/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1779, Series Loss: 0.0063, Class Loss: 0.2443, Accuracy: 0.3025\n",
      "Epoch [2019/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1773, Series Loss: 0.0062, Class Loss: 0.2444, Accuracy: 0.2778\n",
      "Epoch [2020/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1779, Series Loss: 0.0063, Class Loss: 0.2443, Accuracy: 0.2901\n",
      "Epoch [2021/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1782, Series Loss: 0.0063, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2022/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1777, Series Loss: 0.0063, Class Loss: 0.2444, Accuracy: 0.2840\n",
      "Epoch [2023/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1780, Series Loss: 0.0062, Class Loss: 0.2443, Accuracy: 0.2963\n",
      "Epoch [2024/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1776, Series Loss: 0.0061, Class Loss: 0.2443, Accuracy: 0.2716\n",
      "Epoch [2025/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1776, Series Loss: 0.0061, Class Loss: 0.2444, Accuracy: 0.2716\n",
      "Epoch [2026/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1777, Series Loss: 0.0062, Class Loss: 0.2445, Accuracy: 0.2778\n",
      "Epoch [2027/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1782, Series Loss: 0.0062, Class Loss: 0.2443, Accuracy: 0.2716\n",
      "Epoch [2028/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1777, Series Loss: 0.0062, Class Loss: 0.2443, Accuracy: 0.2716\n",
      "Epoch [2029/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1777, Series Loss: 0.0062, Class Loss: 0.2444, Accuracy: 0.2963\n",
      "Epoch [2030/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1778, Series Loss: 0.0062, Class Loss: 0.2443, Accuracy: 0.2778\n",
      "Epoch [2031/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1774, Series Loss: 0.0061, Class Loss: 0.2443, Accuracy: 0.3086\n",
      "Epoch [2032/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1783, Series Loss: 0.0062, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2033/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1777, Series Loss: 0.0062, Class Loss: 0.2443, Accuracy: 0.3025\n",
      "Epoch [2034/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1776, Series Loss: 0.0063, Class Loss: 0.2444, Accuracy: 0.2778\n",
      "Epoch [2035/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1771, Series Loss: 0.0061, Class Loss: 0.2444, Accuracy: 0.3086\n",
      "Epoch [2036/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1768, Series Loss: 0.0061, Class Loss: 0.2444, Accuracy: 0.2963\n",
      "Epoch [2037/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1770, Series Loss: 0.0062, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2038/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1770, Series Loss: 0.0061, Class Loss: 0.2444, Accuracy: 0.2778\n",
      "Epoch [2039/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1769, Series Loss: 0.0061, Class Loss: 0.2443, Accuracy: 0.2901\n",
      "Epoch [2040/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1775, Series Loss: 0.0061, Class Loss: 0.2444, Accuracy: 0.2716\n",
      "Epoch [2041/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1771, Series Loss: 0.0061, Class Loss: 0.2443, Accuracy: 0.2716\n",
      "Epoch [2042/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1781, Series Loss: 0.0061, Class Loss: 0.2445, Accuracy: 0.3272\n",
      "Epoch [2043/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1775, Series Loss: 0.0062, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2044/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1772, Series Loss: 0.0062, Class Loss: 0.2443, Accuracy: 0.2469\n",
      "Epoch [2045/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1770, Series Loss: 0.0061, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2046/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1771, Series Loss: 0.0061, Class Loss: 0.2443, Accuracy: 0.2840\n",
      "Epoch [2047/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1773, Series Loss: 0.0061, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2048/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1776, Series Loss: 0.0061, Class Loss: 0.2444, Accuracy: 0.2901\n",
      "Epoch [2049/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1773, Series Loss: 0.0060, Class Loss: 0.2444, Accuracy: 0.2840\n",
      "Epoch [2050/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1774, Series Loss: 0.0061, Class Loss: 0.2444, Accuracy: 0.2901\n",
      "Epoch [2051/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1779, Series Loss: 0.0061, Class Loss: 0.2445, Accuracy: 0.3210\n",
      "Epoch [2052/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1775, Series Loss: 0.0061, Class Loss: 0.2443, Accuracy: 0.2901\n",
      "Epoch [2053/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1775, Series Loss: 0.0062, Class Loss: 0.2443, Accuracy: 0.2963\n",
      "Epoch [2054/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1778, Series Loss: 0.0062, Class Loss: 0.2445, Accuracy: 0.3086\n",
      "Epoch [2055/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1777, Series Loss: 0.0061, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2056/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1779, Series Loss: 0.0062, Class Loss: 0.2444, Accuracy: 0.2963\n",
      "Epoch [2057/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1777, Series Loss: 0.0062, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [2058/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1779, Series Loss: 0.0061, Class Loss: 0.2445, Accuracy: 0.2840\n",
      "Epoch [2059/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1777, Series Loss: 0.0062, Class Loss: 0.2444, Accuracy: 0.3025\n",
      "Epoch [2060/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1777, Series Loss: 0.0062, Class Loss: 0.2443, Accuracy: 0.3025\n",
      "Epoch [2061/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1782, Series Loss: 0.0062, Class Loss: 0.2444, Accuracy: 0.3148\n",
      "Epoch [2062/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1778, Series Loss: 0.0061, Class Loss: 0.2445, Accuracy: 0.2901\n",
      "Epoch [2063/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1775, Series Loss: 0.0061, Class Loss: 0.2445, Accuracy: 0.3025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2064/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1778, Series Loss: 0.0061, Class Loss: 0.2444, Accuracy: 0.3086\n",
      "Epoch [2065/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1774, Series Loss: 0.0061, Class Loss: 0.2444, Accuracy: 0.2407\n",
      "Epoch [2066/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1778, Series Loss: 0.0061, Class Loss: 0.2444, Accuracy: 0.2963\n",
      "Epoch [2067/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1778, Series Loss: 0.0061, Class Loss: 0.2445, Accuracy: 0.2840\n",
      "Epoch [2068/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1776, Series Loss: 0.0061, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2069/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1778, Series Loss: 0.0062, Class Loss: 0.2444, Accuracy: 0.2778\n",
      "Epoch [2070/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1776, Series Loss: 0.0061, Class Loss: 0.2443, Accuracy: 0.2469\n",
      "Epoch [2071/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1774, Series Loss: 0.0061, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2072/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1776, Series Loss: 0.0061, Class Loss: 0.2443, Accuracy: 0.2840\n",
      "Epoch [2073/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1775, Series Loss: 0.0061, Class Loss: 0.2445, Accuracy: 0.2840\n",
      "Epoch [2074/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1775, Series Loss: 0.0061, Class Loss: 0.2443, Accuracy: 0.2963\n",
      "Epoch [2075/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1774, Series Loss: 0.0061, Class Loss: 0.2443, Accuracy: 0.2963\n",
      "Epoch [2076/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1775, Series Loss: 0.0061, Class Loss: 0.2444, Accuracy: 0.2840\n",
      "Epoch [2077/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1777, Series Loss: 0.0062, Class Loss: 0.2444, Accuracy: 0.2778\n",
      "Epoch [2078/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1772, Series Loss: 0.0061, Class Loss: 0.2443, Accuracy: 0.2840\n",
      "Epoch [2079/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1773, Series Loss: 0.0060, Class Loss: 0.2443, Accuracy: 0.2840\n",
      "Epoch [2080/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1776, Series Loss: 0.0062, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2081/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1777, Series Loss: 0.0061, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2082/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1774, Series Loss: 0.0062, Class Loss: 0.2444, Accuracy: 0.2840\n",
      "Epoch [2083/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1774, Series Loss: 0.0061, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [2084/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1769, Series Loss: 0.0060, Class Loss: 0.2444, Accuracy: 0.2840\n",
      "Epoch [2085/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1770, Series Loss: 0.0062, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2086/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1778, Series Loss: 0.0061, Class Loss: 0.2444, Accuracy: 0.3025\n",
      "Epoch [2087/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1778, Series Loss: 0.0061, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2088/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1778, Series Loss: 0.0061, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2089/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1778, Series Loss: 0.0060, Class Loss: 0.2444, Accuracy: 0.2840\n",
      "Epoch [2090/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1777, Series Loss: 0.0061, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2091/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1774, Series Loss: 0.0060, Class Loss: 0.2443, Accuracy: 0.2840\n",
      "Epoch [2092/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1774, Series Loss: 0.0061, Class Loss: 0.2443, Accuracy: 0.2840\n",
      "Epoch [2093/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1775, Series Loss: 0.0061, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2094/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1772, Series Loss: 0.0060, Class Loss: 0.2443, Accuracy: 0.2716\n",
      "Epoch [2095/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1780, Series Loss: 0.0061, Class Loss: 0.2444, Accuracy: 0.2716\n",
      "Epoch [2096/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1774, Series Loss: 0.0061, Class Loss: 0.2443, Accuracy: 0.2840\n",
      "Epoch [2097/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1779, Series Loss: 0.0061, Class Loss: 0.2444, Accuracy: 0.2840\n",
      "Epoch [2098/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1779, Series Loss: 0.0061, Class Loss: 0.2442, Accuracy: 0.2901\n",
      "Epoch [2099/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1775, Series Loss: 0.0061, Class Loss: 0.2444, Accuracy: 0.2716\n",
      "Epoch [2100/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1778, Series Loss: 0.0061, Class Loss: 0.2443, Accuracy: 0.2346\n",
      "Epoch [2101/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1773, Series Loss: 0.0061, Class Loss: 0.2443, Accuracy: 0.2840\n",
      "Epoch [2102/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1777, Series Loss: 0.0061, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2103/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1773, Series Loss: 0.0061, Class Loss: 0.2442, Accuracy: 0.2840\n",
      "Epoch [2104/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1776, Series Loss: 0.0061, Class Loss: 0.2444, Accuracy: 0.2901\n",
      "Epoch [2105/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1774, Series Loss: 0.0061, Class Loss: 0.2443, Accuracy: 0.3025\n",
      "Epoch [2106/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1777, Series Loss: 0.0061, Class Loss: 0.2443, Accuracy: 0.2963\n",
      "Epoch [2107/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1777, Series Loss: 0.0061, Class Loss: 0.2443, Accuracy: 0.2716\n",
      "Epoch [2108/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1775, Series Loss: 0.0061, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2109/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1778, Series Loss: 0.0060, Class Loss: 0.2444, Accuracy: 0.3025\n",
      "Epoch [2110/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1779, Series Loss: 0.0060, Class Loss: 0.2446, Accuracy: 0.2778\n",
      "Epoch [2111/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1777, Series Loss: 0.0060, Class Loss: 0.2443, Accuracy: 0.3025\n",
      "Epoch [2112/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1771, Series Loss: 0.0060, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [2113/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1775, Series Loss: 0.0060, Class Loss: 0.2443, Accuracy: 0.3086\n",
      "Epoch [2114/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1774, Series Loss: 0.0060, Class Loss: 0.2444, Accuracy: 0.2901\n",
      "Epoch [2115/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1776, Series Loss: 0.0060, Class Loss: 0.2443, Accuracy: 0.2716\n",
      "Epoch [2116/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1771, Series Loss: 0.0060, Class Loss: 0.2444, Accuracy: 0.3025\n",
      "Epoch [2117/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1774, Series Loss: 0.0059, Class Loss: 0.2443, Accuracy: 0.2840\n",
      "Epoch [2118/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1774, Series Loss: 0.0060, Class Loss: 0.2444, Accuracy: 0.2963\n",
      "Epoch [2119/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1775, Series Loss: 0.0061, Class Loss: 0.2442, Accuracy: 0.2716\n",
      "Epoch [2120/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1777, Series Loss: 0.0061, Class Loss: 0.2443, Accuracy: 0.2963\n",
      "Epoch [2121/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1775, Series Loss: 0.0060, Class Loss: 0.2443, Accuracy: 0.2716\n",
      "Epoch [2122/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1779, Series Loss: 0.0061, Class Loss: 0.2444, Accuracy: 0.3025\n",
      "Epoch [2123/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1776, Series Loss: 0.0060, Class Loss: 0.2443, Accuracy: 0.3086\n",
      "Epoch [2124/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1778, Series Loss: 0.0060, Class Loss: 0.2443, Accuracy: 0.2778\n",
      "Epoch [2125/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1779, Series Loss: 0.0060, Class Loss: 0.2444, Accuracy: 0.2963\n",
      "Epoch [2126/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1776, Series Loss: 0.0062, Class Loss: 0.2443, Accuracy: 0.2778\n",
      "Epoch [2127/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1773, Series Loss: 0.0060, Class Loss: 0.2443, Accuracy: 0.2654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2128/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1779, Series Loss: 0.0060, Class Loss: 0.2444, Accuracy: 0.2840\n",
      "Epoch [2129/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1777, Series Loss: 0.0061, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2130/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1779, Series Loss: 0.0061, Class Loss: 0.2444, Accuracy: 0.2901\n",
      "Epoch [2131/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1773, Series Loss: 0.0060, Class Loss: 0.2443, Accuracy: 0.2840\n",
      "Epoch [2132/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1774, Series Loss: 0.0059, Class Loss: 0.2444, Accuracy: 0.2840\n",
      "Epoch [2133/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1775, Series Loss: 0.0061, Class Loss: 0.2444, Accuracy: 0.2716\n",
      "Epoch [2134/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1773, Series Loss: 0.0060, Class Loss: 0.2444, Accuracy: 0.2840\n",
      "Epoch [2135/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1778, Series Loss: 0.0060, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [2136/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1775, Series Loss: 0.0059, Class Loss: 0.2443, Accuracy: 0.3272\n",
      "Epoch [2137/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1776, Series Loss: 0.0060, Class Loss: 0.2443, Accuracy: 0.2716\n",
      "Epoch [2138/4000], Discriminator Loss: 0.0911, Generator Loss: 0.1780, Series Loss: 0.0060, Class Loss: 0.2445, Accuracy: 0.2716\n",
      "Epoch [2139/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1776, Series Loss: 0.0060, Class Loss: 0.2444, Accuracy: 0.2840\n",
      "Epoch [2140/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1781, Series Loss: 0.0061, Class Loss: 0.2443, Accuracy: 0.3086\n",
      "Epoch [2141/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1774, Series Loss: 0.0060, Class Loss: 0.2445, Accuracy: 0.2346\n",
      "Epoch [2142/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1775, Series Loss: 0.0059, Class Loss: 0.2443, Accuracy: 0.2963\n",
      "Epoch [2143/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1774, Series Loss: 0.0060, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2144/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1778, Series Loss: 0.0059, Class Loss: 0.2443, Accuracy: 0.3148\n",
      "Epoch [2145/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1777, Series Loss: 0.0059, Class Loss: 0.2443, Accuracy: 0.2901\n",
      "Epoch [2146/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1776, Series Loss: 0.0059, Class Loss: 0.2444, Accuracy: 0.2840\n",
      "Epoch [2147/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1777, Series Loss: 0.0060, Class Loss: 0.2445, Accuracy: 0.3086\n",
      "Epoch [2148/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1779, Series Loss: 0.0060, Class Loss: 0.2443, Accuracy: 0.2716\n",
      "Epoch [2149/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1777, Series Loss: 0.0061, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2150/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1779, Series Loss: 0.0061, Class Loss: 0.2444, Accuracy: 0.2901\n",
      "Epoch [2151/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1775, Series Loss: 0.0059, Class Loss: 0.2443, Accuracy: 0.2840\n",
      "Epoch [2152/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1773, Series Loss: 0.0060, Class Loss: 0.2444, Accuracy: 0.2778\n",
      "Epoch [2153/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1775, Series Loss: 0.0060, Class Loss: 0.2444, Accuracy: 0.2716\n",
      "Epoch [2154/4000], Discriminator Loss: 0.0909, Generator Loss: 0.1774, Series Loss: 0.0060, Class Loss: 0.2444, Accuracy: 0.3025\n",
      "Epoch [2155/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1772, Series Loss: 0.0060, Class Loss: 0.2443, Accuracy: 0.2778\n",
      "Epoch [2156/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1773, Series Loss: 0.0059, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2157/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1776, Series Loss: 0.0060, Class Loss: 0.2445, Accuracy: 0.2840\n",
      "Epoch [2158/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1774, Series Loss: 0.0061, Class Loss: 0.2444, Accuracy: 0.2963\n",
      "Epoch [2159/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1776, Series Loss: 0.0059, Class Loss: 0.2445, Accuracy: 0.2901\n",
      "Epoch [2160/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1773, Series Loss: 0.0060, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2161/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1773, Series Loss: 0.0060, Class Loss: 0.2442, Accuracy: 0.2840\n",
      "Epoch [2162/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1777, Series Loss: 0.0060, Class Loss: 0.2444, Accuracy: 0.3086\n",
      "Epoch [2163/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1773, Series Loss: 0.0060, Class Loss: 0.2444, Accuracy: 0.2963\n",
      "Epoch [2164/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1772, Series Loss: 0.0059, Class Loss: 0.2443, Accuracy: 0.2778\n",
      "Epoch [2165/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1775, Series Loss: 0.0059, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2166/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1777, Series Loss: 0.0060, Class Loss: 0.2444, Accuracy: 0.2778\n",
      "Epoch [2167/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1773, Series Loss: 0.0059, Class Loss: 0.2443, Accuracy: 0.2469\n",
      "Epoch [2168/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1774, Series Loss: 0.0060, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2169/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1770, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2901\n",
      "Epoch [2170/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1777, Series Loss: 0.0060, Class Loss: 0.2444, Accuracy: 0.2716\n",
      "Epoch [2171/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1777, Series Loss: 0.0059, Class Loss: 0.2445, Accuracy: 0.2716\n",
      "Epoch [2172/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1777, Series Loss: 0.0059, Class Loss: 0.2444, Accuracy: 0.2963\n",
      "Epoch [2173/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1776, Series Loss: 0.0059, Class Loss: 0.2445, Accuracy: 0.2716\n",
      "Epoch [2174/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1773, Series Loss: 0.0060, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2175/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1772, Series Loss: 0.0060, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2176/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1773, Series Loss: 0.0059, Class Loss: 0.2443, Accuracy: 0.2901\n",
      "Epoch [2177/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1776, Series Loss: 0.0060, Class Loss: 0.2444, Accuracy: 0.2778\n",
      "Epoch [2178/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1776, Series Loss: 0.0059, Class Loss: 0.2444, Accuracy: 0.2840\n",
      "Epoch [2179/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1773, Series Loss: 0.0059, Class Loss: 0.2444, Accuracy: 0.2716\n",
      "Epoch [2180/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1780, Series Loss: 0.0059, Class Loss: 0.2444, Accuracy: 0.2778\n",
      "Epoch [2181/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1779, Series Loss: 0.0059, Class Loss: 0.2443, Accuracy: 0.2778\n",
      "Epoch [2182/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1783, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2901\n",
      "Epoch [2183/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1778, Series Loss: 0.0059, Class Loss: 0.2443, Accuracy: 0.3025\n",
      "Epoch [2184/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1776, Series Loss: 0.0059, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [2185/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1779, Series Loss: 0.0059, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2186/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1780, Series Loss: 0.0059, Class Loss: 0.2442, Accuracy: 0.2778\n",
      "Epoch [2187/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1782, Series Loss: 0.0059, Class Loss: 0.2444, Accuracy: 0.2901\n",
      "Epoch [2188/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1775, Series Loss: 0.0059, Class Loss: 0.2443, Accuracy: 0.2778\n",
      "Epoch [2189/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1775, Series Loss: 0.0059, Class Loss: 0.2443, Accuracy: 0.2901\n",
      "Epoch [2190/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1780, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2716\n",
      "Epoch [2191/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1771, Series Loss: 0.0059, Class Loss: 0.2443, Accuracy: 0.2593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2192/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1779, Series Loss: 0.0060, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2193/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1783, Series Loss: 0.0059, Class Loss: 0.2445, Accuracy: 0.2716\n",
      "Epoch [2194/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1775, Series Loss: 0.0059, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2195/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1779, Series Loss: 0.0060, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2196/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1777, Series Loss: 0.0059, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2197/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1774, Series Loss: 0.0059, Class Loss: 0.2443, Accuracy: 0.2716\n",
      "Epoch [2198/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1782, Series Loss: 0.0059, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2199/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1772, Series Loss: 0.0059, Class Loss: 0.2444, Accuracy: 0.2840\n",
      "Epoch [2200/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1773, Series Loss: 0.0059, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2201/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1771, Series Loss: 0.0059, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2202/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1771, Series Loss: 0.0059, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [2203/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1779, Series Loss: 0.0059, Class Loss: 0.2444, Accuracy: 0.2840\n",
      "Epoch [2204/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1774, Series Loss: 0.0059, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [2205/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1775, Series Loss: 0.0058, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [2206/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1775, Series Loss: 0.0059, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2207/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1777, Series Loss: 0.0059, Class Loss: 0.2443, Accuracy: 0.2716\n",
      "Epoch [2208/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1774, Series Loss: 0.0059, Class Loss: 0.2445, Accuracy: 0.2407\n",
      "Epoch [2209/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1777, Series Loss: 0.0059, Class Loss: 0.2443, Accuracy: 0.2778\n",
      "Epoch [2210/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1778, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2211/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1770, Series Loss: 0.0059, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [2212/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1777, Series Loss: 0.0059, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2213/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1775, Series Loss: 0.0059, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2214/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1780, Series Loss: 0.0059, Class Loss: 0.2443, Accuracy: 0.2716\n",
      "Epoch [2215/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1771, Series Loss: 0.0059, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2216/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1773, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2963\n",
      "Epoch [2217/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1772, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2778\n",
      "Epoch [2218/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1769, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2840\n",
      "Epoch [2219/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1771, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2469\n",
      "Epoch [2220/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1776, Series Loss: 0.0059, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2221/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1778, Series Loss: 0.0059, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [2222/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1776, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2716\n",
      "Epoch [2223/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1775, Series Loss: 0.0059, Class Loss: 0.2444, Accuracy: 0.2840\n",
      "Epoch [2224/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1776, Series Loss: 0.0059, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [2225/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1778, Series Loss: 0.0059, Class Loss: 0.2444, Accuracy: 0.2901\n",
      "Epoch [2226/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1778, Series Loss: 0.0059, Class Loss: 0.2445, Accuracy: 0.2778\n",
      "Epoch [2227/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1780, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2778\n",
      "Epoch [2228/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1775, Series Loss: 0.0059, Class Loss: 0.2445, Accuracy: 0.2901\n",
      "Epoch [2229/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1776, Series Loss: 0.0059, Class Loss: 0.2444, Accuracy: 0.2840\n",
      "Epoch [2230/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1775, Series Loss: 0.0059, Class Loss: 0.2444, Accuracy: 0.2778\n",
      "Epoch [2231/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1766, Series Loss: 0.0059, Class Loss: 0.2443, Accuracy: 0.2716\n",
      "Epoch [2232/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1771, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2778\n",
      "Epoch [2233/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1771, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2778\n",
      "Epoch [2234/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1774, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2901\n",
      "Epoch [2235/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1772, Series Loss: 0.0059, Class Loss: 0.2445, Accuracy: 0.2901\n",
      "Epoch [2236/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1776, Series Loss: 0.0059, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2237/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1771, Series Loss: 0.0059, Class Loss: 0.2443, Accuracy: 0.2778\n",
      "Epoch [2238/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1773, Series Loss: 0.0059, Class Loss: 0.2444, Accuracy: 0.2716\n",
      "Epoch [2239/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1783, Series Loss: 0.0060, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [2240/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1781, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2241/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1775, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.3210\n",
      "Epoch [2242/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1777, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2243/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1769, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2244/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1771, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2245/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1775, Series Loss: 0.0059, Class Loss: 0.2444, Accuracy: 0.2963\n",
      "Epoch [2246/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1770, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2247/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1770, Series Loss: 0.0059, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [2248/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1769, Series Loss: 0.0059, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2249/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1767, Series Loss: 0.0059, Class Loss: 0.2443, Accuracy: 0.2963\n",
      "Epoch [2250/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1773, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2901\n",
      "Epoch [2251/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1769, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [2252/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1769, Series Loss: 0.0059, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2253/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1771, Series Loss: 0.0059, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2254/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1768, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2255/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1769, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2256/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1769, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2901\n",
      "Epoch [2257/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1776, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2258/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1771, Series Loss: 0.0059, Class Loss: 0.2444, Accuracy: 0.2840\n",
      "Epoch [2259/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1770, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [2260/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1774, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2901\n",
      "Epoch [2261/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1765, Series Loss: 0.0059, Class Loss: 0.2443, Accuracy: 0.2778\n",
      "Epoch [2262/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1773, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2840\n",
      "Epoch [2263/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1769, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2901\n",
      "Epoch [2264/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1770, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2778\n",
      "Epoch [2265/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1780, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2716\n",
      "Epoch [2266/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1777, Series Loss: 0.0058, Class Loss: 0.2442, Accuracy: 0.2654\n",
      "Epoch [2267/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1771, Series Loss: 0.0058, Class Loss: 0.2442, Accuracy: 0.2593\n",
      "Epoch [2268/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1775, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2269/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1777, Series Loss: 0.0059, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2270/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1778, Series Loss: 0.0059, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2271/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1777, Series Loss: 0.0059, Class Loss: 0.2443, Accuracy: 0.2469\n",
      "Epoch [2272/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1774, Series Loss: 0.0059, Class Loss: 0.2443, Accuracy: 0.2901\n",
      "Epoch [2273/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1777, Series Loss: 0.0059, Class Loss: 0.2443, Accuracy: 0.2840\n",
      "Epoch [2274/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1774, Series Loss: 0.0059, Class Loss: 0.2444, Accuracy: 0.2901\n",
      "Epoch [2275/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1774, Series Loss: 0.0059, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2276/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1772, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2277/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1776, Series Loss: 0.0058, Class Loss: 0.2442, Accuracy: 0.2778\n",
      "Epoch [2278/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1773, Series Loss: 0.0059, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [2279/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1770, Series Loss: 0.0059, Class Loss: 0.2443, Accuracy: 0.2840\n",
      "Epoch [2280/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1775, Series Loss: 0.0059, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2281/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1775, Series Loss: 0.0058, Class Loss: 0.2446, Accuracy: 0.2654\n",
      "Epoch [2282/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1772, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2283/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1776, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2284/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1774, Series Loss: 0.0059, Class Loss: 0.2444, Accuracy: 0.2778\n",
      "Epoch [2285/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1772, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2963\n",
      "Epoch [2286/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1772, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2287/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1785, Series Loss: 0.0059, Class Loss: 0.2443, Accuracy: 0.2778\n",
      "Epoch [2288/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1771, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2716\n",
      "Epoch [2289/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1772, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.3086\n",
      "Epoch [2290/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1773, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2291/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1776, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2840\n",
      "Epoch [2292/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1784, Series Loss: 0.0059, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2293/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1777, Series Loss: 0.0058, Class Loss: 0.2445, Accuracy: 0.2778\n",
      "Epoch [2294/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1774, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2295/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1772, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2778\n",
      "Epoch [2296/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1777, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2778\n",
      "Epoch [2297/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1773, Series Loss: 0.0058, Class Loss: 0.2442, Accuracy: 0.2778\n",
      "Epoch [2298/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1777, Series Loss: 0.0058, Class Loss: 0.2442, Accuracy: 0.2531\n",
      "Epoch [2299/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1774, Series Loss: 0.0058, Class Loss: 0.2442, Accuracy: 0.2778\n",
      "Epoch [2300/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1767, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2778\n",
      "Epoch [2301/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1767, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2778\n",
      "Epoch [2302/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1772, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2303/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1774, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2716\n",
      "Epoch [2304/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1771, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2305/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1772, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [2306/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1773, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [2307/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1771, Series Loss: 0.0058, Class Loss: 0.2442, Accuracy: 0.2716\n",
      "Epoch [2308/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1774, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [2309/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1777, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2310/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1774, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2311/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1768, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2312/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1772, Series Loss: 0.0058, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [2313/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1775, Series Loss: 0.0059, Class Loss: 0.2443, Accuracy: 0.2716\n",
      "Epoch [2314/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1773, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2315/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1773, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2316/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1776, Series Loss: 0.0058, Class Loss: 0.2442, Accuracy: 0.2840\n",
      "Epoch [2317/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1775, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2318/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1778, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2319/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1771, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2320/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1772, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2778\n",
      "Epoch [2321/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1771, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2322/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1780, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2323/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1769, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2324/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1769, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [2325/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1778, Series Loss: 0.0058, Class Loss: 0.2442, Accuracy: 0.2840\n",
      "Epoch [2326/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1773, Series Loss: 0.0059, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2327/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1780, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2328/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1770, Series Loss: 0.0059, Class Loss: 0.2443, Accuracy: 0.2840\n",
      "Epoch [2329/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1773, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [2330/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1778, Series Loss: 0.0059, Class Loss: 0.2444, Accuracy: 0.2716\n",
      "Epoch [2331/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1773, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2963\n",
      "Epoch [2332/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1772, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2333/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1768, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2346\n",
      "Epoch [2334/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1777, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [2335/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1777, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2407\n",
      "Epoch [2336/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1775, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2840\n",
      "Epoch [2337/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1775, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [2338/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1770, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2840\n",
      "Epoch [2339/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1783, Series Loss: 0.0058, Class Loss: 0.2441, Accuracy: 0.2716\n",
      "Epoch [2340/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1772, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2469\n",
      "Epoch [2341/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1770, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2778\n",
      "Epoch [2342/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1774, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2343/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1776, Series Loss: 0.0059, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2344/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1778, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2778\n",
      "Epoch [2345/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1781, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2407\n",
      "Epoch [2346/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1776, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2778\n",
      "Epoch [2347/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1778, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [2348/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1774, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2407\n",
      "Epoch [2349/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1775, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2407\n",
      "Epoch [2350/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1783, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2778\n",
      "Epoch [2351/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1780, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [2352/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1775, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2353/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1775, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2354/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1772, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2355/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1775, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2840\n",
      "Epoch [2356/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1772, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2716\n",
      "Epoch [2357/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1774, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [2358/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1777, Series Loss: 0.0057, Class Loss: 0.2442, Accuracy: 0.2654\n",
      "Epoch [2359/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1774, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2360/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1770, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2901\n",
      "Epoch [2361/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1776, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [2362/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1781, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2901\n",
      "Epoch [2363/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1781, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2364/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1773, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [2365/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1777, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2366/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1770, Series Loss: 0.0058, Class Loss: 0.2442, Accuracy: 0.2716\n",
      "Epoch [2367/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1776, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2778\n",
      "Epoch [2368/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1775, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [2369/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1775, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2778\n",
      "Epoch [2370/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1778, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [2371/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1772, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2372/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1776, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2469\n",
      "Epoch [2373/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1768, Series Loss: 0.0057, Class Loss: 0.2442, Accuracy: 0.2469\n",
      "Epoch [2374/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1771, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [2375/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1773, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [2376/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1775, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [2377/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1775, Series Loss: 0.0058, Class Loss: 0.2442, Accuracy: 0.2531\n",
      "Epoch [2378/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1772, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2379/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1773, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [2380/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1777, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [2381/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1770, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [2382/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1771, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2716\n",
      "Epoch [2383/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1777, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2384/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1774, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2901\n",
      "Epoch [2385/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1782, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2469\n",
      "Epoch [2386/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1776, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [2387/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1777, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2388/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1774, Series Loss: 0.0058, Class Loss: 0.2442, Accuracy: 0.2469\n",
      "Epoch [2389/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1771, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2390/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1769, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2716\n",
      "Epoch [2391/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1772, Series Loss: 0.0058, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [2392/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1773, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2407\n",
      "Epoch [2393/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1770, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [2394/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1776, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2716\n",
      "Epoch [2395/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1779, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2778\n",
      "Epoch [2396/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1778, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2840\n",
      "Epoch [2397/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1774, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2778\n",
      "Epoch [2398/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1783, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [2399/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1780, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2400/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1783, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2716\n",
      "Epoch [2401/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1780, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2407\n",
      "Epoch [2402/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1775, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2716\n",
      "Epoch [2403/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1780, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [2404/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1780, Series Loss: 0.0057, Class Loss: 0.2441, Accuracy: 0.2716\n",
      "Epoch [2405/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1776, Series Loss: 0.0057, Class Loss: 0.2442, Accuracy: 0.2654\n",
      "Epoch [2406/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1776, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2346\n",
      "Epoch [2407/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1772, Series Loss: 0.0058, Class Loss: 0.2442, Accuracy: 0.2593\n",
      "Epoch [2408/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1772, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2409/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1778, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2716\n",
      "Epoch [2410/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1777, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2411/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1780, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2412/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1778, Series Loss: 0.0057, Class Loss: 0.2442, Accuracy: 0.2531\n",
      "Epoch [2413/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1779, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2778\n",
      "Epoch [2414/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1782, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2415/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1782, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2416/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1774, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2407\n",
      "Epoch [2417/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1771, Series Loss: 0.0057, Class Loss: 0.2442, Accuracy: 0.2531\n",
      "Epoch [2418/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1777, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [2419/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1773, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2407\n",
      "Epoch [2420/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1770, Series Loss: 0.0057, Class Loss: 0.2442, Accuracy: 0.2469\n",
      "Epoch [2421/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1776, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2422/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1771, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2423/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1780, Series Loss: 0.0058, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [2424/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1775, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2469\n",
      "Epoch [2425/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1772, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [2426/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1774, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2427/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1774, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2346\n",
      "Epoch [2428/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1779, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.3025\n",
      "Epoch [2429/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1775, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2430/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1772, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [2431/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1775, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.3025\n",
      "Epoch [2432/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1780, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2716\n",
      "Epoch [2433/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1774, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [2434/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1775, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [2435/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1782, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2901\n",
      "Epoch [2436/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1775, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2437/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1775, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2438/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1772, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2840\n",
      "Epoch [2439/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1779, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2440/4000], Discriminator Loss: 0.0911, Generator Loss: 0.1773, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [2441/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1780, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2716\n",
      "Epoch [2442/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1771, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.2716\n",
      "Epoch [2443/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1773, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2778\n",
      "Epoch [2444/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1775, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2445/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1775, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2963\n",
      "Epoch [2446/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1779, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [2447/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1783, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2448/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1776, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2716\n",
      "Epoch [2449/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1776, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2778\n",
      "Epoch [2450/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1779, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2469\n",
      "Epoch [2451/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1782, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2716\n",
      "Epoch [2452/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1776, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2453/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1777, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2716\n",
      "Epoch [2454/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1778, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [2455/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1779, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2716\n",
      "Epoch [2456/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1781, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2457/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1772, Series Loss: 0.0058, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [2458/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1778, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [2459/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1776, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [2460/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1783, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2461/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1774, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2462/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1780, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2463/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1775, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2407\n",
      "Epoch [2464/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1773, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2465/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1779, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2466/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1777, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2467/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1778, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2468/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1773, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2469/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1781, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [2470/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1777, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2716\n",
      "Epoch [2471/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1781, Series Loss: 0.0058, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [2472/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1782, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2716\n",
      "Epoch [2473/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1783, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2474/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1777, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2475/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1783, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2469\n",
      "Epoch [2476/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1780, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2469\n",
      "Epoch [2477/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1786, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2478/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1781, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2346\n",
      "Epoch [2479/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1781, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2480/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1776, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2481/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1782, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [2482/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1780, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2483/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1778, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2484/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1776, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2346\n",
      "Epoch [2485/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1778, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2469\n",
      "Epoch [2486/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1782, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2716\n",
      "Epoch [2487/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1785, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2488/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1778, Series Loss: 0.0058, Class Loss: 0.2442, Accuracy: 0.2531\n",
      "Epoch [2489/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1777, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2490/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1780, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2840\n",
      "Epoch [2491/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1776, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2492/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1777, Series Loss: 0.0057, Class Loss: 0.2442, Accuracy: 0.2593\n",
      "Epoch [2493/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1777, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2407\n",
      "Epoch [2494/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1780, Series Loss: 0.0057, Class Loss: 0.2442, Accuracy: 0.2593\n",
      "Epoch [2495/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1781, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2496/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1775, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2716\n",
      "Epoch [2497/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1778, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2498/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1780, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2499/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1777, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2716\n",
      "Epoch [2500/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1785, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2716\n",
      "Epoch [2501/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1777, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2840\n",
      "Epoch [2502/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1776, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2503/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1776, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2504/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1774, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2505/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1772, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2284\n",
      "Epoch [2506/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1775, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2507/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1786, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2508/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1782, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2407\n",
      "Epoch [2509/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1781, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [2510/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1778, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2407\n",
      "Epoch [2511/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1783, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2512/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1782, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2469\n",
      "Epoch [2513/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1777, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2514/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1775, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2515/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1779, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2516/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1783, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2517/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1779, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2716\n",
      "Epoch [2518/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1783, Series Loss: 0.0057, Class Loss: 0.2442, Accuracy: 0.2593\n",
      "Epoch [2519/4000], Discriminator Loss: 0.0910, Generator Loss: 0.1785, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2901\n",
      "Epoch [2520/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1781, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2521/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1782, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.2778\n",
      "Epoch [2522/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1778, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2469\n",
      "Epoch [2523/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1773, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [2524/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1781, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2525/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1781, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [2526/4000], Discriminator Loss: 0.0911, Generator Loss: 0.1776, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [2527/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1774, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2528/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1772, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2840\n",
      "Epoch [2529/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1772, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2716\n",
      "Epoch [2530/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1779, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2716\n",
      "Epoch [2531/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1775, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2469\n",
      "Epoch [2532/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1777, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2533/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1777, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2534/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1781, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2469\n",
      "Epoch [2535/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1780, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2536/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1786, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2537/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1777, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2538/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1774, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2539/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1776, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2540/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1780, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2541/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1777, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [2542/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1773, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2543/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1774, Series Loss: 0.0057, Class Loss: 0.2442, Accuracy: 0.2531\n",
      "Epoch [2544/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1779, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2469\n",
      "Epoch [2545/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1778, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2407\n",
      "Epoch [2546/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1784, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [2547/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1782, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2548/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1783, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [2549/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1775, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2778\n",
      "Epoch [2550/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1775, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2716\n",
      "Epoch [2551/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1776, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2552/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1775, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2553/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1773, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2554/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1776, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2346\n",
      "Epoch [2555/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1777, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2556/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1775, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2557/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1772, Series Loss: 0.0057, Class Loss: 0.2442, Accuracy: 0.2531\n",
      "Epoch [2558/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1777, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2407\n",
      "Epoch [2559/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1779, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2560/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1779, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2469\n",
      "Epoch [2561/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1776, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2562/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1774, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2563/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1770, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [2564/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1768, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2565/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1776, Series Loss: 0.0056, Class Loss: 0.2442, Accuracy: 0.2654\n",
      "Epoch [2566/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1771, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2469\n",
      "Epoch [2567/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1778, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [2568/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1770, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2569/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1775, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.2407\n",
      "Epoch [2570/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1775, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2407\n",
      "Epoch [2571/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1771, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [2572/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1769, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2346\n",
      "Epoch [2573/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1774, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2407\n",
      "Epoch [2574/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1778, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2346\n",
      "Epoch [2575/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1773, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2576/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1782, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2577/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1778, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [2578/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1774, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2407\n",
      "Epoch [2579/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1772, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2469\n",
      "Epoch [2580/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1771, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2581/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1776, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2582/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1781, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2469\n",
      "Epoch [2583/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1776, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [2584/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1780, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [2585/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1775, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2586/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1769, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2407\n",
      "Epoch [2587/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1776, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [2588/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1776, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2716\n",
      "Epoch [2589/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1769, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [2590/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1772, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2591/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1775, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [2592/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1776, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2593/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1778, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.2716\n",
      "Epoch [2594/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1773, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2595/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1778, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2596/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1779, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [2597/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1778, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2598/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1780, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2599/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1779, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2600/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1777, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2469\n",
      "Epoch [2601/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1781, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2602/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1785, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [2603/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1777, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2604/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1778, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2605/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1774, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [2606/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1771, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2716\n",
      "Epoch [2607/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1768, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [2608/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1776, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2609/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1770, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2610/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1772, Series Loss: 0.0058, Class Loss: 0.2445, Accuracy: 0.2407\n",
      "Epoch [2611/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1776, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2612/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1773, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [2613/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1778, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2614/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1773, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2615/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1771, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2469\n",
      "Epoch [2616/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1770, Series Loss: 0.0056, Class Loss: 0.2442, Accuracy: 0.2407\n",
      "Epoch [2617/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1770, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2618/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1770, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2619/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1769, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [2620/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1773, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [2621/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1774, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2622/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1776, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2623/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1774, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2624/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1774, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [2625/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1776, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2626/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1774, Series Loss: 0.0058, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [2627/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1777, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2628/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1779, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [2629/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1779, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [2630/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1775, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2469\n",
      "Epoch [2631/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1773, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2716\n",
      "Epoch [2632/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1770, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2633/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1773, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2634/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1773, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2635/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1778, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.2407\n",
      "Epoch [2636/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1778, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2346\n",
      "Epoch [2637/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1781, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2638/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1775, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2639/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1769, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2640/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1778, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.2407\n",
      "Epoch [2641/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1779, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2407\n",
      "Epoch [2642/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1777, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [2643/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1778, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2644/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1776, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2645/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1780, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [2646/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1781, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2647/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1770, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2648/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1777, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2649/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1776, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2650/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1772, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [2651/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1775, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2407\n",
      "Epoch [2652/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1773, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2653/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1770, Series Loss: 0.0056, Class Loss: 0.2446, Accuracy: 0.2531\n",
      "Epoch [2654/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1775, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [2655/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1776, Series Loss: 0.0058, Class Loss: 0.2446, Accuracy: 0.2407\n",
      "Epoch [2656/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1778, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [2657/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1774, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2407\n",
      "Epoch [2658/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1776, Series Loss: 0.0057, Class Loss: 0.2446, Accuracy: 0.2531\n",
      "Epoch [2659/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1781, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2660/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1778, Series Loss: 0.0058, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2661/4000], Discriminator Loss: 0.0911, Generator Loss: 0.1780, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [2662/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1778, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [2663/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1782, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2664/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1779, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2407\n",
      "Epoch [2665/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1778, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2407\n",
      "Epoch [2666/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1782, Series Loss: 0.0058, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [2667/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1781, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2668/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1773, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [2669/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1776, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [2670/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1773, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2671/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1770, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2672/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1770, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [2673/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1776, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2674/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1778, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [2675/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1774, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2469\n",
      "Epoch [2676/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1775, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [2677/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1772, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [2678/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1774, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [2679/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1770, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2680/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1773, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [2681/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1773, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2346\n",
      "Epoch [2682/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1770, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2683/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1779, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2684/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1777, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.2407\n",
      "Epoch [2685/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1777, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2686/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1777, Series Loss: 0.0056, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [2687/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1777, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2688/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1771, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [2689/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1772, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [2690/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1776, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [2691/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1775, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [2692/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1786, Series Loss: 0.0056, Class Loss: 0.2446, Accuracy: 0.2531\n",
      "Epoch [2693/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1774, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [2694/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1775, Series Loss: 0.0058, Class Loss: 0.2446, Accuracy: 0.2469\n",
      "Epoch [2695/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1776, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [2696/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1776, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2697/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1776, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2698/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1772, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2699/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1776, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2407\n",
      "Epoch [2700/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1776, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2701/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1771, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2702/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1773, Series Loss: 0.0058, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [2703/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1776, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2704/4000], Discriminator Loss: 0.0910, Generator Loss: 0.1785, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2705/4000], Discriminator Loss: 0.0911, Generator Loss: 0.1772, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [2706/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1779, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2707/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1770, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2407\n",
      "Epoch [2708/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1772, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [2709/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1774, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2710/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1778, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2711/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1769, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2712/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1773, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2713/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1771, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [2714/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1778, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [2715/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1770, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2716/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1773, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2407\n",
      "Epoch [2717/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1771, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [2718/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1772, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2719/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1775, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [2720/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1768, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [2721/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1773, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2722/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1768, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2723/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1772, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2724/4000], Discriminator Loss: 0.0909, Generator Loss: 0.1774, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2725/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1781, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2726/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1778, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2727/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1777, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2346\n",
      "Epoch [2728/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1782, Series Loss: 0.0056, Class Loss: 0.2446, Accuracy: 0.2531\n",
      "Epoch [2729/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1779, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [2730/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1773, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2731/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1776, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [2732/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1777, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2733/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1772, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2734/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1780, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [2735/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1777, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2407\n",
      "Epoch [2736/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1768, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2716\n",
      "Epoch [2737/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1775, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2738/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1770, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [2739/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1771, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [2740/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1775, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2407\n",
      "Epoch [2741/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1774, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2742/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1766, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2743/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1774, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2744/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1774, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2407\n",
      "Epoch [2745/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1775, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2746/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1774, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2747/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1769, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [2748/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1768, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2749/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1772, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2750/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1770, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2751/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1775, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2752/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1777, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [2753/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1774, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [2754/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1780, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2755/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1774, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2756/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1778, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [2757/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1767, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [2758/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1777, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [2759/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1775, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2760/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1770, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2761/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1775, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2762/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1775, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [2763/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1776, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2469\n",
      "Epoch [2764/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1771, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [2765/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1769, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [2766/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1775, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [2767/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1776, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2768/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1780, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [2769/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1778, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2770/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1773, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [2771/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1773, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [2772/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1774, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2773/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1774, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [2774/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1775, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [2775/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1774, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [2776/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1772, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [2777/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1773, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [2778/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1776, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2779/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1773, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2780/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1775, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [2781/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1769, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2782/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1768, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2783/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1776, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2784/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1771, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2785/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1778, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [2786/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1779, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2787/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1780, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2788/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1774, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2789/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1770, Series Loss: 0.0056, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [2790/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1771, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [2791/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1774, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2792/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1770, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2793/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1775, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [2794/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1778, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2407\n",
      "Epoch [2795/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1774, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [2796/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1778, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2346\n",
      "Epoch [2797/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1779, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2798/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1777, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2799/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1772, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2800/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1788, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2801/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1790, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2802/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1776, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2803/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1772, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2804/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1776, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [2805/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1776, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2806/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1775, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2807/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1772, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2808/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1775, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [2809/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1775, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2810/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1775, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2811/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1778, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2812/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1778, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [2813/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1771, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2814/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1775, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [2815/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1775, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [2816/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1776, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [2817/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1774, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2469\n",
      "Epoch [2818/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1780, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [2819/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1776, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [2820/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1768, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [2821/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1772, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [2822/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1776, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [2823/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1775, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2824/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1776, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2825/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1771, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2826/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1772, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2827/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1772, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2828/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1770, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2829/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1777, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2830/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1776, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [2831/4000], Discriminator Loss: 0.0911, Generator Loss: 0.1778, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2832/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1769, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2833/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1781, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [2834/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1772, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [2835/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1778, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2836/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1778, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2837/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1771, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2838/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1767, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2839/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1771, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2716\n",
      "Epoch [2840/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1774, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2841/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1771, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2842/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1771, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2843/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1770, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2844/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1775, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2845/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1772, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2846/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1778, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [2847/4000], Discriminator Loss: 0.0911, Generator Loss: 0.1776, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [2848/4000], Discriminator Loss: 0.0909, Generator Loss: 0.1775, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2849/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1771, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2850/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1771, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2851/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1775, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2852/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1770, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2853/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1771, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [2854/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1773, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2855/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1777, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [2856/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1771, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2857/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1777, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [2858/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1773, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2859/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1776, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2860/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1778, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [2861/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1772, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [2862/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1770, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2863/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1779, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2864/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1770, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [2865/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1771, Series Loss: 0.0056, Class Loss: 0.2442, Accuracy: 0.2593\n",
      "Epoch [2866/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1771, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2867/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1777, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [2868/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1777, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2869/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1772, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2870/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1771, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2871/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1778, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2872/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1767, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2873/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1778, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [2874/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1766, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2469\n",
      "Epoch [2875/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1774, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2407\n",
      "Epoch [2876/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1772, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2877/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1767, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [2878/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1784, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2879/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1775, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [2880/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1770, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [2881/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1780, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [2882/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1773, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [2883/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1777, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [2884/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1770, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2885/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1770, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2469\n",
      "Epoch [2886/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1777, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2887/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1772, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [2888/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1766, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2889/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1775, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [2890/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1773, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [2891/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1781, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2892/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1772, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [2893/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1773, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [2894/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1777, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2895/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1775, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2896/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1782, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2897/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1776, Series Loss: 0.0055, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [2898/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1777, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [2899/4000], Discriminator Loss: 0.0909, Generator Loss: 0.1779, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2900/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1770, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2346\n",
      "Epoch [2901/4000], Discriminator Loss: 0.0911, Generator Loss: 0.1778, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2407\n",
      "Epoch [2902/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1775, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2903/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1777, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2904/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1774, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [2905/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1777, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2716\n",
      "Epoch [2906/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1772, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [2907/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1773, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [2908/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1772, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2909/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1774, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2910/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1774, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [2911/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1774, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2912/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1777, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [2913/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1767, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2914/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1769, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2915/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1776, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2916/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1777, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2917/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1774, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [2918/4000], Discriminator Loss: 0.0907, Generator Loss: 0.1777, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2919/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1778, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [2920/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1780, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2921/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1776, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2922/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1782, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [2923/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1773, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [2924/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1777, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2925/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1777, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2407\n",
      "Epoch [2926/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1775, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2927/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1775, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2928/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1778, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [2929/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1779, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2930/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1774, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2931/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1772, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2932/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1777, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2933/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1777, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2407\n",
      "Epoch [2934/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1777, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2935/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1776, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2936/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1775, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2937/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1776, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [2938/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1772, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [2939/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1775, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [2940/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1772, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2941/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1771, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2942/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1783, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [2943/4000], Discriminator Loss: 0.0909, Generator Loss: 0.1781, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2944/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1781, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2945/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1779, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2946/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1776, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2947/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1777, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2407\n",
      "Epoch [2948/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1778, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2949/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1780, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2950/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1785, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [2951/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1771, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2952/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1773, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2953/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1771, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2954/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1777, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [2955/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1776, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2469\n",
      "Epoch [2956/4000], Discriminator Loss: 0.0911, Generator Loss: 0.1776, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [2957/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1773, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2407\n",
      "Epoch [2958/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1774, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2959/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1771, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2960/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1781, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [2961/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1777, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [2962/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1772, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2963/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1776, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [2964/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1778, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2965/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1777, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [2966/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1776, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2967/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1781, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2968/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1777, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2969/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1779, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [2970/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1783, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [2971/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1785, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [2972/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1782, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [2973/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1776, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2974/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1782, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2975/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1781, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2407\n",
      "Epoch [2976/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1776, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2977/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1775, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [2978/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1775, Series Loss: 0.0057, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [2979/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1770, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2980/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1774, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [2981/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1777, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2982/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1775, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2983/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1771, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2984/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1783, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [2985/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1784, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [2986/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1777, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [2987/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1774, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2988/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1783, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2989/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1771, Series Loss: 0.0058, Class Loss: 0.2443, Accuracy: 0.2407\n",
      "Epoch [2990/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1777, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [2991/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1773, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [2992/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1779, Series Loss: 0.0055, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [2993/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1787, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [2994/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1786, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [2995/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1778, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [2996/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1782, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [2997/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1777, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [2998/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1776, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2778\n",
      "Epoch [2999/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1769, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3000/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1776, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3001/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1774, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2469\n",
      "Epoch [3002/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1778, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [3003/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1776, Series Loss: 0.0055, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [3004/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1790, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [3005/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1773, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [3006/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1774, Series Loss: 0.0055, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [3007/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1791, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2469\n",
      "Epoch [3008/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1778, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3009/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1781, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3010/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1776, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3011/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1780, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [3012/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1779, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [3013/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1780, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [3014/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1777, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3015/4000], Discriminator Loss: 0.0909, Generator Loss: 0.1783, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3016/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1772, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2716\n",
      "Epoch [3017/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1773, Series Loss: 0.0057, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [3018/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1779, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3019/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1777, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3020/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1779, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3021/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1778, Series Loss: 0.0057, Class Loss: 0.2442, Accuracy: 0.2593\n",
      "Epoch [3022/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1773, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3023/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1773, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3024/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1776, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [3025/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1777, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [3026/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1772, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3027/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1787, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [3028/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1778, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [3029/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1779, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3030/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1776, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3031/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1782, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [3032/4000], Discriminator Loss: 0.0910, Generator Loss: 0.1789, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [3033/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1783, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3034/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1776, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3035/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1776, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [3036/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1784, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3037/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1779, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [3038/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1774, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3039/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1776, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3040/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1777, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3041/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1779, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [3042/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1772, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3043/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1774, Series Loss: 0.0055, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [3044/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1775, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3045/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1771, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [3046/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1782, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [3047/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1779, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3048/4000], Discriminator Loss: 0.0910, Generator Loss: 0.1777, Series Loss: 0.0056, Class Loss: 0.2442, Accuracy: 0.2654\n",
      "Epoch [3049/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1778, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3050/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1785, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3051/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1782, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [3052/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1770, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3053/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1783, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [3054/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1784, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3055/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1779, Series Loss: 0.0055, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [3056/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1778, Series Loss: 0.0055, Class Loss: 0.2443, Accuracy: 0.2469\n",
      "Epoch [3057/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1780, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3058/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1778, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [3059/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1774, Series Loss: 0.0055, Class Loss: 0.2443, Accuracy: 0.2469\n",
      "Epoch [3060/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1781, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [3061/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1778, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3062/4000], Discriminator Loss: 0.0910, Generator Loss: 0.1779, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [3063/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1780, Series Loss: 0.0055, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [3064/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1776, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2407\n",
      "Epoch [3065/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1774, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [3066/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1771, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2840\n",
      "Epoch [3067/4000], Discriminator Loss: 0.0911, Generator Loss: 0.1777, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3068/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1770, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [3069/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1778, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3070/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1772, Series Loss: 0.0055, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [3071/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1775, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3072/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1777, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3073/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1769, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [3074/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1776, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2469\n",
      "Epoch [3075/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1776, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2716\n",
      "Epoch [3076/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1777, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2407\n",
      "Epoch [3077/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1774, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3078/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1778, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3079/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1778, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3080/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1774, Series Loss: 0.0055, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [3081/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1771, Series Loss: 0.0055, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [3082/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1772, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3083/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1772, Series Loss: 0.0055, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [3084/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1779, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [3085/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1778, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2716\n",
      "Epoch [3086/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1778, Series Loss: 0.0057, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [3087/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1773, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3088/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1777, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3089/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1780, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3090/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1783, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3091/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1781, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3092/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1779, Series Loss: 0.0055, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [3093/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1777, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [3094/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1772, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3095/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1779, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3096/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1780, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3097/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1786, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3098/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1779, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3099/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1773, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3100/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1787, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [3101/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1777, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2407\n",
      "Epoch [3102/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1791, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3103/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1781, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3104/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1776, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2407\n",
      "Epoch [3105/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1772, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3106/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1785, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [3107/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1774, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3108/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1772, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [3109/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1772, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [3110/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1772, Series Loss: 0.0055, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [3111/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1772, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [3112/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1782, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3113/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1774, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3114/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1778, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2407\n",
      "Epoch [3115/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1775, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [3116/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1773, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3117/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1773, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2469\n",
      "Epoch [3118/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1784, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [3119/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1772, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3120/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1784, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3121/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1784, Series Loss: 0.0055, Class Loss: 0.2446, Accuracy: 0.2407\n",
      "Epoch [3122/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1790, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3123/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1777, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [3124/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1771, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3125/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1772, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3126/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1778, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3127/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1780, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3128/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1780, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3129/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1779, Series Loss: 0.0055, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [3130/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1779, Series Loss: 0.0055, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [3131/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1780, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3132/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1773, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2407\n",
      "Epoch [3133/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1774, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [3134/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1776, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3135/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1784, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3136/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1776, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [3137/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1774, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3138/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1781, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3139/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1779, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [3140/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1779, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3141/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1781, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3142/4000], Discriminator Loss: 0.0910, Generator Loss: 0.1777, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3143/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1782, Series Loss: 0.0057, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3144/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1778, Series Loss: 0.0055, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [3145/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1780, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [3146/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1780, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3147/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1778, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3148/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1779, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3149/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1775, Series Loss: 0.0056, Class Loss: 0.2442, Accuracy: 0.2593\n",
      "Epoch [3150/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1776, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3151/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1785, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3152/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1778, Series Loss: 0.0055, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [3153/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1775, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3154/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1770, Series Loss: 0.0055, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [3155/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1772, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2716\n",
      "Epoch [3156/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1768, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3157/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1772, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3158/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1778, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3159/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1772, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3160/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1772, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [3161/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1772, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3162/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1772, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2469\n",
      "Epoch [3163/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1779, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3164/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1772, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3165/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1782, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3166/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1774, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3167/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1768, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [3168/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1780, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3169/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1770, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3170/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1772, Series Loss: 0.0055, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [3171/4000], Discriminator Loss: 0.0910, Generator Loss: 0.1778, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2716\n",
      "Epoch [3172/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1780, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3173/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1770, Series Loss: 0.0054, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3174/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1778, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3175/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1771, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3176/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1774, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3177/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1779, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [3178/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1776, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [3179/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1773, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3180/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1765, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3181/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1772, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [3182/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1776, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [3183/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1774, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3184/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1780, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3185/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1783, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2407\n",
      "Epoch [3186/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1773, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [3187/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1781, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [3188/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1775, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3189/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1771, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2716\n",
      "Epoch [3190/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1768, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3191/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1774, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3192/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1769, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3193/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1785, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3194/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1772, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3195/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1774, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3196/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1784, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3197/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1789, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3198/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1774, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3199/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1768, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3200/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1767, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3201/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1777, Series Loss: 0.0055, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [3202/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1771, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2716\n",
      "Epoch [3203/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1775, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3204/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1774, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3205/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1779, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3206/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1770, Series Loss: 0.0055, Class Loss: 0.2446, Accuracy: 0.2469\n",
      "Epoch [3207/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1780, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2531\n",
      "Epoch [3208/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1777, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3209/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1776, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3210/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1774, Series Loss: 0.0056, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [3211/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1773, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3212/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1771, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2407\n",
      "Epoch [3213/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1779, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3214/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1776, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [3215/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1780, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3216/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1776, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3217/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1781, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3218/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1777, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3219/4000], Discriminator Loss: 0.0911, Generator Loss: 0.1788, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3220/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1780, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3221/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1774, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3222/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1777, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3223/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1782, Series Loss: 0.0055, Class Loss: 0.2443, Accuracy: 0.2469\n",
      "Epoch [3224/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1774, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3225/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1782, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2407\n",
      "Epoch [3226/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1780, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3227/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1776, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3228/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1780, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3229/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1779, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3230/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1776, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3231/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1772, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3232/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1773, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3233/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1774, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3234/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1785, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3235/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1773, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3236/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1774, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3237/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1777, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3238/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1767, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3239/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1784, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3240/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1772, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3241/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1774, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3242/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1771, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3243/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1776, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3244/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1768, Series Loss: 0.0055, Class Loss: 0.2443, Accuracy: 0.2716\n",
      "Epoch [3245/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1775, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3246/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1784, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3247/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1776, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3248/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1780, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3249/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1773, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3250/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1774, Series Loss: 0.0054, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3251/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1772, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3252/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1770, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3253/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1779, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3254/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1775, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3255/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1775, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2346\n",
      "Epoch [3256/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1779, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3257/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1771, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3258/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1776, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3259/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1780, Series Loss: 0.0055, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3260/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1773, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3261/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1772, Series Loss: 0.0055, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3262/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1775, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3263/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1773, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3264/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1766, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3265/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1773, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3266/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1767, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3267/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1775, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3268/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1780, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3269/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1768, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3270/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1773, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3271/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1778, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [3272/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1780, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [3273/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1779, Series Loss: 0.0054, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3274/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1777, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3275/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1774, Series Loss: 0.0054, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3276/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1771, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3277/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1775, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [3278/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1777, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3279/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1773, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3280/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1768, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3281/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1779, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3282/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1774, Series Loss: 0.0056, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3283/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1773, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [3284/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1774, Series Loss: 0.0054, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3285/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1773, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3286/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1773, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3287/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1773, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2716\n",
      "Epoch [3288/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1771, Series Loss: 0.0055, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [3289/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1776, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3290/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1777, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3291/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1769, Series Loss: 0.0054, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3292/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1768, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3293/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1777, Series Loss: 0.0054, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3294/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1772, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3295/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1765, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2716\n",
      "Epoch [3296/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1770, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3297/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1788, Series Loss: 0.0056, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3298/4000], Discriminator Loss: 0.0904, Generator Loss: 0.1786, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2346\n",
      "Epoch [3299/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1780, Series Loss: 0.0055, Class Loss: 0.2446, Accuracy: 0.2346\n",
      "Epoch [3300/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1782, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3301/4000], Discriminator Loss: 0.0906, Generator Loss: 0.1769, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3302/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1765, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3303/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1777, Series Loss: 0.0054, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3304/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1767, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [3305/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1779, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3306/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1767, Series Loss: 0.0054, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3307/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1778, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [3308/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1777, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3309/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1777, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3310/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1773, Series Loss: 0.0054, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3311/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1775, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3312/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1776, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3313/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1779, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [3314/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1775, Series Loss: 0.0055, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [3315/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1773, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3316/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1778, Series Loss: 0.0054, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3317/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1774, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3318/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1784, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3319/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1779, Series Loss: 0.0054, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3320/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1778, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3321/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1772, Series Loss: 0.0054, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3322/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1795, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3323/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1784, Series Loss: 0.0054, Class Loss: 0.2446, Accuracy: 0.2531\n",
      "Epoch [3324/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1770, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3325/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1787, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2407\n",
      "Epoch [3326/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1776, Series Loss: 0.0054, Class Loss: 0.2446, Accuracy: 0.2531\n",
      "Epoch [3327/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1777, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3328/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1771, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3329/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1774, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3330/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1780, Series Loss: 0.0054, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3331/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1783, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3332/4000], Discriminator Loss: 0.0907, Generator Loss: 0.1788, Series Loss: 0.0054, Class Loss: 0.2446, Accuracy: 0.2531\n",
      "Epoch [3333/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1776, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3334/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1782, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3335/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1781, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3336/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1783, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3337/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1778, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2716\n",
      "Epoch [3338/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1788, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3339/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1774, Series Loss: 0.0054, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3340/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1778, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [3341/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1770, Series Loss: 0.0054, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [3342/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1769, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [3343/4000], Discriminator Loss: 0.0910, Generator Loss: 0.1773, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3344/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1775, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3345/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1767, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3346/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1766, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3347/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1771, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3348/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1772, Series Loss: 0.0054, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3349/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1767, Series Loss: 0.0054, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3350/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1766, Series Loss: 0.0055, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3351/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1776, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3352/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1773, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [3353/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1776, Series Loss: 0.0054, Class Loss: 0.2447, Accuracy: 0.2593\n",
      "Epoch [3354/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1760, Series Loss: 0.0054, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3355/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1773, Series Loss: 0.0054, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3356/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1768, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3357/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1770, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3358/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1763, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3359/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1764, Series Loss: 0.0054, Class Loss: 0.2446, Accuracy: 0.2654\n",
      "Epoch [3360/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1768, Series Loss: 0.0054, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3361/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1772, Series Loss: 0.0053, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3362/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1773, Series Loss: 0.0054, Class Loss: 0.2446, Accuracy: 0.2654\n",
      "Epoch [3363/4000], Discriminator Loss: 0.0932, Generator Loss: 0.1762, Series Loss: 0.0054, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3364/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1774, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [3365/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1772, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3366/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1765, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3367/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1766, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3368/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1784, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2407\n",
      "Epoch [3369/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1771, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3370/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1774, Series Loss: 0.0054, Class Loss: 0.2446, Accuracy: 0.2407\n",
      "Epoch [3371/4000], Discriminator Loss: 0.0935, Generator Loss: 0.1772, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3372/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1782, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3373/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1777, Series Loss: 0.0055, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3374/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1774, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2716\n",
      "Epoch [3375/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1766, Series Loss: 0.0053, Class Loss: 0.2446, Accuracy: 0.2531\n",
      "Epoch [3376/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1776, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3377/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1771, Series Loss: 0.0054, Class Loss: 0.2446, Accuracy: 0.2531\n",
      "Epoch [3378/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1780, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [3379/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1768, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3380/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1774, Series Loss: 0.0054, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3381/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1774, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2716\n",
      "Epoch [3382/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1769, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3383/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1775, Series Loss: 0.0053, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3384/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1777, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3385/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1772, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3386/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1773, Series Loss: 0.0053, Class Loss: 0.2446, Accuracy: 0.2469\n",
      "Epoch [3387/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1768, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3388/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1768, Series Loss: 0.0054, Class Loss: 0.2446, Accuracy: 0.2531\n",
      "Epoch [3389/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1775, Series Loss: 0.0054, Class Loss: 0.2446, Accuracy: 0.2531\n",
      "Epoch [3390/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1772, Series Loss: 0.0054, Class Loss: 0.2446, Accuracy: 0.2531\n",
      "Epoch [3391/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1771, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3392/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1773, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3393/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1763, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3394/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1768, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3395/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1776, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3396/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1780, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3397/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1774, Series Loss: 0.0054, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3398/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1773, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3399/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1774, Series Loss: 0.0054, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3400/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1772, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3401/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1773, Series Loss: 0.0054, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [3402/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1768, Series Loss: 0.0054, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3403/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1767, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3404/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1767, Series Loss: 0.0053, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3405/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1772, Series Loss: 0.0054, Class Loss: 0.2446, Accuracy: 0.2531\n",
      "Epoch [3406/4000], Discriminator Loss: 0.0932, Generator Loss: 0.1768, Series Loss: 0.0053, Class Loss: 0.2447, Accuracy: 0.2531\n",
      "Epoch [3407/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1769, Series Loss: 0.0053, Class Loss: 0.2446, Accuracy: 0.2593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3408/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1770, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3409/4000], Discriminator Loss: 0.0932, Generator Loss: 0.1780, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2407\n",
      "Epoch [3410/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1771, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3411/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1771, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3412/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1779, Series Loss: 0.0054, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3413/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1781, Series Loss: 0.0054, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3414/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1772, Series Loss: 0.0054, Class Loss: 0.2446, Accuracy: 0.2654\n",
      "Epoch [3415/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1774, Series Loss: 0.0055, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [3416/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1769, Series Loss: 0.0054, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3417/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1767, Series Loss: 0.0053, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3418/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1770, Series Loss: 0.0054, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3419/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1779, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3420/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1772, Series Loss: 0.0054, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3421/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1769, Series Loss: 0.0054, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3422/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1774, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3423/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1776, Series Loss: 0.0053, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3424/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1780, Series Loss: 0.0053, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3425/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1766, Series Loss: 0.0054, Class Loss: 0.2446, Accuracy: 0.2469\n",
      "Epoch [3426/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1768, Series Loss: 0.0053, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3427/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1774, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3428/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1773, Series Loss: 0.0054, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3429/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1776, Series Loss: 0.0053, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3430/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1776, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3431/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1775, Series Loss: 0.0054, Class Loss: 0.2446, Accuracy: 0.2531\n",
      "Epoch [3432/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1773, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [3433/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1776, Series Loss: 0.0054, Class Loss: 0.2446, Accuracy: 0.2531\n",
      "Epoch [3434/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1767, Series Loss: 0.0054, Class Loss: 0.2446, Accuracy: 0.2654\n",
      "Epoch [3435/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1776, Series Loss: 0.0053, Class Loss: 0.2446, Accuracy: 0.2654\n",
      "Epoch [3436/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1765, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3437/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1775, Series Loss: 0.0053, Class Loss: 0.2446, Accuracy: 0.2531\n",
      "Epoch [3438/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1772, Series Loss: 0.0054, Class Loss: 0.2446, Accuracy: 0.2654\n",
      "Epoch [3439/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1762, Series Loss: 0.0054, Class Loss: 0.2446, Accuracy: 0.2654\n",
      "Epoch [3440/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1771, Series Loss: 0.0054, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3441/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1776, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2716\n",
      "Epoch [3442/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1767, Series Loss: 0.0053, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3443/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1769, Series Loss: 0.0053, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3444/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1772, Series Loss: 0.0054, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3445/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1768, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3446/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1778, Series Loss: 0.0053, Class Loss: 0.2446, Accuracy: 0.2531\n",
      "Epoch [3447/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1772, Series Loss: 0.0053, Class Loss: 0.2447, Accuracy: 0.2593\n",
      "Epoch [3448/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1767, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3449/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1774, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3450/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1762, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [3451/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1772, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3452/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1767, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3453/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1782, Series Loss: 0.0054, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3454/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1766, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3455/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1764, Series Loss: 0.0053, Class Loss: 0.2446, Accuracy: 0.2654\n",
      "Epoch [3456/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1777, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3457/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1761, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3458/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1776, Series Loss: 0.0054, Class Loss: 0.2446, Accuracy: 0.2531\n",
      "Epoch [3459/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1778, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3460/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1768, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [3461/4000], Discriminator Loss: 0.0934, Generator Loss: 0.1768, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3462/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1770, Series Loss: 0.0054, Class Loss: 0.2444, Accuracy: 0.2716\n",
      "Epoch [3463/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1774, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2716\n",
      "Epoch [3464/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1769, Series Loss: 0.0054, Class Loss: 0.2446, Accuracy: 0.2469\n",
      "Epoch [3465/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1766, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3466/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1766, Series Loss: 0.0053, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3467/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1778, Series Loss: 0.0054, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3468/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1772, Series Loss: 0.0053, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3469/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1771, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [3470/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1767, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3471/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1780, Series Loss: 0.0054, Class Loss: 0.2444, Accuracy: 0.2654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3472/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1772, Series Loss: 0.0053, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3473/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1771, Series Loss: 0.0053, Class Loss: 0.2446, Accuracy: 0.2654\n",
      "Epoch [3474/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1772, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3475/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1777, Series Loss: 0.0054, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3476/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1769, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3477/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1764, Series Loss: 0.0053, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3478/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1771, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3479/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1770, Series Loss: 0.0053, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3480/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1767, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3481/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1776, Series Loss: 0.0053, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3482/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1773, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3483/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1771, Series Loss: 0.0054, Class Loss: 0.2446, Accuracy: 0.2654\n",
      "Epoch [3484/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1764, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3485/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1772, Series Loss: 0.0053, Class Loss: 0.2446, Accuracy: 0.2531\n",
      "Epoch [3486/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1776, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3487/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1772, Series Loss: 0.0053, Class Loss: 0.2447, Accuracy: 0.2531\n",
      "Epoch [3488/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1773, Series Loss: 0.0053, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3489/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1777, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3490/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1773, Series Loss: 0.0054, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3491/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1770, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3492/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1764, Series Loss: 0.0053, Class Loss: 0.2446, Accuracy: 0.2531\n",
      "Epoch [3493/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1776, Series Loss: 0.0053, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3494/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1773, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3495/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1777, Series Loss: 0.0053, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3496/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1775, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3497/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1774, Series Loss: 0.0054, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3498/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1772, Series Loss: 0.0053, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3499/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1765, Series Loss: 0.0053, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3500/4000], Discriminator Loss: 0.0932, Generator Loss: 0.1761, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3501/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1775, Series Loss: 0.0054, Class Loss: 0.2446, Accuracy: 0.2716\n",
      "Epoch [3502/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1767, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3503/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1771, Series Loss: 0.0054, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3504/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1775, Series Loss: 0.0053, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3505/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1770, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3506/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1776, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3507/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1779, Series Loss: 0.0054, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3508/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1772, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3509/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1774, Series Loss: 0.0052, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3510/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1773, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3511/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1777, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3512/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1776, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3513/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1768, Series Loss: 0.0053, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3514/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1772, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3515/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1773, Series Loss: 0.0053, Class Loss: 0.2446, Accuracy: 0.2531\n",
      "Epoch [3516/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1764, Series Loss: 0.0054, Class Loss: 0.2444, Accuracy: 0.2716\n",
      "Epoch [3517/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1775, Series Loss: 0.0054, Class Loss: 0.2446, Accuracy: 0.2654\n",
      "Epoch [3518/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1768, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3519/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1777, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2716\n",
      "Epoch [3520/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1766, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3521/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1762, Series Loss: 0.0054, Class Loss: 0.2446, Accuracy: 0.2407\n",
      "Epoch [3522/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1774, Series Loss: 0.0054, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3523/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1771, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2716\n",
      "Epoch [3524/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1776, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3525/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1778, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3526/4000], Discriminator Loss: 0.0933, Generator Loss: 0.1772, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3527/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1770, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3528/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1781, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3529/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1772, Series Loss: 0.0054, Class Loss: 0.2446, Accuracy: 0.2531\n",
      "Epoch [3530/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1772, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2716\n",
      "Epoch [3531/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1771, Series Loss: 0.0053, Class Loss: 0.2446, Accuracy: 0.2469\n",
      "Epoch [3532/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1770, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3533/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1777, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3534/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1781, Series Loss: 0.0053, Class Loss: 0.2446, Accuracy: 0.2469\n",
      "Epoch [3535/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1773, Series Loss: 0.0053, Class Loss: 0.2447, Accuracy: 0.2654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3536/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1769, Series Loss: 0.0053, Class Loss: 0.2447, Accuracy: 0.2469\n",
      "Epoch [3537/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1775, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3538/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1769, Series Loss: 0.0053, Class Loss: 0.2444, Accuracy: 0.2716\n",
      "Epoch [3539/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1769, Series Loss: 0.0054, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3540/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1768, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3541/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1776, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3542/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1772, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3543/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1766, Series Loss: 0.0053, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3544/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1789, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3545/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1775, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3546/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1771, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [3547/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1784, Series Loss: 0.0052, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3548/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1767, Series Loss: 0.0053, Class Loss: 0.2446, Accuracy: 0.2716\n",
      "Epoch [3549/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1772, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3550/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1769, Series Loss: 0.0053, Class Loss: 0.2444, Accuracy: 0.2716\n",
      "Epoch [3551/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1771, Series Loss: 0.0053, Class Loss: 0.2446, Accuracy: 0.2654\n",
      "Epoch [3552/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1777, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3553/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1781, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3554/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1773, Series Loss: 0.0053, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3555/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1776, Series Loss: 0.0053, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3556/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1778, Series Loss: 0.0053, Class Loss: 0.2443, Accuracy: 0.2654\n",
      "Epoch [3557/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1780, Series Loss: 0.0053, Class Loss: 0.2446, Accuracy: 0.2654\n",
      "Epoch [3558/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1778, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3559/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1786, Series Loss: 0.0052, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [3560/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1773, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3561/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1776, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3562/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1769, Series Loss: 0.0053, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3563/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1774, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3564/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1780, Series Loss: 0.0054, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3565/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1772, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [3566/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1770, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3567/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1777, Series Loss: 0.0053, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3568/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1765, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3569/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1772, Series Loss: 0.0052, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3570/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1777, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3571/4000], Discriminator Loss: 0.0928, Generator Loss: 0.1775, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3572/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1775, Series Loss: 0.0052, Class Loss: 0.2446, Accuracy: 0.2654\n",
      "Epoch [3573/4000], Discriminator Loss: 0.0934, Generator Loss: 0.1772, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3574/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1763, Series Loss: 0.0052, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3575/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1772, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3576/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1773, Series Loss: 0.0052, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3577/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1776, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [3578/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1772, Series Loss: 0.0053, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3579/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1776, Series Loss: 0.0053, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3580/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1771, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3581/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1774, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3582/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1776, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3583/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1771, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3584/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1763, Series Loss: 0.0052, Class Loss: 0.2446, Accuracy: 0.2531\n",
      "Epoch [3585/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1768, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3586/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1771, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3587/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1785, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3588/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1767, Series Loss: 0.0052, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3589/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1769, Series Loss: 0.0053, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3590/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1775, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3591/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1771, Series Loss: 0.0052, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3592/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1785, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [3593/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1781, Series Loss: 0.0054, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3594/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1773, Series Loss: 0.0052, Class Loss: 0.2446, Accuracy: 0.2531\n",
      "Epoch [3595/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1775, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3596/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1771, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3597/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1763, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3598/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1774, Series Loss: 0.0052, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3599/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1778, Series Loss: 0.0053, Class Loss: 0.2444, Accuracy: 0.2593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3600/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1767, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3601/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1773, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3602/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1769, Series Loss: 0.0053, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3603/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1768, Series Loss: 0.0052, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [3604/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1767, Series Loss: 0.0052, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3605/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1770, Series Loss: 0.0052, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3606/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1763, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3607/4000], Discriminator Loss: 0.0931, Generator Loss: 0.1772, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3608/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1779, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [3609/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1765, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3610/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1772, Series Loss: 0.0052, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3611/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1772, Series Loss: 0.0052, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3612/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1770, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2716\n",
      "Epoch [3613/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1770, Series Loss: 0.0053, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3614/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1768, Series Loss: 0.0052, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3615/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1773, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3616/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1768, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2716\n",
      "Epoch [3617/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1769, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3618/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1768, Series Loss: 0.0052, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3619/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1766, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3620/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1775, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3621/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1769, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3622/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1768, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3623/4000], Discriminator Loss: 0.0929, Generator Loss: 0.1773, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3624/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1771, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3625/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1772, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3626/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1769, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3627/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1766, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3628/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1774, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3629/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1775, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3630/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1772, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [3631/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1769, Series Loss: 0.0052, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [3632/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1779, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3633/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1773, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3634/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1775, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3635/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1770, Series Loss: 0.0053, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3636/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1770, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3637/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1778, Series Loss: 0.0052, Class Loss: 0.2443, Accuracy: 0.2716\n",
      "Epoch [3638/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1783, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3639/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1772, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3640/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1767, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3641/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1768, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3642/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1771, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [3643/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1765, Series Loss: 0.0053, Class Loss: 0.2446, Accuracy: 0.2531\n",
      "Epoch [3644/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1775, Series Loss: 0.0053, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [3645/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1763, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3646/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1775, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2716\n",
      "Epoch [3647/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1768, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3648/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1776, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3649/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1773, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3650/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1776, Series Loss: 0.0053, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3651/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1779, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3652/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1770, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3653/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1769, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [3654/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1772, Series Loss: 0.0053, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3655/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1769, Series Loss: 0.0052, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3656/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1767, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3657/4000], Discriminator Loss: 0.0934, Generator Loss: 0.1783, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3658/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1767, Series Loss: 0.0053, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [3659/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1765, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3660/4000], Discriminator Loss: 0.0930, Generator Loss: 0.1766, Series Loss: 0.0053, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3661/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1773, Series Loss: 0.0052, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3662/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1774, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3663/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1772, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3664/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1763, Series Loss: 0.0052, Class Loss: 0.2446, Accuracy: 0.2531\n",
      "Epoch [3665/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1771, Series Loss: 0.0052, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3666/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1778, Series Loss: 0.0053, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3667/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1772, Series Loss: 0.0052, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3668/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1772, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [3669/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1783, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3670/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1775, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3671/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1768, Series Loss: 0.0052, Class Loss: 0.2446, Accuracy: 0.2531\n",
      "Epoch [3672/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1773, Series Loss: 0.0053, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3673/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1774, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3674/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1764, Series Loss: 0.0053, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [3675/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1768, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3676/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1767, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3677/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1774, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [3678/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1770, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3679/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1774, Series Loss: 0.0052, Class Loss: 0.2443, Accuracy: 0.2593\n",
      "Epoch [3680/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1763, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3681/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1771, Series Loss: 0.0053, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3682/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1773, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3683/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1772, Series Loss: 0.0052, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3684/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1767, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2716\n",
      "Epoch [3685/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1774, Series Loss: 0.0052, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3686/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1776, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [3687/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1767, Series Loss: 0.0052, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3688/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1765, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3689/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1773, Series Loss: 0.0052, Class Loss: 0.2446, Accuracy: 0.2654\n",
      "Epoch [3690/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1779, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3691/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1764, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3692/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1777, Series Loss: 0.0052, Class Loss: 0.2446, Accuracy: 0.2654\n",
      "Epoch [3693/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1776, Series Loss: 0.0052, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3694/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1766, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3695/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1776, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [3696/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1766, Series Loss: 0.0052, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3697/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1772, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3698/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1767, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3699/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1773, Series Loss: 0.0052, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [3700/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1775, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3701/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1780, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3702/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1778, Series Loss: 0.0052, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3703/4000], Discriminator Loss: 0.0910, Generator Loss: 0.1777, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [3704/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1781, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3705/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1778, Series Loss: 0.0052, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3706/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1784, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3707/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1774, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3708/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1780, Series Loss: 0.0051, Class Loss: 0.2446, Accuracy: 0.2654\n",
      "Epoch [3709/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1772, Series Loss: 0.0051, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3710/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1778, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3711/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1777, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3712/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1774, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3713/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1772, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3714/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1770, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3715/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1767, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3716/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1774, Series Loss: 0.0052, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3717/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1777, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3718/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1767, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3719/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1776, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3720/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1774, Series Loss: 0.0052, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3721/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1771, Series Loss: 0.0052, Class Loss: 0.2446, Accuracy: 0.2531\n",
      "Epoch [3722/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1768, Series Loss: 0.0052, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3723/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1767, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3724/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1771, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3725/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1770, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3726/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1770, Series Loss: 0.0052, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3727/4000], Discriminator Loss: 0.0911, Generator Loss: 0.1772, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3728/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1776, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3729/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1769, Series Loss: 0.0052, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3730/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1766, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3731/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1773, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3732/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1772, Series Loss: 0.0052, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3733/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1775, Series Loss: 0.0053, Class Loss: 0.2446, Accuracy: 0.2654\n",
      "Epoch [3734/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1779, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [3735/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1772, Series Loss: 0.0054, Class Loss: 0.2448, Accuracy: 0.2593\n",
      "Epoch [3736/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1779, Series Loss: 0.0053, Class Loss: 0.2447, Accuracy: 0.2593\n",
      "Epoch [3737/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1780, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2716\n",
      "Epoch [3738/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1775, Series Loss: 0.0052, Class Loss: 0.2446, Accuracy: 0.2654\n",
      "Epoch [3739/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1778, Series Loss: 0.0053, Class Loss: 0.2446, Accuracy: 0.2531\n",
      "Epoch [3740/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1774, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3741/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1786, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2716\n",
      "Epoch [3742/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1779, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3743/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1771, Series Loss: 0.0052, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3744/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1783, Series Loss: 0.0052, Class Loss: 0.2446, Accuracy: 0.2654\n",
      "Epoch [3745/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1777, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3746/4000], Discriminator Loss: 0.0911, Generator Loss: 0.1769, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3747/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1770, Series Loss: 0.0052, Class Loss: 0.2446, Accuracy: 0.2469\n",
      "Epoch [3748/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1769, Series Loss: 0.0052, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3749/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1786, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3750/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1773, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3751/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1773, Series Loss: 0.0052, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3752/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1769, Series Loss: 0.0052, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [3753/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1779, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3754/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1775, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3755/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1785, Series Loss: 0.0052, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3756/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1774, Series Loss: 0.0052, Class Loss: 0.2446, Accuracy: 0.2654\n",
      "Epoch [3757/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1783, Series Loss: 0.0051, Class Loss: 0.2446, Accuracy: 0.2469\n",
      "Epoch [3758/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1771, Series Loss: 0.0052, Class Loss: 0.2446, Accuracy: 0.2654\n",
      "Epoch [3759/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1771, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3760/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1768, Series Loss: 0.0052, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3761/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1773, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3762/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1770, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3763/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1776, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3764/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1776, Series Loss: 0.0052, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3765/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1778, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3766/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1781, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3767/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1773, Series Loss: 0.0052, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3768/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1782, Series Loss: 0.0052, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3769/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1774, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3770/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1773, Series Loss: 0.0052, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3771/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1779, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3772/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1784, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3773/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1775, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3774/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1774, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3775/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1774, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3776/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1777, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3777/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1778, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3778/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1771, Series Loss: 0.0052, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [3779/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1779, Series Loss: 0.0052, Class Loss: 0.2446, Accuracy: 0.2531\n",
      "Epoch [3780/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1770, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3781/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1780, Series Loss: 0.0052, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3782/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1773, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2407\n",
      "Epoch [3783/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1772, Series Loss: 0.0052, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3784/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1776, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3785/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1773, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2716\n",
      "Epoch [3786/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1780, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3787/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1776, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2407\n",
      "Epoch [3788/4000], Discriminator Loss: 0.0910, Generator Loss: 0.1774, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3789/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1774, Series Loss: 0.0051, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [3790/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1773, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3791/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1778, Series Loss: 0.0052, Class Loss: 0.2444, Accuracy: 0.2593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3792/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1780, Series Loss: 0.0051, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3793/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1778, Series Loss: 0.0052, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3794/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1778, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3795/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1778, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3796/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1775, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3797/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1770, Series Loss: 0.0052, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3798/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1775, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3799/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1781, Series Loss: 0.0052, Class Loss: 0.2447, Accuracy: 0.2531\n",
      "Epoch [3800/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1781, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3801/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1777, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3802/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1773, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3803/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1774, Series Loss: 0.0052, Class Loss: 0.2446, Accuracy: 0.2469\n",
      "Epoch [3804/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1776, Series Loss: 0.0052, Class Loss: 0.2446, Accuracy: 0.2654\n",
      "Epoch [3805/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1778, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2407\n",
      "Epoch [3806/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1774, Series Loss: 0.0052, Class Loss: 0.2446, Accuracy: 0.2531\n",
      "Epoch [3807/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1777, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3808/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1770, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [3809/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1774, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3810/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1767, Series Loss: 0.0053, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3811/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1777, Series Loss: 0.0052, Class Loss: 0.2446, Accuracy: 0.2654\n",
      "Epoch [3812/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1777, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3813/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1785, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3814/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1770, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3815/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1783, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3816/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1770, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3817/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1767, Series Loss: 0.0051, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3818/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1778, Series Loss: 0.0052, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3819/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1785, Series Loss: 0.0051, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3820/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1778, Series Loss: 0.0053, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3821/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1777, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [3822/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1773, Series Loss: 0.0051, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3823/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1779, Series Loss: 0.0052, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3824/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1771, Series Loss: 0.0051, Class Loss: 0.2446, Accuracy: 0.2654\n",
      "Epoch [3825/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1782, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3826/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1769, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3827/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1774, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2407\n",
      "Epoch [3828/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1779, Series Loss: 0.0052, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3829/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1770, Series Loss: 0.0052, Class Loss: 0.2446, Accuracy: 0.2531\n",
      "Epoch [3830/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1777, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3831/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1771, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3832/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1784, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3833/4000], Discriminator Loss: 0.0911, Generator Loss: 0.1774, Series Loss: 0.0052, Class Loss: 0.2446, Accuracy: 0.2654\n",
      "Epoch [3834/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1784, Series Loss: 0.0052, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [3835/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1771, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3836/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1771, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3837/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1780, Series Loss: 0.0052, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3838/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1777, Series Loss: 0.0052, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3839/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1772, Series Loss: 0.0051, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3840/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1781, Series Loss: 0.0052, Class Loss: 0.2447, Accuracy: 0.2654\n",
      "Epoch [3841/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1779, Series Loss: 0.0051, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3842/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1775, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3843/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1780, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3844/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1780, Series Loss: 0.0052, Class Loss: 0.2446, Accuracy: 0.2531\n",
      "Epoch [3845/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1779, Series Loss: 0.0051, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3846/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1776, Series Loss: 0.0052, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3847/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1776, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2407\n",
      "Epoch [3848/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1780, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3849/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1782, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3850/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1784, Series Loss: 0.0051, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3851/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1779, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [3852/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1782, Series Loss: 0.0051, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3853/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1769, Series Loss: 0.0052, Class Loss: 0.2447, Accuracy: 0.2654\n",
      "Epoch [3854/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1780, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3855/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1781, Series Loss: 0.0052, Class Loss: 0.2446, Accuracy: 0.2593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3856/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1774, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3857/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1774, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3858/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1777, Series Loss: 0.0051, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3859/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1783, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3860/4000], Discriminator Loss: 0.0924, Generator Loss: 0.1785, Series Loss: 0.0051, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3861/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1773, Series Loss: 0.0051, Class Loss: 0.2444, Accuracy: 0.2716\n",
      "Epoch [3862/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1785, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3863/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1782, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3864/4000], Discriminator Loss: 0.0910, Generator Loss: 0.1781, Series Loss: 0.0052, Class Loss: 0.2447, Accuracy: 0.2531\n",
      "Epoch [3865/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1778, Series Loss: 0.0052, Class Loss: 0.2446, Accuracy: 0.2654\n",
      "Epoch [3866/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1769, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3867/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1773, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3868/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1771, Series Loss: 0.0051, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3869/4000], Discriminator Loss: 0.0923, Generator Loss: 0.1768, Series Loss: 0.0051, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3870/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1778, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3871/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1775, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3872/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1771, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3873/4000], Discriminator Loss: 0.0911, Generator Loss: 0.1778, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3874/4000], Discriminator Loss: 0.0925, Generator Loss: 0.1773, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3875/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1778, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3876/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1775, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3877/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1778, Series Loss: 0.0052, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3878/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1767, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3879/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1776, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3880/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1778, Series Loss: 0.0051, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3881/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1775, Series Loss: 0.0051, Class Loss: 0.2446, Accuracy: 0.2531\n",
      "Epoch [3882/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1787, Series Loss: 0.0051, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3883/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1781, Series Loss: 0.0052, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3884/4000], Discriminator Loss: 0.0908, Generator Loss: 0.1779, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3885/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1772, Series Loss: 0.0051, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3886/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1766, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3887/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1767, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3888/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1774, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3889/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1775, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3890/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1778, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3891/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1778, Series Loss: 0.0051, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3892/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1768, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3893/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1778, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [3894/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1773, Series Loss: 0.0052, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3895/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1779, Series Loss: 0.0051, Class Loss: 0.2444, Accuracy: 0.2716\n",
      "Epoch [3896/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1767, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3897/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1773, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3898/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1776, Series Loss: 0.0051, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3899/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1781, Series Loss: 0.0051, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3900/4000], Discriminator Loss: 0.0910, Generator Loss: 0.1782, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3901/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1766, Series Loss: 0.0051, Class Loss: 0.2446, Accuracy: 0.2531\n",
      "Epoch [3902/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1785, Series Loss: 0.0051, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3903/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1786, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3904/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1782, Series Loss: 0.0052, Class Loss: 0.2446, Accuracy: 0.2531\n",
      "Epoch [3905/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1774, Series Loss: 0.0050, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3906/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1775, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3907/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1778, Series Loss: 0.0051, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3908/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1786, Series Loss: 0.0050, Class Loss: 0.2445, Accuracy: 0.2716\n",
      "Epoch [3909/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1782, Series Loss: 0.0051, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3910/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1777, Series Loss: 0.0050, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [3911/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1775, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3912/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1774, Series Loss: 0.0051, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3913/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1781, Series Loss: 0.0051, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3914/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1783, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3915/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1781, Series Loss: 0.0050, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3916/4000], Discriminator Loss: 0.0927, Generator Loss: 0.1769, Series Loss: 0.0051, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3917/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1773, Series Loss: 0.0050, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3918/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1775, Series Loss: 0.0051, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3919/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1760, Series Loss: 0.0051, Class Loss: 0.2444, Accuracy: 0.2654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3920/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1778, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3921/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1763, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [3922/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1773, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3923/4000], Discriminator Loss: 0.0907, Generator Loss: 0.1784, Series Loss: 0.0051, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3924/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1779, Series Loss: 0.0050, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3925/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1776, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3926/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1777, Series Loss: 0.0051, Class Loss: 0.2446, Accuracy: 0.2654\n",
      "Epoch [3927/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1779, Series Loss: 0.0050, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3928/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1777, Series Loss: 0.0050, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3929/4000], Discriminator Loss: 0.0926, Generator Loss: 0.1769, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3930/4000], Discriminator Loss: 0.0909, Generator Loss: 0.1776, Series Loss: 0.0052, Class Loss: 0.2447, Accuracy: 0.2469\n",
      "Epoch [3931/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1770, Series Loss: 0.0052, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3932/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1775, Series Loss: 0.0050, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3933/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1781, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3934/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1783, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3935/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1781, Series Loss: 0.0050, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3936/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1775, Series Loss: 0.0050, Class Loss: 0.2445, Accuracy: 0.2716\n",
      "Epoch [3937/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1776, Series Loss: 0.0051, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3938/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1774, Series Loss: 0.0051, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3939/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1774, Series Loss: 0.0051, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3940/4000], Discriminator Loss: 0.0910, Generator Loss: 0.1785, Series Loss: 0.0051, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3941/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1784, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3942/4000], Discriminator Loss: 0.0907, Generator Loss: 0.1783, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2716\n",
      "Epoch [3943/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1771, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3944/4000], Discriminator Loss: 0.0922, Generator Loss: 0.1784, Series Loss: 0.0051, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3945/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1778, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3946/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1780, Series Loss: 0.0051, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3947/4000], Discriminator Loss: 0.0907, Generator Loss: 0.1780, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3948/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1784, Series Loss: 0.0051, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3949/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1777, Series Loss: 0.0051, Class Loss: 0.2444, Accuracy: 0.2716\n",
      "Epoch [3950/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1773, Series Loss: 0.0051, Class Loss: 0.2446, Accuracy: 0.2469\n",
      "Epoch [3951/4000], Discriminator Loss: 0.0905, Generator Loss: 0.1775, Series Loss: 0.0051, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3952/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1775, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3953/4000], Discriminator Loss: 0.0907, Generator Loss: 0.1789, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3954/4000], Discriminator Loss: 0.0920, Generator Loss: 0.1780, Series Loss: 0.0051, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3955/4000], Discriminator Loss: 0.0910, Generator Loss: 0.1787, Series Loss: 0.0051, Class Loss: 0.2447, Accuracy: 0.2593\n",
      "Epoch [3956/4000], Discriminator Loss: 0.0911, Generator Loss: 0.1770, Series Loss: 0.0051, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3957/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1780, Series Loss: 0.0050, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3958/4000], Discriminator Loss: 0.0907, Generator Loss: 0.1780, Series Loss: 0.0051, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3959/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1776, Series Loss: 0.0050, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3960/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1772, Series Loss: 0.0051, Class Loss: 0.2444, Accuracy: 0.2716\n",
      "Epoch [3961/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1779, Series Loss: 0.0051, Class Loss: 0.2444, Accuracy: 0.2469\n",
      "Epoch [3962/4000], Discriminator Loss: 0.0911, Generator Loss: 0.1767, Series Loss: 0.0051, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3963/4000], Discriminator Loss: 0.0905, Generator Loss: 0.1772, Series Loss: 0.0051, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3964/4000], Discriminator Loss: 0.0911, Generator Loss: 0.1769, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3965/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1773, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3966/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1761, Series Loss: 0.0051, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3967/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1780, Series Loss: 0.0052, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3968/4000], Discriminator Loss: 0.0908, Generator Loss: 0.1775, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3969/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1772, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [3970/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1778, Series Loss: 0.0052, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [3971/4000], Discriminator Loss: 0.0906, Generator Loss: 0.1788, Series Loss: 0.0052, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3972/4000], Discriminator Loss: 0.0907, Generator Loss: 0.1780, Series Loss: 0.0052, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3973/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1775, Series Loss: 0.0051, Class Loss: 0.2446, Accuracy: 0.2654\n",
      "Epoch [3974/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1787, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3975/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1777, Series Loss: 0.0051, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3976/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1769, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3977/4000], Discriminator Loss: 0.0913, Generator Loss: 0.1784, Series Loss: 0.0051, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3978/4000], Discriminator Loss: 0.0910, Generator Loss: 0.1778, Series Loss: 0.0052, Class Loss: 0.2444, Accuracy: 0.2654\n",
      "Epoch [3979/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1784, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2716\n",
      "Epoch [3980/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1793, Series Loss: 0.0052, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3981/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1782, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3982/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1776, Series Loss: 0.0051, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3983/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1770, Series Loss: 0.0051, Class Loss: 0.2444, Accuracy: 0.2469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3984/4000], Discriminator Loss: 0.0911, Generator Loss: 0.1783, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3985/4000], Discriminator Loss: 0.0918, Generator Loss: 0.1780, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3986/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1784, Series Loss: 0.0051, Class Loss: 0.2446, Accuracy: 0.2593\n",
      "Epoch [3987/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1775, Series Loss: 0.0051, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3988/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1775, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2531\n",
      "Epoch [3989/4000], Discriminator Loss: 0.0912, Generator Loss: 0.1782, Series Loss: 0.0051, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3990/4000], Discriminator Loss: 0.0910, Generator Loss: 0.1775, Series Loss: 0.0050, Class Loss: 0.2446, Accuracy: 0.2531\n",
      "Epoch [3991/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1771, Series Loss: 0.0050, Class Loss: 0.2444, Accuracy: 0.2593\n",
      "Epoch [3992/4000], Discriminator Loss: 0.0919, Generator Loss: 0.1770, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3993/4000], Discriminator Loss: 0.0916, Generator Loss: 0.1782, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3994/4000], Discriminator Loss: 0.0915, Generator Loss: 0.1770, Series Loss: 0.0051, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [3995/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1775, Series Loss: 0.0050, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3996/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1775, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2593\n",
      "Epoch [3997/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1774, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2654\n",
      "Epoch [3998/4000], Discriminator Loss: 0.0917, Generator Loss: 0.1789, Series Loss: 0.0051, Class Loss: 0.2445, Accuracy: 0.2469\n",
      "Epoch [3999/4000], Discriminator Loss: 0.0921, Generator Loss: 0.1772, Series Loss: 0.0050, Class Loss: 0.2444, Accuracy: 0.2531\n",
      "Epoch [4000/4000], Discriminator Loss: 0.0914, Generator Loss: 0.1791, Series Loss: 0.0051, Class Loss: 0.2444, Accuracy: 0.2593\n"
     ]
    }
   ],
   "source": [
    "#训练循环\n",
    "for epoch in range(epoch_num):\n",
    "    #初始化损失值\n",
    "    D_epoch_loss = 0\n",
    "    G_epoch_loss = 0\n",
    "    C_epoch_loss = 0\n",
    "    S_epoch_loss = 0\n",
    "    acc_num = 0\n",
    "    item_num = 0\n",
    "    count = len(dataloader.dataset) #返回批次数\n",
    "    #对数据集进行迭代\n",
    "    for step,(img,label) in enumerate(dataloader):\n",
    "        img =img.to(device) #把数据放到设备上\n",
    "        label = label.to(device)\n",
    "        size = img.shape[0] #img的第一位是size,获取批次的大小\n",
    "        random_seed = torch.randn(size,100,device=device)\n",
    "        item_num += size\n",
    "        \n",
    "        #判别器训练(真实图片的损失和生成图片的损失),损失的构建和优化\n",
    "        d_optimizer.zero_grad()#梯度归零\n",
    "        #判别器对于真实图片产生的损失\n",
    "        real_output = dis(label,img) #判别器输入真实的图片，real_output对真实图片的预测结果\n",
    "        d_real_loss = loss_fn(real_output,\n",
    "                              torch.ones_like(real_output,device=device)\n",
    "                              )\n",
    "        d_real_loss.backward()#计算梯度\n",
    "        \n",
    "        #在生成器上去计算生成器的损失，优化目标是判别器上的参数\n",
    "        generated_img = gen(random_seed,label) #得到生成的图片\n",
    "        \n",
    "        #因为优化目标是判别器，所以对生成器上的优化目标进行截断\n",
    "        generated_img = torch.reshape(generated_img, (generated_img.size(0), generated_img.size(2)))\n",
    "        fake_output = dis(label,generated_img.detach()) #判别器输入生成的图片，fake_output对生成图片的预测;detach会截断梯度，梯度就不会再传递到gen模型中了\n",
    "        #判别器在生成图像上产生的损失\n",
    "        d_fake_loss = loss_fn(fake_output,\n",
    "                              torch.zeros_like(fake_output,device=device)\n",
    "                              )\n",
    "        d_fake_loss.backward()\n",
    "        #判别器损失\n",
    "        disc_loss = d_real_loss + d_fake_loss\n",
    "        #判别器优化\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        \n",
    "        #生成器上损失的构建和优化\n",
    "        g_optimizer.zero_grad() #先将生成器上的梯度置零\n",
    "        fake_output = dis(label,generated_img)\n",
    "        class_output = cls(torch.reshape(generated_img, (generated_img.size(0), 1, generated_img.size(1))))\n",
    "        cls_loss = class_loss(class_output, label)\n",
    "        series_loss = continue_loss(generated_img)\n",
    "        for i in range(size):\n",
    "            if class_output[i][torch.argmax(label[i])] >= 0.5:\n",
    "                acc_num += 1\n",
    "        gen_loss = loss_fn(fake_output,\n",
    "                              torch.ones_like(fake_output,device=device)\n",
    "                          ) + series_loss + cls_loss\n",
    "        gen_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        #累计每一个批次的loss\n",
    "        with torch.no_grad():\n",
    "            D_epoch_loss +=disc_loss\n",
    "            G_epoch_loss +=gen_loss\n",
    "            S_epoch_loss +=series_loss\n",
    "            C_epoch_loss +=cls_loss\n",
    "    #求平均损失\n",
    "    with torch.no_grad():\n",
    "        D_epoch_loss /=count\n",
    "        G_epoch_loss /=count\n",
    "        S_epoch_loss /=(count * continue_loss_weight)\n",
    "        C_epoch_loss /=(count * class_loss_weight)\n",
    "        acc = acc_num / item_num\n",
    "        D_loss.append(D_epoch_loss)\n",
    "        G_loss.append(G_epoch_loss)\n",
    "        S_loss.append(S_epoch_loss)\n",
    "        C_loss.append(C_epoch_loss)\n",
    "        accs.append(acc)\n",
    "        print(f\"Epoch [{epoch + 1}/{epoch_num}], \"\n",
    "              f\"Discriminator Loss: {D_epoch_loss:.4f}, \"\n",
    "              f\"Generator Loss: {G_epoch_loss:.4f}, \"\n",
    "              f\"Series Loss: {S_epoch_loss:.4f}, \"\n",
    "              f\"Class Loss: {C_epoch_loss:.4f}, \"\n",
    "              f\"Accuracy: {acc:.4f}\")\n",
    "        if acc > 0.8:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52ffa546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f3bf2f86a00>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g_curve = [i.cpu() for i in G_loss]\n",
    "plt.plot(g_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38eb3bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f3bf2ea0fa0>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "d_curve = [i.cpu() for i in D_loss]\n",
    "plt.plot(d_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "463f9c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f3bf2e1e0d0>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "s_curve = [i.cpu() for i in S_loss]\n",
    "plt.plot(s_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9efa5b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f3bf2d68f40>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "c_curve = [i.cpu() for i in C_loss]\n",
    "plt.plot(c_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cada92de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f3bf2d1c940>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a_curve = [i for i in accs]\n",
    "plt.plot(a_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dddb84a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = generated_img.cpu().detach()\n",
    "# output = torch.reshape(output, (output.size(1), output.size(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f3dac15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f3bf2912400>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(output.numpy()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d22f52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose_list(my_list):\n",
    "    transposed_list = list(zip(*my_list))\n",
    "    for i in range(len(transposed_list)):\n",
    "        transposed_list[i] = list(transposed_list[i])\n",
    "    return transposed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d119ae78",
   "metadata": {},
   "outputs": [],
   "source": [
    "transposed_list = transpose_list(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53827e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f3bf2848be0>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(series[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee133abc",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 23.69 GiB total capacity; 3.96 GiB already allocated; 14.81 MiB free; 3.97 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m generated_img \u001b[38;5;241m=\u001b[39m gen(random_seed,label) \u001b[38;5;66;03m#得到生成的图片\u001b[39;00m\n\u001b[1;32m     10\u001b[0m generated_img \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mreshape(generated_img, (generated_img\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), generated_img\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m2\u001b[39m)))\n\u001b[0;32m---> 11\u001b[0m class_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerated_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerated_img\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerated_img\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m auth\u001b[38;5;241m.\u001b[39mappend(class_output)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/can_ppg/transformer.py:42\u001b[0m, in \u001b[0;36mTransformerClassifier.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     40\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m conv_block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_blocks:\n\u001b[0;32m---> 42\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mconv_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Reshape to (batch_size, hidden_size, seq_len)\u001b[39;00m\n\u001b[1;32m     44\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer(x)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/can_ppg/transformer.py:23\u001b[0m, in \u001b[0;36mConvolutionBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 23\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py:171\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    164\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/functional.py:2450\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2448\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2450\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2451\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2452\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 23.69 GiB total capacity; 3.96 GiB already allocated; 14.81 MiB free; 3.97 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "auth = []\n",
    "for step,(img,label) in enumerate(dataloader):\n",
    "        img =img.to(device) #把数据放到设备上\n",
    "        label = label.to(device)\n",
    "        size = img.shape[0] #img的第一位是size,获取批次的大小\n",
    "        random_seed = torch.randn(size,100,device=device)\n",
    "        \n",
    "        #在生成器上去计算生成器的损失，优化目标是判别器上的参数\n",
    "        generated_img = gen(random_seed,label) #得到生成的图片\n",
    "        generated_img = torch.reshape(generated_img, (generated_img.size(0), generated_img.size(2)))\n",
    "        class_output = cls(torch.reshape(generated_img, (generated_img.size(0), 1, generated_img.size(1))))\n",
    "        auth.append(class_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b8f055",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f212dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'seed{}'.format(seed) + 'G{}'.format(generator_rate) + 'D{}'.format(discriminator_rate)\n",
    "isExists=os.path.exists(path)\n",
    "if not isExists:\n",
    "    os.mkdir(path)\n",
    "path = path + '/S{}'.format(continue_loss_weight) + 'C{}'.format(class_loss_weight)\n",
    "os.mkdir(path)\n",
    "torch.save(gen, path + '/generator.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e103dde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(dis, path + \"/discriminator.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc12f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "code = []\n",
    "for _, (_, _) in enumerate(dataloader):\n",
    "    random_seed = torch.randn(size,100,device=device)\n",
    "    code.append(random_seed.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f0388c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf42e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(path + '/code.npy', code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d2c6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(accs, path + '/accs.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d70990",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
